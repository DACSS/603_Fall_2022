---
title: "HW3"
author: "Steph Roberts"
desription: "Homework 3"
date: "10/31/2022"
format:
  html:
    toc: true
    code-fold: true
    code-copy: true
    code-tools: true
categories:
  - hw3
  - Steph Roberts
---

```{r}
#| label: setup
#| warning: false

library(tidyverse)
library(knitr)
library(alr4)
library(smss)
library(fastDummies)

knitr::opts_chunk$set(echo = TRUE)
```

## Question 1

United Nations (Data file: UN11in alr4) The data in the file UN11 contains several variables, including ppgdp, the gross national product per person in U.S. dollars, and fertility, the birth rate per 1000 females, both from the year 2009. The data are for 199 localities, mostly UN member countries, but also other areas such as Hong Kong that are not independent countries. The data were collected from the United Nations (2011). We will study the dependence of fertility on ppgdp.

1.1.1. Identify the predictor and the response. 

1.1.2 Draw the scatterplot of fertility on the vertical axis versus ppgdp on the horizontal axis and summarize the information in this graph. Does a straight-line mean function seem to be plausible for a summary of this graph?

1.1.3 Draw the scatterplot of log(fertility) versus log(ppgdp) using natural logarithms. Does the simple linear regression model seem plausible for a summary of this graph? If you use a different base of logarithms, the shape of the graph won’t change, but the values on the axes will change.

```{r}
attach(UN11)
un <- UN11
head(un)
```
```{r}
#Check correlation
cor.test(UN11$ppgdp,UN11$fertility)
```
There is a weak, negative correlation between fertility and ppGDP. 

```{r}
#Check matrix plot
pairs(UN11)
```
The relationship of per person GDP to fertility looks somewhat curvy, which indicates diminishing returns on fertility from increasing GDP.

```{r}
#Linear regression
summary(lm(fertility ~ ppgdp, data = UN11))
```
The R squared in our linear model is very low 0.19, suggesting a non-linear relationship.

Let's have a closer look of the dependence of fertility on ppGDP
```{r}
#Plot variables
plot( x= UN11$ppgdp, y= UN11$fertility)
```
This graph is a nice visual representation of our negative correlation, because it shows as ppGPD rises, there are fewer and fewer births per 1000 females

But the relationship does not appear linear. 
```{r}
#Plot variables with linear regrssion
ggplot(data = UN11, aes(x = ppgdp, y = fertility)) +
  geom_point() +
  geom_smooth(method = 'lm')
```
As we could have predicted, a linear explanation does not exist here. There are very large residuals and the predicted value of fertility after about 60,000 ppgdp enter negative values. Since we can't have negative births and we do have ppgdp values over 60,000, we should explore a better model to explain this relationship. 

```{r}
#Plot regression of variable logarithms
ggplot(UN11, aes(x = log(ppgdp), y = log(fertility))) +
    geom_point(color=2) + 
    geom_smooth(method = "lm") +
    labs(x="ppgdp-Gross National Product Per Person in U.S. dollars", y="fertility-birth rate per 1000 women")
```

A linear regression for the logarithms of each variable appears to be much more appropriate. 

## Question 2

Annual income, in dollars, is an explanatory variable in a regression analysis. For a British version of the report on the analysis, all responses are converted to British pounds sterling (1 pound equals about 1.33 dollars, as of 2016).

(a) How, if at all, does the slope of the prediction equation change?

If all explanatory values are converted (multiplied) to another number - British pounds - the slope of the prediction equation will change. Since the rate is x 1.33, multiplying by a positive number should make the slope steeper.

(b) How, if at all, does the correlation change?

The correlation would not change if only the units of measurement are different. The values in relation to the predictor variable would remain the same. 

## Question 3

Water runoff in the Sierras (Data file: water in alr4) Can Southern California’s water supply in future years be predicted from past data? One factor affecting water availability is stream runoff. If runoff could be predicted, engineers, planners, and policy makers could do their jobs more efficiently. The data file contains 43 years’ worth of precipitation measurements taken at six sites in the Sierra Nevada mountains (labeled APMAM, APSAB, APSLAKE, OPBPC, OPRC, and OPSLAKE) and stream runoff volume at a site near Bishop, California, labeled BSAAM. Draw the scatterplot matrix for these data and summarize the information available from these plots. 

```{r}
#Load data
data("water")
head(water)
```

```{r}
#Check matrix plot
pairs(water, col = 4,main = "Water Runoff in Sierras")
```

```{r}
#Multiple regression
wat <- (lm(BSAAM ~ APMAM + APSAB + APSLAKE + OPBPC + OPRC + OPSLAKE, data = water))
summary(wat)
```
Analysis: The P-values are not very small across the board. Only OPRC and OPSLAKE have p-values of significance, under 0.05. This shows us that individually, the location precipitation do would not make good explanatory variables. 

However, the model as a whole has a p-value of < 2.2e-16, indicating it is statistically significant. Also, while the residuals have a wide range (-12690 to 18542), the 1Q (-4936) and 3Q (4173) are fairly close in absolute value. Therefore, the range may be due to some outliars. The adjusted R-squared (0.9123) tells us that 91% of the variation of runoff can be explained by combined location precipitation. 

With a strong p-value, decent residuals, and a high adjusted R-squared tells us this model could appropriately be used to predict runoff volume near Bishop, California. 

## Question 4

Professor ratings (Data file: Rateprof in alr4) In the website and online forum RateMyProfessors.com, students rate and comment on their instructors. Launched in 1999, the site includes millions of ratings on thousands of instructors. The data file includes the summaries of the ratings of 364 instructors at a large campus in the Midwest (Bleske-Rechek and Fritsch, 2011). Each instructor included in the data had at least 10 ratings over a several year period. Students provided ratings of 1–5 on quality, helpfulness, clarity, easiness of instructor’s courses, and raterInterest in the subject matter covered in the instructor’s courses. The data file provides the averages of these five ratings. Create a scatterplot matrix of these five variables. Provide a brief description of the relationships between the five ratings.

```{r}
#Load data
data("Rateprof")

#Select 5 variables in question
rateprof <- Rateprof %>%
  select("quality","helpfulness","clarity","easiness","raterInterest")

#Create table of ratings
kable(head(rateprof), format = "markdown", digits = 10, col.names = c('Quality','Helpfulness','Clarity', 'Easiness', 'Rater Interest'), caption = "**Professor Ratings**")
```

```{r}
pairs(rateprof, col = 2,main = "Professor Ratings")
```
Quality, helpfulness, and clarity all appear to have strong positive linear correlations with one another. There is a moderate positive linear correlation between easiness and clarity, helpfulness, and quality. There is also a moderate positive correlation between rater interest and quality, helpfulness, and clarity. There is a weak positive linear correlation between easiness and rater interest. 

```{r}
#Check the calculated correlations
cor(rateprof, use = "complete.obs",method = c("pearson", "kendall", "spearman"))
```
Our correlation calculations reinforce our interpretation of the relationships based on the scatter plots. 

## Question 5

For the student.survey data file in the smss package, conduct regression analyses relating (by convention, y denotes the outcome variable, x denotes the explanatory variable)
(i) y = political ideology and x = religiosity, 
(ii) y = high school GPA and x = hours of TV watching. 

(a)Graphically portray how  the explanatory variable relates to the outcome variable in each of the two cases
(b) Summarize and interpret results of inferential analyses.

```{r}
data("student.survey")
dim(student.survey)
head(student.survey)
```

```{r}
#Select variable in question
ssurvey <- student.survey %>%
  select(c(pi, re, hi, tv))%>%
  rename(political_id = pi, religiosity = re, hs_gpa = hi, tv_hours = tv)

#Check for missing data
is.na(ssurvey) %>% head()
```
Fortunately, we have no missing data.

```{r}
#Summarize our df to understand responses and value ranges
summary(ssurvey)
```
```{r}
#Explore variable relationships
pairs(ssurvey)
```
Let's take a close look at *(i) y = political ideology and x = religiosity.*

```{r}
#Visualize religiosity as an explanatory variable for political ideology
ggplot(ssurvey, aes(x = religiosity, y= political_id,fill= political_id)) + 
  geom_bar(stat = "identity")+
   labs(x="Religiosity", y="Political Ideology")+
    theme(axis.text.y=element_blank(),
        axis.ticks.y=element_blank())
```

This bar graph shows us what we might expect - that those who attend church every week identify with a very conservative political affiliation. On the contrary, people who never or occasionally go to church trend more liberal. 

```{r}
#Transform categorical data to numeric
ssurvey <- ssurvey %>%
    mutate(pi_n = dplyr::recode(political_id, 
                         "very liberal" = 1,
                         "liberal" = 2, 
                         "slightly liberal" = 3, 
                         "moderate" = 4,
                         "slightly conservative" = 5,
                         "conservative" = 6, 
                         "very conservative" = 7
                         )) %>%
    mutate(re_n = dplyr::recode(religiosity, 
                         "never" = 0,
                         "occasionally" = 1,
                         "most weeks" = 2,
                         "every week" = 3
                         )) 
glimpse(ssurvey)

#Visualize linearity
ggplot(data = ssurvey, aes(x = re_n, y = pi_n)) +
  geom_point() +
  geom_smooth(method = 'lm')+
  labs(x="Religiosity", y="Political Ideology")
```
After recoding our variable values, political ideology now spans from 1 to 7 with 1 being very liberal and 7 being very conservative. Religiosity spans 0 to 3 with 0 being never attending church and 3 representing attends every week.

```{r}
#Linear regression summary
(summary(rel_pol <- lm(formula = pi_n ~ re_n, data = ssurvey)))
```
*Interpretation:* The residuals of this regression are fairly symmetrical, but they are not very small in relation to our data values. The coefficients tells us that for every 1 unit of increase in political affiliation (ie. 1 category closer to very conservative), there is an estimated 0.9704 increase in religiosity (ie. almost one category closer to every week). The t-values are moderately large, which indicates a relationship exists. With very small p-values, it is unlikely the relationship is due to chance. Therefore, we could reject the null and conclude there is a relationship between religiosity and political affiliation. 

However, as the ggplot graph, the high residuals, and the R2 (0.3359) tell us, this model is not a perfect fit for this data. It is likely due to the categorical nature of the explanatory variable that partitions our data into column-like sections in a graph. That is hard to run a straight line through. This model shows about 33% of the variance can be explained by the predictor. There may be other variable that need to be controlled for or added to the analysis to complete a well-fitting model. 

Now, let's take a close look at *(ii) y = high school GPA and x = hours of TV watching.*

```{r}
#Visualize hours per week watching tv as an explanatory variable for high school GPA
ggplot(data = ssurvey, aes(x = tv_hours, y = hs_gpa)) +
  geom_point() +
  geom_smooth(method = 'lm')+
  labs(x="TV Hours /Week", y="High School GPA")
```

```{r}
summary(lm(hs_gpa ~ tv_hours, data = ssurvey))
```
*Interpretation:* This model shows fairly symmetrical residuals, but some are very large. This can be seen on our plot where lower hours of tv has a wide range of associated GPS values. The p-value of 0.0388 allows us to reject the null hypothesis and conclude there is a relationship between tv hours and gpa. However, with a VERY small R-squared, this model may not be best at predicting gpa SOLELY from hours of tv watched per week. The combination of all our calculations lead me to conclude that higher number of hours watched per week may be related to lower GPA. However, the opposite may not be true - fewer hours of tv is not necessarily associated with higher a higher GPA

```{r}
cor.test(ssurvey$tv_hours, ssurvey$hs_gpa)
```
There is a weak negative correlation between hours of tv watched per week and high school GPA. 
