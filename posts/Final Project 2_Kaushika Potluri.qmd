---
title: "Final Project Submission 2"
author: "Kaushika Potluri"
desription: "Final Project Submission 2"
date: "11/11/2022"
format:
  html:
    toc: true
    code-fold: true
    code-copy: true
    code-tools: true
editor: 
  markdown: 
    wrap: sentence
---

## Loading in packages:

```{r}
library(readr)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(readxl)
library(DataExplorer)
library(summarytools)
library(lmtest)
library(car)
```

## Reading in Data:

The data was acquired from Professor Sander's article that he used.

```{r}
Womendata <-  read.csv("_data/data.csv")

```

## Summary of the data

```{r}
summary(Womendata)
```
#Exploratory Data Analysis (EDA)

```{r}
str(Womendata)
```


```{r}
print(dfSummary(Womendata, varnumbers = FALSE, plain.ascii = FALSE, graph.magnif = 0.30, style = "grid", valid.col = FALSE), 
      method = 'render', table.classes = 'table-condensed')
```


```{r}
glimpse(Womendata)
```

We can see that we have 28 variables and 4361 observations in this dataset.
The dependent variable of interest - number of living children Then I will perform data manipulation to tidy the data.
The variables of interest are age, yearborn, month born, urban education and many more variables that seem intriguing.
Variables like radio, bicycle, electric can be ignored in this.

```{r}
head(Womendata)
```

```{r}
Womendata <- data.frame(Womendata)

Womendata$mnthborn <- as.factor(Womendata$mnthborn)
Womendata$age <- as.factor(Womendata$age)
Womendata$electric <- as.factor(Womendata$electric)
Womendata$radio <- as.factor(Womendata$radio)
Womendata$tv <- as.factor(Womendata$tv)
Womendata$bicycle <- as.factor(Womendata$bicycle)
Womendata$educ <- as.factor(Womendata$educ)
Womendata$children <- as.factor(Womendata$children)
Womendata$knowmeth <- as.factor(Womendata$knowmeth)
```

The dependent variable of interest â€“ number of living children (children) or number of children every born (ceb) is a count variable.

```{r}
table(is.na(Womendata))
```

Here we can see that we have some missing values in our dataset.
Plotting the missing values we can check if they are important or not using 'plot_missing' by loading library DataExplorer.

```{r}
plot_missing(data = Womendata, geom_label_args = list(size = 1.4), theme_config=list(axis.text=element_text(size = 6 )))
```
We can see how these missing values do not cause much of an issue since these missing observations(parameters) convey less important information than the other parameters. Hence we can ignore these values.

##Removing missing values and parameters that are not required
 The aim is to estimate the effect of education on women's fertility flexibly, while controlling for possible linear and non-linear effects of observable and unobservable confounding factors, and to analyse how the effect of education changes when considering different expectiles of the response variable distribution. We also include two variables regarding the knowledge about and the use of birth control methods as well as marital status. All three obviously influence the number of children. Further, we include variables indicating wealth, e.g. about the availability of electricity, a television set or a bicycle.
```{r}
Womendata <- subset(Womendata, select = -c(agefm,yearfm,monthfm,heduc))
```

```{r}
Womendatacleaned <-Womendata[complete.cases(Womendata), ]
plot_missing(data = Womendatacleaned, geom_label_args = list(size = 1.4), theme_config=list(axis.text=element_text(size = 6 )))

```
```{r}
ggplot(Womendatacleaned,aes(x=factor(children),fill=factor(tv)))+
  
geom_bar()+theme(axis.text.x = element_text(face="bold", size=15),axis.text.y = element_text(face="bold", size=15))+
  
labs(
    title = "Number of Children based if they own a Tv or not",
    x = "Number of children",
    y = "Count",size=15) +
   
scale_fill_manual(
    name = "Access to Telivision or not",
    breaks = c("0", "1"),
    labels = c("No Telivision", "Owns/ has access to a telivision"),
    values = c("0" = "orange", "1"="yellow")
  )
```
We can see that most age groups do not own a TV here.

```{r}
ggplot(Womendatacleaned,aes(x=factor(children),fill=factor(evermarr)))+
  
geom_bar()+theme(axis.text.x = element_text(face="bold", size=15),axis.text.y = element_text(face="bold", size=15))+
  
labs(
    title = "Number of Children based on Marriage status",
    x = "Number of children",
    y = "Count",size=15) +
   
scale_fill_manual(
    name = "Married or not",
    breaks = c("0", "1"),
    labels = c("Not Married", "Married"),
    values = c("0" = "blue", "1"="red")
  )
```

Most people have 1 child in majority. Majority of those mothers are not married. This could say something about our data.

```{r}
ggplot(Womendatacleaned,aes(x=factor(children),fill=factor(tv)))+
  
geom_bar()+theme(axis.text.x = element_text(face="bold", size=15),axis.text.y = element_text(face="bold", size=15))+
  
labs(
    title = "Number of Children based on if the household has TV",
    x = "Number of children",
    y = "Count",size=15) +
   
scale_fill_manual(
    name = "Owns a Telivision or not",
    breaks = c("0", "1"),
    labels = c("No Television", "Owns a Telivision"),
    values = c("0" = "purple", "1"="pink")
  )
```

```{r}
plot_bar(data = Womendata)
```
```{r}
Womendata$educ <-as.integer(as.character(Womendata$educ))
Womendata$age <- as.integer(as.character(Womendata$age))

Womendata$mnthborn <- as.integer(as.character(Womendata$mnthborn))
Womendata$electric <- as.integer(as.character(Womendata$electric))

Womendata$radio <- as.integer(as.character(Womendata$radio))
Womendata$tv <- as.integer(as.character(Womendata$tv))

Womendata$agefbrth <- as.integer(as.character(Womendata$agefbrth))
Womendata$bicycle <- as.integer(as.character(Womendata$bicycle))
Womendata$children <- as.integer(as.character(Womendata$children))

Womendata$knowmeth <- as.integer(as.character(Womendata$knowmeth))

plot_histogram(data = Womendata)
```
## Corelation
```{r}


library(corrplot)
library(RColorBrewer)

M <-cor(Womendata %>% 
          select(age,yearborn, educ, agefbrth, ceb, children, usemeth, knowmeth))

corrplot(M, type="upper", order = "original",col=brewer.pal(n=8, name="RdYlBu"))


```

```{r}
library(PerformanceAnalytics)

chart.Correlation(Womendata %>% 
              select(age,yearborn, educ, ceb, agefbrth, children), histogram=TRUE, pch=19)
```
##Outlier Detection, box plot

```{r}


par(mfrow=c(3,2))
boxplot(Womendata$mnthborn, horizontal = T, main="mnthborn")
boxplot(Womendata$yearborn, horizontal = T, main="yearborn")

boxplot(Womendata$age, horizontal = T, main="age")
boxplot(Womendata$educ, horizontal = T, main="educ")

boxplot(Womendata$children, horizontal = T, main="children")
boxplot(Womendata$idlnchld, horizontal = T, main="idlnchld")


```

```{r}
Womendata$educ <- as.factor(Womendata$educ)
Womendata$age <- as.factor(Womendata$age)

Womendata$mnthborn <- as.factor(Womendata$mnthborn)
Womendata$electric <- as.factor(Womendata$electric)

Womendata$radio <- as.factor(Womendata$radio)
Womendata$tv <- as.factor(Womendata$tv)

Womendata$bicycle <- as.factor(Womendata$bicycle)
Womendata$children <- as.factor(Womendata$children)

Womendata$knowmeth <- as.factor(Womendata$knowmeth)
Womendata$catholic <- as.factor(Womendata$catholic)

Womendata$frsthalf <- as.factor(Womendata$frsthalf)
Womendata$educ0 <- as.factor(Womendata$educ0)

Womendata$evermarr <- as.factor(Womendata$evermarr)
Womendata$protest <- as.factor(Womendata$protest)
Womendata$spirit <- as.factor(Womendata$spirit)

Womendata$urban <- as.factor(Womendata$urban)
Womendata$spirit <- as.factor(Womendata$spirit)
```

```{r}
summary(Womendata)
```

```{r}
lapply(Womendata[c("mnthborn", "age", "electric", "radio", "tv", "agefbrth","children","ceb", "knowmeth","usemeth","urban","bicycle","educ","idlnchld","urb_educ", "protest", "yearborn", "agesq","spirit","catholic","educ0","evermarr","frsthalf")], unique)
```

```{r}
library(MASS)
model1<- lm(log(ceb)~., 
                data = na.omit(Womendata))

#Using stepAIC search method for feature selection to simplify model without impacting much on the performance.
step.model <- stepAIC(model1,direction = "both",trace = FALSE)

summary(step.model)
```

```{r}
par(mfrow=c(2,2)) 

plot(model1)
```
R^2 = 0.95 and adjusted R^2 = 0.95, F test value = 1170 p-value = 0.001. Under normal distribution assumption.
According to Central limit teorem , every distribution approximated by a normal distribution. A normal distribution is approached very quickly as n increases, note that n is the sample size for each mean and not the number of samples
If the null hypothesis is true, the above-mentioned F test statistic can be condensed (dramatically). The test statistic will be this sample variance ratio. If the null hypothesis is incorrect, we will disprove both our presumption that they were equal and the null hypothesis that the ratio was equal to 1.

##Checking for Heteroskedasticity
Breusch Pagan Test for Heteroskedasticity

    Ho: the variance is constant
    H1: the variance is not constant
    
```{r}
bptest(ceb ~ ., data = Womendatacleaned)
```
Ho hypothesis is rejected since the variance is not constant. 

In multiple regression two or more predictor variables might be correlated with each other and situation is referred as collinearity. Multicollinearity is where collinearity exists between three or more variables even if no pair of variables has a particularly high correlation. This means that there is redundancy between predictor variables.Multicollinearity can assessed by computing a score called the variance inflation factor (or VIF), which measures how much the variance of a regression coefficient is inflated due to multicollinearity in the model. The smallest possible value of VIF is one (absence of multicollinearity).  A VIF value that exceeds 5 or 10 indicates a problematic amount of collinearity.
```{r}
vif(step.model)
```

As a thumb rule, since we follow that a VIF value that exceeds 5 or 10 can be a problem. This leads to a simpler model without compromising the model accuracy, which is good. So now the new model will be without yearborn.

## Without Multicollinearity
```{r}
library(MASS)
model2<- lm(log(ceb)~ mnthborn + age +
                            electric +
                            children + knowmeth +
                            usemeth  +
                            urban + radio +
                            tv + bicycle +
                            I(as.factor(educ)) +
                            idlnchld+urb_educ +
                            protest, 
                            data = na.omit(Womendatacleaned))

step.model2 <- stepAIC(model2, 
                        direction = "both", 
                        trace = FALSE)

vif(step.model2) # Variance Inflation Factor (or VIF)
```
Now the new VIF values are all less than 5. This is good for our model.
There is no Multicollinearity.

Next I will check with using Decision Tree, RandomForest,Poisson regression.
We expect from our study, if the level of education increases, the number of children is decreasing. Also, it should be same parameters negative corelation for example between education and number of children.

Will try different models by Part 3 and keep updating Part 2.