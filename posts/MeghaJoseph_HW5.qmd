---
title: "Home Work 5"
author: "Megha Joseph"
desription: "Homework 5"
date: "12/11/2022"
format:
  html:
    toc: true
    code-fold: true
    code-copy: true
    code-tools: true
category: HW5
---

```{r}
# Setup
library(tidyverse)
library(plyr)
library(alr4)
library(smss)
```

## Question 1

### Part A

The first variable to be deleted would be beds because it has the largest p-value.

### Part B

The first variable added in forward selection would be size because it has the smallest p-value.

### Part C

Beds has such a large p-value despite its correlation with price because it also has strong correlations with other variables. This may cause multicollinearity.

### Part D

```{r}
#test regression models
library(smss)
data(house.selling.price.2)
full <- lm(P ~ ., data = house.selling.price.2)
forw1 <- lm(P ~ S, data = house.selling.price.2)
forw2 <- lm(P ~ S + New, data = house.selling.price.2)
forw3 <- lm(P ~ S + New + Ba, data = house.selling.price.2)
```
### a.
I used the forward selection method to fit models, adding variables, one at a time, based on t-values (highest to lowest).

$R^{2}$ is highest for the full model with all variables.

### b.
Adjusted $R^{2}$ is highest for the model of *Price* as a function of *Size*, *Baths*, and *New*.

### c.
```{r}
#calculate PRESS statistics
PRESS <- function(linear.model) {
  pr <- residuals(linear.model)/(1-lm.influence(linear.model)$hat) 
  PRESS <- sum(pr^2) 
  return(PRESS)
}
PRESS(full)
PRESS(forw1)
PRESS(forw2)
PRESS(forw3)
```
The model with *Price* as a function of *Size*, *Baths*, and *New* has the lowest PRESS calculation.

### d.
```{r}
#calculate AIC values
AIC(full, k=2)
AIC(forw1, k=2)
AIC(forw2, k=2)
AIC(forw3, k=2)
```
The model with *Price* as a function of *Size*, *Baths*, and *New* has the lowest AIC calculation.

### e.
```{r}
#calculate BIC values
BIC(full)
BIC(forw1)
BIC(forw2)
BIC(forw3)
```
The model with *Price* as a function of *Size*, *Baths*, and *New* has the lowest BIC calculation.

### Part E

As stated before, Model 1 has better results in four out of the five criteria (Adjusted R-Squared, PRESS, AIC, and BIC). Thus, the model I would prefer overall is Model 1, which omitted the Bed variable. The Bed variable also had an extremely high p-value compared to the other variables, so it would make sense to construct a model without it.



## Question 2

### Part A

```{r}
model <- lm(Volume ~ Girth + Height, data = trees)
summary(model)
```

### Part B

```{r}
plot(model)
```

There are some regression assumptions that are violated because of the data present in the plots. In the Residuals vs. Fitted plot, the line is not linear, indicating that the variances of the error terms are not equal and there may not be a linear relationship. The Scale-Location plot also shows a non-linear line, indicating that the assumption of constant variance is violated. The other two plots, Normal Q-Q and Residuals vs. Leverage, are normal.

## Question 3

### Part A

```{r}
model <- lm(Buchanan ~ Bush, data = florida)
plot(model)
```

Palm Beach is an outlier based on the diagnostic plots for the model because, while all the other data points are fairly close together, the Palm Beach data point is extremely far in each plot. Additionally, in the Residuals vs. Leverage plot, the Palm Beach point is outside of Cook's distance, meaning it is an outlier with extreme influence on the data.

### Part B

```{r}
model <- lm(log(Buchanan) ~ log(Bush), data = florida)
plot(model)
```

The findings do change somewhat because in the new model using logs, the Palm Beach data point is now inside Cook's distance, meaning it has less influence over the data and is less of an outlier. The distance between Palm Beach and the other data points has been reduced, but it still seems to remain somewhat of an outlier but much less than in the previous model.






