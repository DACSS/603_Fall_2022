{
  "hash": "b80b90799c0b6a599dd58aa7468d5b8e",
  "result": {
    "markdown": "---\ntitle: \"Homework 2\"\nauthor: \"Caleb Hill\"\ndesription: \"The second homework on descriptive statistics and probability\"\ndate: \"10/14/2022\"\nformat:\n  html: \n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - hw2\n  - confidence interval\n  - probability\n---\n\n\n# Question 1\n\nFirst, let's load the relevant libraries.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.4 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\nlibrary(dplyr)\ndf <- read_excel(\"_data/LungCapData.xls\")\n```\n:::\n\n\nFor question 1, we need to construct the 90% confident interval to estimate the actual mean wait time for eahc of the two procedures.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns_mean_b <- 19\ns_sd_b <- 10\ns_size_b <- 539\nstandard_error_b <- s_sd_b / sqrt(s_size_b)\nconfidence_level <- 0.90\ntail_area <- (1-confidence_level)/2\nt_score_b <- qt(p = 1 - tail_area, df = s_size_b - 1)\nCI_b <- c(s_mean_b - t_score_b * standard_error_b,\n        s_mean_b + t_score_b * standard_error_b)\nprint(CI_b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 18.29029 19.70971\n```\n:::\n:::\n\n\nThis is the CI for bypass. The following code chunk is for angiography.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns_mean_a <- 18\ns_sd_a <- 9\ns_size_a <- 847\nstandard_error_a <- s_sd_a / sqrt(s_size_a)\nconfidence_level <- 0.90\ntail_area <- (1-confidence_level)/2\nt_score_a <- qt(p = 1 - tail_area, df = s_size_a - 1)\nCI_a <- c(s_mean_a - t_score_a * standard_error_a,\n        s_mean_a + t_score_a * standard_error_a)\nprint(CI_a)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 17.49078 18.50922\n```\n:::\n:::\n\n\nIs the confidence interval narrower for angiograpy or bypass survey? Answer = angiography.\n\n# Question 2\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns_mean_NCPP <- sum(567/1031)\ns_sd_NCPP <- sd(567)\ns_size_NCPP <- 1039\nstandard_error_NCPP <- s_sd_NCPP / sqrt(s_size_NCPP)\nconfidence_level <- 0.95\ntail_area <- (1-confidence_level)/2\nt_score_NCPP <- qt(p = 1 - tail_area, df = s_size_NCPP - 1)\nCI_NCPP <- c(s_mean_NCPP - t_score_NCPP * standard_error_NCPP,\n        s_mean_NCPP + t_score_NCPP * standard_error_NCPP)\nprint(CI_NCPP)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] NA NA\n```\n:::\n:::\n\n\n[I think it's pulling NAs because I'm not calculating the SD correctly. Will need to come back to this.]\n\n# Question 3\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns_mean_3 <- 50\ns_sd_3 <- 9\ns_size_3 <- 15\nstandard_error_3 <- s_sd_3 / sqrt(s_size_3)\nconfidence_level <- 0.95\ntail_area <- (1-confidence_level)/2\nt_score_3 <- qt(p = 1 - tail_area, df = s_size_3 - 1)\nCI_3 <- c(s_mean_3 - t_score_3 * standard_error_3,\n        s_mean_3 + t_score_3 * standard_error_3)\nprint(CI_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 45.01597 54.98403\n```\n:::\n:::\n\n\nAfter messing with random mean, sd, and size, the minimum sample size needs to be 15, if the CI will have to have a length of $10 or less. 14 or less provides a variances of $10+, so outside where the estimate could be useful.\n\n# Question 4\n## A\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns_mean_4a <- 410\ns_sd_4a <- 90\ns_size_4a <- 9\nstandard_error_4a <- s_sd_4a / sqrt(s_size_4a)\nconfidence_level <- 0.95\ntail_area <- (1-confidence_level)/2\nt_score_4a <- qt(p = 1 - tail_area, df = s_size_4a - 1)\nCI_4a <- c(s_mean_4a - t_score_4a * standard_error_4a,\n        s_mean_4a + t_score_4a * standard_error_4a)\nprint(CI_4a)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 340.8199 479.1801\n```\n:::\n:::\n\n\nBased upon the data provided, we can be within a 95% CI that mean income for female employees is less than $500 per week. If Ha : μ < 500, then we can accept the hypothesis, based upon the CI. However, for section B, we'll report the P-value via the t-score.\n\n## B\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt_score_4a <- qt(p = 1 - tail_area, df = s_size_4a - 1)\np_value=pt(q = t_score_4a, df = 8, lower.tail = FALSE)\nprint(p_value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.025\n```\n:::\n:::\n\n\nWith a P-value of 0.025, we can accept the Ha : μ < 500. However, let's change the lower.tail value to TRUE to see about Ha : μ > 500.\n\n## C\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt_score_4a <- qt(p = 1 - tail_area, df = s_size_4a - 1)\np_value = pt(q = t_score_4a, df = 8, lower.tail = TRUE)\nprint(p_value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.975\n```\n:::\n:::\n\n\nJust as I thought. We have to reject the second hypothesis, that Ha : μ > 500, as the P-value is 0.975, outside of statistical significance minimum of 0.05.\n\n# Question 5\n## A\n\nFor Jones:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns_mean_5a <- 519.5\nstandard_error_5a <- 10\ns_size_5a <- 1000\ns_sd_5a <- standard_error_5a * sqrt(s_size_5a)\nconfidence_level <- 0.95\ntail_area <- (1-confidence_level)/2\nt_score_5a <- qt(p = 1 - tail_area, df = s_size_5a - 1)\nprint(t_score_5a)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.962341\n```\n:::\n\n```{.r .cell-code}\nt_score_5a <- qt(p = 1 - tail_area, df = s_size_5a - 1)\np_value = pt(q = t_score_5a, df = 8, lower.tail = FALSE)\nprint(p_value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.04267427\n```\n:::\n\n```{.r .cell-code}\nCI_5a <- c(s_mean_5a - t_score_5a * standard_error_5a,\n        s_mean_5a + t_score_5a * standard_error_5a)\nprint(CI_5a)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 499.8766 539.1234\n```\n:::\n:::\n\nFor Smith:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns_mean_5a <- 519.7\nstandard_error_5a <- 10\ns_size_5a <- 1000\ns_sd_5a <- standard_error_5a * sqrt(s_size_5a)\nconfidence_level <- 0.95\ntail_area <- (1-confidence_level)/2\nt_score_5a <- qt(p = 1 - tail_area, df = s_size_5a - 1)\nprint(t_score_5a)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.962341\n```\n:::\n\n```{.r .cell-code}\nt_score_5a <- qt(p = 1 - tail_area, df = s_size_5a - 1)\np_value = pt(q = t_score_5a, df = 8, lower.tail = FALSE)\nprint(p_value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.04267427\n```\n:::\n\n```{.r .cell-code}\nCI_5a <- c(s_mean_5a - t_score_5a * standard_error_5a,\n        s_mean_5a + t_score_5a * standard_error_5a)\nprint(CI_5a)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 500.0766 539.3234\n```\n:::\n:::\n\n\n## B\n\nCode for Section B are the P-values shown for each code chunk. Are they statistically significant? At 0.043 for both, yes as they are below 0.05.\n\n## C\n\nThe P-value is the likelihood of finding the particular set of observations if the null hypothesis were true. As the P-value is traditionally use in frequentist statistics, we are only able to ascribe probability to this specific set of observations -- which are themselves a set amount of observations.\n\nTherefore, it can sometimes be misleading to report a P-value as 0.05. CI levels allow a range within the set of observations. We can see this problem best with the above results via Jones and Smith. They do not get the same sample mean, even with similar observations. \n\n# Question 6\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\ns_mean_g <- mean(gas_taxes)\ns_sd_g <- sd(gas_taxes)\ns_size_g <- length(gas_taxes)\nstandard_error_g <- s_sd_g / sqrt(s_size_g)\nconfidence_level <- 0.95\ntail_area <- (1-confidence_level)/2\nt_score_g <- qt(p = 1 - tail_area, df = s_size_g - 1)\nCI_g <- c(s_mean_g - t_score_g * standard_error_g,\n        s_mean_g + t_score_g * standard_error_g)\nprint(CI_g)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 36.23386 45.49169\n```\n:::\n:::\n\n\nThere is enough information to conclude that at a 95% confidence interval that the average tax per gallon of gas in the US in 2005 was less than 45 cents. Why? The 95% CI tops out at 45.49, which is 0.49 of a cent higher than our cutoff -- 45 cents. Therefore, we must accept the null hypothesis.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}