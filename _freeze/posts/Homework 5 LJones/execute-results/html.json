{
  "hash": "47a00450b1b94af001ba3383f18fdb23",
  "result": {
    "markdown": "---\ntitle: \"Homework 5\"\nauthor: \"Lindsay Jones\"\ndescription: The final homework\ndate: \"12/4/2022\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - hw5\n---\n\n\n# Homework 5\n\n## Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(alr4)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: car\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: carData\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: effects\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nlattice theme set by effectsTheme()\nSee ?effectsTheme for details.\n```\n:::\n\n```{.r .cell-code}\nlibrary(smss)\nlibrary(stargazer)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nPlease cite as: \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n Hlavac, Marek (2022). stargazer: Well-Formatted Regression and Summary Statistics Tables.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n R package version 5.2.3. https://CRAN.R-project.org/package=stargazer \n```\n:::\n:::\n\n\n## Question 1\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(house.selling.price.2)\nhead(house.selling.price.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      P    S Be Ba New\n1  48.5 1.10  3  1   0\n2  55.0 1.01  3  2   0\n3  68.0 1.45  3  2   0\n4 137.0 2.40  3  3   0\n5 309.4 3.30  4  3   1\n6  17.5 0.40  1  1   0\n```\n:::\n:::\n\n\n### A) For backward elimination, which variable would be deleted first? Why?\n\nThe BEDS variable should be eliminated first because it has the highest p-value and is therefore the weakest predictor of price.\n\n### B) For forward selection, which variable would be added first? Why?\n\nIn forward selection, we add based on the strongest significance. The p-value for SIZE is 0 and the p-value for NEW is 0.000. I am inclined to believe that NEW appears this way because it has a value slightly higher than 0, so I would estimate that SIZE is the most statistically significant and should be added first.\n\n### C) Why do you think that BEDS has such a large P-value in the multiple regression model, even though it has a substantial correlation with PRICE?\n\nI think the correlation between BEDS and PRICE is influenced by another variable, perhaps SIZE. On its own, BEDS may just be a weak indicator of PRICE,\n\n### D) Using software with these four predictors, find the model that would be selected using each criterion:\n\n#### a) R²\n\n#### b) Adjusted R²\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- lm(P ~ S, house.selling.price.2)\nm2 <- lm(P ~ Be, house.selling.price.2)\nm3 <- lm(P ~ Ba, house.selling.price.2)\nm4 <- lm(P ~ New, house.selling.price.2)\nm5 <- lm(P~., house.selling.price.2)\nm6 <- lm(P~.-Be, house.selling.price.2)\nstargazer(m1, m2, m3, m4, m5, m6, type = 'text')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n================================================================================================================================================================\n                                                                                Dependent variable:                                                             \n                    --------------------------------------------------------------------------------------------------------------------------------------------\n                                                                                         P                                                                      \n                              (1)                    (2)                    (3)                    (4)                     (5)                     (6)          \n----------------------------------------------------------------------------------------------------------------------------------------------------------------\nS                          75.607***                                                                                    64.761***               62.263***       \n                            (3.865)                                                                                      (5.630)                 (4.335)        \n                                                                                                                                                                \nBe                                                42.969***                                                              -2.766                                 \n                                                   (6.160)                                                               (3.960)                                \n                                                                                                                                                                \nBa                                                                       76.026***                                      19.203***               20.072***       \n                                                                          (7.822)                                        (5.650)                 (5.495)        \n                                                                                                                                                                \nNew                                                                                             34.158***               18.984***               18.371***       \n                                                                                                 (9.383)                 (3.873)                 (3.761)        \n                                                                                                                                                                \nConstant                  -25.194***               -37.229*              -49.248***             89.249***              -41.795***              -47.992***       \n                            (6.688)                (19.955)               (15.644)               (5.148)                (12.104)                 (8.209)        \n                                                                                                                                                                \n----------------------------------------------------------------------------------------------------------------------------------------------------------------\nObservations                  93                      93                     93                     93                     93                      93           \nR2                           0.808                  0.348                  0.509                  0.127                   0.869                   0.868         \nAdjusted R2                  0.806                  0.341                  0.504                  0.118                   0.863                   0.864         \nResidual Std. Error    19.473 (df = 91)        35.861 (df = 91)       31.119 (df = 91)       41.506 (df = 91)       16.360 (df = 88)        16.313 (df = 89)    \nF Statistic         382.628*** (df = 1; 91) 48.660*** (df = 1; 91) 94.473*** (df = 1; 91) 13.254*** (df = 1; 91) 145.763*** (df = 4; 88) 195.313*** (df = 3; 89)\n================================================================================================================================================================\nNote:                                                                                                                                *p<0.1; **p<0.05; ***p<0.01\n```\n:::\n:::\n\n\nFor parts *a* and *b* above, I compare several models in one chart (I did not run all possible models; just a few that made sense based on previous information). Because a higher R² indicates a stronger fit, the model including all variables (m5) should be selected if using R² and the model including all except BEDS (m6) should be selected if using adjusted R².\n\n#### c) PRESS\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#use PRESS function to test all models from previous questions\n\nPRESS <- function(linear.model) {\n  pr <- residuals(linear.model)/(1-lm.influence(linear.model)$hat)\n  PRESS <- sum(pr^2)\n  return(PRESS)\n}\n\ncat('       ', 'PRESS', '\\n',\n'm1:  ', PRESS(m1), '\\n',\n'm2:  ', PRESS(m2), '\\n',\n'm3:  ', PRESS(m3), '\\n',\n'm4:  ', PRESS(m4), '\\n',\n'm5:  ', PRESS(m5), '\\n',\n'm6:  ', PRESS(m6), '\\n')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        PRESS \n m1:   38203.29 \n m2:   122984.3 \n m3:   95732.14 \n m4:   164039.3 \n m5:   28390.22 \n m6:   27860.05 \n```\n:::\n:::\n\nIf using PRESS as the primary criterion, model m6 is the best choice because it has the lowest PRESS score.\n\n#### d) AIC\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat('       ', 'AIC', '\\n',\n'm1:  ', AIC(m1), '\\n',\n'm2:  ', AIC(m2), '\\n',\n'm3:  ', AIC(m3), '\\n',\n'm4:  ', AIC(m4), '\\n',\n'm5:  ', AIC(m5), '\\n',\n'm6:  ', AIC(m6), '\\n')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        AIC \n m1:   820.1439 \n m2:   933.7168 \n m3:   907.3327 \n m4:   960.908 \n m5:   790.6225 \n m6:   789.1366 \n```\n:::\n:::\n\n\nm6 is the best choice here, but m5 is close.\n\n#### c) BIC\n\n::: {.cell}\n\n```{.r .cell-code}\ncat('       ', 'BIC', '\\n',\n'm1:  ', BIC(m1), '\\n',\n'm2:  ', BIC(m2), '\\n',\n'm3:  ', BIC(m3), '\\n',\n'm4:  ', BIC(m4), '\\n',\n'm5:  ', BIC(m5), '\\n',\n'm6:  ', BIC(m6), '\\n')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        BIC \n m1:   827.7417 \n m2:   941.3146 \n m3:   914.9305 \n m4:   968.5058 \n m5:   805.8181 \n m6:   801.7996 \n```\n:::\n:::\n\n\nSimilar to AIC, m6 is again the best choice here, but m5 is close.\n\n#### d) Explain which model you prefer and why.\nIt seems to me that m6, which includes all variables but BEDS, is the best fit. It meets the criterion for best fit in most tests. Model m5, which includes all variables, would be a close 2nd choice.\n\n## Question 2\n\nTree volume estimation is a big deal, especially in the lumber industry. Use the trees data to build a basic model of tree volume prediction. In particular,\n\n### A) fit a multiple regression model with  the Volume as the outcome and Girth  and Height as the explanatory variables\n\n::: {.cell}\n\n```{.r .cell-code}\ntree <- lm(Volume ~ Girth + Height, data=trees)\ntree\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Volume ~ Girth + Height, data = trees)\n\nCoefficients:\n(Intercept)        Girth       Height  \n   -57.9877       4.7082       0.3393  \n```\n:::\n:::\n\n### B) Run regression diagnostic plots on the model. Based on the plots, do you think any of the regression assumptions are violated?\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(2,3)); plot(tree, which = 1:6)\n```\n\n::: {.cell-output-display}\n![](Homework-5-LJones_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\nThe Residuals vs Fitted plot violates the assumption of linearity. The line in the Scale-Location plot is not quite horizontal, but it is unclear which assumption this violates- perhaps homoskedasticity.\n\n## Question 3\nIn the 2000 election for U.S. president, the counting of votes in Florida was controversial. In Palm Beach County in south Florida, for example, voters used a so-called butterfly ballot. Some believe that the layout of the ballot caused some voters to cast votes for Buchanan when their intended choice was Gore.\n\nThe data has variables for the number of votes for each candidate—Gore, Bush, and Buchanan. \n\n### A) Run a simple linear regression model where the Buchanan vote is the outcome and the Bush vote is the explanatory variable. Produce the regression diagnostic plots. Is Palm Beach County an outlier based on the diagnostic plots? Why or why not?\n\n::: {.cell}\n\n```{.r .cell-code}\nvote <- lm(Buchanan ~ Bush, data=florida)\npar(mfrow = c(2,3)); plot(vote, which = 1:6)\n```\n\n::: {.cell-output-display}\n![](Homework-5-LJones_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\nPalm Beach does appear to be an outlier as it falls way outside the lines on most plots. Dade is also an outlier on a few plots. \n\n### B) Take the log of both variables (Bush vote and Buchanan Vote) and repeat the analysis in (a). Does your findings change?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvote_log <- lm(log(Buchanan)~log(Bush),data=florida)\npar(mfrow = c(2,3)); plot(vote_log, which = 1:6)\n```\n\n::: {.cell-output-display}\n![](Homework-5-LJones_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\nPalm Beach still appears to be a significant outlier, but now there are other counties which also stand out. Dade no longer appears to be an outlier on any plot. \n",
    "supporting": [
      "Homework-5-LJones_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}