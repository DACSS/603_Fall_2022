{
  "hash": "d724a252def994cdb0d439fe51599b33",
  "result": {
    "markdown": "---\ntitle: 'Homework #5'\nauthor: \"Kalimah Muhammad\"\ndate: \"12/9/2022\"\ndesription: \"Homework #5\"\nformat:\n  \n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories: \n  - hw5\n  - Kalimah Muhammad\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(alr4)\nlibrary(smss)\nknitr::opts_chunk$set(echo = TRUE)\n```\n:::\n\n\n## Question 1\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"house.selling.price.2\") #load housing data\nsummary(lm(P ~ ., data = house.selling.price.2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = P ~ ., data = house.selling.price.2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-36.212  -9.546   1.277   9.406  71.953 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -41.795     12.104  -3.453 0.000855 ***\nS             64.761      5.630  11.504  < 2e-16 ***\nBe            -2.766      3.960  -0.698 0.486763    \nBa            19.203      5.650   3.399 0.001019 ** \nNew           18.984      3.873   4.902  4.3e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 16.36 on 88 degrees of freedom\nMultiple R-squared:  0.8689,\tAdjusted R-squared:  0.8629 \nF-statistic: 145.8 on 4 and 88 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n### 1.A\n\nFor backward elimination, the first variable that should be deleted is Beds as it has the largest p-value in the regression model at 0.486763.\n\n### 1.B\n\nFor forward selection, the first variable that should be added is New since it has the lowest p-value at 4.3e-06.\n\n### 1.C\n\nThe BEDS variable could have a large p-value and high correlation because it no longer becomes significant compared to the other variables are added.\n\n### 1.D\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#model 1\nhouse_model1 <-lm(P ~ New, data = house.selling.price.2)\nsummary(house_model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = P ~ New, data = house.selling.price.2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-71.749 -21.249  -7.449  17.251 190.751 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   89.249      5.148  17.336  < 2e-16 ***\nNew           34.158      9.383   3.641 0.000451 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 41.51 on 91 degrees of freedom\nMultiple R-squared:  0.1271,\tAdjusted R-squared:  0.1175 \nF-statistic: 13.25 on 1 and 91 DF,  p-value: 0.0004515\n```\n:::\n\n```{.r .cell-code}\n#model 2\nhouse_model2 <-lm(P ~ S, data = house.selling.price.2)\nsummary(house_model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = P ~ S, data = house.selling.price.2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-56.407 -10.656   2.126  11.412  85.091 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -25.194      6.688  -3.767 0.000293 ***\nS             75.607      3.865  19.561  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 19.47 on 91 degrees of freedom\nMultiple R-squared:  0.8079,\tAdjusted R-squared:  0.8058 \nF-statistic: 382.6 on 1 and 91 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\n#model 3\nhouse_model3 <-lm(P ~ Ba, data = house.selling.price.2)\nsummary(house_model3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = P ~ Ba, data = house.selling.price.2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-52.903 -21.003  -2.703  12.197 130.571 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -49.248     15.644  -3.148  0.00222 ** \nBa            76.026      7.822   9.720 9.84e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 31.12 on 91 degrees of freedom\nMultiple R-squared:  0.5094,\tAdjusted R-squared:  0.504 \nF-statistic: 94.47 on 1 and 91 DF,  p-value: 9.839e-16\n```\n:::\n\n```{.r .cell-code}\n#model 4\nhouse_model4 <-lm(P ~ Be, data = house.selling.price.2)\nsummary(house_model4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = P ~ Be, data = house.selling.price.2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-72.079 -19.679  -3.779  14.352 174.752 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   -37.23      19.95  -1.866   0.0653 .  \nBe             42.97       6.16   6.976 4.76e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 35.86 on 91 degrees of freedom\nMultiple R-squared:  0.3484,\tAdjusted R-squared:  0.3413 \nF-statistic: 48.66 on 1 and 91 DF,  p-value: 4.759e-10\n```\n:::\n\n```{.r .cell-code}\n#summary of AIC comparisons\nhouse.selling.price.2%>%\nsummarise(AIC(house_model1), AIC(house_model2), AIC(house_model3), AIC(house_model4))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  AIC(house_model1) AIC(house_model2) AIC(house_model3) AIC(house_model4)\n1           960.908          820.1439          907.3327          933.7168\n```\n:::\n\n```{.r .cell-code}\n#summary of BIC comparisons        \nhouse.selling.price.2%>%\nsummarise(BIC(house_model1), BIC(house_model2), BIC(house_model3), BIC(house_model4))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  BIC(house_model1) BIC(house_model2) BIC(house_model3) BIC(house_model4)\n1          968.5058          827.7417          914.9305          941.3146\n```\n:::\n:::\n\n\nUsing software with these four predictors, find the model that would be selected using each criterion: a. R2 - Model2 with the Size variable would be the best with the highest R-squared value of 0.8079. b. Adjusted R2 - Model2 would be the best fit with the highest value at 0.8058. c. PRESS - Model2 is the best fit. d. AIC - Model2 with the Size would be the best with an AIC of 820.1439. e. BIC - Model2 with the Size would be the best with an BIC of 827.74.\n\n### 1.E\n\nThe model using the Size variable resulted in the best fit model.\n\n## Question 2\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"trees\")\n```\n:::\n\n\n### 2.A\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_model1 <-lm(Volume ~ Girth + Height, trees)\nsummary(tree_model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Volume ~ Girth + Height, data = trees)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.4065 -2.6493 -0.2876  2.2003  8.4847 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -57.9877     8.6382  -6.713 2.75e-07 ***\nGirth         4.7082     0.2643  17.816  < 2e-16 ***\nHeight        0.3393     0.1302   2.607   0.0145 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.882 on 28 degrees of freedom\nMultiple R-squared:  0.948,\tAdjusted R-squared:  0.9442 \nF-statistic:   255 on 2 and 28 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\ntree_model2 <- lm(Volume ~ Girth * Height, trees)\nsummary(tree_model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Volume ~ Girth * Height, data = trees)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.5821 -1.0673  0.3026  1.5641  4.6649 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  69.39632   23.83575   2.911  0.00713 ** \nGirth        -5.85585    1.92134  -3.048  0.00511 ** \nHeight       -1.29708    0.30984  -4.186  0.00027 ***\nGirth:Height  0.13465    0.02438   5.524 7.48e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.709 on 27 degrees of freedom\nMultiple R-squared:  0.9756,\tAdjusted R-squared:  0.9728 \nF-statistic: 359.3 on 3 and 27 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nThe best fit model to predict tree volume includes girth plus height as an interaction term. This is displayed in tree_model2.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#create matrix of model plots\npar(mfrow = c(2,3)); plot(tree_model2, which = 1:6)\n```\n\n::: {.cell-output-display}\n![](KalimahMuhammad_hw5_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n### 2.B\n\nA few assumptions that may be violated include:\\\n- Potential heteroskedasticity as suggested in the curved red line in the Scale-Location plot suggesting standardized residuals may be changing as a product of fitting.\\\n- Observation #18 has significant leverage compared to the observation's (see Cook's distance) and may indicate a larger potential influence on the model.\n\n## Question 3\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"florida\") #load data\n```\n:::\n\n\n### 3.A\n\nRun a simple linear regression model where the Buchanan vote is the outcome and the Bush vote is the explanatory variable. Produce the regression diagnostic plots.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfla_model <- (lm(Buchanan ~ Bush, data=florida))\nsummary(fla_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Buchanan ~ Bush, data = florida)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-907.50  -46.10  -29.19   12.26 2610.19 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 4.529e+01  5.448e+01   0.831    0.409    \nBush        4.917e-03  7.644e-04   6.432 1.73e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 353.9 on 65 degrees of freedom\nMultiple R-squared:  0.3889,\tAdjusted R-squared:  0.3795 \nF-statistic: 41.37 on 1 and 65 DF,  p-value: 1.727e-08\n```\n:::\n\n```{.r .cell-code}\npar(mfrow = c(2,3)); plot(fla_model, which = 1:6)\n```\n\n::: {.cell-output-display}\n![](KalimahMuhammad_hw5_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nPalm Beach County is an outlier. This may be due to this county having the most Buchanan votes (3404).\n\n### 3.B\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfla_model2 <- (lm(log(Buchanan) ~ log(Bush), data=florida))\nsummary(fla_model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = log(Buchanan) ~ log(Bush), data = florida)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.96075 -0.25949  0.01282  0.23826  1.66564 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -2.57712    0.38919  -6.622 8.04e-09 ***\nlog(Bush)    0.75772    0.03936  19.251  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4673 on 65 degrees of freedom\nMultiple R-squared:  0.8508,\tAdjusted R-squared:  0.8485 \nF-statistic: 370.6 on 1 and 65 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\npar(mfrow = c(2,3)); plot(fla_model2, which = 1:6)\n```\n\n::: {.cell-output-display}\n![](KalimahMuhammad_hw5_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nPalm Beach County, remains as the most prominent outlier. However, the second model highlights a second tier of outliers including Glades and Liberty.\n",
    "supporting": [
      "KalimahMuhammad_hw5_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}