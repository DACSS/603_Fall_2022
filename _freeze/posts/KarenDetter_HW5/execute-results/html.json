{
  "hash": "a3eea80cc9e98c52d070a19182a76338",
  "result": {
    "markdown": "---\ntitle: \"HW 5\"\nauthor: \"Karen Detter\"\ndesription: \"Homework 5\"\ndate: \"12/09/2022\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - hw5\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nknitr::opts_chunk$set(echo = TRUE)\n```\n:::\n\n\n# Q.1\n\n## A.\nUsing backward elimination would result in *Beds* being removed, because it has the highest p-value of all the variables.\n\n## B.\nUnder the forward selection method, *Size* would be added first, because it has the largest t-value, indicating the greatest improvement to the null model.\n\n## C.\nThe fact that *Beds* has a substantial correlation with *Price*, but a large p-value in the regression model is an indication of small sample size, since p-value is a function of both correlation coefficient and sample size.\n\n## D.\n\n::: {.cell}\n\n```{.r .cell-code}\n#test regression models\nlibrary(smss)\ndata(house.selling.price.2)\nfull <- lm(P ~ ., data = house.selling.price.2)\nforw1 <- lm(P ~ S, data = house.selling.price.2)\nforw2 <- lm(P ~ S + New, data = house.selling.price.2)\nforw3 <- lm(P ~ S + New + Ba, data = house.selling.price.2)\n```\n:::\n\n### a.\nI used the forward selection method to fit models, adding variables, one at a time, based on t-values (highest to lowest).\n\n$R^{2}$ is highest for the full model with all variables.\n\n### b.\nAdjusted $R^{2}$ is highest for the model of *Price* as a function of *Size*, *Baths*, and *New*.\n\n### c.\n\n::: {.cell}\n\n```{.r .cell-code}\n#calculate PRESS statistics\nPRESS <- function(linear.model) {\n  pr <- residuals(linear.model)/(1-lm.influence(linear.model)$hat) \n  PRESS <- sum(pr^2) \n  return(PRESS)\n}\nPRESS(full)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 28390.22\n```\n:::\n\n```{.r .cell-code}\nPRESS(forw1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 38203.29\n```\n:::\n\n```{.r .cell-code}\nPRESS(forw2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 31066\n```\n:::\n\n```{.r .cell-code}\nPRESS(forw3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 27860.05\n```\n:::\n:::\n\nThe model with *Price* as a function of *Size*, *Baths*, and *New* has the lowest PRESS calculation.\n\n### d.\n\n::: {.cell}\n\n```{.r .cell-code}\n#calculate AIC values\nAIC(full, k=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 790.6225\n```\n:::\n\n```{.r .cell-code}\nAIC(forw1, k=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 820.1439\n```\n:::\n\n```{.r .cell-code}\nAIC(forw2, k=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 800.1262\n```\n:::\n\n```{.r .cell-code}\nAIC(forw3, k=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 789.1366\n```\n:::\n:::\n\nThe model with *Price* as a function of *Size*, *Baths*, and *New* has the lowest AIC calculation.\n\n### e.\n\n::: {.cell}\n\n```{.r .cell-code}\n#calculate BIC values\nBIC(full)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 805.8181\n```\n:::\n\n```{.r .cell-code}\nBIC(forw1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 827.7417\n```\n:::\n\n```{.r .cell-code}\nBIC(forw2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 810.2566\n```\n:::\n\n```{.r .cell-code}\nBIC(forw3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 801.7996\n```\n:::\n:::\n\nThe model with *Price* as a function of *Size*, *Baths*, and *New* has the lowest BIC calculation.\n\n## E.\nSince the model with *Price* as a function of *Size*, *Baths*, and *New* has the highest Adjusted $R^{2}$, and the lowest PRESS, AIC, and BIC calculations, I would choose it as the best one. \n\n# Q.2\n\n## A.\n\n::: {.cell}\n\n```{.r .cell-code}\n#fit multiple regression model\ntrees_full <- lm(Volume ~ Girth + Height, data = trees)\nsummary(trees_full)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Volume ~ Girth + Height, data = trees)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.4065 -2.6493 -0.2876  2.2003  8.4847 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -57.9877     8.6382  -6.713 2.75e-07 ***\nGirth         4.7082     0.2643  17.816  < 2e-16 ***\nHeight        0.3393     0.1302   2.607   0.0145 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.882 on 28 degrees of freedom\nMultiple R-squared:  0.948,\tAdjusted R-squared:  0.9442 \nF-statistic:   255 on 2 and 28 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n## B.\n\n::: {.cell}\n\n```{.r .cell-code}\n#run diagnostic plots\npar(mfrow = c(2,3)); plot(trees_full, which = 1:6)\n```\n\n::: {.cell-output-display}\n![](KarenDetter_HW5_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nFrom the appearance of the Residuals vs Fitted plot, it seems the assumption of a linear relationship is violated, because the residuals form a pattern of groups, instead of being randomly distributed around the 0 line.\n\nIt also appears that the assumption of constant variance is violated, as the Scale-Location plot shows heteroskedasticity in the residuals because the baseline shows magnitude changes.\n\n# Q.3\n\n## a)\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(alr4)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: car\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: carData\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'car'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:dplyr':\n\n    recode\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:purrr':\n\n    some\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: effects\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nlattice theme set by effectsTheme()\nSee ?effectsTheme for details.\n```\n:::\n\n```{.r .cell-code}\ndata(florida)\nvote <- lm(Buchanan ~ Bush, data = florida)\n#produce diagnostic plots\npar(mfrow = c(2,3)); plot(vote, which = 1:6)\n```\n\n::: {.cell-output-display}\n![](KarenDetter_HW5_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nPalm Beach County is a definite outlier in this model, as it does not follow the patterns produced by the other county data in any of the diagnostic plots, and its residual values are much higher.\n\n## b)\n\n::: {.cell}\n\n```{.r .cell-code}\n#log both variables in model\nvote_log <- lm(log(Buchanan) ~ log(Bush), data = florida)\npar(mfrow = c(2,3)); plot(vote_log, which = 1:6)\n```\n\n::: {.cell-output-display}\n![](KarenDetter_HW5_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nPalm Beach County still appears to be at the high end of the data, but it no longer appears to be an actual outlier, because it is now much closer in line with the patterns and values of the other counties.\n\n\n\n",
    "supporting": [
      "KarenDetter_HW5_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}