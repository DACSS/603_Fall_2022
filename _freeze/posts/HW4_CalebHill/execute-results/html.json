{
  "hash": "07198d841049a68e5975bbb35f0ae9bf",
  "result": {
    "markdown": "---\ntitle: \"Homework 4\"\nauthor: \"Caleb Hill\"\ndesription: \"The fourth homework on regressions\"\ndate: \"11/12/2022\"\nformat:\n  html: \n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - hw4\n  - regression\n  - prediction\n---\n\n\n# Question 1\n\nFirst, let's load the relevant libraries and set all the graph themes to minimal.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.4 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(alr4)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: car\nLoading required package: carData\n\nAttaching package: 'car'\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\nThe following object is masked from 'package:purrr':\n\n    some\n\nLoading required package: effects\nlattice theme set by effectsTheme()\nSee ?effectsTheme for details.\n```\n:::\n\n```{.r .cell-code}\nlibrary(smss)\ntheme_minimal()\n```\n:::\n\n\n## A\n\nThe prediction equation for the following three subsections is: ŷ = −10,536 + 53.8x1 + 2.84x.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- sum(-10536 + (53.8*1240) + (2.84*18000))\ny <- 145000\n\ny - x\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 37704\n```\n:::\n:::\n\n\nThe predicted sale price is \\$107,296.That is a difference (residual) of \\$37,704.\n\n## B\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- sum(-10536 + (53.8*500) + (2.84*1000))\ny <- sum(-10536 + (53.8*501) + (2.84*1000))\ny - x\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 53.8\n```\n:::\n:::\n\n\nFor a fixed lot size, the house selling price is predicted to increase \\$53.80 per each square-foot increase. This is because we are multiplying the size of the home (in square feet) by \\$53.80.\n\n## C\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(53.8/2.84)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 18.94366\n```\n:::\n:::\n\n\nLot size would have to increase by almost 19 square feet to have the same impact as a one-square-foot increase in home size.\n\n# Question 2\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(salary)\nhead(salary)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   degree rank    sex year ysdeg salary\n1 Masters Prof   Male   25    35  36350\n2 Masters Prof   Male   13    22  35350\n3 Masters Prof   Male   10    23  28200\n4 Masters Prof Female    7    27  26775\n5     PhD Prof   Male   19    30  33696\n6 Masters Prof   Male   16    21  28516\n```\n:::\n:::\n\n\n## A\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(salary ~ sex, salary)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  salary by sex\nt = 1.7744, df = 21.591, p-value = 0.09009\nalternative hypothesis: true difference in means between group Male and group Female is not equal to 0\n95 percent confidence interval:\n -567.8539 7247.1471\nsample estimates:\n  mean in group Male mean in group Female \n            24696.79             21357.14 \n```\n:::\n:::\n\n\nWhile there is a difference in salary by `Sex,` the p-value does not meet the threshold for statistical significance (0.05). We cannot reject the null hypothesis.\n\n## B\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalary$sex <- relevel(salary$sex, ref = 1)\nmodel1 <- lm(salary ~ sex + rank + degree + year + ysdeg, data = salary)\nconfint(model1, level = 0.95)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 2.5 %      97.5 %\n(Intercept) 14134.4059 17357.68946\nsexFemale    -697.8183  3030.56452\nrankAssoc    2985.4107  7599.31080\nrankProf     8396.1546 13841.37340\ndegreePhD    -663.2482  3440.47485\nyear          285.1433   667.47476\nysdeg        -280.6397    31.49105\n```\n:::\n:::\n\n\nThe 95% CI for the female sex's impact on salary is between -697.82 to 3030.56.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalary$sex <- relevel(salary$sex, ref = 2)\n\nmodel_relevel_sex <- lm(salary ~ sex + rank + degree + year + ysdeg, data = salary)\nconfint(model_relevel_sex, level = 0.95)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 2.5 %      97.5 %\n(Intercept) 15268.0220 18556.81956\nsexMale     -3030.5645   697.81832\nrankAssoc    2985.4107  7599.31080\nrankProf     8396.1546 13841.37340\ndegreePhD    -663.2482  3440.47485\nyear          285.1433   667.47476\nysdeg        -280.6397    31.49105\n```\n:::\n:::\n\n\nThe 95% CI for the male sex's impact on salary is between -3030.56 to 697.82.\n\n## C\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ sex + rank + degree + year + ysdeg, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4045.2 -1094.7  -361.5   813.2  9193.1 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 15746.05     800.18  19.678  < 2e-16 ***\nsexFemale    1166.37     925.57   1.260    0.214    \nrankAssoc    5292.36    1145.40   4.621 3.22e-05 ***\nrankProf    11118.76    1351.77   8.225 1.62e-10 ***\ndegreePhD    1388.61    1018.75   1.363    0.180    \nyear          476.31      94.91   5.018 8.65e-06 ***\nysdeg        -124.57      77.49  -1.608    0.115    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2398 on 45 degrees of freedom\nMultiple R-squared:  0.855,\tAdjusted R-squared:  0.8357 \nF-statistic: 44.24 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nThree variables reach statistical significance (low p-value): `rankAssoc,` `rankProf,` and `year.` `SexFemale` does not reach statistical significance.\n\n`Year` has the lowest estimate and standard error, about 5x to 10x less than the other two variables. The t-value is less than that of `rankProf,` but it is still the second highest.\n\n## D\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalary$rank <- relevel(salary$rank, ref = 3)\n\nmodel_relevel_rank <- lm(salary ~ rank + degree + sex + year + ysdeg, data = salary)\nsummary(model_relevel_rank)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ rank + degree + sex + year + ysdeg, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4045.2 -1094.7  -361.5   813.2  9193.1 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  28031.18    1677.06  16.715  < 2e-16 ***\nrankAsst    -11118.76    1351.77  -8.225 1.62e-10 ***\nrankAssoc    -5826.40    1012.93  -5.752 7.28e-07 ***\ndegreePhD     1388.61    1018.75   1.363    0.180    \nsexMale      -1166.37     925.57  -1.260    0.214    \nyear           476.31      94.91   5.018 8.65e-06 ***\nysdeg         -124.57      77.49  -1.608    0.115    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2398 on 45 degrees of freedom\nMultiple R-squared:  0.855,\tAdjusted R-squared:  0.8357 \nF-statistic: 44.24 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nWe excluded Assoc from the `rank` variable in this relevel and included Asst and Prof. This has shown a positive relationship between `rank` and `salary` for Prof, but not for Asst, and the variables are statistically significant at the 0.001 scale for both of them. The standard error is also lower for both compared Assoc, though not by much.\n\n## E\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2 <- lm(salary ~ degree + sex + year + ysdeg, data = salary)\nsummary(model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ degree + sex + year + ysdeg, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8146.9 -2186.9  -491.5  2279.1 11186.6 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 15897.03    1259.87  12.618  < 2e-16 ***\ndegreePhD   -3299.35    1302.52  -2.533 0.014704 *  \nsexMale      1286.54    1313.09   0.980 0.332209    \nyear          351.97     142.48   2.470 0.017185 *  \nysdeg         339.40      80.62   4.210 0.000114 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3744 on 47 degrees of freedom\nMultiple R-squared:  0.6312,\tAdjusted R-squared:  0.5998 \nF-statistic: 20.11 on 4 and 47 DF,  p-value: 1.048e-09\n```\n:::\n:::\n\n\nExcluding rank, we now see that `ysdeg` is the best predictor variable, with the lowest estimate score, standard error, and meets the 0.001 p-value threshold to be statistically significant.\n\n## F\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalary$dean <- ifelse(salary$ysdeg >= '15', \"Old Dean\",\n                  \"New Dean\")\ntable(salary$dean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nNew Dean Old Dean \n      11       41 \n```\n:::\n\n```{.r .cell-code}\nmodel3 <- lm(salary ~ dean, data = salary)\nsummary(model3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ dean, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9311.1 -4185.9  -573.6  3931.8 13383.9 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     20580       1727  11.913 3.23e-16 ***\ndeanOld Dean     4082       1945   2.098    0.041 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5729 on 50 degrees of freedom\nMultiple R-squared:  0.08091,\tAdjusted R-squared:  0.06253 \nF-statistic: 4.402 on 1 and 50 DF,  p-value: 0.04097\n```\n:::\n:::\n\n\nIt looks like those hired prior to the new Dean do have a statistically significant impact on salary, though at a minor code of 0.05. What's interesting though is the positive relationship, which rejects the belief that the new Dean has been making more generous offers to new hires. However, we should add some control variables, making sure to avoid multicollinearity. Three variables that would impact multicollinearity are `rank,` `ysdeg,` and `year.`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel4 <- lm(salary ~ dean + degree + sex, data = salary)\nsummary(model4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ dean + degree + sex, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8919.1 -4457.4  -344.1  3386.5 15921.8 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     18088       2159   8.379 5.92e-11 ***\ndeanOld Dean     4035       1921   2.100   0.0410 *  \ndegreePhD         345       1654   0.209   0.8357    \nsexMale          3296       1768   1.864   0.0685 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5640 on 48 degrees of freedom\nMultiple R-squared:  0.145,\tAdjusted R-squared:  0.09157 \nF-statistic: 2.714 on 3 and 48 DF,  p-value: 0.05514\n```\n:::\n:::\n\n\nThe standard error drops, but everything else remains very similar.\n\n# Question 3\n\n## A\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(house.selling.price)\n\nmodel5 <- lm(Price ~ Size + New, house.selling.price)\nsummary(model5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ Size + New, data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205102  -34374   -5778   18929  163866 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -40230.867  14696.140  -2.738  0.00737 ** \nSize           116.132      8.795  13.204  < 2e-16 ***\nNew          57736.283  18653.041   3.095  0.00257 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 53880 on 97 degrees of freedom\nMultiple R-squared:  0.7226,\tAdjusted R-squared:  0.7169 \nF-statistic: 126.3 on 2 and 97 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n`Size` is statistically significant (SS) at the 0.001 level, while `New` is SS at the 0.01 level. `Size` has a small standard error and larger t-value, while `New` has a larger estimate, standard error, and lower t-value. We could relevel to see if Old houses had a better impact on `Price` but that can be observed in other questions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhouse.selling.price$New <- relevel(factor(house.selling.price$New), ref = 1)\n\nmodel_relevel_new <- lm(Price ~ Size + New, house.selling.price)\nsummary(model_relevel_new)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ Size + New, data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205102  -34374   -5778   18929  163866 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -40230.867  14696.140  -2.738  0.00737 ** \nSize           116.132      8.795  13.204  < 2e-16 ***\nNew1         57736.283  18653.041   3.095  0.00257 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 53880 on 97 degrees of freedom\nMultiple R-squared:  0.7226,\tAdjusted R-squared:  0.7169 \nF-statistic: 126.3 on 2 and 97 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n## B\n\nThe prediction equation for houses is as follows:\n\nNew: Predicted Price = -40,230 + 116.13(Size) + 57,736(New).\n\nOld: Predicted Price = -40,230 + 116.13(Size) + -57,736(Old).\n\n## C\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(-40230 + (116.13*3000) + (57736*1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 365896\n```\n:::\n\n```{.r .cell-code}\nsum(-40230 + (116.13*3000) + (-57736*1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 250424\n```\n:::\n:::\n\n\nFor a new house, the predicted selling price is \\$365,896. For an old house, it's \\$250,424.\n\n## D\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel6 <- lm(Price ~ Taxes + Size + New, house.selling.price)\nsummary(model6)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ Taxes + Size + New, data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-165501  -25426    1449   20536  168747 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -21353.776  13311.487  -1.604  0.11196    \nTaxes           37.231      6.735   5.528 2.78e-07 ***\nSize            61.704     12.499   4.937 3.35e-06 ***\nNew1         46373.703  16459.019   2.818  0.00588 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 47170 on 96 degrees of freedom\nMultiple R-squared:  0.7896,\tAdjusted R-squared:  0.783 \nF-statistic: 120.1 on 3 and 96 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n## E\n\nThe predicted selling price for the new model for new homes is as follows:\n\nNew: Predicted Price = -21,353 + 37.23(Taxes) + 61.74(Size) + 46,373.70(New)\n\nOld: Predicted Price = -21,353 + 37.23(Taxes) + 61.74(Size) + -46,373.70(Old)\n\n## F\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(-21353 + (37.23*1) + (61.74*3000) + (46373.70*1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 210277.9\n```\n:::\n\n```{.r .cell-code}\nsum(-21353 + (37.23*1) + (61.74*3000) + (-46373.70*1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 117530.5\n```\n:::\n:::\n\n\nThe predicted selling price for a new 3000 square foot house is \\$210,277.90 and for an old house is \\$117,530.50.\n\n## G\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(-21353 + (37.23*1) + (61.74*1500) + (46373.70*1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 117667.9\n```\n:::\n\n```{.r .cell-code}\nsum(-21353 + (37.23*1) + (61.74*1500) + (-46373.70*1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 24920.53\n```\n:::\n:::\n\n\nThe predicted selling price for a new 1500 square foot house is \\$117,667.90 and for an old one is \\$24,920.53. For each square foot increase, we have a dollar increase of \\$61.74.\n\n## H\n\nI prefer the model that includes taxes. This reduces both the residuals and the standard error for the original variables, `Size` and `New.` With a smaller standard error, we should have a more accurate prediction value when attempting to ascertain what the potential sales price for a house is. There is also a larger adjusted R squared percentage. With all that, I would include `Taxes` in the model for the best prediction value.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}