{
  "hash": "602b9a8c4db5f66ceb44133f9d7c034e",
  "result": {
    "markdown": "---\ntitle: \"Homework 4\"\nauthor: \"Steve O'Neill\"\ndescription: \"Homework 4\"\ndate: \"11/16/2022\"\ndf-paged: true\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - hw4\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(alr4)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: car\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: carData\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: effects\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nlattice theme set by effectsTheme()\nSee ?effectsTheme for details.\n```\n:::\n\n```{.r .cell-code}\nlibrary(smss)\n```\n:::\n\n\n## Question 1\n\n*For recent data in Jacksonville, Florida, on y = selling price of home (in dollars), x1 = size of home (in square feet), and x2 = lot size (in square feet), the prediction equation is ŷ = −10,536 + 53.8x1 + 2.84x2*\n\n*A. A particular home of 1240 square feet on a lot of 18,000 square feet sold for \\$145,000. Find the predicted selling price and the residual, and interpret.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhome_size <- 1240\nlot_size <- 18000\n\ny = -10536 + (53.8 * home_size) + (2.84 * lot_size)\ny\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 107296\n```\n:::\n\n```{.r .cell-code}\n145000 - y\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 37704\n```\n:::\n:::\n\n\nThe predicted selling price of the home is \\$107,296. The residual is \\$37704, which means the model under-predicted.\n\nB. Holding home size fixed, each one-square-foot increase in lot size brings a 2.84 increase in dollar value.\n\nC. Holding lot size fixed, each sq. ft. increase in home size results in a \\$53.8 increase in home price.\n\n\n\n## Question 2\n\n*(Data file: salary in alr4 R package). The data file concerns salary and other characteristics of all faculty in a small Midwestern college collected in the early 1980s for presentation in legal proceedings for which discrimination against women in salary was at issue. All persons in the data hold tenured or tenure track positions; temporary faculty are not included. The variables include degree, a factor with levels PhD and MS; rank, a factor with levels Asst, Assoc, and Prof; sex, a factor with levels Male and Female; Year, years in current rank; ysdeg, years since highest degree, and salary, academic year salary in dollars.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(salary)\nsalary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    degree  rank    sex year ysdeg salary\n1  Masters  Prof   Male   25    35  36350\n2  Masters  Prof   Male   13    22  35350\n3  Masters  Prof   Male   10    23  28200\n4  Masters  Prof Female    7    27  26775\n5      PhD  Prof   Male   19    30  33696\n6  Masters  Prof   Male   16    21  28516\n7      PhD  Prof Female    0    32  24900\n8  Masters  Prof   Male   16    18  31909\n9      PhD  Prof   Male   13    30  31850\n10     PhD  Prof   Male   13    31  32850\n11 Masters  Prof   Male   12    22  27025\n12 Masters Assoc   Male   15    19  24750\n13 Masters  Prof   Male    9    17  28200\n14     PhD Assoc   Male    9    27  23712\n15 Masters  Prof   Male    9    24  25748\n16 Masters  Prof   Male    7    15  29342\n17 Masters  Prof   Male   13    20  31114\n18     PhD Assoc   Male   11    14  24742\n19     PhD Assoc   Male   10    15  22906\n20     PhD  Prof   Male    6    21  24450\n21     PhD  Asst   Male   16    23  19175\n22     PhD Assoc   Male    8    31  20525\n23 Masters  Prof   Male    7    13  27959\n24 Masters  Prof Female    8    24  38045\n25 Masters Assoc   Male    9    12  24832\n26 Masters  Prof   Male    5    18  25400\n27 Masters Assoc   Male   11    14  24800\n28 Masters  Prof Female    5    16  25500\n29     PhD Assoc   Male    3     7  26182\n30     PhD Assoc   Male    3    17  23725\n31     PhD  Asst Female   10    15  21600\n32     PhD Assoc   Male   11    31  23300\n33     PhD  Asst   Male    9    14  23713\n34     PhD Assoc Female    4    33  20690\n35     PhD Assoc Female    6    29  22450\n36 Masters Assoc   Male    1     9  20850\n37 Masters  Asst Female    8    14  18304\n38 Masters  Asst   Male    4     4  17095\n39 Masters  Asst   Male    4     5  16700\n40 Masters  Asst   Male    4     4  17600\n41 Masters  Asst   Male    3     4  18075\n42     PhD  Asst   Male    3    11  18000\n43 Masters Assoc   Male    0     7  20999\n44 Masters  Asst Female    3     3  17250\n45 Masters  Asst   Male    2     3  16500\n46 Masters  Asst   Male    2     1  16094\n47 Masters  Asst Female    2     6  16150\n48 Masters  Asst Female    2     2  15350\n49 Masters  Asst   Male    1     1  16244\n50 Masters  Asst Female    1     1  16686\n51 Masters  Asst Female    1     1  15000\n52 Masters  Asst Female    0     2  20300\n```\n:::\n:::\n\n\nTest the hypothesis that the mean salary for men and women is the same, without regard to any other variable but sex. Explain your findings.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(salary$salary ~ salary$sex))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary$salary ~ salary$sex)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8602.8 -4296.6  -100.8  3513.1 16687.9 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         24697        938  26.330   <2e-16 ***\nsalary$sexFemale    -3340       1808  -1.847   0.0706 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5782 on 50 degrees of freedom\nMultiple R-squared:  0.0639,\tAdjusted R-squared:  0.04518 \nF-statistic: 3.413 on 1 and 50 DF,  p-value: 0.0706\n```\n:::\n:::\n\n\nThe hypothesis that mean salary for men and women is *the same* without regard to any other variable but sex is confirmed. Normally, I would expect this to be phrased as the null hypothesis. But to answer the specific wording of this question, the hypothesis (of 'sameness') is confirmed and the null hypothesis (of difference) is rejected.\n\n*Run a multiple linear regression with salary as the outcome variable and everything else as predictors, including sex. Assuming no interactions between sex and the other predictors, obtain a 95% confidence interval for the difference in salary between males and females.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(salary ~ ., data = salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ ., data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4045.2 -1094.7  -361.5   813.2  9193.1 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 15746.05     800.18  19.678  < 2e-16 ***\ndegreePhD    1388.61    1018.75   1.363    0.180    \nrankAssoc    5292.36    1145.40   4.621 3.22e-05 ***\nrankProf    11118.76    1351.77   8.225 1.62e-10 ***\nsexFemale    1166.37     925.57   1.260    0.214    \nyear          476.31      94.91   5.018 8.65e-06 ***\nysdeg        -124.57      77.49  -1.608    0.115    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2398 on 45 degrees of freedom\nMultiple R-squared:  0.855,\tAdjusted R-squared:  0.8357 \nF-statistic: 44.24 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\nmoe = qt(.975, df=45) * 925.57 #aka standard error\nupper<- 1166.37 + moe #1166.37 is the coefficient of sexFemale\nlower<- 1166.37 - moe \nupper\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3030.564\n```\n:::\n\n```{.r .cell-code}\nlower\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -697.8237\n```\n:::\n:::\n\n\nThe confidence interval is (-697.8237, 3030.564)\n\nHere are the findings from earlier:\n\n*Interpret your finding for each predictor variable; discuss (a) statistical significance, (b) interpretation of the coefficient / slope in relation to the outcome variable and other variables*\n\nThe standout variables are `rank` and `year`. Being a full professor has double the effect on salary as an associate, and the p-value is also much smaller. Year has a smaller yet significant effect. `Asst` is missing because it is the baseline category.\n\nYears since highest degree earned is not statistically significant, nor seems to be sex (in this dataset, with these observations).\n\n*Change the baseline category for the rank variable. Interpret the coefficients related to rank again.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalary$rank <- relevel(salary$rank, ref = \"Assoc\")\nsummary(lm(salary ~ ., data = salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ ., data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4045.2 -1094.7  -361.5   813.2  9193.1 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 21038.41    1109.12  18.969  < 2e-16 ***\ndegreePhD    1388.61    1018.75   1.363    0.180    \nrankAsst    -5292.36    1145.40  -4.621 3.22e-05 ***\nrankProf     5826.40    1012.93   5.752 7.28e-07 ***\nsexFemale    1166.37     925.57   1.260    0.214    \nyear          476.31      94.91   5.018 8.65e-06 ***\nysdeg        -124.57      77.49  -1.608    0.115    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2398 on 45 degrees of freedom\nMultiple R-squared:  0.855,\tAdjusted R-squared:  0.8357 \nF-statistic: 44.24 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nWith `rankAssoc` excluded and `rankAsst` included, now we also see that being an assistant professor is negatively correlated with salary - this makes sense considering basic intuition.\n\n*Finkelstein (1980), in a discussion of the use of regression in discrimination cases, wrote, \"\\[a\\] variable may reflect a position or status bestowed by the employer, in which case if there is discrimination in the award of the position or status, the variable may be 'tainted.'\" Thus, for example, if discrimination is at work in promotion of faculty to higher ranks, using rank to adjust salaries before comparing the sexes may not be acceptable to the courts.*\n\n*Exclude the variable rank, refit, and summarize how your findings changed, if they did.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(salary ~ . - rank, data = salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ . - rank, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8146.9 -2186.9  -491.5  2279.1 11186.6 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 17183.57    1147.94  14.969  < 2e-16 ***\ndegreePhD   -3299.35    1302.52  -2.533 0.014704 *  \nsexFemale   -1286.54    1313.09  -0.980 0.332209    \nyear          351.97     142.48   2.470 0.017185 *  \nysdeg         339.40      80.62   4.210 0.000114 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3744 on 47 degrees of freedom\nMultiple R-squared:  0.6312,\tAdjusted R-squared:  0.5998 \nF-statistic: 20.11 on 4 and 47 DF,  p-value: 1.048e-09\n```\n:::\n:::\n\n\nWith rank removed entirely, years since highest degree earned becomes the most significant variable, with PhD and years of service also being significant.\n\n*Everyone in this dataset was hired the year they earned their highest degree. It is also known that a new Dean was appointed 15 years ago, and everyone in the dataset who earned their highest degree 15 years ago or less than that has been hired by the new Dean. Some people have argued that the new Dean has been making offers that are a lot more generous to newly hired faculty than the previous one and that this might explain some of the variation in Salary.*\n\n*Create a new variable that would allow you to test this hypothesis and run another multiple regression model to test this. Select variables carefully to make sure there is no multicollinearity. Explain why multicollinearity would be a concern in this case and how you avoided it. Do you find support for the hypothesis that the people hired by the new Dean are making higher than those that were not?*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalary$dean_old <- ifelse(salary$year >=15, 1, 0)\nhead(salary[c('dean_old', 'year')], n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   dean_old year\n1         1   25\n2         0   13\n3         0   10\n4         0    7\n5         1   19\n6         1   16\n7         0    0\n8         1   16\n9         0   13\n10        0   13\n```\n:::\n:::\n\n\nFor the new linear model, I am excluding years of service and only including years since highest degree attained. Since `dean_old` is derived from `year`, this avoids multicolinearity:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(salary ~ . -year, data = salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ . - year, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5076.5 -1468.1  -569.6  1382.1  9444.4 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 21735.66    1362.56  15.952  < 2e-16 ***\ndegreePhD     436.19    1217.06   0.358  0.72172    \nrankAsst    -4265.73    1372.22  -3.109  0.00325 ** \nrankProf     6153.34    1225.02   5.023 8.52e-06 ***\nsexFemale    -661.30    1013.29  -0.653  0.51732    \nysdeg          57.20      80.92   0.707  0.48324    \ndean_old     2401.72    1415.86   1.696  0.09674 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2904 on 45 degrees of freedom\nMultiple R-squared:  0.7875,\tAdjusted R-squared:  0.7592 \nF-statistic: 27.79 on 6 and 45 DF,  p-value: 1.34e-13\n```\n:::\n:::\n\n\nAfter including the new \"dean\" variable and removing year, I don't find a significant difference in the salaries of professors hiring the two new deans - in other words, the null hypothesis fails to be rejected. It would be significant at a 90% confidence level, but we went in with a 5% significance level\n\nIt could be argued that `year`, representing years of service to the university, is colinear with `ysdeg`, years since highest degree earned. Both of them are a function of time and represent the career-stage of a professor. However, I think professors often come in from different universities so they are not necessarily correlated. I could really see it both ways. If that variable is also removed, the `dean_old` variable becomes significant at the 5% confidence level.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(smss)\ndata(\"house.selling.price\")\nhouse.selling.price\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    case Taxes Beds Baths New  Price Size\n1      1  3104    4     2   0 279900 2048\n2      2  1173    2     1   0 146500  912\n3      3  3076    4     2   0 237700 1654\n4      4  1608    3     2   0 200000 2068\n5      5  1454    3     3   0 159900 1477\n6      6  2997    3     2   1 499900 3153\n7      7  4054    3     2   0 265500 1355\n8      8  3002    3     2   1 289900 2075\n9      9  6627    5     4   0 587000 3990\n10    10   320    3     2   0  70000 1160\n11    11   630    3     2   0  64500 1220\n12    12  1780    3     2   0 167000 1690\n13    13  1630    3     2   0 114600 1380\n14    14  1530    3     2   0 103000 1590\n15    15   930    3     1   0 101000 1050\n16    16   590    2     1   0  70000  770\n17    17  1050    3     2   0  85000 1410\n18    18    20    3     1   0  22500 1060\n19    19   870    2     2   0  90000 1300\n20    20  1320    3     2   0 133000 1500\n21    21  1350    2     1   0  90500  820\n22    22  5616    4     3   1 577500 3949\n23    23   680    2     1   0 142500 1170\n24    24  1840    3     2   0 160000 1500\n25    25  3680    4     2   0 240000 2790\n26    26  1660    3     1   0  87000 1030\n27    27  1620    3     2   0 118600 1250\n28    28  3100    3     2   0 140000 1760\n29    29  2070    2     3   0 148000 1550\n30    30   830    3     2   0  69000 1120\n31    31  2260    4     2   0 176000 2000\n32    32  1760    3     1   0  86500 1350\n33    33  2750    3     2   1 180000 1840\n34    34  2020    4     2   0 179000 2510\n35    35  4900    3     3   1 338000 3110\n36    36  1180    4     2   0 130000 1760\n37    37  2150    3     2   0 163000 1710\n38    38  1600    2     1   0 125000 1110\n39    39  1970    3     2   0 100000 1360\n40    40  2060    3     1   0 100000 1250\n41    41  1980    3     1   0 100000 1250\n42    42  1510    3     2   0 146500 1480\n43    43  1710    3     2   0 144900 1520\n44    44  1590    3     2   0 183000 2020\n45    45  1230    3     2   0  69900 1010\n46    46  1510    2     2   0  60000 1640\n47    47  1450    2     2   0 127000  940\n48    48   970    3     2   0  86000 1580\n49    49   150    2     2   0  50000  860\n50    50  1470    3     2   0 137000 1420\n51    51  1850    3     2   0 121300 1270\n52    52   820    2     1   0  81000  980\n53    53  2050    4     2   0 188000 2300\n54    54   710    3     2   0  85000 1430\n55    55  1280    3     2   0 137000 1380\n56    56  1360    3     2   0 145000 1240\n57    57   830    3     2   0  69000 1120\n58    58   800    3     2   0 109300 1120\n59    59  1220    3     2   0 131500 1900\n60    60  3360    4     3   0 200000 2430\n61    61   210    3     2   0  81900 1080\n62    62   380    2     1   0  91200 1350\n63    63  1920    4     3   0 124500 1720\n64    64  4350    3     3   0 225000 4050\n65    65  1510    3     2   0 136500 1500\n66    66  4154    3     3   0 381000 2581\n67    67  1976    3     2   1 250000 2120\n68    68  3605    3     3   1 354900 2745\n69    69  1400    3     2   0 140000 1520\n70    70   790    2     2   0  89900 1280\n71    71  1210    3     2   0 137000 1620\n72    72  1550    3     2   0 103000 1520\n73    73  2800    3     2   0 183000 2030\n74    74  2560    3     2   0 140000 1390\n75    75  1390    4     2   0 160000 1880\n76    76  5443    3     2   0 434000 2891\n77    77  2850    2     1   0 130000 1340\n78    78  2230    2     2   0 123000  940\n79    79    20    2     1   0  21000  580\n80    80  1510    4     2   0  85000 1410\n81    81   710    3     2   0  69900 1150\n82    82  1540    3     2   0 125000 1380\n83    83  1780    3     2   1 162600 1470\n84    84  2920    2     2   1 156900 1590\n85    85  1710    3     2   1 105900 1200\n86    86  1880    3     2   0 167500 1920\n87    87  1680    3     2   0 151800 2150\n88    88  3690    5     3   0 118300 2200\n89    89   900    2     2   0  94300  860\n90    90   560    3     1   0  93900 1230\n91    91  2040    4     2   0 165000 1140\n92    92  4390    4     3   1 285000 2650\n93    93   690    3     1   0  45000 1060\n94    94  2100    3     2   0 124900 1770\n95    95  2880    4     2   0 147000 1860\n96    96   990    2     2   0 176000 1060\n97    97  3030    3     2   0 196500 1730\n98    98  1580    3     2   0 132200 1370\n99    99  1770    3     2   0  88400 1560\n100  100  1430    3     2   0 127200 1340\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(Price ~ Size + New, data = house.selling.price))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ Size + New, data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205102  -34374   -5778   18929  163866 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -40230.867  14696.140  -2.738  0.00737 ** \nSize           116.132      8.795  13.204  < 2e-16 ***\nNew          57736.283  18653.041   3.095  0.00257 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 53880 on 97 degrees of freedom\nMultiple R-squared:  0.7226,\tAdjusted R-squared:  0.7169 \nF-statistic: 126.3 on 2 and 97 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nBoth `size` and `new` are statistically significant variables. The `size` variable has a much lower p-value, meeting 0.1 % significance level.\n\nAn increase in one sq. ft. of size may increase a house's value by \\$116.13 if `new` is held constant. A house being new can affect the price by \\$57,736.28 with `size` being held constant.\n\nThe prediction equation would be:\n\nPredicted Price = 116.132(Size) + 57736.283(New) -40230.867\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(Price ~ New, data = house.selling.price))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ New, data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-185064  -49042   -9967   22183  448433 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   138567       9504  14.580  < 2e-16 ***\nNew           152396      28655   5.318 6.61e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 89660 on 98 degrees of freedom\nMultiple R-squared:  0.224,\tAdjusted R-squared:  0.2161 \nF-statistic: 28.28 on 1 and 98 DF,  p-value: 6.608e-07\n```\n:::\n:::\n\n\n*Report and interpret the prediction equation, and form separate equations relating selling price to size for new and for not new homes.*\n\nEquations for just size and just newness, respectively, are:\n\nPredicted Price = 126.594(Size) -50926.255\n\nPredicted Price = 152396(New) + 138567\n\n*Find the predicted selling price for a home of 3000 square feet that is (i) new, (ii) not new.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew <- 1\nnotnew <- 0\nsize <- 3000\n\n(116.132 * size) + (57736.283 * new) -40230.867\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 365901.4\n```\n:::\n\n```{.r .cell-code}\n(116.132 * size) + (57736.283 * notnew) -40230.867\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 308165.1\n```\n:::\n:::\n\n\nThe predicted selling price of a new vs not new home of 3000 sq/ft is \\$365901.4 and \\$308165.1, respectively.\n\n*Fit another model, this time with an interaction term allowing interaction between size and new, and report the regression results*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- summary(lm(Price ~ Size + New + Size * New, data = house.selling.price))\nfit\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ Size + New + Size * New, data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-175748  -28979   -6260   14693  192519 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -22227.808  15521.110  -1.432  0.15536    \nSize           104.438      9.424  11.082  < 2e-16 ***\nNew         -78527.502  51007.642  -1.540  0.12697    \nSize:New        61.916     21.686   2.855  0.00527 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 52000 on 96 degrees of freedom\nMultiple R-squared:  0.7443,\tAdjusted R-squared:  0.7363 \nF-statistic: 93.15 on 3 and 96 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n*Report the lines relating the predicted selling price to the size for homes that are (i) new, (ii) not new.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\nnew_labels <- c(\n                    `0` = \"Not New\",\n                    `1` = \"New\"\n                    )\n\nggplot(house.selling.price, aes(x = Size, y = Price)) + \n  geom_point() +\n  stat_smooth(method = \"lm\", col = \"red\") +\n  facet_grid(house.selling.price$New, labeller = as_labeller(new_labels)) + \n  scale_y_continuous(labels=scales::dollar_format())\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](HW4_SteveONeill_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nHere is a faceted plot representation of `New`, re: Size and Price.\n\n*Find the predicted selling price for a home of 3000 square feet that is (i) new, (ii) not new.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsize <- 3000\nsize_coef <- 104.438\nnew_coef <- -78527.502\nsizenew_coef <- 61.916\n\n(size_coef * size) + (new_coef * 0) + (sizenew_coef * 0 * 3000) - 22227.808\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 291086.2\n```\n:::\n\n```{.r .cell-code}\n(size_coef * size) + (new_coef * 1) + (sizenew_coef * 1 * 3000) - 22227.808\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 398306.7\n```\n:::\n:::\n\n\nThe predicted selling price for homes of 3000 sq/ft are, taking into account condition:\n\nNot new: \\$291086.2 New: \\$398306.7\n\n*Find the predicted selling price for a home of 1500 square feet that is (i) new, (ii) not new. Comparing to (F), explain how the difference in predicted selling prices changes as the size of home increases.*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsize <- 1500\nsize_coef <- 104.438\nnew_coef <- -78527.502\nsizenew_coef <- 61.916\n\n(size_coef * size) + (new_coef * 0) + (sizenew_coef * 0 * size) - 22227.808\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 134429.2\n```\n:::\n\n```{.r .cell-code}\n(size_coef * size) + (new_coef * 1) + (sizenew_coef * 1 * size) - 22227.808\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 148775.7\n```\n:::\n:::\n\n\nHere, the costs are \\$134429.2 and \\$148775.7, respectively. This is a much smaller difference. It means that as the size of houses increase, newness increases the price of the house more, per dollar.\n\n*Do you think the model with interaction or the one without it represents the relationship of size and new to the outcome price? What makes you prefer one model over another?*\n\nThe model with interaction variables has a higher R-squared, and to me it makes sense that the cost of newness is seen in larger houses. Therefore I think the second model is the better one.\n",
    "supporting": [
      "HW4_SteveONeill_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}