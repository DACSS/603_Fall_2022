{
  "hash": "7bdf39760eda1ec40cd8cb2c0553269f",
  "result": {
    "markdown": "---\ntitle: \"DACSS603_FinalProject\"\nauthor: \"Rahul Gundeti\"\ndescription: \"Health Insurance Predection\"\ndate: \"12/12/2022\"\nformat:\n  html:\n    df-print: paged\n    css: styles.css\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - Final Project\n  - Health Insurance Predection \n  - Rahul Gundeti\n---\n\n::: {.cell}\n\n```{.r .cell-code}\n# Library Input\n\nlibrary(dplyr)\nlibrary(GGally)\nlibrary(ggcorrplot)\nlibrary(MLmetrics)\nlibrary(performance)\nlibrary(ggplot2)\nlibrary(lmtest)\nlibrary(car)\nlibrary(RColorBrewer)\nlibrary(DT)\n\nknitr::opts_chunk$set(echo = TRUE)\n```\n:::\n\n\n## Introduction\n\nTo predict things have been never so easy. I used to wonder how Insurance amount is charged normally. So, in the mean time I came across this dataset and thought of working on it! Using this I wanted to know how few features determine our insurance amount! As an International student I am completely aware of the benefits of having the health insurance but what got me thinking is how is this a successful industry and how can it give a dymanic quote to each individual by considering very few parameters and assess the risk they own and build a successful business on it. It's almost a gamble and it's my attempt to understand and analyse the basic fundamentals on how the industry operates.\n\n## Reading data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Data Input\n\nlibrary(readr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'readr' was built under R version 4.1.3\n```\n:::\n\n```{.r .cell-code}\ninsurance <- read_csv(\"_data/insurance.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 1338 Columns: 7\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr (3): sex, smoker, region\ndbl (4): age, bmi, children, expenses\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nView(insurance)\n```\n:::\n\n\n\nThe data used in this report contains a list of insurance contract of 1.338 individuals. The insurance data used consists of several variables with the following details:\n\nage: age of primary beneficiary\nsex: insurance contractor gender, female, male\nbmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\nchildren: Number of children covered by health insurance / Number of dependents\nsmoker: Smoking or not\nregion: the beneficiary’s residential area in the US, northeast, southeast, southwest, northwest\nexpenses: Individual medical costs billed by health insurance\n\n## Research Question\n\n1.  What are the variables or factors that are affecting a expenses variable?\n2.  To find out which model fits/accurately predicts the expense.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Data Coercion\ninsurance[ , c(\"sex\", \"smoker\", \"region\")] <- \n  lapply(insurance[ , c(\"sex\", \"smoker\", \"region\")], as.factor)\n\nstr(insurance)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nspc_tbl_ [1,338 x 7] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ age     : num [1:1338] 19 18 28 33 32 31 46 37 37 60 ...\n $ sex     : Factor w/ 2 levels \"female\",\"male\": 1 2 2 2 2 1 1 1 2 1 ...\n $ bmi     : num [1:1338] 27.9 33.8 33 22.7 28.9 25.7 33.4 27.7 29.8 25.8 ...\n $ children: num [1:1338] 0 1 3 0 0 0 1 3 2 0 ...\n $ smoker  : Factor w/ 2 levels \"no\",\"yes\": 2 1 1 1 1 1 1 1 1 1 ...\n $ region  : Factor w/ 4 levels \"northeast\",\"northwest\",..: 4 3 3 2 2 3 3 2 1 2 ...\n $ expenses: num [1:1338] 16885 1726 4449 21984 3867 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   age = col_double(),\n  ..   sex = col_character(),\n  ..   bmi = col_double(),\n  ..   children = col_double(),\n  ..   smoker = col_character(),\n  ..   region = col_character(),\n  ..   expenses = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Checking Missing Values\ncolSums(is.na(insurance))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     age      sex      bmi children   smoker   region expenses \n       0        0        0        0        0        0        0 \n```\n:::\n:::\n\n# Exploratory Data Analysis\n\nExploratory Data Analysis refers to the critical process of performing initial investigations on data so as to discover patterns,to spot anomalies,to test hypothesis and to check assumptions with the help of summary statistics and graphical representations.\n\nAll data types have been converted to the desired data types and there’s no more missing value.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Correlation\nmodel.matrix(~0+., data=insurance) %>% \n  cor(use=\"pairwise.complete.obs\") %>% \n  ggcorrplot(show.diag = F, type=\"lower\", lab=TRUE, lab_size=2, \n             colors = c(\"#1B9E77\", \"white\", \"#D95F02\")) \n```\n\n::: {.cell-output-display}\n![](RahulGundeti_DACSS603_FinalProject_HealthInsurancePrediction_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\nAs can be seen from the correlation plot, smoker, age and bmi are positively related to charges. So, we are going to analyse their relationship further.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Scatter Plot 1\nggplot(insurance, aes(x=age, y=expenses, shape=smoker, color=smoker)) +\n  geom_point() +\n  theme_minimal() +\n  scale_color_brewer(palette = \"Dark2\")\n```\n\n::: {.cell-output-display}\n![](RahulGundeti_DACSS603_FinalProject_HealthInsurancePrediction_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\nAs can be seen from the plot above, the older the age, the more expensive the charges. Also, it can be seen that smoker paid higher charges than non-smoker.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Scatter Plot 2\nggplot(insurance, aes(x=bmi, y=expenses, shape=smoker, color=smoker)) +\n  geom_point() +\n  theme_minimal() +\n  scale_color_brewer(palette = \"Dark2\")\n```\n\n::: {.cell-output-display}\n![](RahulGundeti_DACSS603_FinalProject_HealthInsurancePrediction_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nAs can be seen from the plot above, the higher the bmi, the charge gets relatively more expensive. The same with the previous plot, it can be seen that smoker paid higher charges than non-smoker.\n\n\n\nBefore making the model, the Train-Test Split is necessary. In this process, we will split the data into train data set and test data set. The train data set will be used to build a linear regression model, while the test data set will be used to predict the target variable. We will took 80% of the data as the train data set and the rest will be used as the test data set.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Splitting the data set\nRNGkind(sample.kind = \"Rounding\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in RNGkind(sample.kind = \"Rounding\"): non-uniform 'Rounding' sampler\nused\n```\n:::\n\n```{.r .cell-code}\n# Modeling\n\nset.seed(100) \n\nindex_ins <- sample(x = nrow(insurance) , size = nrow(insurance)*0.8) \nins_train <- insurance[index_ins , ]\nins_test <- insurance[-index_ins, ]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Building Model (all variables)\nmodel_all <- lm(formula = expenses ~ . , data = ins_train)\nsummary(model_all)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = expenses ~ ., data = ins_train)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-10564  -2842   -976   1363  30402 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     -12157.96    1103.69 -11.016  < 2e-16 ***\nage                254.36      13.19  19.282  < 2e-16 ***\nsexmale            -65.82     368.74  -0.179  0.85836    \nbmi                345.97      31.77  10.891  < 2e-16 ***\nchildren           463.26     151.97   3.048  0.00236 ** \nsmokeryes        23452.86     457.46  51.268  < 2e-16 ***\nregionnorthwest   -155.81     533.18  -0.292  0.77018    \nregionsoutheast  -1001.55     533.88  -1.876  0.06093 .  \nregionsouthwest  -1187.37     530.59  -2.238  0.02544 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5998 on 1061 degrees of freedom\nMultiple R-squared:  0.7476,\tAdjusted R-squared:  0.7457 \nF-statistic: 392.8 on 8 and 1061 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n\nForm the first model, it can be seen that the most significant variables are age, bmi, and smoker. Which is in accordance to our previous statement. As can be seen from the model summary, the adjusted R-squared is 0.7457. That means based on the predictor variables included in the model, 74.57% of them are able to explain the charges variable, the rest was explained by other variables that were not included in the model.\n\nNext, we are going to do ‘Feature Selection’. Feature selection is the stage in selecting the variables to be used in the model. This process will evaluate the stepwise model using the AIC (Akaike Information Criterion/ Information Loss) value. AIC shows a lot of missing information on the model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Feature Selection (backward)\nmodel_backward <- step(object = model_all, direction = \"backward\", trace = 0)\nsummary(model_backward)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = expenses ~ age + bmi + children + smoker + region, \n    data = ins_train)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-10596  -2835   -977   1375  30373 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     -12180.42    1095.99 -11.114  < 2e-16 ***\nage                254.37      13.19  19.292  < 2e-16 ***\nbmi                345.68      31.71  10.901  < 2e-16 ***\nchildren           462.28     151.80   3.045  0.00238 ** \nsmokeryes        23447.04     456.08  51.410  < 2e-16 ***\nregionnorthwest   -153.79     532.81  -0.289  0.77292    \nregionsoutheast  -1002.27     533.62  -1.878  0.06062 .  \nregionsouthwest  -1187.63     530.35  -2.239  0.02534 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5995 on 1062 degrees of freedom\nMultiple R-squared:  0.7476,\tAdjusted R-squared:  0.7459 \nF-statistic: 449.3 on 7 and 1062 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n\n\nNow, we will compare the two models we have produced. Too see if this action affect our model, we can check the Adjusted R-Squared value from our two previous models. The first model with complete variables has adjusted R-squared of 0.7457, meaning that the model can explain 74.57% of variance in the target variable (insurance charges). Meanwhile, our simpler model has adjusted R-squared of 74.59%. Which is not a big difference compared to the first model. This shows that it is safe to remove variables that has no significant coefficient values.\n\nThus, we are going to use the second model, which gives the formula:\ny^=−12178.81+254.39∗xage+345.64∗xbmi+462.07∗xchildren+23448.18∗xsmokeryes−154.11∗xregionnorthwest−1001.87∗xregionsoutheast−1188.67∗xregionsouthwest\n\nNotes:\n\nx_{smokeryes} will be “1” if the beneficiary smokes and “0” if they didn’t\nx_{regionnorthwest} will be “1” if beneficiary’s residential area is in northwest and “0” if it isn’t\nx_{regionsoutheast} will be “1” if beneficiary’s residential area is in southeast and “0” if it isn’t\nx_{regionsouthwest} will be “1” if beneficiary’s residential area is in southwest and “0” if it isn’t\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Building Model (all variables)\n\nmodel_all <- lm(formula = expenses ~ . , data = ins_train)\nsummary(model_all)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = expenses ~ ., data = ins_train)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-10564  -2842   -976   1363  30402 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     -12157.96    1103.69 -11.016  < 2e-16 ***\nage                254.36      13.19  19.282  < 2e-16 ***\nsexmale            -65.82     368.74  -0.179  0.85836    \nbmi                345.97      31.77  10.891  < 2e-16 ***\nchildren           463.26     151.97   3.048  0.00236 ** \nsmokeryes        23452.86     457.46  51.268  < 2e-16 ***\nregionnorthwest   -155.81     533.18  -0.292  0.77018    \nregionsoutheast  -1001.55     533.88  -1.876  0.06093 .  \nregionsouthwest  -1187.37     530.59  -2.238  0.02544 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5998 on 1061 degrees of freedom\nMultiple R-squared:  0.7476,\tAdjusted R-squared:  0.7457 \nF-statistic: 392.8 on 8 and 1061 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_3 <-lm(expenses ~ age + smoker, data =insurance)\nsummary(model_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = expenses ~ age + smoker, data = insurance)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-16088.1  -2046.8  -1336.4   -212.7  28760.0 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -2391.63     528.30  -4.527 6.52e-06 ***\nage           274.87      12.46  22.069  < 2e-16 ***\nsmokeryes   23855.30     433.49  55.031  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6397 on 1335 degrees of freedom\nMultiple R-squared:  0.7214,\tAdjusted R-squared:  0.721 \nF-statistic:  1728 on 2 and 1335 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n\nModel 3 has Multiple R-squared:  0.7214,\tAdjusted R-squared:  0.721 \nF-statistic:  1728 on 2 and 1335 DF,  p-value: < 2.2e-16.\n\nThis model explains about 72.1% of the variance for the target variable. \n\nModel Performance\n\nThe prediction will originally run on the test data set. But we will predict based on the train data set as well to check whether or not our model is over-fitted.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prediction of train data set\npred <- predict(model_backward, newdata = ins_train)\nins_train$prediction <- pred\n\n\n# Error on the train data set prediction\nMAPE(y_pred = ins_train$prediction, y_true = ins_train$expenses)*100\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 42.98898\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prediction of test data set\nprediction <- predict(model_backward, newdata = ins_test)\nins_test$prediction <- prediction\n\n\n# Error on the train data set prediction\nMAPE(y_pred = ins_test$prediction, y_true = ins_test$expenses)*100\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 38.73763\n```\n:::\n:::\n\n\nBased on the prediction’s error, we can conclude that the model is not overfit. As can be seen from the MAPE of test data set prediction, the error percentage is around 38.7% ; which is quite high.\n\n\n\nPrediction Result\n\nHere are the prediction result of the test data set, with prediction is the prediction of the insurance charges, and charges is the actual insurance charges.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatatable(ins_test)\n```\n\n::: {.cell-output-display}\n```{=html}\n<div class=\"datatables html-widget html-fill-item-overflow-hidden html-fill-item\" id=\"htmlwidget-685ebf1c1fb8dc3daa51\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-685ebf1c1fb8dc3daa51\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\",\"151\",\"152\",\"153\",\"154\",\"155\",\"156\",\"157\",\"158\",\"159\",\"160\",\"161\",\"162\",\"163\",\"164\",\"165\",\"166\",\"167\",\"168\",\"169\",\"170\",\"171\",\"172\",\"173\",\"174\",\"175\",\"176\",\"177\",\"178\",\"179\",\"180\",\"181\",\"182\",\"183\",\"184\",\"185\",\"186\",\"187\",\"188\",\"189\",\"190\",\"191\",\"192\",\"193\",\"194\",\"195\",\"196\",\"197\",\"198\",\"199\",\"200\",\"201\",\"202\",\"203\",\"204\",\"205\",\"206\",\"207\",\"208\",\"209\",\"210\",\"211\",\"212\",\"213\",\"214\",\"215\",\"216\",\"217\",\"218\",\"219\",\"220\",\"221\",\"222\",\"223\",\"224\",\"225\",\"226\",\"227\",\"228\",\"229\",\"230\",\"231\",\"232\",\"233\",\"234\",\"235\",\"236\",\"237\",\"238\",\"239\",\"240\",\"241\",\"242\",\"243\",\"244\",\"245\",\"246\",\"247\",\"248\",\"249\",\"250\",\"251\",\"252\",\"253\",\"254\",\"255\",\"256\",\"257\",\"258\",\"259\",\"260\",\"261\",\"262\",\"263\",\"264\",\"265\",\"266\",\"267\",\"268\"],[32,46,25,23,56,23,22,19,19,60,31,41,55,60,48,58,25,64,28,40,58,31,55,64,28,61,19,55,52,49,37,44,18,26,32,53,26,29,51,53,19,40,48,18,42,32,38,26,30,36,56,18,64,60,28,35,63,26,24,34,23,55,18,54,27,19,19,41,25,30,55,46,46,59,18,28,58,43,26,34,29,56,62,46,46,46,56,44,18,20,19,48,33,47,19,48,59,56,24,62,56,27,19,61,45,50,42,46,18,57,37,54,54,28,34,50,49,62,22,32,58,42,51,19,51,30,37,59,58,53,19,33,42,39,32,55,49,40,26,21,50,49,24,60,60,51,49,45,27,31,50,19,64,24,47,57,41,40,53,19,23,26,64,36,41,28,59,57,61,49,20,38,57,61,26,42,21,51,36,47,63,32,18,50,19,57,62,45,18,50,18,19,37,51,52,50,34,22,45,34,27,43,34,63,48,28,48,38,59,18,20,22,64,24,21,54,60,62,22,50,51,52,29,50,33,46,34,39,60,18,43,30,41,38,37,46,38,41,56,52,45,37,45,32,41,55,57,39,47,18,36,58,18,33,43,25,41,42,19,18,19,39,31,42,31,23,52,57],[\"male\",\"female\",\"male\",\"male\",\"female\",\"male\",\"male\",\"female\",\"male\",\"male\",\"female\",\"male\",\"male\",\"female\",\"male\",\"female\",\"male\",\"male\",\"female\",\"male\",\"male\",\"male\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"male\",\"female\",\"female\",\"male\",\"male\",\"female\",\"female\",\"female\",\"male\",\"female\",\"female\",\"female\",\"male\",\"female\",\"male\",\"male\",\"female\",\"female\",\"male\",\"female\",\"female\",\"female\",\"female\",\"male\",\"female\",\"female\",\"female\",\"male\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"male\",\"male\",\"male\",\"male\",\"male\",\"male\",\"male\",\"male\",\"female\",\"male\",\"female\",\"female\",\"male\",\"female\",\"male\",\"male\",\"female\",\"male\",\"male\",\"female\",\"male\",\"male\",\"male\",\"male\",\"female\",\"male\",\"male\",\"male\",\"female\",\"male\",\"female\",\"female\",\"male\",\"male\",\"female\",\"male\",\"male\",\"female\",\"male\",\"male\",\"male\",\"female\",\"male\",\"female\",\"male\",\"male\",\"male\",\"male\",\"male\",\"female\",\"male\",\"male\",\"male\",\"male\",\"female\",\"female\",\"male\",\"female\",\"female\",\"female\",\"male\",\"female\",\"female\",\"male\",\"male\",\"male\",\"male\",\"male\",\"female\",\"male\",\"male\",\"male\",\"female\",\"female\",\"female\",\"male\",\"female\",\"female\",\"female\",\"male\",\"female\",\"male\",\"male\",\"female\",\"female\",\"male\",\"male\",\"female\",\"male\",\"male\",\"male\",\"male\",\"female\",\"female\",\"male\",\"male\",\"male\",\"female\",\"male\",\"male\",\"female\",\"male\",\"male\",\"female\",\"female\",\"female\",\"male\",\"female\",\"female\",\"female\",\"male\",\"male\",\"female\",\"male\",\"female\",\"female\",\"female\",\"male\",\"male\",\"female\",\"male\",\"male\",\"female\",\"female\",\"female\",\"female\",\"male\",\"female\",\"female\",\"male\",\"male\",\"male\",\"male\",\"female\",\"female\",\"female\",\"female\",\"male\",\"female\",\"male\",\"male\",\"female\",\"male\",\"male\",\"male\",\"female\",\"male\",\"male\",\"male\",\"male\",\"male\",\"female\",\"male\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"female\",\"male\",\"female\",\"male\",\"male\",\"male\",\"female\",\"male\",\"female\",\"female\",\"male\",\"female\",\"male\",\"male\",\"female\",\"female\",\"male\",\"male\",\"male\",\"female\",\"male\",\"female\",\"male\",\"female\",\"female\",\"male\",\"male\",\"female\",\"female\",\"female\",\"male\",\"male\",\"male\",\"male\",\"female\",\"male\",\"male\",\"female\",\"male\",\"female\",\"female\",\"male\",\"female\",\"male\",\"female\",\"male\",\"female\"],[28.9,33.4,26.2,34.4,39.8,17.4,35.6,28.6,20.4,39.9,36.6,21.8,37.3,24.5,28,31.8,33.7,24.7,25.9,26.3,32,26.9,27,31.3,37.6,29.9,28.4,29.7,32.2,27.2,23.4,37.1,23.8,28.8,17.8,35.9,32.5,38.8,37.7,37.4,28.4,25.5,24.4,25.2,26.6,29.8,27.8,29.9,30.9,26.2,26.6,34.4,39.3,24,28.9,27.7,31.8,29.9,23.2,33.7,36.7,26.8,17.3,34.2,30.3,31.9,37,37.1,27.6,27.6,32.4,26.6,48.1,36.8,23,27.5,34.9,36,29.6,30.8,27.2,28.8,30,33.3,27.6,43.9,32.3,32,30.4,33.3,37.4,31.4,24.3,23.6,17.5,30.2,36.5,26.7,23.4,38.1,25.9,32.7,28.7,25.1,30.5,27.4,26.1,39.4,25.5,42.1,36.2,47.4,30.2,35.4,34.2,44.8,31.9,36.9,26.8,23.7,29,29.5,31.6,28.3,34.1,37.8,34.1,28.8,38,36.1,24.5,42.4,28.3,26.2,31.5,40.8,23.2,41.7,40.2,34.9,44.7,28.7,22.6,28.9,24.3,40.7,34.8,24,29.2,26.6,26.4,21.8,37.9,33.6,27.8,31.8,34.2,32.3,20.9,36.6,37.1,17.7,31.8,28,30.8,23.8,31.4,29.8,32.3,23.8,29.6,28,43.7,23.7,29.5,24.9,22.1,37.1,30,38.9,39.8,24.6,31.7,32.1,23.4,20.1,39.2,35.3,23.2,46.1,40.2,22.6,34.2,42.9,36.8,28.2,23.6,20.2,40,21.4,30.6,30.1,34.7,36.9,29.6,29.3,32.3,27.6,25.5,23.3,30.7,52.6,26.4,39.5,31.3,28.9,18.3,30.5,30.4,33.7,35,30.9,38.9,26.2,35.8,38.2,32.8,23.9,32.8,30.3,34.6,38.8,28.3,29.3,24.3,34.6,30.2,23.9,34.4,34.5,27.8,22.7,25.7,33.6,28.1,30.5,23.7,29.9,27.6,21.7,25.9,25.2,26.1,27.5,27.8,30.2,32.2,26.3,34.7,28.3,20.6,26.3,31.1,40.4,25.9,24.2,38.6,25.7],[0,1,0,0,0,1,0,5,0,0,2,1,0,0,1,2,4,1,1,1,1,1,0,2,1,3,1,2,3,0,2,2,0,0,2,2,1,3,1,1,1,1,0,0,0,2,2,2,3,0,1,0,0,0,1,2,0,1,0,1,2,1,2,2,3,0,0,2,0,1,1,1,2,1,0,2,0,3,4,0,0,0,0,1,0,3,3,2,3,0,0,1,0,1,0,2,1,1,0,2,0,0,0,0,2,0,1,1,0,1,0,0,0,0,0,1,5,1,0,1,0,2,0,0,0,2,4,0,0,1,1,5,3,1,1,3,2,0,0,0,0,3,0,0,1,0,1,2,0,0,0,0,0,4,0,0,2,2,0,0,3,0,2,1,3,2,0,0,2,3,0,3,1,0,1,0,0,3,0,2,3,0,0,2,2,1,0,0,0,1,0,0,1,2,2,3,0,0,3,0,1,3,0,0,0,2,1,0,0,1,0,1,0,0,0,2,0,2,0,4,2,0,1,2,1,2,1,5,0,0,1,1,1,2,2,1,3,1,0,3,2,3,3,1,1,0,0,1,2,0,1,0,0,2,0,0,2,1,2,1,0,2,3,2,1,2,2,2],[\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"no\",\"yes\",\"no\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"yes\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"yes\",\"yes\",\"yes\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"yes\",\"yes\",\"no\",\"yes\",\"yes\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"yes\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"no\",\"yes\",\"no\",\"yes\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"yes\",\"yes\",\"no\",\"no\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"no\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"no\",\"no\",\"no\",\"yes\",\"yes\",\"no\",\"no\",\"yes\",\"no\",\"yes\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"yes\",\"no\",\"yes\",\"yes\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"yes\",\"yes\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"yes\",\"yes\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"yes\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"no\",\"no\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"no\",\"no\",\"yes\",\"yes\",\"yes\",\"no\",\"no\",\"no\",\"no\",\"yes\",\"yes\",\"no\",\"no\",\"yes\",\"no\",\"no\",\"no\",\"no\",\"yes\",\"no\",\"no\",\"no\",\"no\"],[\"northwest\",\"southeast\",\"northeast\",\"southwest\",\"southeast\",\"northwest\",\"southwest\",\"southwest\",\"northwest\",\"southwest\",\"southeast\",\"southeast\",\"southwest\",\"southeast\",\"southwest\",\"northeast\",\"southeast\",\"northwest\",\"northwest\",\"northwest\",\"southeast\",\"northeast\",\"northwest\",\"southwest\",\"southeast\",\"southeast\",\"southwest\",\"southwest\",\"northeast\",\"southeast\",\"northwest\",\"southwest\",\"northeast\",\"northeast\",\"northwest\",\"southwest\",\"northeast\",\"southeast\",\"southeast\",\"northwest\",\"southwest\",\"northeast\",\"southeast\",\"northeast\",\"northwest\",\"southwest\",\"northwest\",\"southeast\",\"southwest\",\"southwest\",\"northwest\",\"southeast\",\"northeast\",\"northwest\",\"northeast\",\"northeast\",\"southwest\",\"southeast\",\"southeast\",\"southwest\",\"northeast\",\"southwest\",\"northeast\",\"southeast\",\"southwest\",\"northwest\",\"northwest\",\"northwest\",\"northwest\",\"northeast\",\"northeast\",\"southeast\",\"northeast\",\"northeast\",\"northeast\",\"southwest\",\"northeast\",\"southeast\",\"northeast\",\"southwest\",\"southwest\",\"northeast\",\"northwest\",\"northeast\",\"southwest\",\"southeast\",\"northeast\",\"northwest\",\"northeast\",\"southeast\",\"northwest\",\"northeast\",\"southeast\",\"southwest\",\"northwest\",\"southwest\",\"southeast\",\"northwest\",\"southwest\",\"northeast\",\"northeast\",\"southeast\",\"southwest\",\"southeast\",\"northwest\",\"northeast\",\"southeast\",\"northeast\",\"northeast\",\"southeast\",\"southeast\",\"southeast\",\"northwest\",\"northeast\",\"southeast\",\"southeast\",\"southwest\",\"northeast\",\"southeast\",\"southeast\",\"southwest\",\"southeast\",\"northwest\",\"northwest\",\"southeast\",\"southwest\",\"southwest\",\"northwest\",\"southwest\",\"southwest\",\"northwest\",\"southwest\",\"northwest\",\"northwest\",\"northeast\",\"southeast\",\"northwest\",\"southeast\",\"northwest\",\"southeast\",\"northeast\",\"northwest\",\"southwest\",\"southwest\",\"northwest\",\"northeast\",\"northwest\",\"northeast\",\"southeast\",\"southeast\",\"northwest\",\"northwest\",\"northwest\",\"northeast\",\"southeast\",\"northwest\",\"northwest\",\"northwest\",\"southeast\",\"northwest\",\"southwest\",\"northwest\",\"northeast\",\"northeast\",\"northeast\",\"northwest\",\"northwest\",\"southeast\",\"northwest\",\"northeast\",\"southwest\",\"southwest\",\"southwest\",\"northeast\",\"southeast\",\"southeast\",\"northeast\",\"northeast\",\"northwest\",\"southeast\",\"southwest\",\"southwest\",\"northeast\",\"northeast\",\"southwest\",\"southwest\",\"southeast\",\"southwest\",\"southeast\",\"southeast\",\"northeast\",\"northwest\",\"northeast\",\"southeast\",\"northwest\",\"southeast\",\"northeast\",\"northwest\",\"northeast\",\"northeast\",\"northeast\",\"northwest\",\"northeast\",\"southeast\",\"southwest\",\"northeast\",\"northwest\",\"southwest\",\"northwest\",\"southeast\",\"northeast\",\"southeast\",\"northeast\",\"southeast\",\"northwest\",\"northeast\",\"northeast\",\"northwest\",\"northwest\",\"southwest\",\"northeast\",\"northeast\",\"southeast\",\"northwest\",\"southeast\",\"southeast\",\"southwest\",\"southeast\",\"southwest\",\"northeast\",\"northwest\",\"southeast\",\"northwest\",\"northwest\",\"northwest\",\"southwest\",\"northwest\",\"northeast\",\"southeast\",\"northwest\",\"southeast\",\"northeast\",\"southwest\",\"northeast\",\"southeast\",\"southwest\",\"southwest\",\"northeast\",\"northwest\",\"northeast\",\"southwest\",\"northeast\",\"northeast\",\"northwest\",\"southwest\",\"southwest\",\"southwest\",\"northwest\",\"southwest\",\"northeast\",\"southwest\",\"northwest\",\"northwest\",\"southeast\",\"northwest\",\"northeast\",\"southwest\",\"southeast\"],[3866.86,8240.59,2721.32,1826.84,11090.72,2775.19,35585.58,4687.8,1625.43,48173.36,4949.76,6272.48,20630.28,12629.9,23568.27,13607.37,4504.66,30166.62,4133.64,6389.38,11946.63,4441.21,11082.58,47291.06,3766.88,30942.19,2331.52,11881.36,11488.32,8601.33,6686.43,7740.34,1705.62,3385.4,32734.19,11163.57,3490.55,5138.26,9877.61,10959.69,1842.52,7077.19,21223.68,15518.18,21348.71,5152.13,6455.86,3981.98,5325.65,4883.87,12044.34,1137.47,14901.52,13012.21,4337.74,20984.09,13880.95,3392.98,25081.77,5012.47,38511.63,35160.13,12829.46,44260.75,4260.74,33750.29,36219.41,7265.7,2523.17,4237.13,11879.1,7742.11,9432.93,47896.79,1704.57,20177.67,11944.59,42124.52,24671.66,35491.64,2866.09,11658.38,13352.1,8334.46,24603.05,8944.12,13430.27,8116.27,3481.87,1391.53,2138.07,8964.06,4185.1,8539.67,1621.34,8968.33,28287.9,26109.33,1969.61,15230.32,11165.42,2497.04,1253.94,24513.09,8413.46,25656.58,38245.59,8342.91,1708,48675.52,19214.71,63770.43,10231.5,3268.85,3935.18,9058.73,11552.9,31620,1665,17626.24,11842.44,7640.31,9174.14,17468.98,9283.56,39241.44,40182.25,12129.61,11365.95,10085.85,2709.11,6666.24,32787.46,6123.57,5148.55,12485.8,10156.78,5438.75,3201.25,2020.55,9541.7,10264.44,2457.5,12146.97,13112.6,9875.68,9583.89,8604.48,18246.5,3757.84,8827.21,1627.28,14210.54,17128.43,23065.42,11842.62,7261.74,6986.7,21195.82,2136.88,3597.6,2680.95,16069.08,20773.63,39597.41,4719.74,12622.18,27533.91,14119.62,24106.91,1875.34,7151.09,11576.13,13129.6,3392.37,5966.89,2585.85,46255.11,5272.18,44202.65,15170.07,17496.31,33732.69,25333.33,2913.57,12032.33,13470.8,7348.14,1121.87,9549.57,2217.47,1628.47,39047.29,47462.89,26467.1,10702.64,4992.38,2527.82,9704.67,4500.34,16796.41,8410.05,4518.83,13887.97,21232.18,4438.26,8765.25,5383.54,12124.99,1711.03,33475.82,44501.4,14394.56,2480.98,1909.53,12096.65,13204.29,15019.76,33907.55,11299.34,44641.2,23045.57,3471.41,10493.95,38282.75,8347.16,14358.36,8582.3,52590.83,2203.74,7727.25,18963.17,7153.55,6457.84,6198.75,41661.6,7537.16,6858.48,10594.23,60021.4,8515.76,6985.51,9101.8,37607.53,6770.19,10704.47,10959.33,22462.04,24535.7,14283.46,5472.45,11931.13,1708.93,5261.47,37829.72,33900.65,6875.96,6940.91,36397.58,11272.33,1731.68,7201.7,5425.02,43896.38,4239.89,22395.74,10325.21,12629.17],[5795.84703994632,10526.3877030861,3235.70000780091,4373.92089921138,14820.1762476937,-6.54958225637,27981.4043915862,3662.87549225532,-449.262493618537,39133.9041385587,8279.2955461521,5244.62542369032,13516.244708631,10548.7222015611,32430.1241513588,14490.2918429751,6675.15299479116,12946.1067624671,4203.59845808685,7394.31350295835,13094.8751252819,5466.17673907964,10989.5655090231,38103.0759819184,7399.58879624741,37503.6451277838,1744.62627955907,11813.6178179775,13564.6217306421,8683.99158239487,6091.00330901134,11573.5926580201,625.471870997711,4388.8434272074,26330.3683691116,13448.1059227773,6130.14507636275,8993.33380310562,13284.6712905194,14538.196269277,1744.62627955907,7271.55360131733,30908.7470243792,24556.4619525447,30991.5155414092,5997.67172622507,7866.37435109354,4691.37512848458,6331.45976932121,4846.14082239612,11567.9410931809,3287.42628686383,17684.5716522851,11224.3704044938,5394.43020431675,30669.5165622231,13649.9551325658,4229.0969259404,942.008865686812,7392.29374611698,30728.2124357691,10348.8617789003,22750.130458112,36747.2082728404,5360.94000180453,26973.1159151644,28736.0941794122,11844.3276282094,3565.86911700049,5453.78396124527,13472.3122880314,8175.75001742237,17072.4664084838,39457.8291539821,348.92626091962,4185.12235063975,14637.3496769394,35033.6420448805,6514.50184746222,29374.5729709501,3411.2315284248,12019.9490267885,13807.2028533848,11494.0944194949,7873.79750655983,15080.6052404494,14616.6706785127,10844.4599239197,4293.80776177449,3415.91644631187,5427.33172054086,11346.0389688649,3611.59075941853,7207.71784536627,-1451.74033015161,10205.8675177074,14904.8143686239,35049.544558351,825.788947290357,17685.5692689509,11017.4711902555,4989.09854532223,1386.05268079417,11010.5015957723,10580.307091676,10009.7730892357,30432.4635284231,13602.7546963404,1213.13129241365,39778.9285297754,8742.68745594092,40385.6544340405,11841.3777626827,7179.08508365704,7288.21287078758,15484.6433933097,12434.7317334086,16808.4726512896,1677.7237377328,3612.08956775144,11410.1945640289,8623.02530988881,11562.2220203613,25728.6606698129,11577.9378426238,31701.4227176109,33127.546982657,12629.2738783096,14521.3326774074,13054.9641227526,1430.31196057585,11994.4698792402,32966.0095704577,7105.37511504588,7310.68418368136,16298.3226812712,9074.30914632428,11407.0490851859,8175.8326623831,4223.37785312075,15990.0719071743,11437.8384181553,549.243337212268,11884.3667360746,11790.3532108172,14861.7140434366,12621.9422899124,8487.15971822862,27226.2467651409,3897.91901508762,9510.30536820097,34.6923240181195,17046.8311262114,7388.48952454726,31829.6956805584,13157.579542797,10841.8497916764,9930.6837810882,30970.7109135511,5150.78611046277,6694.09694085747,397.987378936845,16016.5129628914,30565.3131501109,33729.6301237361,3939.94443417605,13528.0471110634,35064.7615722807,15272.457700795,33344.8175287745,1951.53667878473,7363.94342600978,16699.6281651053,11528.8216958042,4090.82412090135,6108.33164685143,800.923009539884,38451.1286696281,7193.57800041451,36591.3224254802,17802.2458409792,26722.6041195395,26803.3950344292,12559.0349535328,478.494419115197,8541.53266780167,16138.9881600514,10281.1788169087,-584.212254229415,15934.0300096866,6294.65687759854,311.237934096209,32962.9118148688,38991.5312224815,14538.6950776099,10670.8783892777,4626.25845492146,244.711663820055,14480.3501223346,3865.75802720672,5727.71943907999,10395.5721158757,8463.32879475495,15598.2897177296,9073.90190506046,5994.98121189998,11503.3670717657,5838.83601333819,11488.5232367375,-87.3658504254726,26966.453395137,34505.6331292057,13225.2736897759,6576.62567102787,3827.41181700084,12470.3332598313,9407.76864112444,14904.600264772,27217.703456226,12849.0513401928,37262.9182406289,11728.4005066327,8103.34559927701,10365.7253707698,31496.2473707456,12647.9395660988,7081.17993477913,7310.93008701662,36679.5618491156,2872.40495288218,11026.5847674766,8323.14758466996,8340.04771480627,8384.89736998996,6402.11712034919,34202.8850611976,9158.28938387199,6972.83256781386,12953.4933796666,37652.9399150899,8798.47644843099,6465.08981117427,8349.4661036042,31483.6516740467,7422.42210305527,11165.6070229672,9323.70971060889,31985.2195340045,33533.6048923587,23346.5749084531,5204.71442116102,11284.2341547425,1420.54049997222,6490.81881405073,30626.8586130316,26877.8320835172,9116.64023633368,7903.05387626376,27831.7364253786,2643.31913023114,-1413.97162124648,7602.22151884983,7688.81188864091,35837.9945111131,4966.70901804496,2960.15201438864,14127.0771701381,11124.9864618085]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>age<\\/th>\\n      <th>sex<\\/th>\\n      <th>bmi<\\/th>\\n      <th>children<\\/th>\\n      <th>smoker<\\/th>\\n      <th>region<\\/th>\\n      <th>expenses<\\/th>\\n      <th>prediction<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,3,4,7,8]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n:::\n:::\n\n\n\nModel Assumption\n\nLinear regression is an analysis that assesses whether one or more predictor variables explain the dependent (criterion) variable. The regression has five key assumptions: Linear relationship, Multivariate normality, No or little multicollinearity, No auto-correlation and Homoscedasticity. Next we are going to see whether or not our model fulfilled these certain assumptions.\n\n1. Linearity\nFirst, linear regression needs the relationship between the independent and dependent variables to be linear. It is also important to check for outliers since linear regression is sensitive to outlier effects. The linearity assumption can best be tested with scatter plots.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Linearity Scatter Plot\nresact <- data.frame(residual = model_backward$residuals, fitted = model_backward$fitted.values)\n\nggplot(resact, aes(fitted, residual)) + \n  geom_point(aes(col = \"#D95F02\")) + \n  geom_smooth(aes(col = \"#1B9E77\")) + \n  geom_hline(aes(yintercept = 0)) + \n    theme(panel.grid = element_blank(), panel.background = element_blank()) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n```\n:::\n\n::: {.cell-output-display}\n![](RahulGundeti_DACSS603_FinalProject_HealthInsurancePrediction_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n\n\nBased on our pattern, it can be seen that there’s little to no linearity of our model.\n\n\n2. Normality of Residual\n\nSecondly, the linear regression analysis requires all variables to be multivariate normal. This assumption can best be checked with histogram or the Shapiro test.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(model_backward$residuals, col = \"#1B9E77\")\n```\n\n::: {.cell-output-display}\n![](RahulGundeti_DACSS603_FinalProject_HealthInsurancePrediction_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Shapiro Test\nshapiro.test(model_backward$residuals)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  model_backward$residuals\nW = 0.8975, p-value < 2.2e-16\n```\n:::\n:::\n\n\nBased on the test result, our model does NOT fulfill the normality assumption. Thus, further data transformation will be needed.\n\n\n3. No Multicolinearity\n\nThirdly, linear regression assumes that there is little or no multicollinearity in the data. Multicollinearity occurs when the independent variables are too highly correlated with each other.The presence or absence of multicollinearity can be seen from the value of VIF (Variance Inflation Factor): When the VIF value is more than 10, it means that there is multicollinearity.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvif(model_backward)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             GVIF Df GVIF^(1/(2*Df))\nage      1.011690  1        1.005828\nbmi      1.108901  1        1.053044\nchildren 1.004036  1        1.002016\nsmoker   1.007921  1        1.003953\nregion   1.109869  3        1.017525\n```\n:::\n:::\n\n\nBased on the values of VIF, since all VIF < 10, that means there’s no multicolinearity.\n\n\n4. No Autocorrelation\n\nFourthly, linear regression analysis requires that there is little or no autocorrelation in the data. Autocorrelation occurs when the residuals are not independent from each other. In other words when the value of y(x+1) is not independent from the value of y(x). We can test the linear regression model for autocorrelation with the Durbin-Watson test.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndurbinWatsonTest(model_backward)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n lag Autocorrelation D-W Statistic p-value\n   1      0.04038038      1.915413   0.162\n Alternative hypothesis: rho != 0\n```\n:::\n:::\n\n\nThe result shows that the null hypothesis is not rejected, meaning that our residual has no autocorrelation in it.\n\n\n5. Homoscedasticity of Residual\n\nThe last assumption of the linear regression analysis is homoscedasticity. The scatter plot is good way to check whether the data are homoscedastic (meaning the residuals are equal across the regression line). We can also check it using the Breusch-Pagan test.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(x = model_backward$fitted.values, y = model_backward$residuals, col = \"#1B9E77\")\nabline(h = 0, col = \"#D95F02\", lty = 2)\n```\n\n::: {.cell-output-display}\n![](RahulGundeti_DACSS603_FinalProject_HealthInsurancePrediction_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbptest(model_backward)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tstudentized Breusch-Pagan test\n\ndata:  model_backward\nBP = 102.47, df = 7, p-value < 2.2e-16\n```\n:::\n:::\n\n\n\nBased on the test, Because p-value < alpha, it means that the error variance does NOT spreads randomly or is heteroscedasticity. Thus, further data transformation is needed.\n\nBased on the previous evaluation, we can conclude that the model doesn’t fulfill some of the assumptions, such as Linearity, Normality of Residual, and Homoscedasticity of Residual. Which indicates that further data transformation might be needed. However, after doing data transformation (scaling) and re-building the model, unfortunately, it didn’t improve the model and the model still didn’t fulfill those three assumptions. Which means this data set might not be large enough and there aren’t enough predictors to explain the target variables.\n\nIt is important to notice that, these assumption only need to be fulfilled if the purpose of making the linear regression model is to interpret or to see the effect of each predictor on the value of the target variable. If the purpose of the linear regression model is to make predictions, then the model assumptions are not required to be met.\n\n## Conclusion\n\nFrom the 3 models: model_all, model backward and model 3, we can clearly observe that model 3 models are very close and they are in the vicinity of 70% while model-backward performed the best of the 3.\n\n\n",
    "supporting": [
      "RahulGundeti_DACSS603_FinalProject_HealthInsurancePrediction_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/htmlwidgets-1.6.0/htmlwidgets.js\"></script>\r\n<link href=\"../site_libs/datatables-css-0.0.0/datatables-crosstalk.css\" rel=\"stylesheet\" />\r\n<script src=\"../site_libs/datatables-binding-0.26/datatables.js\"></script>\r\n<script src=\"../site_libs/jquery-3.6.0/jquery-3.6.0.min.js\"></script>\r\n<link href=\"../site_libs/dt-core-1.12.1/css/jquery.dataTables.min.css\" rel=\"stylesheet\" />\r\n<link href=\"../site_libs/dt-core-1.12.1/css/jquery.dataTables.extra.css\" rel=\"stylesheet\" />\r\n<script src=\"../site_libs/dt-core-1.12.1/js/jquery.dataTables.min.js\"></script>\r\n<link href=\"../site_libs/crosstalk-1.2.0/css/crosstalk.min.css\" rel=\"stylesheet\" />\r\n<script src=\"../site_libs/crosstalk-1.2.0/js/crosstalk.min.js\"></script>\r\n<link href=\"../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}