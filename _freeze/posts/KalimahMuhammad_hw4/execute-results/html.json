{
  "hash": "6492a62a91f768c5e3f3179db0ede8c1",
  "result": {
    "markdown": "---\ntitle: 'Homework #4'\nauthor: \"Kalimah Muhammad\"\ndate: \"11/14/2022\"\ndesription: \"Homework #4\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories: \n  - hw4\n  - Kalimah Muhammad\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(alr4)\nlibrary(smss)\nknitr::opts_chunk$set(echo = TRUE)\n```\n:::\n\n\n## Question 1\nFor recent data in Jacksonville, Florida, on y = selling price of home (in dollars), x1 = size of home (in square feet), and x2 = lot size (in square feet), the prediction equation is \nŷ = −10,536 + 53.8x1 + 2.84x2.\n\n### 1.A\nA particular home of 1240 square feet on a lot of 18,000 square feet sold for $145,000. Find the predicted selling price and the residual, and interpret.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest <- data.frame(sq=c(1240), lot=c(18000), price=c(145000))\ntest_fit <- lm(price~sq+lot, data=test)\npredict(test_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     1 \n145000 \n```\n:::\n\n```{.r .cell-code}\nsummary(test_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = price ~ sq + lot, data = test)\n\nResiduals:\nALL 1 residuals are 0: no residual degrees of freedom!\n\nCoefficients: (2 not defined because of singularities)\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)   145000        NaN     NaN      NaN\nsq                NA         NA      NA       NA\nlot               NA         NA      NA       NA\n\nResidual standard error: NaN on 0 degrees of freedom\n```\n:::\n:::\n\n\n### 1.B\nFor fixed lot size, how much is the house selling price predicted to increase for each square-foot increase in home size? Why?  The selling price would increase by 2,374.01 for each sqaure foot.\n\n### 1.C\nAccording to this prediction equation, for fixed home size, how much would lot size need to increase to have the same impact as a one-square-foot increase in home size? 2.84.\n\n## Question 2\n(Data file: salary in alr4 R package). The data file concerns salary and other characteristics of all faculty in a small Midwestern college collected in the early 1980s for presentation in legal proceedings for which discrimination against women in salary was at issue. All persons in the data hold tenured or tenure track positions; temporary faculty are not included. The variables include degree, a factor with levels PhD and MS; rank, a factor with levels Asst, Assoc, and Prof; sex, a factor with levels Male and Female; Year, years in current rank; ysdeg, years since highest degree, and salary, academic year salary in dollars.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(salary) #load salary data\n```\n:::\n\n\n### 2.A \nTest the hypothesis that the mean salary for men and women is the same, without regard to any other variable but sex. Explain your findings.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(salary ~ sex, data=salary)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  salary by sex\nt = 1.7744, df = 21.591, p-value = 0.09009\nalternative hypothesis: true difference in means between group Male and group Female is not equal to 0\n95 percent confidence interval:\n -567.8539 7247.1471\nsample estimates:\n  mean in group Male mean in group Female \n            24696.79             21357.14 \n```\n:::\n:::\n\nBased on the above t.test, the average male salary is higher than the average female salary, 24,696.79 to 21,357.14 respectively. \n\n### 2.B\nRun a multiple linear regression with salary as the outcome variable and everything else as predictors, including sex. Assuming no interactions between sex and the other predictors, obtain a 95% confidence interval for the difference in salary between males and females.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalaryfit<-lm(salary ~ degree + rank + sex + year + ysdeg, data=salary)\nsalaryfit\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ degree + rank + sex + year + ysdeg, data = salary)\n\nCoefficients:\n(Intercept)    degreePhD    rankAssoc     rankProf    sexFemale         year  \n    15746.0       1388.6       5292.4      11118.8       1166.4        476.3  \n      ysdeg  \n     -124.6  \n```\n:::\n\n```{.r .cell-code}\nsummary(salaryfit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ degree + rank + sex + year + ysdeg, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4045.2 -1094.7  -361.5   813.2  9193.1 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 15746.05     800.18  19.678  < 2e-16 ***\ndegreePhD    1388.61    1018.75   1.363    0.180    \nrankAssoc    5292.36    1145.40   4.621 3.22e-05 ***\nrankProf    11118.76    1351.77   8.225 1.62e-10 ***\nsexFemale    1166.37     925.57   1.260    0.214    \nyear          476.31      94.91   5.018 8.65e-06 ***\nysdeg        -124.57      77.49  -1.608    0.115    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2398 on 45 degrees of freedom\nMultiple R-squared:  0.855,\tAdjusted R-squared:  0.8357 \nF-statistic: 44.24 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\npairs(salary)\n```\n\n::: {.cell-output-display}\n![](KalimahMuhammad_hw4_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n### 2.C \nInterpret your finding for each predictor variable; discuss (a) statistical significance, (b) interpretation of the coefficient / slope in relation to the outcome variable and other variables.\n\n-MS degree: baseline estimate   \n-PHD degree: increase in estimate   \n-Rank Asst.: significantly lowers estimate, statistically significant   \n-Rank Assoc.: significantly lowers estimate, statistically significant  \n-Rank Prof.: baseline estimate, statistically significant   \n-Female: increase in estimate  \n-Year: statistically significant  \n-Year since degree: minimally lowers estimate  \n\nFrom the pairs graph, we also see an association between rank, year, years since degree, and salary.  \n\n### 2.D\nChange the baseline category for the rank variable. Interpret the coefficients related to rank again.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalary$rank <-relevel(salary$rank, ref=\"Prof\")\nlm(salary ~ rank, data=salary)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ rank, data = salary)\n\nCoefficients:\n(Intercept)     rankAsst    rankAssoc  \n      29659       -11890        -6483  \n```\n:::\n\n```{.r .cell-code}\nsummary(lm(salary ~ rank, data=salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ rank, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5209.0 -1819.2  -417.8  1586.6  8386.0 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  29659.0      669.3  44.316  < 2e-16 ***\nrankAsst    -11890.3      972.4 -12.228  < 2e-16 ***\nrankAssoc    -6483.0     1043.0  -6.216 1.09e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2993 on 49 degrees of freedom\nMultiple R-squared:  0.7542,\tAdjusted R-squared:  0.7442 \nF-statistic: 75.17 on 2 and 49 DF,  p-value: 1.174e-15\n```\n:::\n:::\n\nHere, we can see higher salary associated with higher ranking (Professor compared to Assistant and Associate Professor) based on the estimate and coefficient values.  \n\n### 2.E \nFinkelstein (1980), in a discussion of the use of regression in discrimination cases, wrote, “[a] variable may reflect a position or status bestowed by the employer, in which case if there is discrimination in the award of the position or status, the variable may be ‘tainted.’ ” Thus, for example, if discrimination is at work in promotion of faculty to higher ranks, using rank to adjust salaries before comparing the sexes may not be acceptable to the courts. \n\nExclude the variable rank, refit, and summarize how your findings changed, if they did.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalaryfit2<-lm(salary ~ degree + sex + year + ysdeg, data=salary)\nsalaryfit2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ degree + sex + year + ysdeg, data = salary)\n\nCoefficients:\n(Intercept)    degreePhD    sexFemale         year        ysdeg  \n    17183.6      -3299.3      -1286.5        352.0        339.4  \n```\n:::\n\n```{.r .cell-code}\nsummary(salaryfit2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ degree + sex + year + ysdeg, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8146.9 -2186.9  -491.5  2279.1 11186.6 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 17183.57    1147.94  14.969  < 2e-16 ***\ndegreePhD   -3299.35    1302.52  -2.533 0.014704 *  \nsexFemale   -1286.54    1313.09  -0.980 0.332209    \nyear          351.97     142.48   2.470 0.017185 *  \nysdeg         339.40      80.62   4.210 0.000114 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3744 on 47 degrees of freedom\nMultiple R-squared:  0.6312,\tAdjusted R-squared:  0.5998 \nF-statistic: 20.11 on 4 and 47 DF,  p-value: 1.048e-09\n```\n:::\n:::\n\n\nExcluding rank, variables for degree, year, and years since degree become more significant. \n\n### 2.F\nEveryone in this dataset was hired the year they earned their highest degree. It is also known that a new Dean was appointed 15 years ago, and everyone in the dataset who earned their highest degree 15 years ago or less than that has been hired by the new Dean. Some people have argued that the new Dean has been making offers that are a lot more generous to newly hired faculty than the previous one and that this might explain some of the variation in Salary.\n\nCreate a new variable that would allow you to test this hypothesis and run another multiple regression model to test this. Select variables carefully to make sure there is no multicollinearity. Explain why multicollinearity would be a concern in this case and how you avoided it. Do you find support for the hypothesis that the people hired by the new Dean are making higher than those that were not?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalary2 <- salary%>%\n  mutate(new_dean= year<'16') #create column determining if new dean present\n\nt.test(salary ~ new_dean, data=salary2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  salary by new_dean\nt = -0.55774, df = 39.995, p-value = 0.5801\nalternative hypothesis: true difference in means between group FALSE and group TRUE is not equal to 0\n95 percent confidence interval:\n -4337.222  2461.145\nsample estimates:\nmean in group FALSE  mean in group TRUE \n           23454.91            24392.95 \n```\n:::\n\n```{.r .cell-code}\nsummary(lm(salary ~ new_dean, data=salary2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ new_dean, data = salary2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9392.9 -5208.2   264.1  3441.8 14590.1 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     23455       1037  22.613   <2e-16 ***\nnew_deanTRUE      938       1716   0.547    0.587    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5958 on 50 degrees of freedom\nMultiple R-squared:  0.005941,\tAdjusted R-squared:  -0.01394 \nF-statistic: 0.2988 on 1 and 50 DF,  p-value: 0.587\n```\n:::\n:::\n\n\nBased on the two-sample t-test and regression model, faculty hired by the new dean 15 years ago have a slightly higher salary than those hired prior. This may be attributed to the rank or experience of those hired under the new dean's tenure so we will perform another model using the interacting term rank and degree.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(salary ~ degree + rank *new_dean, data=salary2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ degree + rank * new_dean, data = salary2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5886.9 -1584.4  -499.6  1538.8  8831.1 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)             29213.89     867.27  33.685  < 2e-16 ***\ndegreePhD                1054.74    1020.26   1.034    0.307    \nrankAsst               -11764.52    1208.79  -9.732 1.21e-12 ***\nrankAssoc               -6958.52    1610.43  -4.321 8.47e-05 ***\nnew_deanTRUE              518.22    1468.73   0.353    0.726    \nrankAsst:new_deanTRUE    -212.54    2189.70  -0.097    0.923    \nrankAssoc:new_deanTRUE    -33.19    2301.23  -0.014    0.989    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3075 on 45 degrees of freedom\nMultiple R-squared:  0.7617,\tAdjusted R-squared:  0.7299 \nF-statistic: 23.97 on 6 and 45 DF,  p-value: 1.663e-12\n```\n:::\n:::\n\n\nOnce controlled for the dean status, faculty hired as Assistant and Associate Professors during the prior dean's tenure were estimated considerably less.\n\n### 3.A\nUsing the house.selling.price data, run and report regression results modeling y = selling price (in dollars) in terms of size of home (in square feet) and whether the home is new (1 = yes; 0 = no). In particular, for each variable; discuss statistical significance and interpret the meaning of the coefficient.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(house.selling.price) #load data\nsummary(lm(Price ~ Size + New, data=house.selling.price))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ Size + New, data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205102  -34374   -5778   18929  163866 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -40230.867  14696.140  -2.738  0.00737 ** \nSize           116.132      8.795  13.204  < 2e-16 ***\nNew          57736.283  18653.041   3.095  0.00257 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 53880 on 97 degrees of freedom\nMultiple R-squared:  0.7226,\tAdjusted R-squared:  0.7169 \nF-statistic: 126.3 on 2 and 97 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nNewness appears as the most statistically significant variable in determining price followed by size.\n\n### 3.B\nReport and interpret the prediction equation, and form separate equations relating selling price to size for new and for not new homes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(Price ~ New*Size, data=house.selling.price))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ New * Size, data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-175748  -28979   -6260   14693  192519 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -22227.808  15521.110  -1.432  0.15536    \nNew         -78527.502  51007.642  -1.540  0.12697    \nSize           104.438      9.424  11.082  < 2e-16 ***\nNew:Size        61.916     21.686   2.855  0.00527 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 52000 on 96 degrees of freedom\nMultiple R-squared:  0.7443,\tAdjusted R-squared:  0.7363 \nF-statistic: 93.15 on 3 and 96 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nOlder homes are estimated less than newer homes but the size of a newer home is the most statistically significant. \n\n### 3.C\nFind the predicted selling price for a home of 3000 square feet that is (i) new, (ii) not new.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nold <- data.frame(Size=c(3000), New = 0)\npredict((lm(Price~Size+New, data=house.selling.price)), old)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n308163.9 \n```\n:::\n\n```{.r .cell-code}\nnew <- data.frame(Size=c(3000), New = 1)\npredict((lm(Price~Size+New, data=house.selling.price)), new)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n365900.2 \n```\n:::\n:::\n\n\n### 3.D\nFit another model, this time with an interaction term allowing interaction between size and new, and report the regression results.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nold <- data.frame(Size=c(3000), New = 0)\npredict((lm(Price~Size*New, data=house.selling.price)), old)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n291087.4 \n```\n:::\n\n```{.r .cell-code}\nnew <- data.frame(Size=c(3000), New = 1)\npredict((lm(Price~Size*New, data=house.selling.price)), new)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n398307.5 \n```\n:::\n:::\n\n\n### 3.E\nReport the lines relating the predicted selling price to the size for homes that are (i) new, (ii) not new.\n\nWhen the interacting term is added both the price of the older home decreases and the price for the newer home increases. This creates a greater range in variability compared to the first model. \n\n### 3.F\nFind the predicted selling price for a home of 3000 square feet that is (i) new, (ii) not new.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nold <- data.frame(Size=c(3000), New = 0)\npredict((lm(Price~Size+New, data=house.selling.price)), old)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n308163.9 \n```\n:::\n\n```{.r .cell-code}\nnew <- data.frame(Size=c(3000), New = 1)\npredict((lm(Price~Size+New, data=house.selling.price)), new)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n365900.2 \n```\n:::\n:::\n\n\nFor an older home, the price for a 3000sq home is predicted at 308,163.90. For a new home, the predicted price would be 365,900.20.\n\n### 3.G\nFind the predicted selling price for a home of 1500 square feet that is (i) new, (ii) not new. Comparing to (F), explain how the difference in predicted selling prices changes as the size of home increases.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nold2 <- data.frame(Size=c(1500), New = 0)\npredict((lm(Price~ Size + New, data=house.selling.price)), old2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n133966.5 \n```\n:::\n\n```{.r .cell-code}\nnew2 <- data.frame(Size=c(1500), New = 1)\npredict((lm(Price~ Size + New, data=house.selling.price)), new2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n191702.8 \n```\n:::\n:::\n\n\nFor an older home, the price for a 1500sq home is predicted at 133,966.50. For a new home, the predicted price would be 191,702.80.\n\nAs the size of the home doubles, the predicted price of both the older and newer home increased by the same value of 174,197.40.\n\n### 3.H\nDo you think the model with interaction or the one without it represents the relationship of size and new to the outcome price? What makes you prefer one model over another?\nThe model that adds whether the home is new rather than multiply by it, is a better model more reflective of the actual rates. \n",
    "supporting": [
      "KalimahMuhammad_hw4_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}