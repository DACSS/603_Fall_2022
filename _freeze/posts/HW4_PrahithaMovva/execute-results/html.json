{
  "hash": "be43464e62ad6cfd8bff1e104b000925",
  "result": {
    "markdown": "---\ntitle: \"Homework 4 - Prahitha Movva\"\nauthor: \"Prahitha Movva\"\ndescription: \"The fourth homework\"\ndate: \"11/17/2022\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - hw4\n  - multiple regression\n  - interaction term\n  - covariance\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'ggplot2' was built under R version 4.2.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\nlibrary(alr4)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: car\nLoading required package: carData\n\nAttaching package: 'car'\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\nThe following object is masked from 'package:purrr':\n\n    some\n\nLoading required package: effects\nlattice theme set by effectsTheme()\nSee ?effectsTheme for details.\n```\n:::\n\n```{.r .cell-code}\nlibrary(smss)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'smss' was built under R version 4.2.2\n```\n:::\n\n```{.r .cell-code}\nknitr::opts_chunk$set(echo=TRUE, warning=FALSE)\n```\n:::\n\n\n\n\n## Question 1\n\n### A\n\nGiven prediction equation: y = -10536 + 53.8x1 + 2.84x2 where x1 is the size of the home (sq ft) and x2 is the lot size (sq ft)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlot.size = 18000\nhome.size = 1240\nactual.price = 145000\n\npredicted.price = -10536 + (53.8*home.size) + (2.84*lot.size)\nprint(predicted.price)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 107296\n```\n:::\n\n```{.r .cell-code}\nresidual = actual.price - predicted.price\nprint(residual)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 37704\n```\n:::\n:::\n\n\nUsing the prediction equation, the value that we get is \\$107,296 and the residual is \\$37,704. The residual tells us that the house was under-priced (under-predicted) by \\$37,704.\n\n\n### B\n\nFor a fixed lot size (say k), our prediction equation becomes y = -10536 + 53.8x1 + 2.84k where x1 (home size) is the only variable. So for each square-foot increase in home size, the house selling price predicted by the model increases by $53.8\n\n\n::: {.cell}\n\n```{.r .cell-code}\ny1 = -10536 + (53.8*1) + 2.84\ny2 = -10536 + (53.8*2) + 2.84\n\ny2 - y1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 53.8\n```\n:::\n:::\n\n\n\n### C\n\nFor a fixed home size (say k), our prediction equation becomes y = -10536 + 53.8k + 2.84x2 where x2 (lot size) is the only variable. So for each square-foot increase in lot size, the house selling price predicted by the model increases by \\$2.84. For this to be equal to \\$53.8 we need to multiply it by 19.94366 - i.e., an increase by 18.94366. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n53.8/2.84\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 18.94366\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ny1 = -10536 + (53.8*1) + 2.84\ny2 = -10536 + (53.8*2) + 2.84\nprint(y2 - y1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 53.8\n```\n:::\n\n```{.r .cell-code}\ny1 = -10536 + (53.8*1) + 2.84\ny2 = -10536 + (53.8*1) + (2.84*(1 + 18.94366))\nprint(y2 - y1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 53.79999\n```\n:::\n:::\n\n\n\n\n## Question 2\n\n### A\n\nH0: Mean salary for men and women is the same\n\nHa: Mean salary for men and women is NOT the same\n\nWe can test this using a two-sample t-test\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(salary)\n\n# testing for variance\nvar.test(salary ~ sex, data=salary)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tF test to compare two variances\n\ndata:  salary by sex\nF = 0.84242, num df = 37, denom df = 13, p-value = 0.6525\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.3015275 1.9189474\nsample estimates:\nratio of variances \n         0.8424225 \n```\n:::\n:::\n\n\nThe p-value of F-test is 0.6525 which is greater than the significance level (alpha = 0.05). So we can say that there is no significant difference between the variances of the two sets of data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(salary ~ sex, data=salary, var.equal=TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tTwo Sample t-test\n\ndata:  salary by sex\nt = 1.8474, df = 50, p-value = 0.0706\nalternative hypothesis: true difference in means between group Male and group Female is not equal to 0\n95 percent confidence interval:\n -291.257 6970.550\nsample estimates:\n  mean in group Male mean in group Female \n            24696.79             21357.14 \n```\n:::\n:::\n\n\nThe p-value of t-test is 0.0706 which is greater than the significance level (alpha = 0.05). So we can say that there is no significant difference in the mean salary between male and female faculty (at a 5% significance level).\n\n\n### B\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel = lm(salary ~ degree + rank + sex + year + ysdeg, data=salary)\nconfint(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 2.5 %      97.5 %\n(Intercept) 14134.4059 17357.68946\ndegreePhD    -663.2482  3440.47485\nrankAssoc    2985.4107  7599.31080\nrankProf     8396.1546 13841.37340\nsexFemale    -697.8183  3030.56452\nyear          285.1433   667.47476\nysdeg        -280.6397    31.49105\n```\n:::\n:::\n\n\nFrom sexFemale, we can say that the 95% confidence interval for the difference in salary between males and females is [-697.8183, 3030.56452]\n\n\n### C\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ degree + rank + sex + year + ysdeg, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4045.2 -1094.7  -361.5   813.2  9193.1 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 15746.05     800.18  19.678  < 2e-16 ***\ndegreePhD    1388.61    1018.75   1.363    0.180    \nrankAssoc    5292.36    1145.40   4.621 3.22e-05 ***\nrankProf    11118.76    1351.77   8.225 1.62e-10 ***\nsexFemale    1166.37     925.57   1.260    0.214    \nyear          476.31      94.91   5.018 8.65e-06 ***\nysdeg        -124.57      77.49  -1.608    0.115    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2398 on 45 degrees of freedom\nMultiple R-squared:  0.855,\tAdjusted R-squared:  0.8357 \nF-statistic: 44.24 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n#### (a)\nAt a 95% confidence level, only rank and year are (statistically) significant predictors of salary. \n\n#### (b)\nSince we now know that rank and year are the significant variables, we will only consider those for interpretation. Associate Professors (rankAssoc) and Full Professors (rankProf) earn more than Assistant Professors (baseline category) by \\$5292.36 and \\$11118.76 respectively. Similarly, professors with more working experience (year) earn more. However, rank has a higher effect on salary than year as the coefficient for rank is much higher.\n\n\n### D\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalary$rank <- relevel(salary$rank, ref='Assoc')\nmodel.modified = lm(salary ~ degree + rank + sex + year + ysdeg, data=salary)\nsummary(model.modified)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ degree + rank + sex + year + ysdeg, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4045.2 -1094.7  -361.5   813.2  9193.1 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 21038.41    1109.12  18.969  < 2e-16 ***\ndegreePhD    1388.61    1018.75   1.363    0.180    \nrankAsst    -5292.36    1145.40  -4.621 3.22e-05 ***\nrankProf     5826.40    1012.93   5.752 7.28e-07 ***\nsexFemale    1166.37     925.57   1.260    0.214    \nyear          476.31      94.91   5.018 8.65e-06 ***\nysdeg        -124.57      77.49  -1.608    0.115    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2398 on 45 degrees of freedom\nMultiple R-squared:  0.855,\tAdjusted R-squared:  0.8357 \nF-statistic: 44.24 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n5826.40 + 5292.36\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 11118.76\n```\n:::\n:::\n\n\n\nWe see similar results as above. Since the baseline category is now Associate Professor, we see a negative coefficient for Assistant Professor category which says that Associate Professors make \\$5292.36 more than Assistant Professors. Similarly, Full Professors make \\$5826.40 more than Associate Professors.\n\n\n### E\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(salary ~ degree + sex + year + ysdeg, data=salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ degree + sex + year + ysdeg, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8146.9 -2186.9  -491.5  2279.1 11186.6 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 17183.57    1147.94  14.969  < 2e-16 ***\ndegreePhD   -3299.35    1302.52  -2.533 0.014704 *  \nsexFemale   -1286.54    1313.09  -0.980 0.332209    \nyear          351.97     142.48   2.470 0.017185 *  \nysdeg         339.40      80.62   4.210 0.000114 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3744 on 47 degrees of freedom\nMultiple R-squared:  0.6312,\tAdjusted R-squared:  0.5998 \nF-statistic: 20.11 on 4 and 47 DF,  p-value: 1.048e-09\n```\n:::\n:::\n\n\n\nIn addition to the variable year, degreePhD and ysdeg are also significantly contributing to salary. However, the p-value for sexFemale is still much greater than 0.05, meaning - sex is not significant when predicting for salary (at a 95% confidence level). We also observe that the coefficients for degreePhD, sexFemale and ysdeg got reversed (positive to negative and vice-versa). This suggests that professors with an MS are earning approximately \\$3300 more than the professors with a PhD, male professors are earning around \\$1286 more than female professors. We also see that the R-squared value has dropped - so this model does a poor job in explaining the variation in comparison with the other model where we included rank.\n\n\n### F\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalary <- mutate(salary, dean = case_when(ysdeg < 15 ~ \"New\",\n                                         ysdeg >=15 ~ \"Old\"))\n```\n:::\n\n\nSince the hypothesis depends on ysdeg and we created a new variable using it, I'm assuming that removing ysdeg should remove any multicollinearity.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvif(lm(salary ~ dean + degree + sex + rank + year + ysdeg, data=salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           GVIF Df GVIF^(1/(2*Df))\ndean   3.986217  1        1.996551\ndegree 2.144390  1        1.464373\nsex    1.542571  1        1.242003\nrank   4.347951  2        1.444013\nyear   2.445467  1        1.563799\nysdeg  6.821294  1        2.611761\n```\n:::\n:::\n\n\nAs a rule of thumb, a vif score over 5 is a problem. So I will be removing ysdeg from the predictors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(salary ~ dean + degree + sex + rank + year, data=salary))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = salary ~ dean + degree + sex + rank + year, data = salary)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3588.0 -1532.2  -232.2   565.7  9132.5 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  20468.7      951.7  21.507  < 2e-16 ***\ndeanOld      -2421.6     1187.9  -2.038   0.0474 *  \ndegreePhD     1073.5      843.3   1.273   0.2096    \nsexFemale     1046.7      858.0   1.220   0.2289    \nrankAsst     -5012.5     1002.3  -5.001 9.16e-06 ***\nrankProf      6213.3     1045.0   5.946 3.76e-07 ***\nyear           450.7       81.5   5.530 1.55e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2360 on 45 degrees of freedom\nMultiple R-squared:  0.8597,\tAdjusted R-squared:  0.841 \nF-statistic: 45.95 on 6 and 45 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nWe see a negative coefficient for deanOld with a p-value less than 0.05 which suggests that the hypothesis is true. The faculty hired by the new dean make \\$2421.6 more than the old faculty.\n\n\n\n## Question 3\n\n### A\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"house.selling.price\")\nsummary(lm(Price ~ Size + New, data = house.selling.price))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ Size + New, data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205102  -34374   -5778   18929  163866 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -40230.867  14696.140  -2.738  0.00737 ** \nSize           116.132      8.795  13.204  < 2e-16 ***\nNew          57736.283  18653.041   3.095  0.00257 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 53880 on 97 degrees of freedom\nMultiple R-squared:  0.7226,\tAdjusted R-squared:  0.7169 \nF-statistic: 126.3 on 2 and 97 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nBoth size and new are significant at a 95% confidence level. The coefficient for size suggests that for 1 square foot increase in the size of home, the price increases by \\$116.132 (considering that both are of the same condition - either old/new) and that for new suggests that if the home is new, the price increases by \\$57736.283 when compared to that of an old home of the same size.\n\n\n### B\n\nUsing the coefficients from above, the prediction equation becomes:\n\nprice = -40230.867 + (116.132 * home.size) + (57736.283 * home.new)\n\nSeparate equations for new and not new homes: \n\nprice.old = -40230.867 + (116.132 * home.size)\nprice.new = -40230.867 + (116.132 * home.size) + 57736.283\n\n\n### C\n\n#### (i)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprice.new = -40230.867 + (116.132 * 3000) + 57736.283\nprice.new\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 365901.4\n```\n:::\n:::\n\n\n#### (ii)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprice.old = -40230.867 + (116.132 * 3000)\nprice.old\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 308165.1\n```\n:::\n:::\n\n\n\n### D\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(lm(Price ~ Size * New, data = house.selling.price))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Price ~ Size * New, data = house.selling.price)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-175748  -28979   -6260   14693  192519 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -22227.808  15521.110  -1.432  0.15536    \nSize           104.438      9.424  11.082  < 2e-16 ***\nNew         -78527.502  51007.642  -1.540  0.12697    \nSize:New        61.916     21.686   2.855  0.00527 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 52000 on 96 degrees of freedom\nMultiple R-squared:  0.7443,\tAdjusted R-squared:  0.7363 \nF-statistic: 93.15 on 3 and 96 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n\n### E\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.old <- subset(house.selling.price, New == 0)\ndata.new <- subset(house.selling.price, New == 1)\n\n\nggplot() +\n  geom_smooth(data=data.old, aes(x = Size, y = Price), \n              method = \"lm\", se = FALSE, color = \"blue\") +\n  geom_point(data=data.old, aes(x = Size, y = Price), color = \"blue\") +\n  geom_smooth(data=data.new, aes(x = Size, y = Price), \n              method = \"lm\", se = FALSE, color = \"red\") +\n  geom_point(data=data.new, aes(x = Size, y = Price), color = \"red\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](HW4_PrahithaMovva_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nThe red line and dots represent the new homes whereas the blue line and dots the not new homes.\n\n\n### F\n\nFrom the coefficients that we got in D, the prediction equations become:\n\nprice = -22227.808 + (104.438 * home.size) + (-78527.502 * home.new) + (61.916 * home.size * home.new)\n\nprice.old = -22227.808 + (104.438 * home.size)\n\nprice.new = -22227.808 + (104.438 * home.size) - 78527.502 + (61.916 * home.size)\n\n#### (i)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprice.new = -22227.808 + (104.438 * 3000) - 78527.502 + (61.916 * 3000)\nprice.new\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 398306.7\n```\n:::\n:::\n\n\n#### (ii)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprice.old = -22227.808 + (104.438 * 3000)\nprice.old\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 291086.2\n```\n:::\n:::\n\n\n\n### G\n\n#### (i)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprice.new = -22227.808 + (104.438 * 1500) - 78527.502 + (61.916 * 1500)\nprice.new\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 148775.7\n```\n:::\n:::\n\n\n#### (ii)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprice.old = -22227.808 + (104.438 * 1500)\nprice.old\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 134429.2\n```\n:::\n:::\n\n\nThe difference in the price for new and not new homes of the same size seems to be less for smaller homes. This could suggest that size contributes more to price than the condition of the home.\n\n\n### H\n\nI would prefer the second model with interaction as both the multiple R-squared and adjusted R-squared for that model are higher than that without interaction.\n\n",
    "supporting": [
      "HW4_PrahithaMovva_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}