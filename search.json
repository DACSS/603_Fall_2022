[
  {
    "objectID": "about/AboutTemplate_mani.html",
    "href": "about/AboutTemplate_mani.html",
    "title": "Your Name",
    "section": "",
    "text": "##Instructions"
  },
  {
    "objectID": "about/AboutTemplate_mani.html#educationwork-background",
    "href": "about/AboutTemplate_mani.html#educationwork-background",
    "title": "Your Name",
    "section": "Education/Work Background",
    "text": "Education/Work Background"
  },
  {
    "objectID": "about/AboutTemplate_mani.html#r-experience",
    "href": "about/AboutTemplate_mani.html#r-experience",
    "title": "Your Name",
    "section": "R experience",
    "text": "R experience"
  },
  {
    "objectID": "about/AboutTemplate_mani.html#research-interests",
    "href": "about/AboutTemplate_mani.html#research-interests",
    "title": "Your Name",
    "section": "Research interests",
    "text": "Research interests"
  },
  {
    "objectID": "about/AboutTemplate_mani.html#hometown",
    "href": "about/AboutTemplate_mani.html#hometown",
    "title": "Your Name",
    "section": "Hometown",
    "text": "Hometown"
  },
  {
    "objectID": "about/AboutTemplate_mani.html#hobbies",
    "href": "about/AboutTemplate_mani.html#hobbies",
    "title": "Your Name",
    "section": "Hobbies",
    "text": "Hobbies"
  },
  {
    "objectID": "about/AboutTemplate_mani.html#fun-fact",
    "href": "about/AboutTemplate_mani.html#fun-fact",
    "title": "Your Name",
    "section": "Fun fact",
    "text": "Fun fact"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Contributors",
    "section": "",
    "text": "Your Name\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DACSS 603 Introduction to Quantitative Analysis Fall 2022",
    "section": "",
    "text": "The blog posts here are contributed by students enrolled in DACSS 603, Introduction to Quantitative Analysis.\n\n\n\n\n\n\n\n\n\n\nHW1\n\n\n\n\n\n\n\n\n\n\n\n\nKatie Popiela\n\n\n\n\n\n\n\n\nHW1 Quat\n\n\n\n\n\n\n\n\n\n\n\n\nAmy Quarkume\n\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\n\n\n\n\n\n\n\n\nOct 11, 2022\n\n\nShoshana Buck & Roy Yoon\n\n\n\n\n\n\n\n\nFinal Project Part 1\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\n\n\n\n\n\n\n\nOct 11, 2022\n\n\nEmma Rasmussen\n\n\n\n\n\n\n\n\nFinal Project Submission 1\n\n\n\n\n\n\n\n\n\n\n\n\nOct 11, 2022\n\n\nKaushika Potluri\n\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\nPart 1 of my final project\n\n\n\n\n\n\nOct 11, 2022\n\n\nNiharika Pola\n\n\n\n\n\n\n\n\nFinal project part 1\n\n\n\n\n\n\n\nfinalpart1\n\n\nBank Customer Churn Prediction\n\n\nMani Shanker Kamarapu\n\n\n\n\nThe first part of final project\n\n\n\n\n\n\nOct 11, 2022\n\n\nMani Shanker Kamarapu\n\n\n\n\n\n\n\n\nFinal_Project_1\n\n\n\n\n\n\n\nProject Proposal\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nProject Proposal\n\n\n\n\n\n\nOct 11, 2022\n\n\nMani Kanta Gogula & Rahul Gundeti\n\n\n\n\n\n\n\n\nFinal Project Proposal\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\n\n\n\n\n\n\n\nOct 11, 2022\n\n\nKaren Detter\n\n\n\n\n\n\n\n\nProject Proposal\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\nProject proposal part1\n\n\n\n\n\n\nOct 11, 2022\n\n\nMEGHA JOSEPH\n\n\n\n\n\n\n\n\nFinal Project Proposal\n\n\n\n\n\n\n\nfinalpart1\n\n\nNiyati Sharma\n\n\n\n\nInitial proposal for my final project\n\n\n\n\n\n\nOct 11, 2022\n\n\nNiyati Sharma\n\n\n\n\n\n\n\n\nProject Rough Draft Proposal\n\n\n\n\n\n\n\nfinalproject1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nInternational Trade’s influence on War\n\n\n\n\n\n\nOct 11, 2022\n\n\nYakub Rabiutheen\n\n\n\n\n\n\n\n\nFinal Project Proposal\n\n\n\n\n\n\n\nfinal project\n\n\nproposal\n\n\nEmily Duryea\n\n\ndataset\n\n\nggplot2\n\n\n\n\n\n\n\n\n\n\n\nOct 10, 2022\n\n\nEmily Duryea\n\n\n\n\n\n\n\n\nFinal Project\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\n\n\n\n\n\n\n\nOct 10, 2022\n\n\nEthan Campbell\n\n\n\n\n\n\n\n\nFinal Project 1\n\n\n\n\n\n\n\nfinalpart1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\n\n\n\n\n\n\n\nOct 10, 2022\n\n\nKen Docekal\n\n\n\n\n\n\n\n\nFinal Project Proposal\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\n\n\n\n\n\n\n\nOct 9, 2022\n\n\nSaaradhaa M\n\n\n\n\n\n\n\n\nDACSS 603 Final Project - Proposal\n\n\n\n\n\n\n\n\n\n\n\n\nOct 7, 2022\n\n\n\n\n\n\n\n\nFinal Project Proposal\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\nInitial proposal for my final project\n\n\n\n\n\n\nOct 7, 2022\n\n\nLindsay Jones\n\n\n\n\n\n\n\n\nFinal Project Part 1\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\n\n\n\n\n\n\n\nOct 7, 2022\n\n\nDonny Snyder\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\nnboonstra\n\n\n\n\nThe first homework on descriptive statistics and probability\n\n\n\n\n\n\nOct 5, 2022\n\n\nNick Boonstra\n\n\n\n\n\n\n\n\nHomework 1 - Prahitha Movva\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThe first homework on descriptive statistics and probability\n\n\n\n\n\n\nOct 5, 2022\n\n\nPrahitha Movva\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThe first homework on descriptive statistics and probability\n\n\n\n\n\n\nOct 4, 2022\n\n\nOmer Yalcin\n\n\n\n\n\n\n\n\nDACSS 603 HW 1 Kimble\n\n\n\n\n\nDACSS 603 HW 1\n\n\n\n\n\n\nOct 3, 2022\n\n\nKaren Kimble\n\n\n\n\n\n\n\n\nDuryea Homework 1\n\n\n\n\n\n\n\nhw1\n\n\ndescriptive statistics\n\n\nprobability\n\n\n\n\nHomework 1 for DACSS 603\n\n\n\n\n\n\nOct 3, 2022\n\n\nEmily Duryea\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2022\n\n\nQuinn He\n\n\n\n\n\n\n\n\nHomework #1\n\n\n\n\n\n\n\nHW1\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2022\n\n\nKalimah Muhammad\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndescriptive statistics\n\n\nprobability\n\n\n\n\nThe first homework on descriptive statistics and probability\n\n\n\n\n\n\nOct 3, 2022\n\n\nKaren Detter\n\n\n\n\n\n\n\n\nDACSS 603: Homework 1\n\n\n\n\n\n\n\nhw1\n\n\nTory Bartelloni\n\n\nLungCap\n\n\ndplyr\n\n\nggplot2\n\n\nEDA\n\n\nDescriptive Statistics\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2022\n\n\nTory Bartelloni\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nHomework_1_603\n\n\n\n\n\n\nOct 3, 2022\n\n\nMani Kanta Gogula\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2022\n\n\nQuinn He\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2022\n\n\nKen Docekal\n\n\n\n\n\n\n\n\nHOME WORK1 603\n\n\n\n\n\n\n\nhw1\n\n\ndescriptive statistics\n\n\nmegha joseph\n\n\nprobability\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2022\n\n\nMegha Joseph\n\n\n\n\n\n\n\n\nHW1\n\n\n\n\n\n\n\nhw1\n\n\nNiyati Sharma\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2022\n\n\nNiyati Sharma\n\n\n\n\n\n\n\n\nShoshanaBuck-HW1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nFirst homeowrk on descriptive statistics and probability\n\n\n\n\n\n\nOct 3, 2022\n\n\nShoshana Buck\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\nchallenge1\n\n\nSteph Roberts\n\n\ndataset\n\n\nggplot2\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2022\n\n\nSteph Roberts\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndescriptive statistics\n\n\nprobability\n\n\n\n\n\n\n\n\n\n\n\nOct 2, 2022\n\n\nCaleb Hill\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThe first homework on descriptive statistics and probability.\n\n\n\n\n\n\nOct 2, 2022\n\n\nLindsay Jones\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThe homework-1 on descriptive statistics and probability\n\n\n\n\n\n\nOct 2, 2022\n\n\nNiharika Pola\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThe first homework on descriptive statistics and probability\n\n\n\n\n\n\nOct 2, 2022\n\n\nMani Shanker Kamarapu\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThe homework-1 on descriptive statistics and probability\n\n\n\n\n\n\nOct 2, 2022\n\n\nNiharika Pola\n\n\n\n\n\n\n\n\nDACSS603_HW1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nDescriptive Statistics and Probability functions\n\n\n\n\n\n\nOct 2, 2022\n\n\nRahul Gundeti\n\n\n\n\n\n\n\n\nHomework 1 - Donny Snyder\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThe first homework on descriptive statistics and probability\n\n\n\n\n\n\nOct 1, 2022\n\n\nDonny Snyder\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2022\n\n\nSaaradhaa M\n\n\n\n\n\n\n\n\nHomework 1 Solution\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nIntro to Quant Analysis Homework 1\n\n\n\n\n\n\nOct 1, 2022\n\n\nDane Shelton\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThe first homework on descriptive statistics and probability\n\n\n\n\n\n\nSep 29, 2022\n\n\nEmma Rasmussen\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThe first homework on descriptive statistics and probability\n\n\n\n\n\n\nSep 21, 2022\n\n\nEthan Campbell\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThe first homework on descriptive statistics and probability\n\n\n\n\n\n\nSep 20, 2022\n\n\nSteve O’Neill\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThe first homework on descriptive statistics and probability\n\n\n\n\n\n\nSep 20, 2022\n\n\nYakub Rabiutheen\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\nchallenge1\n\n\nmy name\n\n\ndataset\n\n\nggplot2\n\n\n\n\n\n\n\n\n\n\n\nAug 2, 2022\n\n\nKaushika Potluri\n\n\n\n\n\n\n\n\nBlog Post Template\n\n\n\n\n\n\n\nhw1\n\n\nchallenge1\n\n\nmy name\n\n\ndataset\n\n\nggplot2\n\n\n\n\n\n\n\n\n\n\n\nAug 2, 2022\n\n\nYour Name\n\n\n\n\n\n\n\n\nBlog Post Template\n\n\n\n\n\n\n\nhw1\n\n\nchallenge1\n\n\nmy name\n\n\ndataset\n\n\nggplot2\n\n\n\n\n\n\n\n\n\n\n\nAug 2, 2022\n\n\nYour Name\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html",
    "href": "posts/Blog Post 2_Kaushika Potluri.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#a-distribution-of-lungcap",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#a-distribution-of-lungcap",
    "title": "Homework 1",
    "section": "1(a) Distribution of LungCap:",
    "text": "1(a) Distribution of LungCap:\n\n\nCode\nhist(df$LungCap)\n\n\n\n\n\nThe distribution appears to be very similar to a normal distribution, according to the histogram."
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#b",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#b",
    "title": "Homework 1",
    "section": "1(b)",
    "text": "1(b)\nThe boxplots below show the probability distributions grouped by Gender.\n\n\nCode\nboxplot(LungCap~Gender, data=df)\n\n\n\n\n\nLooks like males have a slightly higher lung capacity than females."
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#c",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#c",
    "title": "Homework 1",
    "section": "1 (c)",
    "text": "1 (c)\n\n\nCode\ndf %>%\n  group_by(Smoke) %>%\n  summarize(Mean = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke  Mean\n  <chr> <dbl>\n1 no     7.77\n2 yes    8.65\n\n\nSurprisingly, the mean lung capacity is higher for smokers than it is for non-smokers."
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#d",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#d",
    "title": "Homework 1",
    "section": "1 (d)",
    "text": "1 (d)\n\n\nCode\n# convert Age to categorical variable.\ndf <- mutate(df, AgeGroup = case_when(Age <= 13 ~ \"13 and lower\", Age == 14 | Age == 15 ~ \"14-15\", Age == 16 | Age == 17 ~ \"16-17\", Age >= 18 ~ \"18 and above\"))\narrange(df, Age)\n\n\n# A tibble: 725 × 7\n   LungCap   Age Height Smoke Gender Caesarean AgeGroup    \n     <dbl> <dbl>  <dbl> <chr> <chr>  <chr>     <chr>       \n 1   5.88      3   55.9 no    male   no        13 and lower\n 2   0.507     3   51.6 no    female yes       13 and lower\n 3   1.18      3   51.9 no    male   no        13 and lower\n 4   4.7       3   52.7 no    male   no        13 and lower\n 5   5.48      3   52.9 no    male   no        13 and lower\n 6   1.02      3   47   no    female no        13 and lower\n 7   2         3   51   no    female no        13 and lower\n 8   1.68      3   51.9 no    male   no        13 and lower\n 9   4.08      3   53.6 no    male   yes       13 and lower\n10   1.45      3   45.3 no    female no        13 and lower\n# … with 715 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nCode\n# construct histogram.\nggplot(df, aes(x = LungCap)) +\n  geom_histogram() +\n  facet_grid(AgeGroup~Smoke)\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nMajority seem to be non-smokers, and looks like non-smokers seem to have higher lung capacity."
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#e",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#e",
    "title": "Homework 1",
    "section": "1 (e)",
    "text": "1 (e)\n\n\nCode\nclass(df$AgeGroup)\n\n\n[1] \"character\"\n\n\n\n\nCode\ndf$AgeGroup <- as.factor(df$AgeGroup) #converting to factor\n\n# construct table.\ndf %>% select(Smoke, LungCap, AgeGroup) %>% group_by(AgeGroup, Smoke) %>% summarise(mean(LungCap))\n\n\n`summarise()` has grouped output by 'AgeGroup'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 3\n# Groups:   AgeGroup [4]\n  AgeGroup     Smoke `mean(LungCap)`\n  <fct>        <chr>           <dbl>\n1 13 and lower no               6.36\n2 13 and lower yes              7.20\n3 14-15        no               9.14\n4 14-15        yes              8.39\n5 16-17        no              10.5 \n6 16-17        yes              9.38\n7 18 and above no              11.1 \n8 18 and above yes             10.5 \n\n\nThe mean lung capacity for smokers aged 13 and under is greater than that of non-smokers in the same age group which is different from expectation. Non-smokers have higher mean lung capacity for ages 14-15, 16-17 and 18 and above. Either there may be an error or extreme outlier in the data for smokers aged 13 and under."
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#f",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#f",
    "title": "Homework 1",
    "section": "1 (f)",
    "text": "1 (f)\n\n\nCode\ncor(df$LungCap,df$Age)\n\n\n[1] 0.8196749\n\n\n\n\nCode\ncov(df$LungCap,df$Age)\n\n\n[1] 8.738289\n\n\nLung capacity and age have a high positive correlation of 0.82, meaning that as age increases, lung capacity also does. The covariance is a little more challenging to interpret; the positive number indicates a positive association between lung capacity and age, but because covariance varies from negative infinity to infinity, it is difficult to judge the strength of the relationship. In most situations, I would choose to employ correlation."
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#section",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#section",
    "title": "Homework 1",
    "section": "2",
    "text": "2\n\n\nCode\ndf1 <- c(0:4)\nInmate_count <- c(128, 434, 160, 64, 24)\nIP<- data_frame(df1, Inmate_count)\n\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nPlease use `tibble()` instead.\nThis warning is displayed once every 8 hours.\nCall `lifecycle::last_lifecycle_warnings()` to see where this warning was generated."
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#a",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#a",
    "title": "Homework 1",
    "section": "2(a)",
    "text": "2(a)\n\n\nCode\nIP <- mutate(IP, Probability = Inmate_count/sum(Inmate_count))\nIP\n\n\n# A tibble: 5 × 3\n    df1 Inmate_count Probability\n  <int>        <dbl>       <dbl>\n1     0          128      0.158 \n2     1          434      0.536 \n3     2          160      0.198 \n4     3           64      0.0790\n5     4           24      0.0296\n\n\n\n\nCode\nIP %>%\n  filter(df1 == 2) %>%\n  select(Probability)\n\n\n# A tibble: 1 × 1\n  Probability\n        <dbl>\n1       0.198\n\n\nThe probability is about 19.75%."
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#b-1",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#b-1",
    "title": "Homework 1",
    "section": "(b)",
    "text": "(b)\n\n\nCode\ndf2 <- IP %>%\n  filter(df1 < 2)\nsum(df2$Probability)\n\n\n[1] 0.6938272\n\n\nThe probability that a randomly selected inmate has fewer than 2 prior convictions is 0.6938272"
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#c-1",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#c-1",
    "title": "Homework 1",
    "section": "2(c)",
    "text": "2(c)\n\n\nCode\ndf3 <- IP %>%\n  filter(df1 <= 2)\nsum(df3$Probability)\n\n\n[1] 0.891358\n\n\nThe probability that a randomly selected inmate has 2 or fewer prior convictions is 0.891358."
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#d-1",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#d-1",
    "title": "Homework 1",
    "section": "2(d)",
    "text": "2(d)\n\n\nCode\ndf4 <- IP %>%\n  filter(df1 > 2)\nsum(df4$Probability)\n\n\n[1] 0.108642\n\n\nThe probability that a randomly selected inmate has more than 2 prior convictions is 0.108642."
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#e-1",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#e-1",
    "title": "Homework 1",
    "section": "2(e)",
    "text": "2(e)\n\n\nCode\nIP <- mutate(IP, X = df1*Probability)\nexpectedvalue<- sum(IP$X)\nexpectedvalue\n\n\n[1] 1.28642\n\n\nThe expected value for the number of prior convictions is 1.2864198. We can round this to 1."
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#f-1",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#f-1",
    "title": "Homework 1",
    "section": "2(f)",
    "text": "2(f)\n\n\nCode\nvar1 <-sum(((IP$df1-expectedvalue)^2)*IP$Probability)\nvar1\n\n\n[1] 0.8562353\n\n\n\n\nCode\nsqrt(var1)\n\n\n[1] 0.9253298\n\n\nThe variance and the standard deviation for prior convictions are 0.8562353 and 0.9253298 respectively."
  },
  {
    "objectID": "posts/Buck_Yoon_finalpart1.html",
    "href": "posts/Buck_Yoon_finalpart1.html",
    "title": "finalpart1",
    "section": "",
    "text": "we are going to be using the National Longitudinal Study of Adolescent to Adult Health, 1994-2018 we are interested in exploring the relation between education levels and health.\n#Some of our research questions are:\nWhat is the correlation and relationship between someone’s education and health? Does the type and duration of education matter? Are there fields that may be “more healthy”? How does the relationship between education and health differ among the education levels/ is there a difference?\nWhat does this data set have to say to a possible causal link between education and health? Does the data set provide apt data to establish a causal link?"
  },
  {
    "objectID": "posts/Buck_Yoon_finalpart1.html#hypothesis",
    "href": "posts/Buck_Yoon_finalpart1.html#hypothesis",
    "title": "finalpart1",
    "section": "Hypothesis",
    "text": "Hypothesis\nWe are going to be using the hypothesis from researchers Eric R. Ride and Mark H. Showalter, but using the data from the National Longitudinal Study\nThere hypothesis was: ’The empirical link between education and health is firmly established. Numerous studies document that higher levels of education are positively associated with longer life and better health throughout the lifespan…But measuring the causal links between education and health is a more challenging task.” Estimating the relation between health and education: what do we know and what do we need to know?\nWe are hypothesizing that a positive correlation exists between education and health; the more education an individual receives, the better health the individual may have.\nWe want to look at the National Longitudinal Study of Adolescent to Adult Health 1992-2018 and observe what other factors beyond education there is that can affect the correlation to health. What are the potential moderating or mediating variables?"
  },
  {
    "objectID": "posts/Buck_Yoon_finalpart1.html#descriptive-statistics",
    "href": "posts/Buck_Yoon_finalpart1.html#descriptive-statistics",
    "title": "finalpart1",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\nThis is an overview of the entire data set we are still determining which specific sections we want to analyze for our final project.\nAccording to ICPSR:\nStudy Purpose: Add Health was developed in response to a mandate from the U.S. Congress to fund a study of adolescent health. Waves I and II focused on the forces that may influence adolescents’ health and risk behaviors, including personal traits, families, friendships, romantic relationships, peer groups, schools, neighborhoods, and communities. As participants aged into adulthood, the scientific goals of the study expanded and evolved. Wave III explored adolescent experiences and behaviors related to decisions, behavior, and health outcomes in the transition to adulthood. Wave IV expanded to examine developmental and health trajectories across the life course of adolescence into young adulthood, using an integrative study design which combined social, behavioral, and biomedical measures data collection. Wave V aimed to track the emergence of chronic disease as the cohort aged into their 30s and early 40s.\nStudy Design: Add health is a school-based longitudinal study of a nationally-representative sample of adolescents in grates 7-12 in the United States in 1945-45. Over more than 20 years of data collection, data have been collected from adolescents, their fellow students, school administrators, parents, siblings, friends, and romantic partners through multiple data collection components. In addition, existing databases with information about respondents’ neighborhoods and communities have been merged with Add Health data, including variables on income poverty, unemployment, availability and utilization of health services, crime, church membership, and social programs and policies.\nSample:\n\nWave I: The Stage 1 in-school sample was a stratified, random sample of all high schools in the United States. A school was eligible for the sample if it included an 11th grade and had a minimum enrollment of 30 students. A feeder school – a school that sent graduates to the high school and that included a 7th grade – was also recruited from the community. The in-school questionnaire was administered to more than 90,000 students in grades 7 through 12. The Stage 2 in-home sample of 27,000 adolescents consisted of a core sample from each community, plus selected special over samples. Eligibility for over samples was determined by an adolescent’s responses on the in-school questionnaire. Adolescents could qualify for more than one sample.\nWave II: The Wave II in-home interview surveyed almost 15,000 of the same students one year after Wave I.\nWave III: The in-home Wave III sample consists of over 15,000 Wave I respondents who could be located and re-interviewed six years later.\nWave IV: All original Wave I in-home respondents were eligible for in-home interviews at Wave IV. At Wave IV, the Add Health sample was dispersed across the nation with respondents living in all 50 states. Administrators were able to locate 92.5% of the Wave IV sample and interviewed 80.3% of eligible sample members.\nWave V: All Wave I respondents who were still living were eligible at Wave V, yielding a pool of 19,828 persons. This pool was split into three stratified random samples for the purposes of survey design testing.\nTime Method: Longitudinal:Panel\nUniverse: Adolescents in grades 7 through 12 during the 1994-1995 school year. Respondents were geographically located in the United States.\nUnits of Observation: Individual\nData Types: Survey Data\nTime periods: 1994 - 2018\nDate of Collections: Wave 1(1994-01 - 1995-12), Wave II(1996-04 - 1996-09), Wave III(2001-04 - 2002 -04), Wave IV(2007-04 - 2009-01), Wave V(2016-03 - 2018-11)\nResponse Rates: Wave 1(79%), Wave 2(88.6%), Wave III(77.4%), Wave IV(80.3%), Wave V(71.8%)."
  },
  {
    "objectID": "posts/CalebHill_HW1.html",
    "href": "posts/CalebHill_HW1.html",
    "title": "Homework 1",
    "section": "",
    "text": "First, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(dplyr)\ndf <- read_excel(\"_data/LungCapData.xls\")\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(df$LungCap)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\n\n\n\nNext, let’s compare the probability distribution of the LungCap with respect to Males and Females, using a boxplot.\n\n\nCode\nboxplot(LungCap ~ Gender, df)\n\n\n\n\n\nThe minimum and mean are very similar to each other, with the minimum around 1 and the mean around 8. The maximum does differ though by gender, at 13 to 14/15 respectively.\n\n\n\nFor the third question, we’re going to compare the mean lung capacities for smokers and non-smokers. To compare the mean, we’ll again use the box-plot.\n\n\nCode\nboxplot(LungCap ~ Smoke, df)\n\n\n\n\n\nWhile the mean is very similar, hovering between 8 and 9, the range is what is substantial. A smoker’s lung capacity has a much smaller range, 4 - 13, compared to non-smokers, at 1 - 15. This makes sense, as a smoker’s lungs would start to have less capacity through consistent substance abuse.\n\n\n\nFor question four, we need to create a new variable, Age Group, followed by comparing the relationship between Smoking and Lung Capacity, broken down by Age Group. First, we’ll create the new column, referencing the Age column to determine groups.\n\n\nCode\ndf_new <- df %>%\n  mutate(\n    Age_Group = dplyr::case_when(\n      Age <= 13 ~ \"Less than or equal to 13\",\n      Age == 14 | Age == 15 ~ \"14 or 15\",\n      Age == 16 | Age == 17 ~ \"16 or 17\",\n      Age >= 18 ~ \"Greater than or equal to 18\"\n    ),\n    Age_Group = factor(\n      Age_Group,\n      level = c(\"Less than or equal to 13\", \"14 or 15\", \"16 or 17\", \"Greater than or equal to 18\")\n    )\n  )\nhead(df_new)\n\n\n# A tibble: 6 × 7\n  LungCap   Age Height Smoke Gender Caesarean Age_Group                  \n    <dbl> <dbl>  <dbl> <chr> <chr>  <chr>     <fct>                      \n1    6.48     6   62.1 no    male   no        Less than or equal to 13   \n2   10.1     18   74.7 yes   female no        Greater than or equal to 18\n3    9.55    16   69.7 no    female yes       16 or 17                   \n4   11.1     14   71   no    male   no        14 or 15                   \n5    4.8      5   56.9 no    male   no        Less than or equal to 13   \n6    6.22    11   58.7 no    female no        Less than or equal to 13   \n\n\nGood. Now we can place a histogram to better understand the relationship between LungCap and Smoking status. To view it by age group, we’ll add a facet wrap to the visualization.\n\n\nCode\nggplot(df_new, aes(LungCap, color=Smoke)) +\n  geom_histogram() +\n  facet_wrap(~Age_Group)\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nThose that are smokers have a smaller sample size than non-smokers. Looking purely at the distribution of each, we can see that three of the four age groups follow a normal distribution, save the 14 or 15 group that has a somewhat “two hump” distribution.\nEven so, smoking status does seem to mirror the non-smoker distribution, when it comes to the overall sample count and LungCap.\n\n\n\nFor the fifth question, we’ll compare the lung capacities for smokers and non-smokers within each age group. We’ll use a box-plot and facet wrap this visualization again by Age Group.\n\n\nCode\nggplot(df_new, aes(LungCap, Smoke)) +\n  geom_boxplot() +\n  facet_wrap(~Age_Group)\n\n\n\n\n\nWe can readily see that smokers, irrespective of age, have a substantially smaller lung capacity range compared to non-smokers. While the mean might be similar, sometimes even smaller for “13 years old or less”, the length of each capacity varies for non-smokers where it doesn’t for smokers.\n\n\n\nFor the sixth question, we shall calculate the covariance and correlation between LungCap and Age.\n\n\nCode\ncov(df$LungCap, df$Age)\n\n\n[1] 8.738289\n\n\nCode\ncor(df$LungCap, df$Age)\n\n\n[1] 0.8196749\n\n\nCovariance is the relationship between a pair of random variables where change in one variable causes change in another variable. With a covariance of 8.73, that means that there is a positive relationship between the two variables and that, by every 1 point change of Age, that can result in an average of 8.73 point change in LungCap.\nCorrelations show whether and how strongly pairs or variables are related to one another. Correlation can range from 0.0 to 1.0. With a result of 0.81, that means there is a high correlation between LungCap and Age."
  },
  {
    "objectID": "posts/CalebHill_HW1.html#a-1",
    "href": "posts/CalebHill_HW1.html#a-1",
    "title": "Homework 1",
    "section": "a",
    "text": "a\nLet’s calculate the probability that a randomly selected inmate has EXACTLY 2 prior convictions.\n\n\nCode\ndbinom(2, 810, 0.1975)\n\n\n[1] 7.90917e-74\n\n\nSo 7.9%."
  },
  {
    "objectID": "posts/CalebHill_HW1.html#b-1",
    "href": "posts/CalebHill_HW1.html#b-1",
    "title": "Homework 1",
    "section": "b",
    "text": "b\nLet’s calculate the probability that a randomly selected inmate has FEWER THAN 2 prior convictions.\n\n\nCode\npbinom(2, 810, 0.1975, lower.tail=FALSE)\n\n\n[1] 1\n\n\nNot sure why it’s pulling 1."
  },
  {
    "objectID": "posts/CalebHill_HW1.html#c-1",
    "href": "posts/CalebHill_HW1.html#c-1",
    "title": "Homework 1",
    "section": "c",
    "text": "c\nLet’s calculate the probability that a randomly selected inmate has 2 OR FEWER prior convictions.\n\n\nCode\npbinom(2, 810, 0.1975)\n\n\n[1] 7.989018e-74\n\n\nSo 7.98%."
  },
  {
    "objectID": "posts/CalebHill_HW1.html#d-1",
    "href": "posts/CalebHill_HW1.html#d-1",
    "title": "Homework 1",
    "section": "d",
    "text": "d\nLet’s calculate the probability that a randomly selected inmate has MORE THAN 2 prior convictions."
  },
  {
    "objectID": "posts/CalebHill_HW1.html#e-1",
    "href": "posts/CalebHill_HW1.html#e-1",
    "title": "Homework 1",
    "section": "e",
    "text": "e\nLet’s calculate the expected value for the number of prior convictions. As I am unable to calculate sections B and D, I’m unable to determine the expected value."
  },
  {
    "objectID": "posts/CalebHill_HW1.html#f-1",
    "href": "posts/CalebHill_HW1.html#f-1",
    "title": "Homework 1",
    "section": "f",
    "text": "f\nLet’s calculate the variance and the standard deviation for the Prior Convictions.As I am unable to determine the expected value, I cannot calculate the variance and standard deviation either."
  },
  {
    "objectID": "posts/DACSS 603 Final Part 1.html",
    "href": "posts/DACSS 603 Final Part 1.html",
    "title": "DACSS 603 Final Project - Proposal",
    "section": "",
    "text": "Code\n# Setup\n\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(readr)\nlibrary(scales)\n\n\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\n\nCode\n# Importing datasets\n\nNYC_2019 <- read_csv(\"/Users/karenkimble/Documents/UMass/SPP/Fall 2022/DACSS 603/DACSS Final Project/NYC School Data/2018-2019_School_Demographic_Snapshot.csv\", col_types = cols(`Grade PK (Half Day & Full Day)` = col_skip(), `# Multiple Race Categories Not Represented` = col_skip(), `% Multiple Race Categories Not Represented` = col_skip()))\n\n\nError: '/Users/karenkimble/Documents/UMass/SPP/Fall 2022/DACSS 603/DACSS Final Project/NYC School Data/2018-2019_School_Demographic_Snapshot.csv' does not exist.\n\n\nCode\nNYC_2019$`% Poverty` <- percent(NYC_2019$`% Poverty`, accuracy=0.1)\n\n\nError in number(x = x, accuracy = accuracy, scale = scale, prefix = prefix, : object 'NYC_2019' not found\n\n\nCode\nNYC_2021 <- read_csv(\"/Users/karenkimble/Documents/UMass/SPP/Fall 2022/DACSS 603/DACSS Final Project/NYC School Data/2020-2021_Demographic_Snapshot_School.csv\", col_types = cols(`Grade 3K+PK (Half Day & Full Day)` = col_skip(), `# Multi-Racial` = col_skip(), `% Multi-Racial` = col_skip(), `# Native American` = col_skip(), `% Native American` = col_skip(), `# Missing Race/Ethnicity Data` = col_skip(), `% Missing Race/Ethnicity Data` = col_skip()))\n\n\nError: '/Users/karenkimble/Documents/UMass/SPP/Fall 2022/DACSS 603/DACSS Final Project/NYC School Data/2020-2021_Demographic_Snapshot_School.csv' does not exist.\n\n\nCode\n# In order to bind the data, I had to remove columns that were not present in the other spreadsheet: Grade PK or 3K, Native American, the different multi-racial categories, and Missing Data\n\nschool_data <- rbind(NYC_2019, NYC_2021)\n\n\nError in rbind(NYC_2019, NYC_2021): object 'NYC_2019' not found\n\n\nCode\n# Making values coded as \"above 95%\" to equal 95% and \"below 5%\" to equal 5% for the purposes of this analysis\n\nschool_data$`% Poverty` <- recode(school_data$`% Poverty`, \"Above 95%\" = \"95%\", \"Below 5%\" = \"5%\")\n\n\nError in recode(school_data$`% Poverty`, `Above 95%` = \"95%\", `Below 5%` = \"5%\"): object 'school_data' not found\n\n\nCode\n# Re-coding variables as numeric\n\nschool_data$`% Poverty` <- sapply(school_data$`% Poverty`, function(x) gsub(\"%\", \"\", x))\n\n\nError in lapply(X = X, FUN = FUN, ...): object 'school_data' not found\n\n\nCode\nschool_data$`% Poverty` <- as.numeric(school_data$`% Poverty`)\n\n\nError in eval(expr, envir, enclos): object 'school_data' not found\n\n\nCode\nschool_data$`Economic Need Index` <- as.numeric(school_data$`Economic Need Index`)\n\n\nError in eval(expr, envir, enclos): object 'school_data' not found"
  },
  {
    "objectID": "posts/DACSS 603 Final Part 1.html#research-question",
    "href": "posts/DACSS 603 Final Part 1.html#research-question",
    "title": "DACSS 603 Final Project - Proposal",
    "section": "Research Question",
    "text": "Research Question\nThe research question I want to explore is whether child poverty has increased in schools that are predominantly made up of non-white students from the 2014-2015 school year to the 2020-2021 school year. I think this is extremely important to look at because of the pandemic’s impact on not only child learning but also families’ economic resources. According to the Columbia University Center on Poverty and Social Policy, “nearly a quarter of children ages 0-3 live in poverty and nearly half of the city’s young children live in lower-opportunity neighborhoods where the poverty rate is at least 20 percent” (“Poverty”). Unfortunately, research shows that poverty is disproportionately felt according to one’s race or ethnicity. In New York State, as of 2021, child poverty among children of color is almost 30%, with Black or African American children more than twice as likely to live in poverty than White, Non-Hispanic children (“New York State”, 2021). With this disproportionate level of economic need in children of color, it seems important to investigate if the poverty level within New York City schools that are predominately non-White has increased significantly compared to schools that are predominantly White. When searching the UMass Libraries databases and other sources, it was hard to find studies that used this data in this way. It is important to understand if there is increasing poverty levels within an already vulnerable group."
  },
  {
    "objectID": "posts/DACSS 603 Final Part 1.html#hypothesis",
    "href": "posts/DACSS 603 Final Part 1.html#hypothesis",
    "title": "DACSS 603 Final Project - Proposal",
    "section": "Hypothesis",
    "text": "Hypothesis\nI hypothesize that the poverty rate in NYC schools that are predominantly children of color will have increased more between the 2014-2015 and the 2020-2021 school years than the poverty rate in schools that are predominantly White. Since I have not found many previous studies on this, it is hard to know if this hypothesis was tested before. However, this data is fairly recent and also relates to the pandemic’s effects on economics, so I think it is still a significant contribution to test this hypothesis."
  },
  {
    "objectID": "posts/DACSS 603 Final Part 1.html#descriptive-statistics",
    "href": "posts/DACSS 603 Final Part 1.html#descriptive-statistics",
    "title": "DACSS 603 Final Project - Proposal",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\nA description and summary of your data. How was your data collected by its original collectors? What are the important variables of interest for your research question? Use functions like glimpse() and summary() to present your data.\nThe data was collected by New York City and put on its Open Data source. The data covers NYC schools in the academic years 2014-2015 to 2020-2021. The important variables of interest included in the data are:\n\nAcademic year\nNumber and percentage of Asisan, Black, Hispanic, and White students\nNumber and percentage of students in poverty\nEconomic need index, which is the average of students’ “Economic Need Values”\n\nThe Economic Need Index (ENI) estimates the percentage of students facing economic hardship\n\n\nThe other variables included are: DBN (district, borough, school number), school name, total enrollment, enrollment numbers for K-12, number and percentage of female and male students, number and percentage of students with disabilities, and number and percentage of English-Language Learner (ELL) students.\n\n\nCode\nglimpse(school_data)\n\n\nError in glimpse(school_data): object 'school_data' not found\n\n\n\n\nCode\nsummary(school_data)\n\n\nError in summary(school_data): object 'school_data' not found\n\n\nCode\n# Note: the summary data for the enrollment numbers split by grade is somewhat off (especially minimums) because there is no variable listed for type of school (i.e., middle versus high school). So, for example, an elementary school would have an enrollment total of 0 for grade 12, which would show up as the minimum.\n\n\nAs we can see from this summary, the median percent of poverty in NYC schools (81.4%) is higher than the mean percent (75.89%), indicating that there may be low outliers with very low percentages of poverty. The same holds true for the Economic Need Index, with the mean (0.691) lower than the median (0.743). It is troubling, however, that both the mean and median percentages of poverty in NYC schools overall is more than three-fourths of the population."
  },
  {
    "objectID": "posts/DACSS 603 Final Part 1.html#references",
    "href": "posts/DACSS 603 Final Part 1.html#references",
    "title": "DACSS 603 Final Project - Proposal",
    "section": "References",
    "text": "References\nNew York State Child Poverty Facts. Schuyler Center for Analysis and Advocacy. (2021, February 18). Retrieved from https://scaany.org/wp-content/uploads/2021/02/NYS-Child-Poverty-Facts_Feb2021.pdf\nPoverty in New York City. Columbia University Center on Poverty and Social Policy. (n.d.). Retrieved from https://www.povertycenter.columbia.edu/poverty-in-new-york-city#:~:text=Children%20and%20Families%20in%20New%20York%20City&text=Through%20surveys%2C%20we%20find%20that,is%20at%20least%2020%20percent."
  },
  {
    "objectID": "posts/DACSS 603 HW 1.html",
    "href": "posts/DACSS 603 HW 1.html",
    "title": "DACSS 603 HW 1 Kimble",
    "section": "",
    "text": "Code\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(readxl)\nlibrary(tidyverse)\n\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ stringr 1.4.0\n✔ tidyr   1.2.0     ✔ forcats 0.5.1\n✔ readr   2.1.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nknitr::opts_chunk$set(echo = TRUE)\n\n# Reading in File\nLungCapData <- read_excel(\"LungCapData.xls\")\n\n\nError: `path` does not exist: 'LungCapData.xls'\n\n\n\n\n\n\n\nCode\nhist(LungCapData$LungCap)\n\n\nError in hist(LungCapData$LungCap): object 'LungCapData' not found\n\n\nThe histogram above shows that the Lung Cap data is roughly normally distributed because a majority of the observations are centered around the mean. There are fewer observations at the tail ends of the histogram.\n\n\n\n\n\nCode\nboxplot(LungCap ~ Gender, data = LungCapData, main = \"Lung Capacity by Gender\",\n        xlab = \"Gender\", ylab = \"Lung Capacity\")\n\n\nError in eval(m$data, parent.frame()): object 'LungCapData' not found\n\n\nFrom the box-plots above, it appears that males in this study had slightly higher lung capacities than females, with the median for males at 9 and the median for females at 8. However, both genders had large ranges, but these ranges reflected the overall pattern of males having slightly higher lung capacities.\n\n\n\n\n\nCode\nsmokers <- filter(LungCapData, Smoke == \"yes\")\n\n\nError in filter(LungCapData, Smoke == \"yes\"): object 'LungCapData' not found\n\n\nCode\nmean(smokers$LungCap)\n\n\nError in mean(smokers$LungCap): object 'smokers' not found\n\n\nCode\nnonsmokers <- filter(LungCapData, Smoke == \"no\")\n\n\nError in filter(LungCapData, Smoke == \"no\"): object 'LungCapData' not found\n\n\nCode\nmean(nonsmokers$LungCap)\n\n\nError in mean(nonsmokers$LungCap): object 'nonsmokers' not found\n\n\nThe mean lung capacity for smokers (8.65) is higher than the mean lung capacity for non-smokers (7.77). Based on what we now know about how smoking affects the lungs, these results don’t seem to make sense. However, there is the possibility that smokers may be more used to deep inhales/exhales and therefore could have better lung capacity until the substance has more of an effect on their lungs. There may also be external factors that led to these results that aren’t clear from the data right now.\n\n\n\n\n\nCode\nLungCapData <- within(LungCapData, {\n  Age.group <- NA\n  Age.group[Age <= 13] <- \"13 and Under\"\n  Age.group[Age >= 14 & Age <= 15] <- \"14-15\"\n  Age.group[Age >= 16 & Age <= 17] <- \"16-17\"\n  Age.group[Age >= 18] <- \"18 and Over\"\n} )\n\n\nError in within(LungCapData, {: object 'LungCapData' not found\n\n\n\n\n\n\nCode\n# Boxplots\n\nsmoking_age <- filter(LungCapData, Smoke == \"yes\")\n\n\nError in filter(LungCapData, Smoke == \"yes\"): object 'LungCapData' not found\n\n\nCode\nboxplot(LungCap ~ Age.group, data = smoking_age,\n        main = \"Lung Capacity of Smokers by Age Group\",\n        xlab = \"Age Group\", ylab = \"Lung Capacity\")\n\n\nError in eval(m$data, parent.frame()): object 'smoking_age' not found\n\n\nFrom the boxplot above, we can see that smokers’ lung capacities reach about a maximum of 12 as age increases, but there is not very much improvement in the maximums. The medians move a bit more as age increases, but still not very dramatically after ages 14 and 15. Smokers that are 18 and over have higher lung capacities overall, but this may just be because of natural aging processes and development.\n\n\nCode\n# Means\n\nsmoking_age %>%\n  group_by(Age.group) %>%\n  summarise_at(vars(LungCap), list(name = mean))\n\n\nError in group_by(., Age.group): object 'smoking_age' not found\n\n\nWe see the same trend in means as in the medians: mean lung capacity to increases as the age increases.\n\n\n\n\n\nCode\n# Boxplot\n\nnonsmoking_age <- filter(LungCapData, Smoke == \"no\")\n\n\nError in filter(LungCapData, Smoke == \"no\"): object 'LungCapData' not found\n\n\nCode\nboxplot(LungCap ~ Age.group, data = nonsmoking_age,\n        main = \"Lung Capacity of Non-Smokers by Age Group\",\n        xlab = \"Age Group\", ylab = \"Lung Capacity\")\n\n\nError in eval(m$data, parent.frame()): object 'nonsmoking_age' not found\n\n\nIn non-smokers, we see the same trend of increasing lung capacities as age increases, but the median lung capacities in the two older age groups in the non-smoking group are higher than those in the smoking group. There are also more outliers for non-smokers, especially in the 14-15 category.\n\n\nCode\n# Means\n\nnonsmoking_age %>%\n  group_by(Age.group) %>%\n  summarise_at(vars(LungCap), list(name = mean))\n\n\nError in group_by(., Age.group): object 'nonsmoking_age' not found\n\n\nThe means of the non-smoking group by age follow the same trend as the medians, as well as in the smoking group. However, the mean lung capacity for the oldest two age groups in the non-smoking category are higher than the means for those groups in the smoking category.\n\n\n\n\n\n\n\n\nCode\nLungCapData %>%\n  filter(Age.group == \"13 and Under\") %>%\n  group_by(Smoke) %>%\n  summarise_at(vars(LungCap), list(name = mean))\n\n\nError in filter(., Age.group == \"13 and Under\"): object 'LungCapData' not found\n\n\nThe mean lung capacity for smokers is higher than the mean lung capacity for non-smokers in the age group 13 and under, which mirrors the general means we found earlier. However, from the boxplot of Smokers by Age Group, we can see that there is a very low outlier in this age group, which might be affecting the mean for this group as well as overall smokers.\n\n\n\n\n\nCode\nLungCapData %>%\n  filter(Age.group == \"14-15\") %>%\n  group_by(Smoke) %>%\n  summarise_at(vars(LungCap), list(name = mean))\n\n\nError in filter(., Age.group == \"14-15\"): object 'LungCapData' not found\n\n\nIn this age group, the mean lung capacity for non-smokers is higher than the mean lung capacity for smokers–unlike the younger group.\n\n\n\n\n\nCode\nLungCapData %>%\n  filter(Age.group == \"16-17\") %>%\n  group_by(Smoke) %>%\n  summarise_at(vars(LungCap), list(name = mean))\n\n\nError in filter(., Age.group == \"16-17\"): object 'LungCapData' not found\n\n\nThe same trend continues in this age group, with the mean lung capacity in non-smokers ages 16 and 17 higher than the mean lung capacity of smokers in this group. Yet as the ages increase, the mean lung capacities for non-smokers and smokers increase about the same amount (by 1).\n\n\n\n\n\nCode\nLungCapData %>%\n  filter(Age.group == \"18 and Over\") %>%\n  group_by(Smoke) %>%\n  summarise_at(vars(LungCap), list(name = mean))\n\n\nError in filter(., Age.group == \"18 and Over\"): object 'LungCapData' not found\n\n\nIn this oldest age group, the same trend continues: the mean lung capacity for non-smokers is higher than that of smokers. This pattern in the groups 18+, 16-17, and 14-15 are not found in the overall means for smokers and nonsmokers, suggesting that the outlier in the 13 and Under group might have brought down the overall mean for smokers.\n\n\n\n\n\n\nCode\n# Correlation\n\ncor(LungCapData$Age, LungCapData$LungCap, use = \"everything\")\n\n\nError in is.data.frame(y): object 'LungCapData' not found\n\n\nThe correlation between lung capacity and age is positive and strong. As age increases, lung capacity also increases. The value of 0.8 is close to 1, meaning there is a somewhat strong relationship between the two variables.\n\n\nCode\n# Covariance\n\ncov(LungCapData$Age, LungCapData$LungCap, use = \"everything\")\n\n\nError in is.data.frame(y): object 'LungCapData' not found\n\n\nThe covariance is positive, meaning that there is a positive relationship between the varaibles, which is also clear from the correlation (since the correlation coefficient is a function of the covariance). Age and lung capacity have an overall positive relationship: as age increases, so does lung capacity."
  },
  {
    "objectID": "posts/DACSS 603 HW 1.html#part-a",
    "href": "posts/DACSS 603 HW 1.html#part-a",
    "title": "DACSS 603 HW 1 Kimble",
    "section": "Part A",
    "text": "Part A\n\n\nCode\n160/810\n\n\n[1] 0.1975309"
  },
  {
    "objectID": "posts/DACSS 603 HW 1.html#part-b",
    "href": "posts/DACSS 603 HW 1.html#part-b",
    "title": "DACSS 603 HW 1 Kimble",
    "section": "Part B",
    "text": "Part B\n\n\nCode\n(434 + 128)/810\n\n\n[1] 0.6938272"
  },
  {
    "objectID": "posts/DACSS 603 HW 1.html#part-c",
    "href": "posts/DACSS 603 HW 1.html#part-c",
    "title": "DACSS 603 HW 1 Kimble",
    "section": "Part C",
    "text": "Part C\n\n\nCode\n(160 + 434 + 128)/810\n\n\n[1] 0.891358"
  },
  {
    "objectID": "posts/DACSS 603 HW 1.html#part-d",
    "href": "posts/DACSS 603 HW 1.html#part-d",
    "title": "DACSS 603 HW 1 Kimble",
    "section": "Part D",
    "text": "Part D\n\n\nCode\n(64 + 24)/810\n\n\n[1] 0.108642"
  },
  {
    "objectID": "posts/DACSS 603 HW 1.html#part-e",
    "href": "posts/DACSS 603 HW 1.html#part-e",
    "title": "DACSS 603 HW 1 Kimble",
    "section": "Part E",
    "text": "Part E\n\n\nCode\n# Creating vector\nconvict <- c(rep(0, 128), rep(1, 434), rep(2, 160), rep(3, 64), rep(4, 24))\n\nweighted.mean(convict)\n\n\n[1] 1.28642\n\n\nThe expected value for the number of prior convictions is 1.27–but since prior convictions have to be a whole number, that would be rounded to 1."
  },
  {
    "objectID": "posts/DACSS 603 HW 1.html#part-f",
    "href": "posts/DACSS 603 HW 1.html#part-f",
    "title": "DACSS 603 HW 1 Kimble",
    "section": "Part F",
    "text": "Part F\n\n\nCode\nvar(convict)\n\n\n[1] 0.8572937\n\n\nCode\nsd(convict)\n\n\n[1] 0.9259016"
  },
  {
    "objectID": "posts/Emily Duryea Homework 1.html",
    "href": "posts/Emily Duryea Homework 1.html",
    "title": "Duryea Homework 1",
    "section": "",
    "text": "Code\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(readxl)\ndf <- read_excel(\"_data/LungCapData.xls\")  \n\nhist(df$LungCap)\n\n\n\n\n\nPart A: Plotting probability density histogram\n\n\nCode\nhist(df$LungCap, \n     col=\"yellow\",\n     border=\"black\",\n     prob = TRUE,\n     xlab = \"LungCap\",\n     main = \"Density Plot\")\n\nlines(density(df$LungCap),\n      lwd = 2,\n      col = \"chocolate3\")\n\n\n\n\n\nPart B: Compare the probability distribution of the LungCap with respect to Males and Females\n\n\nCode\nggplot(df, aes(y = dnorm(LungCap), color = Gender)) +\n  geom_boxplot() +\n  labs(title = \"LungCap Probability Distribution for Males and Females\", y = \"Probability density\")\n\n\n\n\n\nPart C: Compare the mean lung capacities for smokers and non-smokers\n\n\nCode\nmean_smoking <- df %>%\n  group_by(Smoke) %>%\n  summarise(mean = mean(LungCap))\nmean_smoking\n\n\n# A tibble: 2 × 2\n  Smoke  mean\n  <chr> <dbl>\n1 no     7.77\n2 yes    8.65\n\n\nThe means of smokers vs non smokers does not make sense since non smokers have a lower mean lung cap, when one would think it would be the other way around. However, limited data is provided on the sample, so there could be other factors in play.\nPart D: Examine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”\n\n\nCode\ndf <- mutate(df, AgeGroup = case_when(Age <= 13 ~ \"less than or equal to 13\",\n                                    Age == 14 | Age == 15 ~ \"14 to 15\",\n                                    Age == 16 | Age == 17 ~ \"16 to 17\",\n                                    Age >= 18 ~ \"greater than or equal to 18\"))\n\ndf %>%\n  ggplot(aes(y = LungCap, color = Smoke)) +\n  geom_histogram(bins = 25) +\n  facet_wrap(vars(AgeGroup)) +\n  theme_classic() + \n  labs(title = \"LungCap and Smoke based on age groups\", y = \"Lung Capacity\", x = \"Frequency\")\n\n\n\n\n\nBased on the histograms, Part D seems to contrast with Part C, since the plots seem to demonstrate non-smokers having higher lung capacity than smokers in all age groups. Additionally, lung capacity appears to decrease with age based on the graph.\nPart E: Compare the lung capacities for smokers and non-smokers within each age group\n\n\nCode\ndf %>%\n  ggplot(aes(x = Age, y = LungCap, color = Smoke)) +\n  geom_line() +\n  facet_wrap(vars(Smoke)) +\n  labs(title = \"LungCap and Smoke based on age and smoker vs nonsmoker\", y = \"Lung Capacity\", x = \"Age\")\n\n\n\n\n\nBased on information gained in Part D and Part E, it appears that lung capacity decreases with age, and, despite the means in Part C, lung capacity is higher for non-smokers.\nPart F: Calculate the correlation and covariance between Lung Capacity and Age\n\n\nCode\nCov_lungcapage <- cov(df$LungCap, df$Age)\nCor_lungcapeage <- cor(df$LungCap, df$Age)\nCov_lungcapage\n\n\n[1] 8.738289\n\n\nCode\nCor_lungcapeage\n\n\n[1] 0.8196749\n\n\nBecause both the covariance and correlation are positive numbers, the relationship between lung capacity and age are positively related, meaning as one increases, the other also increases in a proportional manner.\nQuestion 2\n\n\nCode\nPrior_Convictions <- c(0:4)\nInmate_Number <- c(128, 434, 160, 64, 24)\nip <- tibble(Prior_Convictions, Inmate_Number)\n\nip <- mutate(ip, Probability = Inmate_Number/sum(Inmate_Number))\nip\n\n\n# A tibble: 5 × 3\n  Prior_Convictions Inmate_Number Probability\n              <int>         <dbl>       <dbl>\n1                 0           128      0.158 \n2                 1           434      0.536 \n3                 2           160      0.198 \n4                 3            64      0.0790\n5                 4            24      0.0296\n\n\nPart A: What is the probability that a randomly selected inmate has exactly 2 prior convictions?\n\n\nCode\nip %>%\n  filter(Prior_Convictions == 2) %>%\n  select(Probability)\n\n\n# A tibble: 1 × 1\n  Probability\n        <dbl>\n1       0.198\n\n\nThe probability that a randomly selected inmate has exactly two prior convictions is 0.1975309.\nPart B: What is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\n\nCode\npartb <- ip %>%\n  filter(Prior_Convictions < 2)\nsum(partb$Probability)\n\n\n[1] 0.6938272\n\n\nThe probability that a randomly selected inmate has fewer than two prior convictions is 0.6938272.\nPart C: What is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\n\nCode\npartc <- ip %>%\n  filter(Prior_Convictions <= 2)\nsum(partc$Probability)\n\n\n[1] 0.891358\n\n\nThe probability that a randomly selected inmate has two or fewer prior convictions is 0.891358.\nPart D: What is the probability that a randomly selected inmate has more than 2 prior convictions?\n\n\nCode\npartd <- ip %>%\n  filter(Prior_Convictions > 2)\nsum(partd$Probability)\n\n\n[1] 0.108642\n\n\nThe probability that a randomly selected inmate has more than two prior convictions is 0.108642.\nPart E: What is the expected value for the number of prior convictions?\n\n\nCode\nip <- mutate(ip, vl = Prior_Convictions*Probability)\nparte <- sum(ip$vl)\nparte\n\n\n[1] 1.28642\n\n\nThe expected value for the number of prior convictions is 1.28642.\nPart F: Calculate the variance and the standard deviation for the Prior Convictions\n\n\nCode\nip_var <-sum(((ip$Prior_Convictions-parte)^2)*ip$Probability)\nip_var\n\n\n[1] 0.8562353\n\n\nCode\nsqrt(ip_var)\n\n\n[1] 0.9253298\n\n\nThe variance for prior convictions is 0.8562353 and the standard deviation is 0.9253298."
  },
  {
    "objectID": "posts/EmmaRasmussenFinalPart1.html",
    "href": "posts/EmmaRasmussenFinalPart1.html",
    "title": "Final Project Part 1",
    "section": "",
    "text": "Code\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)\n\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(dplyr)"
  },
  {
    "objectID": "posts/EmmaRasmussenFinalPart1.html#research-question",
    "href": "posts/EmmaRasmussenFinalPart1.html#research-question",
    "title": "Final Project Part 1",
    "section": "Research Question:",
    "text": "Research Question:\nDoes political partisanship correlate with COVID-19 death rates?\nThe COVID-19 pandemic became a political matter. Behaviors associated with COVID-19 prevention were adopted on partisan lines (masking, social distancing, and vaccine uptake). Early in the pandemic, mask mandates were protested in some communities. My research question is have these behaviors affected COVID-19 death rates along partisan lines? If so, public health interventions could target communities that may be higher risk for COVID-19 deaths based on political partisanship.\nI am thinking death toll would make the most sense to measure than infection rates as infection rates are constantly changing (other studies have looked at infection rates over waves of the pandemic, see this study from the Pew Research Center (Jones 2022)). I also think that one way to measure partisanship will be the 2020 county-level election results (% voting for Trump). In other words, my research is looking to see if (county-level) Trump support correlates with COVID-19 death rates. Both these variables can be found in county-level data sets so I can join multiple dataset with county name (or FIPS code) as the “key”.\nOther variables to consider at the county-level (confounding variables): vaccine (and booster) uptake, average age of population"
  },
  {
    "objectID": "posts/EmmaRasmussenFinalPart1.html#hypothesis",
    "href": "posts/EmmaRasmussenFinalPart1.html#hypothesis",
    "title": "Final Project Part 1",
    "section": "Hypothesis:",
    "text": "Hypothesis:\nWhile I came up with this research idea on my own, other organizations such as NPR (Wood and Brumfiel 2021) and the Pew Research Center ()have already tested this. For this project, I will use the most recent data I can find. I was hoping to consider the confounding variable of population density, for instance I am guessing more urban populations will tend to vote democratic but these more densely populated places may also have higher infection rates. However, I cannot find any county level population density data sets, so I may use the “Urban Rural Description” variable in one of my datasets.\nH0: B1 (and all beta values) is zero. There is no correlation Ha: B1 (or any beta value) is not zero. There is a correlation between partisanship and COVID-19 death rates."
  },
  {
    "objectID": "posts/EmmaRasmussenFinalPart1.html#descriptive-statistics",
    "href": "posts/EmmaRasmussenFinalPart1.html#descriptive-statistics",
    "title": "Final Project Part 1",
    "section": "Descriptive Statistics:",
    "text": "Descriptive Statistics:\n\n\nCode\n#set wd to change file path so I can access data on my computer without adding to posts folder\nsetwd(\"/Users/emmarasmussen/Documents\")\n\n\nError in setwd(\"/Users/emmarasmussen/Documents\"): cannot change working directory\n\n\nCode\nvotedf<- read_csv(\"countypres_2000-2020.csv\")\n\n\nError: 'countypres_2000-2020.csv' does not exist in current working directory ('C:/Users/srika/OneDrive/Desktop/DACSS/603_Fall_2022/posts').\n\n\nCode\nhead(votedf, 12)\n\n\nError in head(votedf, 12): object 'votedf' not found\n\n\nCode\ncoviddf<- read_csv(\"Provisional_COVID-19_Deaths_by_County__and_Race_and_Hispanic_Origin.csv\")\n\n\nError: 'Provisional_COVID-19_Deaths_by_County__and_Race_and_Hispanic_Origin.csv' does not exist in current working directory ('C:/Users/srika/OneDrive/Desktop/DACSS/603_Fall_2022/posts').\n\n\nCode\nhead(coviddf, 12)\n\n\nError in head(coviddf, 12): object 'coviddf' not found\n\n\nCode\n#counting the number of distinct counties in df\nn_distinct(votedf$county_name)\n\n\nError in list2(...): object 'votedf' not found\n\n\nCode\nn_distinct(coviddf$\"County Name\")\n\n\nError in list2(...): object 'coviddf' not found\n\n\n\n\nCode\nsummary(votedf)\n\n\nError in summary(votedf): object 'votedf' not found\n\n\nCode\nsummary(coviddf)\n\n\nError in summary(coviddf): object 'coviddf' not found\n\n\nThis data is going to require some tidying before merging. In the coviddf, each county is listed 3 times, (once per indicator) so I will likely filter out just the indicator “Distribution of COVID-19 deaths (%)” so each county is listed only once. Similarly, the votedf contains extra years. For my research, I am only concerned with 2016 data so I will filter out % voting for Trump in 2016 as a measure of political affiliation/partisanship. Then I will merge the two dfs based on county names (will also require some data tidying).\nThe votedf was compiled by the MIT Election Data and Science Lab. It was first published in 2018 and has been updated with the 2020 election. It contains county-level presidential election data beginning in 2000 and going up to the 2020 election. The data has 12 columns, and 72,617 rows (many of which I will filter out before conducting analysis.) There are 1,892 distinct county names in the data set.\nThe coviddf only has 857 unique county names in the data frame. This may be because not all counties reported COVID-19 death counts. When I join the data sets, I will join so as to only include observations that we have information from both data frames. The coviddf is provisional, meaning that it is consistently updated (I believe on a weekly basis) with current COVID-19 death toll data. It is likely compiled by counties/towns reporting these numbers to the CDC. This data has limitations, not all counties report this, and not all report it accurately/ attribute COVID-19 as the true cause of death in all circumstances. Using the summary function, we can see the “mean” COVID-19 deaths by county is 852.7, however this isn’t super meaningful given each county has this reported 3 times in the data and the median is significantly lower. Statistics provided by the summary function will be more meaningful once the data is tidied."
  },
  {
    "objectID": "posts/EmmaRasmussenFinalPart1.html#references",
    "href": "posts/EmmaRasmussenFinalPart1.html#references",
    "title": "Final Project Part 1",
    "section": "References",
    "text": "References\nJones, B. (2022). The Changing Political Geography of COVID-19 Over the Last Two Years. Pew Research Center. March 3, 2022. https://www.pewresearch.org/politics/2022/03/03/the-changing-political-geography-of-covid-19-over-the-last-two-years/\nMIT Election Data and Science Lab. (2021) County Presidential Election Returns 2000-2020. Accessed from the Harvard Dataverse [October 11, 2022]. https://doi.org/10.7910/DVN/VOQCHQ\nNational Center for Health Statistics. (2022). Provisional COVID-19 Deaths by County, and Race and Hispanic Origin. Accessed from the Centers for Disease Control [October 11, 2022]. https://data.cdc.gov/d/k8wy-p9cg\nWood, D. and Brumfiel, G. (2021). Pro-Trump counties now have far higher COVID death rates. Misinformation is to blame. NPR. December 5, 2021. https://www.npr.org/sections/health-shots/2021/12/05/1059828993/data-vaccine-misinformation-trump-counties-covid-death-rate\n[Need to add italics to references]"
  },
  {
    "objectID": "posts/Final Project 1_Kaushika Potluri.html",
    "href": "posts/Final Project 1_Kaushika Potluri.html",
    "title": "Final Project Submission 1",
    "section": "",
    "text": "the research question that I have been interested in is the impact of education about sex and fertility for women and how that changes the fetility rate. Women’s education raises the value of time spent working in the market and, as a result, the opportunity cost of spending time to take care of their child seems less. Across time and places, there is a clear negative link between women’s education and fertility, although its meaning is ambiguous. Women’s level of education may impact fertility through its effects on children’s health, the number of children desired, and women’s ability to give birth and understanding of various birth control options. Each of these are influenced by local, institutional, and national circumstances. Their relative importance may fluctuate as a society develops economically. Since having children affects how much mothers must pay for childcare, women’s education may also be correlated with fertility. The data was acquired from various years of the National Opinion Resource Center’s General Social Survey. Compared to other women, mothers who stay at home with their kids are less likely to invest more money in their education. The correlation between women’s education and unobservable qualities that are jointly linked with fertility may be even more significant.\n###Hypothesis It can be thought of as the total number of unplanned and intended children. The number of kids a family can have, the number of kids the family desires, and the capability to regulate birth through the availability of modern contraceptives and the knowledge of how to use them are all impacted by advancements in women’s education. The number of children a woman has is halfway between the amount she wants and her level of natural fertility. Age and fertility control are the determining variables.If there was a variation by region in birth control availability, such information might be valuable. However, our data set does not contain geographical information (parameters). My assumption would be that if the level of education increases, the number of children would decrease.\n\n\nCode\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/Final Project 1_Kaushika Potluri.html#loading-in-packages",
    "href": "posts/Final Project 1_Kaushika Potluri.html#loading-in-packages",
    "title": "Final Project Submission 1",
    "section": "Loading in packages:",
    "text": "Loading in packages:\n\n\nCode\nlibrary(readr)\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6     ✔ dplyr   1.0.9\n✔ tibble  3.1.8     ✔ stringr 1.4.0\n✔ tidyr   1.2.0     ✔ forcats 0.5.1\n✔ purrr   0.3.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(readxl)"
  },
  {
    "objectID": "posts/Final Project 1_Kaushika Potluri.html#reading-in-data",
    "href": "posts/Final Project 1_Kaushika Potluri.html#reading-in-data",
    "title": "Final Project Submission 1",
    "section": "Reading in Data:",
    "text": "Reading in Data:\nThe data was acquired from Professor Sander’s article that he used.\n\n\nCode\nWomendata <-  read.csv(\"_data/data.csv\")"
  },
  {
    "objectID": "posts/Final Project 1_Kaushika Potluri.html#summary-of-the-data",
    "href": "posts/Final Project 1_Kaushika Potluri.html#summary-of-the-data",
    "title": "Final Project Submission 1",
    "section": "Summary of the data",
    "text": "Summary of the data\n\n\nCode\nsummary(Womendata)\n\n\n       X           mnthborn         yearborn          age       \n Min.   :   1   Min.   : 1.000   Min.   :38.00   Min.   :15.00  \n 1st Qu.:1091   1st Qu.: 3.000   1st Qu.:55.00   1st Qu.:20.00  \n Median :2181   Median : 6.000   Median :62.00   Median :26.00  \n Mean   :2181   Mean   : 6.331   Mean   :60.43   Mean   :27.41  \n 3rd Qu.:3271   3rd Qu.: 9.000   3rd Qu.:68.00   3rd Qu.:33.00  \n Max.   :4361   Max.   :12.000   Max.   :73.00   Max.   :49.00  \n                                                                \n    electric          radio              tv             bicycle      \n Min.   :0.0000   Min.   :0.0000   Min.   :0.00000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000  \n Median :0.0000   Median :1.0000   Median :0.00000   Median :0.0000  \n Mean   :0.1402   Mean   :0.7018   Mean   :0.09291   Mean   :0.2758  \n 3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.00000   Max.   :1.0000  \n NA's   :3        NA's   :2        NA's   :2         NA's   :3       \n      educ             ceb            agefbrth        children     \n Min.   : 0.000   Min.   : 0.000   Min.   :10.00   Min.   : 0.000  \n 1st Qu.: 3.000   1st Qu.: 1.000   1st Qu.:17.00   1st Qu.: 0.000  \n Median : 7.000   Median : 2.000   Median :19.00   Median : 2.000  \n Mean   : 5.856   Mean   : 2.442   Mean   :19.01   Mean   : 2.268  \n 3rd Qu.: 8.000   3rd Qu.: 4.000   3rd Qu.:20.00   3rd Qu.: 4.000  \n Max.   :20.000   Max.   :13.000   Max.   :38.00   Max.   :13.000  \n                                   NA's   :1088                    \n    knowmeth         usemeth          monthfm          yearfm     \n Min.   :0.0000   Min.   :0.0000   Min.   : 1.00   Min.   :50.00  \n 1st Qu.:1.0000   1st Qu.:0.0000   1st Qu.: 3.00   1st Qu.:72.00  \n Median :1.0000   Median :1.0000   Median : 6.00   Median :78.00  \n Mean   :0.9633   Mean   :0.5776   Mean   : 6.27   Mean   :76.91  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.: 9.00   3rd Qu.:83.00  \n Max.   :1.0000   Max.   :1.0000   Max.   :12.00   Max.   :88.00  \n NA's   :7        NA's   :71       NA's   :2282    NA's   :2282   \n     agefm          idlnchld          heduc            agesq       \n Min.   :10.00   Min.   : 0.000   Min.   : 0.000   Min.   : 225.0  \n 1st Qu.:17.00   1st Qu.: 3.000   1st Qu.: 0.000   1st Qu.: 400.0  \n Median :20.00   Median : 4.000   Median : 6.000   Median : 676.0  \n Mean   :20.69   Mean   : 4.616   Mean   : 5.145   Mean   : 826.5  \n 3rd Qu.:23.00   3rd Qu.: 6.000   3rd Qu.: 8.000   3rd Qu.:1089.0  \n Max.   :46.00   Max.   :20.000   Max.   :20.000   Max.   :2401.0  \n NA's   :2282    NA's   :120      NA's   :2405                     \n     urban           urb_educ          spirit          protest      \n Min.   :0.0000   Min.   : 0.000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.: 0.000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :1.0000   Median : 0.000   Median :0.0000   Median :0.0000  \n Mean   :0.5166   Mean   : 3.469   Mean   :0.4222   Mean   :0.2277  \n 3rd Qu.:1.0000   3rd Qu.: 7.000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n Max.   :1.0000   Max.   :20.000   Max.   :1.0000   Max.   :1.0000  \n                                                                    \n    catholic         frsthalf          educ0           evermarr     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :1.0000   Median :0.0000   Median :0.0000  \n Mean   :0.1025   Mean   :0.5405   Mean   :0.2078   Mean   :0.4767  \n 3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n                                                                    \n\n\n\n\nCode\nglimpse(Womendata)\n\n\nRows: 4,361\nColumns: 28\n$ X        <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ mnthborn <int> 5, 1, 7, 11, 5, 8, 7, 9, 12, 9, 6, 10, 12, 2, 1, 6, 1, 8, 4, …\n$ yearborn <int> 64, 56, 58, 45, 45, 52, 51, 70, 53, 39, 46, 59, 42, 40, 53, 6…\n$ age      <int> 24, 32, 30, 42, 43, 36, 37, 18, 34, 49, 42, 29, 45, 48, 35, 2…\n$ electric <int> 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ radio    <int> 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ tv       <int> 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1…\n$ bicycle  <int> 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0…\n$ educ     <int> 12, 13, 5, 4, 11, 7, 16, 10, 5, 4, 15, 7, 0, 4, 12, 7, 7, 5, …\n$ ceb      <int> 0, 3, 1, 3, 2, 1, 4, 0, 1, 0, 3, 3, 4, 10, 3, 0, 4, 2, 0, 1, …\n$ agefbrth <int> NA, 25, 27, 17, 24, 26, 20, NA, 19, NA, 25, 23, 18, 19, 23, N…\n$ children <int> 0, 3, 1, 2, 2, 1, 4, 0, 1, 0, 3, 3, 2, 8, 3, 0, 4, 2, 0, 1, 0…\n$ knowmeth <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ usemeth  <int> 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1…\n$ monthfm  <int> NA, 11, 6, 1, 3, 11, 5, NA, 7, 11, 6, 1, 1, 10, 1, NA, NA, NA…\n$ yearfm   <int> NA, 80, 83, 61, 66, 76, 78, NA, 72, 61, 70, 84, 66, 66, 74, N…\n$ agefm    <int> NA, 24, 24, 15, 20, 24, 26, NA, 18, 22, 24, 24, 23, 26, 21, N…\n$ idlnchld <int> 2, 3, 5, 3, 2, 4, 4, 4, 4, 4, 3, 6, 6, 4, 3, 4, 5, 1, 2, 3, 2…\n$ heduc    <int> NA, 12, 7, 11, 14, 9, 17, NA, 3, 1, 16, 7, NA, 3, 16, NA, NA,…\n$ agesq    <int> 576, 1024, 900, 1764, 1849, 1296, 1369, 324, 1156, 2401, 1764…\n$ urban    <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ urb_educ <int> 12, 13, 5, 4, 11, 7, 16, 10, 5, 4, 15, 7, 0, 4, 12, 7, 7, 5, …\n$ spirit   <int> 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0…\n$ protest  <int> 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1…\n$ catholic <int> 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0…\n$ frsthalf <int> 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0…\n$ educ0    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ evermarr <int> 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1…\n\n\nWe can see that we have 28 variables and 4361 observations in this dataset. The dependent variable of interest - number of living children Then I will perform data manipulation to tidy the data. The variables of interest are age, yearborn, month born, urban education and many more variables that seem intriguing. Variables like radio, bicycle, electric can be ignored in this.\n###References [1] The effect of women’s schooling on fertility by W Sander · 1992 [2] The Impact of Women’s Schooling on Fertility and Contraceptive Use by M Ainsworth · 1996"
  },
  {
    "objectID": "posts/Final Project Proposal.html",
    "href": "posts/Final Project Proposal.html",
    "title": "Final Project Proposal",
    "section": "",
    "text": "The research questions that I am looking to investigate involve the factors that increase university students’ GPA. These include the following:\n1) Does classroom engagement (i.e., taking notes, attending class, listening) result in a higher GPA in university students?\n2) Does reported studying (i.e., weekly study hours) result in a higher GPA in university students?\n3) Does collaboration between students (i.e., studying together, positive class discussions) result in a higher GPA in university students?\n\n\n\n\n\nFor the first research question, it is reasonable to hypothesize that classroom engagement will have a positive effect on students’ academic achievement. Previous research supports this hypothesis. For example, one study found that classroom engagement, as well as other related factors such as time management and autonomous motivation, are predictors of academic achievement (Fokkens-Bruinsma, et al., 2021). Another study found that attendance in higher education is a small, but still statistically significant, predictor of academic performance (Büchele, 2021). In this study, classroom engagement will be defined as “taking notes, attendance, and frequency of listening.” These measures will be reported by university students via survey.\n\n\n\nIn regards to the second research question, it is hypothesized that students who study more will have a higher GPA. There are many previous studies that support this claim. For instance, one study found that university freshmen who studied more than eight hours a week saw an average increase in GPA of 0.580 (Nelson, 2003). Research has also found that increasing study time leads to an increased GPA (Thibodeaux, et al., 2017). In this study, hours spent studying will be measured through students’ estimated range of hours studied, reported via survey.\n\n\n\nIn response to the third research question, it is hypothesized that student collaboration will have a positive effect on student GPA. There is some research literature that supports this statement. One study found that students who study with their peers achieve significantly higher homework scores (Vargas, et al., 2018). Another study found that university students who had a strong social network and exhibited collaborative behaviors tended to achieve higher grades (Ellis & Han, 2021). Effective student collaboration can also occur during class time, such as through small group discussions. Research has found that students who participate in small group discussions demonstrate an increase in resilience, which has shown to improve academic performance (Torrento-estimo, et al, 2012). In this study, student collaboration will be measured through students’ reported time spent studying with peers, and impact that their class discussions have.\n\n\n\n\nThe dataset used is one retrieved from Kaggle using the link here. The dataset is named, “Higher Education Student Performance Evaluation.” This dataset was used in a self-report survey study conducted by Yılmaz and Sekeroglu (2019).\n\n\nCode\nstudentsurvey <- read.csv(\"student_prediction.csv\")\n\n\nWarning in file(file, \"rt\"): cannot open file 'student_prediction.csv': No such\nfile or directory\n\n\nError in file(file, \"rt\"): cannot open the connection\n\n\nCode\nsummary(studentsurvey)\n\n\nError in summary(studentsurvey): object 'studentsurvey' not found\n\n\nCode\nlibrary(ggplot2)\n\n\nTo begin, it is important to examine the demographic variables through descriptive statistics to observe the sample.\n\n\nTo start, students’ reported gender (1 = female and 2 = male) is plotted in the bar graph below.\n\n\nCode\nggplot(studentsurvey, aes(x = GENDER)) + geom_bar()\n\n\nError in ggplot(studentsurvey, aes(x = GENDER)): object 'studentsurvey' not found\n\n\nIn this sample, there are more males than females.\n\n\n\nThe bar graph below plots the students’ reported ages at the time of the survey (1 = 18-21, 2 = 22-25, 3 = 26 or above).\n\n\nCode\nggplot(studentsurvey, aes(x = AGE)) + geom_bar()\n\n\nError in ggplot(studentsurvey, aes(x = AGE)): object 'studentsurvey' not found\n\n\nThe majority of students are between the ages 18-25, with very few above the age of 26.\n\n\n\nThe bar graph below depicts what type of high school the university students graduated from (1= private, 2 = state, 3 = other).\n\n\nCode\nggplot(studentsurvey, aes(x = HS_TYPE)) + geom_bar()\n\n\nError in ggplot(studentsurvey, aes(x = HS_TYPE)): object 'studentsurvey' not found\n\n\nAccording to the graph, most students attended a state (public) high school.\n\n\n\nThe bar graph below demonstrates what percentage of their tuition was paid for by scholarship (1 = None, 2 = 25%, 3 = 50%, 4 = 75%, 5 = Full)\n\n\nCode\nggplot(studentsurvey, aes(x = SCHOLARSHIP)) + geom_bar()\n\n\nError in ggplot(studentsurvey, aes(x = SCHOLARSHIP)): object 'studentsurvey' not found\n\n\nMost students have received at least 50% scholarship at this university.\n\n\n\nThe bar graph below depicts how many students work a job outside of their classes (1 = Yes, 2 = No)\n\n\nCode\nggplot(studentsurvey, aes(x = WORK)) + geom_bar()\n\n\nError in ggplot(studentsurvey, aes(x = WORK)): object 'studentsurvey' not found\n\n\nMost students do not have a job while they are studying at university in this sample.\n\n\n\nThis sample may not be representative of the U.S. student population. There are more male than female students, which is not the case at most schools: there is about a 1:2 male to female ratio at U.S. colleges (Leukhina & Smaldone, 2022). The ages of students, however, do align with the ages of current university students: about a third of students in university are ages 24 and under (Hanson, 2022). Additionally, like in the sample, the vast majority of students attended public schools (Riser-Kositsky, 2022). In regards to scholarships, the students at this particular university receive scholarships at significantly higher rates than the rest of the U.S. Only about one in eight students receive a scholarship, and only 5% receive a full scholarship (Scholarship Statistics, 2021). While the enrollment statuses of the students were not given, if all students were full-time students, it would align with research that shows that less than half of full-time students (40%) in U.S. universities work while in school. While this sample may not be entirely representative of the U.S. college student population, analyses of this dataset conducted may provide some insight on factors that improve university students GPA.\n\n\n\n\nBüchele, S. (2021). Evaluating the link between attendance and performance in higher education: the role of classroom engagement dimensions. Assessment & Evaluation in Higher Education, 46(1), 132-150.\nEllis, R., & Han, F. (2021). Assessing university student collaboration in new ways. Assessment & Evaluation in Higher Education, 46(4), 509-524.\nFokkens-Bruinsma, M., Vermue, C., Deinumdataset, J. F., & van Rooij, E. (2021). First-year academic achievement: the role of academic self-efficacy, self-regulated learning and beyond classroom engagement. Assessment & Evaluation in Higher Education, 46(7), 1115-1126.\nHanson, M. (2022, July 26). College Enrollment & Student Demographic Statistics. EducationData.org. Retrieved from https://educationdata.org/college-enrollment-statistics.\nLeukhina, O., & Smaldone, A. (2022, March 14). Why do women outnumber men in college enrollment? Saint Louis Fed Eagle. Retrieved from https://www.stlouisfed.org/on-the-economy/2022/mar/why-women-outnumber-men-college-enrollment#:~:text=When%20the%20fall%20college%20enrollment,seen%20in%20U.S.%20college%20enrollment.\nNational Center for Education Statistics. (2022, May). College Student Employment. Coe - college student employment. Retrieved from https://nces.ed.gov/programs/coe/indicator/ssa/college-student-employment\nNelson, R. (2003). Student Efficiency: A study on the behavior and productive efficiency of college students and the determinants of GPA. Issues in Political Economy, 12, 32-43.\nRiser-Kositsky, M. (2022, August 2). Education statistics: Facts about American Schools. Education Week. Retrieved from https://www.edweek.org/leadership/education-statistics-facts-about-american-schools/2019/01.\nScholarship statistics. ThinkImpact.com. (2021, November 10). Retrieved from https://www.thinkimpact.com/scholarship-statistics/.\nThibodeaux, J., Deutsch, A., Kitsantas, A., & Winsler, A. (2017). First-year college students' time use: Relations with self-regulation and GPA. Journal of Advanced Academics, 28(1), 5-27.\nTorrento-estimo, E., Lourdes, C., & Evidente, L. G. (2012). Collaborative Learning in Small Group Discussions and Its Impact on Resilience Quotient and Academic Performance. JPAIR Multidisciplinary Research Journal, 7(1), 1-1.\nVargas, D. L., Bridgeman, A. M., Schmidt, D. R., Kohl, P. B., Wilcox, B. R., & Carr, L. D. (2018). Correlation between student collaboration network centrality and academic performance. Physical Review Physics Education Research, 14(2), 020112.\nYılmaz, N., & Sekeroglu, B. (2019, August). Student Performance Classification Using Artificial Intelligence Techniques. In International Conference on Theory and Application of Soft Computing, Computing with Words and Perceptions (pp. 596-603). Springer, Cham."
  },
  {
    "objectID": "posts/Final Project.html",
    "href": "posts/Final Project.html",
    "title": "Final Project",
    "section": "",
    "text": "Extensive research has been done on climate change and economic changes respectively but there is not a significant amount of research about their relation towards one another. There are research papers that touch on this but in different aspects and focus more on other factors like political aspects. I would like to look a little broader and look at the difference between each climate zone and their economic differences. This can be taken with a grain of salt as there are many factors that could effect the economic situation being left out. The data was pulled from NASA’s POWER data access viewer; here I pulled the data by region since pulling the whole country in one go was unavailable. Thus, I will conduct research on each region respectively and then compare the results.\n\n\n\n\n\n\nResearch Questions\n\n\n\nA. Is there a relation between climate zone and economic growth?\nB. Do Southern climates have the largest economic growth?"
  },
  {
    "objectID": "posts/Final Project.html#reading-in-the-data",
    "href": "posts/Final Project.html#reading-in-the-data",
    "title": "Final Project",
    "section": "Reading in the data",
    "text": "Reading in the data\n\n## problem 1 how to merge files that are this large together? do we reduce the file sizes or is there another work around\n# May just need to keep regions separated \n# Weather data\n# Reading in all the weather data \nAmherst <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/amherst.csv\", skip = 14)\nFlorida <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/flordia.csv\", skip = 14)\nIllinois <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/illinois.csv\", skip = 14)\nMiddle <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/middle.csv\", skip = 14)\nNewmexico <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/Newmexico.csv\", skip = 14)\nNorth <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/North.csv\", skip = 14)\nSouth <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/south.csv\", skip = 14)\nSouthCali <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/SouthCali.csv\", skip = 14)\nTexas <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/Texas.csv\", skip = 14)\nWashington <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/washington.csv\", skip = 14)\nWestV <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/WestV.csv\", skip = 14)\n\n\nAmherst\nHad trouble with pivot_wider since it would split the values up by each name but then would fill in the values with NA for the other sections. This added a ton of NA values that one looked bad and were hard to deal with. I had to go a more manual way and do it for each part of PARAMETER to get the exact number of rows I needed. This stopped the NA values and got them all lined up so it reduced the size of the document from 500k+ rows to 89290 rows. This is huge in terms of running the data and working with it. Finally, I just merged the data together and then I was able to rename all the columns and start regression analysis.\n\n# Bringing all the month columns into one column\nAmherst <- Amherst %>%\npivot_longer(\n  cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, DEC),\n  names_to = \"MONTH\",\n  values_to = \"Month_Average\",\n)\n\n## getting the parameter section broken up into different sections since the normal pivot_longer did not work\nTidy_amherst <- Amherst %>%\n  select(PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN) %>%\n  filter(PARAMETER == 'PS')\n\nTidy_amherst <- Tidy_amherst %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nTidy_amherst <- Tidy_amherst %>%\n  select(PS, YEAR, MONTH, LAT, LON, ANN)\n\n\nt2m <- Amherst %>%\n  select(PARAMETER, Month_Average, YEAR) %>%\n  filter(PARAMETER == 'T2M')\n\nt2m <- t2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nt2m <- t2m %>%\n  select(T2M, YEAR)\n\nTidy_amherst$T2M <- t2m$T2M\n\nrh2m <- Amherst %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'RH2M')\n\nrh2m <- rh2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nrh2m <- rh2m %>%\n  select(RH2M, YEAR)\n\nTidy_amherst$RH2M <- rh2m$RH2M\n\nwh10m <- Amherst %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS10M')\n\nwh10m <- wh10m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nwh10m <- wh10m %>%\n  select(WS10M, YEAR)\n\nTidy_amherst$WS10M <- wh10m$WS10M\n\n\nwh50m <- Amherst %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS50M')\n\nwh50m <- wh50m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nwh50m <- wh50m %>%\n  select(WS50M, YEAR)\n\nTidy_amherst$WS50M <- wh50m$WS50M\n\nPRECTOTCORR <- Amherst %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'PRECTOTCORR')\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  select(PRECTOTCORR, YEAR)\n\nTidy_amherst$PRECTOTCORR <- PRECTOTCORR$PRECTOTCORR\n\n\n# renaming all the variables to easier to digest names\nTidy_amherst <- Tidy_amherst %>%\n  dplyr::rename(Temperature = T2M) %>%\n  dplyr::rename(Humidity = RH2M) %>%\n  dplyr::rename(Wind_10_meter = WS10M) %>%\n  dplyr::rename(Surface_Pressure = PS) %>%\n  dplyr::rename(Wind_50_meter = WS50M) %>%\n  dplyr::rename(Precipitation = PRECTOTCORR) %>%\n  dplyr::rename(Annual = ANN) %>%\n  dplyr::rename(Latitude = LAT) %>%\n  dplyr::rename(Longitude = LON) %>%\n  dplyr::rename(Month = MONTH) %>%\n  dplyr::rename(Year = YEAR)\n\n## Getting them in clean looking order\nTidy_amherst <- Tidy_amherst %>%\n  select(Year, Month, Latitude, Longitude, Temperature, Humidity, Precipitation, Surface_Pressure, Wind_10_meter, Wind_50_meter, Annual)\n\n## Summary and starting regression information \nsummary(Tidy_amherst)\n\n      Year         Month              Latitude       Longitude     \n Min.   :1990   Length:89280       Min.   :35.25   Min.   :-78.75  \n 1st Qu.:1997   Class :character   1st Qu.:37.12   1st Qu.:-77.25  \n Median :2005   Mode  :character   Median :39.00   Median :-75.25  \n Mean   :2005                      Mean   :39.00   Mean   :-75.25  \n 3rd Qu.:2013                      3rd Qu.:40.88   3rd Qu.:-73.25  \n Max.   :2020                      Max.   :42.75   Max.   :-71.75  \n  Temperature        Humidity     Precipitation   Surface_Pressure\n Min.   :-13.64   Min.   :52.25   Min.   : 0.02   Min.   : 94.28  \n 1st Qu.:  6.42   1st Qu.:76.19   1st Qu.: 2.28   1st Qu.: 98.53  \n Median : 14.19   Median :79.60   Median : 3.21   Median :101.19  \n Mean   : 13.18   Mean   :79.49   Mean   : 3.47   Mean   :100.08  \n 3rd Qu.: 20.79   3rd Qu.:83.19   3rd Qu.: 4.36   3rd Qu.:101.68  \n Max.   : 29.59   Max.   :99.29   Max.   :17.34   Max.   :102.57  \n Wind_10_meter    Wind_50_meter        Annual      \n Min.   : 1.220   Min.   : 2.680   Min.   : 94.80  \n 1st Qu.: 2.420   1st Qu.: 4.590   1st Qu.: 98.52  \n Median : 3.610   Median : 5.710   Median :101.25  \n Mean   : 4.363   Mean   : 6.126   Mean   :100.08  \n 3rd Qu.: 6.100   3rd Qu.: 7.420   3rd Qu.:101.71  \n Max.   :11.410   Max.   :12.510   Max.   :101.92  \n\nview_amherst <- Tidy_amherst %>%\n  slice(1:10)\n\nkable(view_amherst, digits = 2, align = \"ccccccc\", col.names = c(\"Year\", \"Month\", \"Latitude\", \"Longitude\", \"Temperature\", \"Humidity\", \"Precipitation\", \"Surface Pressure\", \"Wind 10 Meters\", \"Wind 50 Meters\", \"Annual\"), caption = \"Amherst Data\") %>%\n  kable_styling(font_size = 16)\n\n\n\nAmherst Data\n \n  \n    Year \n    Month \n    Latitude \n    Longitude \n    Temperature \n    Humidity \n    Precipitation \n    Surface Pressure \n    Wind 10 Meters \n    Wind 50 Meters \n    Annual \n  \n \n\n  \n    1990 \n    NOV \n    35.25 \n    -71.75 \n    19.38 \n    72.58 \n    5.12 \n    101.90 \n    7.68 \n    8.44 \n    101.91 \n  \n  \n    1990 \n    JAN \n    35.25 \n    -71.75 \n    17.30 \n    76.22 \n    5.03 \n    102.01 \n    8.38 \n    9.44 \n    101.91 \n  \n  \n    1990 \n    FEB \n    35.25 \n    -71.75 \n    17.01 \n    77.36 \n    4.96 \n    102.22 \n    9.68 \n    10.94 \n    101.91 \n  \n  \n    1990 \n    MAR \n    35.25 \n    -71.75 \n    17.56 \n    78.92 \n    5.29 \n    102.36 \n    7.51 \n    8.26 \n    101.91 \n  \n  \n    1990 \n    APR \n    35.25 \n    -71.75 \n    18.62 \n    75.35 \n    3.96 \n    101.87 \n    7.51 \n    8.26 \n    101.91 \n  \n  \n    1990 \n    MAY \n    35.25 \n    -71.75 \n    21.07 \n    76.08 \n    3.31 \n    101.63 \n    7.21 \n    8.15 \n    101.91 \n  \n  \n    1990 \n    JUN \n    35.25 \n    -71.75 \n    23.71 \n    82.84 \n    4.56 \n    101.67 \n    6.56 \n    7.42 \n    101.91 \n  \n  \n    1990 \n    JUL \n    35.25 \n    -71.75 \n    25.97 \n    83.94 \n    4.89 \n    101.81 \n    6.32 \n    7.19 \n    101.91 \n  \n  \n    1990 \n    AUG \n    35.25 \n    -71.75 \n    26.21 \n    79.47 \n    3.31 \n    101.76 \n    4.12 \n    4.57 \n    101.91 \n  \n  \n    1990 \n    SEP \n    35.25 \n    -71.75 \n    24.91 \n    74.81 \n    2.72 \n    101.67 \n    5.11 \n    5.57 \n    101.91 \n  \n\n\n\n\n\n\n\nFlorida\n\nFlorida <- Florida %>%\npivot_longer(\n  cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, DEC),\n  names_to = \"MONTH\",\n  values_to = \"Month_Average\",\n)\n\n\nTidy_Florida <- Florida %>%\n  select(PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN) %>%\n  filter(PARAMETER == 'PS')\n\nTidy_Florida <- Tidy_Florida %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nTidy_Florida <- Tidy_Florida %>%\n  select(PS, YEAR, MONTH, LAT, LON, ANN)\n\nt2m <- Florida %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'T2M')\n\nt2m <- t2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nt2m <- t2m %>%\n  select(T2M, YEAR)\n\nTidy_Florida$T2M <- t2m$T2M\n\nrh2m <- Florida %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'RH2M')\n\nrh2m <- rh2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nrh2m <- rh2m %>%\n  select(RH2M, YEAR)\n\nTidy_Florida$RH2M <- rh2m$RH2M\n\nwh10m <- Florida %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS10M')\n\nwh10m <- wh10m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nwh10m <- wh10m %>%\n  select(WS10M, YEAR)\n\nTidy_Florida$WS10M <- wh10m$WS10M\n\n\nwh50m <- Florida %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS50M')\n\nwh50m <- wh50m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nwh50m <- wh50m %>%\n  select(WS50M, YEAR)\n\nTidy_Florida$WS50M <- wh50m$WS50M\n\nPRECTOTCORR <- Florida %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'PRECTOTCORR')\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  select(PRECTOTCORR, YEAR)\n\nTidy_Florida$PRECTOTCORR <- PRECTOTCORR$PRECTOTCORR\n\nTidy_Florida <- Tidy_Florida %>%\n  dplyr::rename(Temperature = T2M) %>%\n  dplyr::rename(Humidity = RH2M) %>%\n  dplyr::rename(Wind_10_meter = WS10M) %>%\n  dplyr::rename(Surface_Pressure = PS) %>%\n  dplyr::rename(Wind_50_meter = WS50M) %>%\n  dplyr::rename(Precipitation = PRECTOTCORR) %>%\n  dplyr::rename(Annual = ANN) %>%\n  dplyr::rename(Latitude = LAT) %>%\n  dplyr::rename(Longitude = LON) %>%\n  dplyr::rename(Month = MONTH) %>%\n  dplyr::rename(Year = YEAR)\n\nTidy_Florida <- Tidy_Florida %>%\n  select(Year, Month, Latitude, Longitude, Temperature, Humidity, Precipitation, Surface_Pressure, Wind_10_meter, Wind_50_meter, Annual)\n\nsummary(Tidy_Florida)\n\n      Year         Month              Latitude       Longitude     \n Min.   :1990   Length:88536       Min.   :25.25   Min.   :-85.75  \n 1st Qu.:1997   Class :character   1st Qu.:26.75   1st Qu.:-83.75  \n Median :2005   Mode  :character   Median :28.50   Median :-81.75  \n Mean   :2005                      Mean   :28.50   Mean   :-81.75  \n 3rd Qu.:2013                      3rd Qu.:30.25   3rd Qu.:-79.75  \n Max.   :2020                      Max.   :31.75   Max.   :-77.75  \n  Temperature       Humidity     Precipitation    Surface_Pressure\n Min.   : 3.76   Min.   :51.16   Min.   : 0.030   Min.   : 99.85  \n 1st Qu.:20.46   1st Qu.:74.69   1st Qu.: 1.760   1st Qu.:101.45  \n Median :23.99   Median :77.32   Median : 3.050   Median :101.64  \n Mean   :23.20   Mean   :77.26   Mean   : 3.529   Mean   :101.61  \n 3rd Qu.:27.24   3rd Qu.:80.12   3rd Qu.: 4.760   3rd Qu.:101.82  \n Max.   :30.83   Max.   :91.78   Max.   :22.510   Max.   :102.48  \n Wind_10_meter  Wind_50_meter        Annual     \n Min.   :1.24   Min.   : 2.520   Min.   :100.3  \n 1st Qu.:3.51   1st Qu.: 4.660   1st Qu.:101.6  \n Median :4.69   Median : 5.660   Median :101.7  \n Mean   :4.74   Mean   : 5.719   Mean   :101.6  \n 3rd Qu.:5.95   3rd Qu.: 6.690   3rd Qu.:101.8  \n Max.   :9.74   Max.   :10.840   Max.   :101.9  \n\nTidy_Florida <- Tidy_Florida %>%\n  slice(1:10)\n\nkable(Tidy_Florida, digits = 2, align = \"ccccccc\", col.names = c(\"Year\", \"Month\", \"Latitude\", \"Longitude\", \"Temperature\", \"Humidity\", \"Precipitation\", \"Surface Pressure\", \"Wind 10 Meters\", \"Wind 50 Meters\", \"Annual\"), caption = \"Florida Data\") %>%\n  kable_styling(font_size = 16)\n\n\n\nFlorida Data\n \n  \n    Year \n    Month \n    Latitude \n    Longitude \n    Temperature \n    Humidity \n    Precipitation \n    Surface Pressure \n    Wind 10 Meters \n    Wind 50 Meters \n    Annual \n  \n \n\n  \n    1990 \n    NOV \n    25.25 \n    -77.75 \n    24.69 \n    74.40 \n    1.29 \n    101.74 \n    6.76 \n    7.59 \n    101.77 \n  \n  \n    1990 \n    JAN \n    25.25 \n    -77.75 \n    24.01 \n    76.50 \n    0.49 \n    101.99 \n    5.74 \n    6.45 \n    101.77 \n  \n  \n    1990 \n    FEB \n    25.25 \n    -77.75 \n    23.83 \n    73.11 \n    0.72 \n    102.09 \n    7.30 \n    8.20 \n    101.77 \n  \n  \n    1990 \n    MAR \n    25.25 \n    -77.75 \n    23.44 \n    75.67 \n    1.04 \n    102.02 \n    7.12 \n    7.99 \n    101.77 \n  \n  \n    1990 \n    APR \n    25.25 \n    -77.75 \n    24.18 \n    72.43 \n    0.82 \n    101.72 \n    5.53 \n    6.10 \n    101.77 \n  \n  \n    1990 \n    MAY \n    25.25 \n    -77.75 \n    25.89 \n    78.25 \n    2.60 \n    101.65 \n    5.60 \n    6.24 \n    101.77 \n  \n  \n    1990 \n    JUN \n    25.25 \n    -77.75 \n    27.27 \n    77.06 \n    2.91 \n    101.74 \n    4.18 \n    4.62 \n    101.77 \n  \n  \n    1990 \n    JUL \n    25.25 \n    -77.75 \n    28.25 \n    76.18 \n    2.41 \n    101.74 \n    4.47 \n    4.93 \n    101.77 \n  \n  \n    1990 \n    AUG \n    25.25 \n    -77.75 \n    28.77 \n    74.23 \n    5.13 \n    101.71 \n    3.16 \n    3.44 \n    101.77 \n  \n  \n    1990 \n    SEP \n    25.25 \n    -77.75 \n    28.55 \n    74.47 \n    2.09 \n    101.51 \n    3.85 \n    4.16 \n    101.77 \n  \n\n\n\n\n\n\n\nIllinois\n\nIllinois <- Illinois %>%\npivot_longer(\n  cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, DEC),\n  names_to = \"MONTH\",\n  values_to = \"Month_Average\",\n)\n\n\nTidy_Illinois <- Illinois %>%\n  select(PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN) %>%\n  filter(PARAMETER == 'PS')\n\nTidy_Illinois <- Tidy_Illinois %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nTidy_Illinois <- Tidy_Illinois %>%\n  select(PS, YEAR, MONTH, LAT, LON, ANN)\n\nt2m <- Illinois %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'T2M')\n\nt2m <- t2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nt2m <- t2m %>%\n  select(T2M, YEAR)\n\nTidy_Illinois$T2M <- t2m$T2M\n\nrh2m <- Illinois %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'RH2M')\n\nrh2m <- rh2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nrh2m <- rh2m %>%\n  select(RH2M, YEAR)\n\nTidy_Illinois$RH2M <- rh2m$RH2M\n\nwh10m <- Illinois %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS10M')\n\nwh10m <- wh10m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nwh10m <- wh10m %>%\n  select(WS10M, YEAR)\n\nTidy_Illinois$WS10M <- wh10m$WS10M\n\n\nwh50m <- Illinois %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS50M')\n\nwh50m <- wh50m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nwh50m <- wh50m %>%\n  select(WS50M, YEAR)\n\nTidy_Illinois$WS50M <- wh50m$WS50M\n\nPRECTOTCORR <- Illinois %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'PRECTOTCORR')\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  select(PRECTOTCORR, YEAR)\n\nTidy_Illinois$PRECTOTCORR <- PRECTOTCORR$PRECTOTCORR\n\nTidy_Illinois <- Tidy_Illinois %>%\n  dplyr::rename(Temperature = T2M) %>%\n  dplyr::rename(Humidity = RH2M) %>%\n  dplyr::rename(Wind_10_meter = WS10M) %>%\n  dplyr::rename(Surface_Pressure = PS) %>%\n  dplyr::rename(Wind_50_meter = WS50M) %>%\n  dplyr::rename(Precipitation = PRECTOTCORR) %>%\n  dplyr::rename(Annual = ANN) %>%\n  dplyr::rename(Latitude = LAT) %>%\n  dplyr::rename(Longitude = LON) %>%\n  dplyr::rename(Month = MONTH) %>%\n  dplyr::rename(Year = YEAR)\n\nTidy_Illinois <- Tidy_Illinois %>%\n  select(Year, Month, Latitude, Longitude, Temperature, Humidity, Precipitation, Surface_Pressure, Wind_10_meter, Wind_50_meter, Annual)\n\nsummary(Tidy_Illinois)\n\n      Year         Month              Latitude       Longitude      \n Min.   :1990   Length:66960       Min.   :43.25   Min.   :-102.75  \n 1st Qu.:1997   Class :character   1st Qu.:44.25   1st Qu.:-100.75  \n Median :2005   Mode  :character   Median :45.50   Median : -98.50  \n Mean   :2005                      Mean   :45.50   Mean   : -98.50  \n 3rd Qu.:2013                      3rd Qu.:46.75   3rd Qu.: -96.25  \n Max.   :2020                      Max.   :47.75   Max.   : -94.25  \n  Temperature         Humidity     Precipitation    Surface_Pressure\n Min.   :-22.850   Min.   :31.92   Min.   : 0.010   Min.   :89.54   \n 1st Qu.: -2.780   1st Qu.:61.57   1st Qu.: 0.570   1st Qu.:94.45   \n Median :  7.450   Median :68.34   Median : 1.220   Median :95.83   \n Mean   :  7.186   Mean   :69.63   Mean   : 1.615   Mean   :95.46   \n 3rd Qu.: 18.120   3rd Qu.:77.34   3rd Qu.: 2.340   3rd Qu.:96.79   \n Max.   : 30.490   Max.   :97.99   Max.   :10.000   Max.   :99.02   \n Wind_10_meter   Wind_50_meter        Annual     \n Min.   :3.130   Min.   : 4.740   Min.   :90.08  \n 1st Qu.:4.690   1st Qu.: 6.660   1st Qu.:94.51  \n Median :5.130   Median : 7.180   Median :95.81  \n Mean   :5.104   Mean   : 7.155   Mean   :95.46  \n 3rd Qu.:5.520   3rd Qu.: 7.650   3rd Qu.:96.74  \n Max.   :7.600   Max.   :10.240   Max.   :98.28  \n\nTidy_Illinois <- Tidy_Illinois %>%\n  slice(1:10)\n\nkable(Tidy_Illinois, digits = 2, align = \"ccccccc\", col.names = c(\"Year\", \"Month\", \"Latitude\", \"Longitude\", \"Temperature\", \"Humidity\", \"Precipitation\", \"Surface Pressure\", \"Wind 10 Meters\", \"Wind 50 Meters\", \"Annual\"), caption = \"Amherst Data\") %>%\n  kable_styling(font_size = 16)\n\n\n\nAmherst Data\n \n  \n    Year \n    Month \n    Latitude \n    Longitude \n    Temperature \n    Humidity \n    Precipitation \n    Surface Pressure \n    Wind 10 Meters \n    Wind 50 Meters \n    Annual \n  \n \n\n  \n    1990 \n    NOV \n    43.25 \n    -100.25 \n    4.22 \n    58.51 \n    0.38 \n    93.25 \n    5.64 \n    8.36 \n    93.34 \n  \n  \n    1990 \n    JAN \n    43.25 \n    -100.25 \n    -0.49 \n    64.46 \n    0.05 \n    93.03 \n    6.12 \n    8.84 \n    93.34 \n  \n  \n    1990 \n    FEB \n    43.25 \n    -100.25 \n    -1.83 \n    59.56 \n    0.35 \n    93.50 \n    5.79 \n    7.96 \n    93.34 \n  \n  \n    1990 \n    MAR \n    43.25 \n    -100.25 \n    2.89 \n    63.46 \n    1.46 \n    93.49 \n    5.29 \n    7.35 \n    93.34 \n  \n  \n    1990 \n    APR \n    43.25 \n    -100.25 \n    8.98 \n    52.07 \n    1.52 \n    93.29 \n    5.24 \n    7.18 \n    93.34 \n  \n  \n    1990 \n    MAY \n    43.25 \n    -100.25 \n    13.64 \n    62.47 \n    4.21 \n    93.15 \n    5.01 \n    6.97 \n    93.34 \n  \n  \n    1990 \n    JUN \n    43.25 \n    -100.25 \n    22.23 \n    54.08 \n    2.60 \n    93.06 \n    5.26 \n    7.45 \n    93.34 \n  \n  \n    1990 \n    JUL \n    43.25 \n    -100.25 \n    23.62 \n    53.65 \n    2.88 \n    93.46 \n    4.07 \n    5.88 \n    93.34 \n  \n  \n    1990 \n    AUG \n    43.25 \n    -100.25 \n    24.19 \n    55.66 \n    1.93 \n    93.42 \n    3.73 \n    5.50 \n    93.34 \n  \n  \n    1990 \n    SEP \n    43.25 \n    -100.25 \n    20.72 \n    43.86 \n    0.50 \n    93.55 \n    4.70 \n    6.89 \n    93.34 \n  \n\n\n\n\n\n\n\nMiddle\n\nMiddle <- Middle %>%\npivot_longer(\n  cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, DEC),\n  names_to = \"MONTH\",\n  values_to = \"Month_Average\",\n)\n\n\nTidy_Middle <- Middle %>%\n  select(PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN) %>%\n  filter(PARAMETER == 'PS')\n\nTidy_Middle <- Tidy_Middle %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nTidy_Middle <- Tidy_Middle %>%\n  select(PS, YEAR, MONTH, LAT, LON, ANN)\n\nt2m <- Middle %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'T2M')\n\nt2m <- t2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nt2m <- t2m %>%\n  select(T2M, YEAR)\n\nTidy_Middle$T2M <- t2m$T2M\n\nrh2m <- Middle %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'RH2M')\n\nrh2m <- rh2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nrh2m <- rh2m %>%\n  select(RH2M, YEAR)\n\nTidy_Middle$RH2M <- rh2m$RH2M\n\nwh10m <- Middle %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS10M')\n\nwh10m <- wh10m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nwh10m <- wh10m %>%\n  select(WS10M, YEAR)\n\nTidy_Middle$WS10M <- wh10m$WS10M\n\n\nwh50m <- Middle %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS50M')\n\nwh50m <- wh50m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nwh50m <- wh50m %>%\n  select(WS50M, YEAR)\n\nTidy_Middle$WS50M <- wh50m$WS50M\n\nPRECTOTCORR <- Middle %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'PRECTOTCORR')\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  select(PRECTOTCORR, YEAR)\n\nTidy_Middle$PRECTOTCORR <- PRECTOTCORR$PRECTOTCORR\n\nTidy_Middle <- Tidy_Middle %>%\n  dplyr::rename(Temperature = T2M) %>%\n  dplyr::rename(Humidity = RH2M) %>%\n  dplyr::rename(Wind_10_meter = WS10M) %>%\n  dplyr::rename(Surface_Pressure = PS) %>%\n  dplyr::rename(Wind_50_meter = WS50M) %>%\n  dplyr::rename(Precipitation = PRECTOTCORR) %>%\n  dplyr::rename(Annual = ANN) %>%\n  dplyr::rename(Latitude = LAT) %>%\n  dplyr::rename(Longitude = LON) %>%\n  dplyr::rename(Month = MONTH) %>%\n  dplyr::rename(Year = YEAR)\n\nTidy_Middle <- Tidy_Middle %>%\n  select(Year, Month, Latitude, Longitude, Temperature, Humidity, Precipitation, Surface_Pressure, Wind_10_meter, Wind_50_meter, Annual)\n\nsummary(Tidy_Middle)\n\n      Year         Month              Latitude       Longitude      \n Min.   :1990   Length:77748       Min.   :38.25   Min.   :-102.75  \n 1st Qu.:1997   Class :character   1st Qu.:39.25   1st Qu.:-100.75  \n Median :2005   Mode  :character   Median :40.75   Median : -98.25  \n Mean   :2005                      Mean   :40.75   Mean   : -98.25  \n 3rd Qu.:2013                      3rd Qu.:42.25   3rd Qu.: -95.75  \n Max.   :2020                      Max.   :43.25   Max.   : -93.75  \n  Temperature        Humidity     Precipitation    Surface_Pressure\n Min.   :-14.92   Min.   :32.96   Min.   : 0.000   Min.   :85.57   \n 1st Qu.:  1.38   1st Qu.:58.52   1st Qu.: 0.690   1st Qu.:91.58   \n Median : 10.92   Median :66.34   Median : 1.540   Median :95.39   \n Mean   : 10.92   Mean   :66.23   Mean   : 1.949   Mean   :94.30   \n 3rd Qu.: 20.83   3rd Qu.:74.14   3rd Qu.: 2.840   3rd Qu.:97.13   \n Max.   : 32.89   Max.   :96.56   Max.   :15.870   Max.   :99.52   \n Wind_10_meter   Wind_50_meter        Annual     \n Min.   :2.440   Min.   : 3.890   Min.   :86.13  \n 1st Qu.:4.530   1st Qu.: 6.550   1st Qu.:91.57  \n Median :5.030   Median : 7.160   Median :95.46  \n Mean   :4.994   Mean   : 7.111   Mean   :94.30  \n 3rd Qu.:5.480   3rd Qu.: 7.710   3rd Qu.:97.14  \n Max.   :7.450   Max.   :10.050   Max.   :98.86  \n\nTidy_Middle <- Tidy_Middle %>%\n  slice(1:10)\n\nkable(Tidy_Middle, digits = 2, align = \"ccccccc\", col.names = c(\"Year\", \"Month\", \"Latitude\", \"Longitude\", \"Temperature\", \"Humidity\", \"Precipitation\", \"Surface Pressure\", \"Wind 10 Meters\", \"Wind 50 Meters\", \"Annual\"), caption = \"Amherst Data\") %>%\n  kable_styling(font_size = 16)\n\n\n\nAmherst Data\n \n  \n    Year \n    Month \n    Latitude \n    Longitude \n    Temperature \n    Humidity \n    Precipitation \n    Surface Pressure \n    Wind 10 Meters \n    Wind 50 Meters \n    Annual \n  \n \n\n  \n    1990 \n    NOV \n    38.25 \n    -100.25 \n    8.05 \n    51.61 \n    0.62 \n    92.47 \n    5.22 \n    7.63 \n    92.41 \n  \n  \n    1990 \n    JAN \n    38.25 \n    -100.25 \n    1.32 \n    60.67 \n    0.99 \n    92.31 \n    5.20 \n    7.99 \n    92.41 \n  \n  \n    1990 \n    FEB \n    38.25 \n    -100.25 \n    2.00 \n    56.02 \n    1.05 \n    92.53 \n    5.04 \n    7.06 \n    92.41 \n  \n  \n    1990 \n    MAR \n    38.25 \n    -100.25 \n    7.51 \n    59.24 \n    1.22 \n    92.45 \n    5.05 \n    7.07 \n    92.41 \n  \n  \n    1990 \n    APR \n    38.25 \n    -100.25 \n    12.46 \n    55.89 \n    2.66 \n    92.34 \n    5.83 \n    7.93 \n    92.41 \n  \n  \n    1990 \n    MAY \n    38.25 \n    -100.25 \n    16.73 \n    59.86 \n    3.97 \n    92.05 \n    5.70 \n    7.80 \n    92.41 \n  \n  \n    1990 \n    JUN \n    38.25 \n    -100.25 \n    26.79 \n    47.33 \n    1.43 \n    92.11 \n    6.06 \n    8.42 \n    92.41 \n  \n  \n    1990 \n    JUL \n    38.25 \n    -100.25 \n    26.56 \n    50.47 \n    3.16 \n    92.47 \n    5.35 \n    7.31 \n    92.41 \n  \n  \n    1990 \n    AUG \n    38.25 \n    -100.25 \n    26.06 \n    52.42 \n    1.77 \n    92.52 \n    4.82 \n    6.97 \n    92.41 \n  \n  \n    1990 \n    SEP \n    38.25 \n    -100.25 \n    22.98 \n    47.95 \n    1.43 \n    92.63 \n    4.49 \n    6.54 \n    92.41 \n  \n\n\n\n\n\n\n\nNew Mexico\n\nNewmexico <- Newmexico %>%\npivot_longer(\n  cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, DEC),\n  names_to = \"MONTH\",\n  values_to = \"Month_Average\",\n)\n\n\nTidy_Newmexico <- Newmexico %>%\n  select(PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN) %>%\n  filter(PARAMETER == 'PS')\n\nTidy_Newmexico <- Tidy_Newmexico %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nTidy_Newmexico <- Tidy_Newmexico %>%\n  select(PS, YEAR, MONTH, LAT, LON, ANN)\n\nt2m <- Newmexico %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'T2M')\n\nt2m <- t2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nt2m <- t2m %>%\n  select(T2M, YEAR)\n\nTidy_Newmexico$T2M <- t2m$T2M\n\nrh2m <- Newmexico %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'RH2M')\n\nrh2m <- rh2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nrh2m <- rh2m %>%\n  select(RH2M, YEAR)\n\nTidy_Newmexico$RH2M <- rh2m$RH2M\n\nwh10m <- Newmexico %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS10M')\n\nwh10m <- wh10m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nwh10m <- wh10m %>%\n  select(WS10M, YEAR)\n\nTidy_Newmexico$WS10M <- wh10m$WS10M\n\n\nwh50m <- Newmexico %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS50M')\n\nwh50m <- wh50m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nwh50m <- wh50m %>%\n  select(WS50M, YEAR)\n\nTidy_Newmexico$WS50M <- wh50m$WS50M\n\nPRECTOTCORR <- Newmexico %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'PRECTOTCORR')\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  select(PRECTOTCORR, YEAR)\n\nTidy_Newmexico$PRECTOTCORR <- PRECTOTCORR$PRECTOTCORR\n\nTidy_Newmexico <- Tidy_Newmexico %>%\n  dplyr::rename(Temperature = T2M) %>%\n  dplyr::rename(Humidity = RH2M) %>%\n  dplyr::rename(Wind_10_meter = WS10M) %>%\n  dplyr::rename(Surface_Pressure = PS) %>%\n  dplyr::rename(Wind_50_meter = WS50M) %>%\n  dplyr::rename(Precipitation = PRECTOTCORR) %>%\n  dplyr::rename(Annual = ANN) %>%\n  dplyr::rename(Latitude = LAT) %>%\n  dplyr::rename(Longitude = LON) %>%\n  dplyr::rename(Month = MONTH) %>%\n  dplyr::rename(Year = YEAR)\n\nTidy_Newmexico <- Tidy_Newmexico %>%\n  select(Year, Month, Latitude, Longitude, Temperature, Humidity, Precipitation, Surface_Pressure, Wind_10_meter, Wind_50_meter, Annual)\n\nsummary(Tidy_Newmexico)\n\n      Year         Month              Latitude       Longitude     \n Min.   :1990   Length:81840       Min.   :32.75   Min.   :-112.8  \n 1st Qu.:1997   Class :character   1st Qu.:33.75   1st Qu.:-110.4  \n Median :2005   Mode  :character   Median :35.25   Median :-108.0  \n Mean   :2005                      Mean   :35.25   Mean   :-108.0  \n 3rd Qu.:2013                      3rd Qu.:36.75   3rd Qu.:-105.6  \n Max.   :2020                      Max.   :37.75   Max.   :-103.2  \n  Temperature        Humidity     Precipitation    Surface_Pressure\n Min.   :-14.10   Min.   :11.31   Min.   :0.0000   Min.   :69.19   \n 1st Qu.:  4.54   1st Qu.:38.12   1st Qu.:0.3000   1st Qu.:79.63   \n Median : 12.08   Median :46.83   Median :0.7200   Median :82.13   \n Mean   : 12.43   Mean   :46.47   Mean   :0.9725   Mean   :82.40   \n 3rd Qu.: 20.55   3rd Qu.:54.76   3rd Qu.:1.3900   3rd Qu.:84.65   \n Max.   : 36.19   Max.   :95.05   Max.   :8.0500   Max.   :97.50   \n Wind_10_meter   Wind_50_meter        Annual     \n Min.   :1.630   Min.   : 2.530   Min.   :70.07  \n 1st Qu.:3.240   1st Qu.: 4.750   1st Qu.:79.57  \n Median :3.770   Median : 5.510   Median :82.15  \n Mean   :3.879   Mean   : 5.638   Mean   :82.40  \n 3rd Qu.:4.460   3rd Qu.: 6.460   3rd Qu.:84.68  \n Max.   :7.730   Max.   :10.510   Max.   :96.93  \n\nTidy_Newmexico <- Tidy_Newmexico %>%\n  slice(1:10)\n\nkable(Tidy_Newmexico, digits = 2, align = \"ccccccc\", col.names = c(\"Year\", \"Month\", \"Latitude\", \"Longitude\", \"Temperature\", \"Humidity\", \"Precipitation\", \"Surface Pressure\", \"Wind 10 Meters\", \"Wind 50 Meters\", \"Annual\"), caption = \"Amherst Data\") %>%\n  kable_styling(font_size = 16)\n\n\n\nAmherst Data\n \n  \n    Year \n    Month \n    Latitude \n    Longitude \n    Temperature \n    Humidity \n    Precipitation \n    Surface Pressure \n    Wind 10 Meters \n    Wind 50 Meters \n    Annual \n  \n \n\n  \n    1990 \n    NOV \n    32.75 \n    -103.25 \n    10.38 \n    53.91 \n    0.81 \n    89.29 \n    4.55 \n    6.89 \n    89.14 \n  \n  \n    1990 \n    JAN \n    32.75 \n    -103.25 \n    5.43 \n    44.72 \n    0.42 \n    89.19 \n    5.05 \n    7.59 \n    89.14 \n  \n  \n    1990 \n    FEB \n    32.75 \n    -103.25 \n    8.46 \n    41.76 \n    0.68 \n    89.11 \n    5.54 \n    7.98 \n    89.14 \n  \n  \n    1990 \n    MAR \n    32.75 \n    -103.25 \n    11.39 \n    47.90 \n    0.83 \n    89.07 \n    4.88 \n    6.90 \n    89.14 \n  \n  \n    1990 \n    APR \n    32.75 \n    -103.25 \n    17.02 \n    45.33 \n    0.92 \n    88.92 \n    5.27 \n    7.37 \n    89.14 \n  \n  \n    1990 \n    MAY \n    32.75 \n    -103.25 \n    21.71 \n    32.06 \n    0.35 \n    88.77 \n    5.65 \n    7.89 \n    89.14 \n  \n  \n    1990 \n    JUN \n    32.75 \n    -103.25 \n    30.18 \n    28.31 \n    0.07 \n    88.93 \n    5.54 \n    7.52 \n    89.14 \n  \n  \n    1990 \n    JUL \n    32.75 \n    -103.25 \n    25.56 \n    52.40 \n    2.68 \n    89.26 \n    4.55 \n    6.00 \n    89.14 \n  \n  \n    1990 \n    AUG \n    32.75 \n    -103.25 \n    25.00 \n    53.48 \n    1.68 \n    89.34 \n    3.80 \n    5.52 \n    89.14 \n  \n  \n    1990 \n    SEP \n    32.75 \n    -103.25 \n    22.76 \n    57.93 \n    2.12 \n    89.33 \n    3.37 \n    4.93 \n    89.14 \n  \n\n\n\n\n\n\n\nNorth\n\nNorth <- North %>%\npivot_longer(\n  cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, DEC),\n  names_to = \"MONTH\",\n  values_to = \"Month_Average\",\n)\nTidy_North <- North %>%\n  select(PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN) %>%\n  filter(PARAMETER == 'PS')\n\nTidy_North <- Tidy_North %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nTidy_North <- Tidy_North %>%\n  select(PS, YEAR, MONTH, LAT, LON, ANN)\n\n\nt2m <- North %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'T2M')\n\nt2m <- t2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nt2m <- t2m %>%\n  select(T2M, YEAR)\n\nTidy_North$T2M <- t2m$T2M\n\nrh2m <- North %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'RH2M')\n\nrh2m <- rh2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nrh2m <- rh2m %>%\n  select(RH2M, YEAR)\n\nTidy_North$RH2M <- rh2m$RH2M\n\nwh10m <- North %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS10M')\n\nwh10m <- wh10m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nwh10m <- wh10m %>%\n  select(WS10M, YEAR)\n\nTidy_North$WS10M <- wh10m$WS10M\n\n\nwh50m <- North %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS50M')\n\nwh50m <- wh50m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nwh50m <- wh50m %>%\n  select(WS50M, YEAR)\n\nTidy_North$WS50M <- wh50m$WS50M\n\nPRECTOTCORR <- North %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'PRECTOTCORR')\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  select(PRECTOTCORR, YEAR)\n\nTidy_North$PRECTOTCORR <- PRECTOTCORR$PRECTOTCORR\n\nTidy_North <- Tidy_North %>%\n  dplyr::rename(Temperature = T2M) %>%\n  dplyr::rename(Humidity = RH2M) %>%\n  dplyr::rename(Wind_10_meter = WS10M) %>%\n  dplyr::rename(Surface_Pressure = PS) %>%\n  dplyr::rename(Wind_50_meter = WS50M) %>%\n  dplyr::rename(Precipitation = PRECTOTCORR) %>%\n  dplyr::rename(Annual = ANN) %>%\n  dplyr::rename(Latitude = LAT) %>%\n  dplyr::rename(Longitude = LON) %>%\n  dplyr::rename(Month = MONTH) %>%\n  dplyr::rename(Year = YEAR)\n\nTidy_North <- Tidy_North %>%\n  select(Year, Month, Latitude, Longitude, Temperature, Humidity, Precipitation, Surface_Pressure, Wind_10_meter, Wind_50_meter, Annual)\n\nsummary(Tidy_North)\n\n      Year         Month              Latitude       Longitude     \n Min.   :1990   Length:74400       Min.   :43.25   Min.   :-113.2  \n 1st Qu.:1997   Class :character   1st Qu.:44.25   1st Qu.:-110.9  \n Median :2005   Mode  :character   Median :45.50   Median :-108.5  \n Mean   :2005                      Mean   :45.50   Mean   :-108.5  \n 3rd Qu.:2013                      3rd Qu.:46.75   3rd Qu.:-106.1  \n Max.   :2020                      Max.   :47.75   Max.   :-103.8  \n  Temperature         Humidity     Precipitation   Surface_Pressure\n Min.   :-18.250   Min.   :21.78   Min.   :0.010   Min.   :72.47   \n 1st Qu.: -2.540   1st Qu.:53.77   1st Qu.:0.620   1st Qu.:81.50   \n Median :  5.350   Median :63.19   Median :1.090   Median :85.36   \n Mean   :  6.032   Mean   :64.19   Mean   :1.318   Mean   :85.14   \n 3rd Qu.: 14.840   3rd Qu.:73.32   3rd Qu.:1.780   3rd Qu.:89.66   \n Max.   : 28.130   Max.   :99.59   Max.   :8.280   Max.   :94.15   \n Wind_10_meter   Wind_50_meter        Annual     \n Min.   :1.520   Min.   : 2.780   Min.   :73.43  \n 1st Qu.:3.180   1st Qu.: 4.880   1st Qu.:81.50  \n Median :4.080   Median : 5.950   Median :85.36  \n Mean   :4.042   Mean   : 5.959   Mean   :85.14  \n 3rd Qu.:4.860   3rd Qu.: 6.960   3rd Qu.:89.62  \n Max.   :8.080   Max.   :10.790   Max.   :93.67  \n\nTidy_North <- Tidy_North %>%\n  slice(1:10)\n\nkable(Tidy_North, digits = 2, align = \"ccccccc\", col.names = c(\"Year\", \"Month\", \"Latitude\", \"Longitude\", \"Temperature\", \"Humidity\", \"Precipitation\", \"Surface Pressure\", \"Wind 10 Meters\", \"Wind 50 Meters\", \"Annual\"), caption = \"Amherst Data\") %>%\n  kable_styling(font_size = 16)\n\n\n\nAmherst Data\n \n  \n    Year \n    Month \n    Latitude \n    Longitude \n    Temperature \n    Humidity \n    Precipitation \n    Surface Pressure \n    Wind 10 Meters \n    Wind 50 Meters \n    Annual \n  \n \n\n  \n    1990 \n    NOV \n    43.25 \n    -103.75 \n    3.48 \n    54.59 \n    0.69 \n    87.57 \n    5.30 \n    7.95 \n    87.65 \n  \n  \n    1990 \n    JAN \n    43.25 \n    -103.75 \n    -1.23 \n    64.91 \n    0.13 \n    87.29 \n    5.90 \n    8.62 \n    87.65 \n  \n  \n    1990 \n    FEB \n    43.25 \n    -103.75 \n    -2.22 \n    63.34 \n    0.49 \n    87.60 \n    4.96 \n    7.16 \n    87.65 \n  \n  \n    1990 \n    MAR \n    43.25 \n    -103.75 \n    1.79 \n    62.66 \n    1.24 \n    87.66 \n    4.54 \n    6.50 \n    87.65 \n  \n  \n    1990 \n    APR \n    43.25 \n    -103.75 \n    7.32 \n    57.72 \n    1.78 \n    87.56 \n    4.28 \n    6.03 \n    87.65 \n  \n  \n    1990 \n    MAY \n    43.25 \n    -103.75 \n    11.66 \n    59.12 \n    2.78 \n    87.45 \n    4.49 \n    6.32 \n    87.65 \n  \n  \n    1990 \n    JUN \n    43.25 \n    -103.75 \n    20.12 \n    47.00 \n    1.33 \n    87.55 \n    4.55 \n    6.61 \n    87.65 \n  \n  \n    1990 \n    JUL \n    43.25 \n    -103.75 \n    22.43 \n    47.81 \n    2.41 \n    87.90 \n    3.38 \n    5.03 \n    87.65 \n  \n  \n    1990 \n    AUG \n    43.25 \n    -103.75 \n    22.72 \n    47.12 \n    1.01 \n    87.90 \n    3.29 \n    4.93 \n    87.65 \n  \n  \n    1990 \n    SEP \n    43.25 \n    -103.75 \n    18.85 \n    45.72 \n    1.11 \n    88.01 \n    3.91 \n    5.89 \n    87.65 \n  \n\n\n\n\n\n\n\nSouth\n\nSouth <- South %>%\npivot_longer(\n  cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, DEC),\n  names_to = \"MONTH\",\n  values_to = \"Month_Average\",\n)\nTidy_South <- South %>%\n  select(PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN) %>%\n  filter(PARAMETER == 'PS')\n\nTidy_South <- Tidy_South %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nTidy_South <- Tidy_South %>%\n  select(PS, YEAR, MONTH, LAT, LON, ANN)\n\nt2m <- South %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'T2M')\n\nt2m <- t2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nt2m <- t2m %>%\n  select(T2M, YEAR)\n\nTidy_South$T2M <- t2m$T2M\n\nrh2m <- South %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'RH2M')\n\nrh2m <- rh2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nrh2m <- rh2m %>%\n  select(RH2M, YEAR)\n\nTidy_South$RH2M <- rh2m$RH2M\n\nwh10m <- South %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS10M')\n\nwh10m <- wh10m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nwh10m <- wh10m %>%\n  select(WS10M, YEAR)\n\nTidy_South$WS10M <- wh10m$WS10M\n\n\nwh50m <- South %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS50M')\n\nwh50m <- wh50m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nwh50m <- wh50m %>%\n  select(WS50M, YEAR)\n\nTidy_South$WS50M <- wh50m$WS50M\n\nPRECTOTCORR <- South %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'PRECTOTCORR')\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  select(PRECTOTCORR, YEAR)\n\nTidy_South$PRECTOTCORR <- PRECTOTCORR$PRECTOTCORR\n\nTidy_South <- Tidy_South %>%\n  dplyr::rename(Temperature = T2M) %>%\n  dplyr::rename(Humidity = RH2M) %>%\n  dplyr::rename(Wind_10_meter = WS10M) %>%\n  dplyr::rename(Surface_Pressure = PS) %>%\n  dplyr::rename(Wind_50_meter = WS50M) %>%\n  dplyr::rename(Precipitation = PRECTOTCORR) %>%\n  dplyr::rename(Annual = ANN) %>%\n  dplyr::rename(Latitude = LAT) %>%\n  dplyr::rename(Longitude = LON) %>%\n  dplyr::rename(Month = MONTH) %>%\n  dplyr::rename(Year = YEAR)\n\nTidy_South <- Tidy_South %>%\n  select(Year, Month, Latitude, Longitude, Temperature, Humidity, Precipitation, Surface_Pressure, Wind_10_meter, Wind_50_meter, Annual)\n\nsummary(Tidy_South)\n\n      Year         Month              Latitude       Longitude     \n Min.   :1990   Length:84816       Min.   :32.25   Min.   :-91.25  \n 1st Qu.:1997   Class :character   1st Qu.:33.62   1st Qu.:-89.25  \n Median :2005   Mode  :character   Median :35.00   Median :-86.75  \n Mean   :2005                      Mean   :35.00   Mean   :-86.75  \n 3rd Qu.:2013                      3rd Qu.:36.38   3rd Qu.:-84.25  \n Max.   :2020                      Max.   :37.75   Max.   :-82.25  \n  Temperature       Humidity     Precipitation    Surface_Pressure\n Min.   :-5.29   Min.   :36.84   Min.   : 0.010   Min.   : 92.41  \n 1st Qu.: 8.10   1st Qu.:72.24   1st Qu.: 2.380   1st Qu.: 98.34  \n Median :15.73   Median :78.50   Median : 3.340   Median : 99.68  \n Mean   :15.46   Mean   :76.75   Mean   : 3.612   Mean   : 99.15  \n 3rd Qu.:23.33   3rd Qu.:82.34   3rd Qu.: 4.570   3rd Qu.:100.43  \n Max.   :32.63   Max.   :92.29   Max.   :16.850   Max.   :102.22  \n Wind_10_meter   Wind_50_meter       Annual      \n Min.   :1.140   Min.   :2.360   Min.   : 92.91  \n 1st Qu.:1.980   1st Qu.:3.880   1st Qu.: 98.36  \n Median :2.430   Median :4.520   Median : 99.69  \n Mean   :2.605   Mean   :4.626   Mean   : 99.15  \n 3rd Qu.:3.100   3rd Qu.:5.260   3rd Qu.:100.43  \n Max.   :6.430   Max.   :9.270   Max.   :101.42  \n\nTidy_South <- Tidy_South %>%\n  slice(1:10)\n\nkable(Tidy_South, digits = 2, align = \"ccccccc\", col.names = c(\"Year\", \"Month\", \"Latitude\", \"Longitude\", \"Temperature\", \"Humidity\", \"Precipitation\", \"Surface Pressure\", \"Wind 10 Meters\", \"Wind 50 Meters\", \"Annual\"), caption = \"Amherst Data\") %>%\n  kable_styling(font_size = 16)\n\n\n\nAmherst Data\n \n  \n    Year \n    Month \n    Latitude \n    Longitude \n    Temperature \n    Humidity \n    Precipitation \n    Surface Pressure \n    Wind 10 Meters \n    Wind 50 Meters \n    Annual \n  \n \n\n  \n    1990 \n    NOV \n    32.25 \n    -82.25 \n    13.54 \n    79.79 \n    1.68 \n    101.36 \n    3.13 \n    5.15 \n    101.16 \n  \n  \n    1990 \n    JAN \n    32.25 \n    -82.25 \n    10.43 \n    86.30 \n    4.15 \n    101.39 \n    3.21 \n    5.16 \n    101.16 \n  \n  \n    1990 \n    FEB \n    32.25 \n    -82.25 \n    12.68 \n    85.29 \n    3.16 \n    101.49 \n    4.03 \n    6.34 \n    101.16 \n  \n  \n    1990 \n    MAR \n    32.25 \n    -82.25 \n    15.02 \n    82.99 \n    2.07 \n    101.50 \n    3.30 \n    5.19 \n    101.16 \n  \n  \n    1990 \n    APR \n    32.25 \n    -82.25 \n    17.33 \n    73.48 \n    1.24 \n    101.13 \n    3.53 \n    5.58 \n    101.16 \n  \n  \n    1990 \n    MAY \n    32.25 \n    -82.25 \n    23.49 \n    64.33 \n    2.01 \n    100.85 \n    3.49 \n    5.38 \n    101.16 \n  \n  \n    1990 \n    JUN \n    32.25 \n    -82.25 \n    28.00 \n    58.58 \n    1.52 \n    100.91 \n    3.20 \n    4.89 \n    101.16 \n  \n  \n    1990 \n    JUL \n    32.25 \n    -82.25 \n    29.27 \n    61.62 \n    3.32 \n    100.95 \n    3.30 \n    5.03 \n    101.16 \n  \n  \n    1990 \n    AUG \n    32.25 \n    -82.25 \n    28.28 \n    68.83 \n    4.06 \n    100.90 \n    2.13 \n    3.45 \n    101.16 \n  \n  \n    1990 \n    SEP \n    32.25 \n    -82.25 \n    26.26 \n    58.85 \n    0.97 \n    100.96 \n    2.71 \n    4.34 \n    101.16 \n  \n\n\n\n\n\n\n\nSouth California\n\nSouthCali <- SouthCali %>%\npivot_longer(\n  cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, DEC),\n  names_to = \"MONTH\",\n  values_to = \"Month_Average\",\n)\nTidy_SouthCali <- SouthCali %>%\n  select(PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN) %>%\n  filter(PARAMETER == 'PS')\n\nTidy_SouthCali <- Tidy_SouthCali %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nTidy_SouthCali <- Tidy_SouthCali %>%\n  select(PS, YEAR, MONTH, LAT, LON, ANN)\n\nt2m <- SouthCali %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'T2M')\n\nt2m <- t2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nt2m <- t2m %>%\n  select(T2M, YEAR)\n\nTidy_SouthCali$T2M <- t2m$T2M\n\nrh2m <- SouthCali %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'RH2M')\n\nrh2m <- rh2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nrh2m <- rh2m %>%\n  select(RH2M, YEAR)\n\nTidy_SouthCali$RH2M <- rh2m$RH2M\n\nwh10m <- SouthCali %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS10M')\n\nwh10m <- wh10m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nwh10m <- wh10m %>%\n  select(WS10M, YEAR)\n\nTidy_SouthCali$WS10M <- wh10m$WS10M\n\n\nwh50m <- SouthCali %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS50M')\n\nwh50m <- wh50m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nwh50m <- wh50m %>%\n  select(WS50M, YEAR)\n\nTidy_SouthCali$WS50M <- wh50m$WS50M\n\nPRECTOTCORR <- SouthCali %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'PRECTOTCORR')\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  select(PRECTOTCORR, YEAR)\n\nTidy_SouthCali$PRECTOTCORR <- PRECTOTCORR$PRECTOTCORR\n\nTidy_SouthCali <- Tidy_SouthCali %>%\n  dplyr::rename(Temperature = T2M) %>%\n  dplyr::rename(Humidity = RH2M) %>%\n  dplyr::rename(Wind_10_meter = WS10M) %>%\n  dplyr::rename(Surface_Pressure = PS) %>%\n  dplyr::rename(Wind_50_meter = WS50M) %>%\n  dplyr::rename(Precipitation = PRECTOTCORR) %>%\n  dplyr::rename(Annual = ANN) %>%\n  dplyr::rename(Latitude = LAT) %>%\n  dplyr::rename(Longitude = LON) %>%\n  dplyr::rename(Month = MONTH) %>%\n  dplyr::rename(Year = YEAR)\n\nTidy_SouthCali <- Tidy_SouthCali %>%\n  select(Year, Month, Latitude, Longitude, Temperature, Humidity, Precipitation, Surface_Pressure, Wind_10_meter, Wind_50_meter, Annual)\n\nsummary(Tidy_SouthCali)\n\n      Year         Month              Latitude       Longitude     \n Min.   :1990   Length:78120       Min.   :33.75   Min.   :-121.8  \n 1st Qu.:1997   Class :character   1st Qu.:35.25   1st Qu.:-120.2  \n Median :2005   Mode  :character   Median :37.25   Median :-118.5  \n Mean   :2005                      Mean   :37.25   Mean   :-118.5  \n 3rd Qu.:2013                      3rd Qu.:39.25   3rd Qu.:-116.8  \n Max.   :2020                      Max.   :40.75   Max.   :-115.2  \n  Temperature       Humidity     Precipitation     Surface_Pressure\n Min.   :-8.91   Min.   :11.89   Min.   : 0.0000   Min.   : 73.88  \n 1st Qu.: 7.29   1st Qu.:33.86   1st Qu.: 0.1100   1st Qu.: 82.98  \n Median :13.43   Median :49.53   Median : 0.4100   Median : 89.04  \n Mean   :13.38   Mean   :50.99   Mean   : 0.9714   Mean   : 89.33  \n 3rd Qu.:19.72   3rd Qu.:66.72   3rd Qu.: 1.1300   3rd Qu.: 96.48  \n Max.   :35.71   Max.   :97.56   Max.   :19.2300   Max.   :102.32  \n Wind_10_meter  Wind_50_meter        Annual      \n Min.   :1.65   Min.   : 2.360   Min.   : 74.61  \n 1st Qu.:2.80   1st Qu.: 3.900   1st Qu.: 82.87  \n Median :3.26   Median : 4.480   Median : 89.09  \n Mean   :3.44   Mean   : 4.632   Mean   : 89.33  \n 3rd Qu.:3.79   3rd Qu.: 5.150   3rd Qu.: 96.60  \n Max.   :9.93   Max.   :11.320   Max.   :101.82  \n\nTidy_SouthCali <- Tidy_SouthCali %>%\n  slice(1:10)\n\nkable(Tidy_SouthCali, digits = 2, align = \"ccccccc\", col.names = c(\"Year\", \"Month\", \"Latitude\", \"Longitude\", \"Temperature\", \"Humidity\", \"Precipitation\", \"Surface Pressure\", \"Wind 10 Meters\", \"Wind 50 Meters\", \"Annual\"), caption = \"Amherst Data\") %>%\n  kable_styling(font_size = 16)\n\n\n\nAmherst Data\n \n  \n    Year \n    Month \n    Latitude \n    Longitude \n    Temperature \n    Humidity \n    Precipitation \n    Surface Pressure \n    Wind 10 Meters \n    Wind 50 Meters \n    Annual \n  \n \n\n  \n    1990 \n    NOV \n    33.75 \n    -115.25 \n    15.08 \n    28.55 \n    0.05 \n    97.24 \n    4.21 \n    6.12 \n    96.94 \n  \n  \n    1990 \n    JAN \n    33.75 \n    -115.25 \n    9.52 \n    44.28 \n    0.36 \n    97.38 \n    3.46 \n    5.05 \n    96.94 \n  \n  \n    1990 \n    FEB \n    33.75 \n    -115.25 \n    10.93 \n    38.61 \n    0.16 \n    97.32 \n    3.84 \n    5.48 \n    96.94 \n  \n  \n    1990 \n    MAR \n    33.75 \n    -115.25 \n    16.89 \n    31.98 \n    0.09 \n    96.99 \n    3.46 \n    4.86 \n    96.94 \n  \n  \n    1990 \n    APR \n    33.75 \n    -115.25 \n    21.34 \n    34.41 \n    0.10 \n    96.76 \n    3.72 \n    5.14 \n    96.94 \n  \n  \n    1990 \n    MAY \n    33.75 \n    -115.25 \n    23.52 \n    27.32 \n    0.09 \n    96.58 \n    4.18 \n    5.66 \n    96.94 \n  \n  \n    1990 \n    JUN \n    33.75 \n    -115.25 \n    30.54 \n    21.35 \n    0.15 \n    96.54 \n    3.69 \n    5.03 \n    96.94 \n  \n  \n    1990 \n    JUL \n    33.75 \n    -115.25 \n    33.59 \n    28.24 \n    0.32 \n    96.62 \n    3.58 \n    4.67 \n    96.94 \n  \n  \n    1990 \n    AUG \n    33.75 \n    -115.25 \n    30.76 \n    31.84 \n    0.59 \n    96.78 \n    3.12 \n    4.21 \n    96.94 \n  \n  \n    1990 \n    SEP \n    33.75 \n    -115.25 \n    28.74 \n    31.53 \n    0.38 \n    96.73 \n    2.85 \n    3.96 \n    96.94 \n  \n\n\n\n\n\n\n\nTexas\n\nTexas <- Texas %>%\npivot_longer(\n  cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, DEC),\n  names_to = \"MONTH\",\n  values_to = \"Month_Average\",\n)\nTidy_Texas <- Texas %>%\n  select(PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN) %>%\n  filter(PARAMETER == 'PS')\n\nTidy_Texas <- Tidy_Texas %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nTidy_Texas <- Tidy_Texas %>%\n  select(PS, YEAR, MONTH, LAT, LON, ANN)\n\nt2m <- Texas %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'T2M')\n\nt2m <- t2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nt2m <- t2m %>%\n  select(T2M, YEAR)\n\nTidy_Texas$T2M <- t2m$T2M\n\nrh2m <- Texas %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'RH2M')\n\nrh2m <- rh2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nrh2m <- rh2m %>%\n  select(RH2M, YEAR)\n\nTidy_Texas$RH2M <- rh2m$RH2M\n\nwh10m <- Texas %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS10M')\n\nwh10m <- wh10m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nwh10m <- wh10m %>%\n  select(WS10M, YEAR)\n\nTidy_Texas$WS10M <- wh10m$WS10M\n\n\nwh50m <- Texas %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS50M')\n\nwh50m <- wh50m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nwh50m <- wh50m %>%\n  select(WS50M, YEAR)\n\nTidy_Texas$WS50M <- wh50m$WS50M\n\nPRECTOTCORR <- Texas %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'PRECTOTCORR')\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  select(PRECTOTCORR, YEAR)\n\nTidy_Texas$PRECTOTCORR <- PRECTOTCORR$PRECTOTCORR\n\nTidy_Texas <- Tidy_Texas %>%\n  dplyr::rename(Temperature = T2M) %>%\n  dplyr::rename(Humidity = RH2M) %>%\n  dplyr::rename(Wind_10_meter = WS10M) %>%\n  dplyr::rename(Surface_Pressure = PS) %>%\n  dplyr::rename(Wind_50_meter = WS50M) %>%\n  dplyr::rename(Precipitation = PRECTOTCORR) %>%\n  dplyr::rename(Annual = ANN) %>%\n  dplyr::rename(Latitude = LAT) %>%\n  dplyr::rename(Longitude = LON) %>%\n  dplyr::rename(Month = MONTH) %>%\n  dplyr::rename(Year = YEAR)\n\nTidy_Texas <- Tidy_Texas %>%\n  select(Year, Month, Latitude, Longitude, Temperature, Humidity, Precipitation, Surface_Pressure, Wind_10_meter, Wind_50_meter, Annual)\n\nsummary(Tidy_Texas)\n\n      Year         Month              Latitude       Longitude      \n Min.   :1990   Length:104160      Min.   :29.25   Min.   :-103.75  \n 1st Qu.:1997   Class :character   1st Qu.:30.75   1st Qu.:-101.38  \n Median :2005   Mode  :character   Median :32.50   Median : -99.00  \n Mean   :2005                      Mean   :32.50   Mean   : -99.00  \n 3rd Qu.:2013                      3rd Qu.:34.25   3rd Qu.: -96.62  \n Max.   :2020                      Max.   :35.75   Max.   : -94.25  \n  Temperature       Humidity     Precipitation    Surface_Pressure\n Min.   :-2.62   Min.   :14.00   Min.   : 0.000   Min.   : 84.89  \n 1st Qu.:10.66   1st Qu.:52.22   1st Qu.: 0.750   1st Qu.: 92.21  \n Median :18.42   Median :62.76   Median : 1.710   Median : 96.59  \n Mean   :17.99   Mean   :62.28   Mean   : 2.156   Mean   : 95.64  \n 3rd Qu.:25.80   3rd Qu.:73.30   3rd Qu.: 3.050   3rd Qu.: 99.23  \n Max.   :35.35   Max.   :94.14   Max.   :33.700   Max.   :102.51  \n Wind_10_meter   Wind_50_meter       Annual      \n Min.   :1.220   Min.   :2.690   Min.   : 85.42  \n 1st Qu.:3.840   1st Qu.:5.670   1st Qu.: 92.23  \n Median :4.470   Median :6.490   Median : 96.61  \n Mean   :4.348   Mean   :6.387   Mean   : 95.64  \n 3rd Qu.:5.010   3rd Qu.:7.200   3rd Qu.: 99.16  \n Max.   :7.200   Max.   :9.780   Max.   :101.75  \n\nTidy_Texas <- Tidy_Texas %>%\n  slice(1:10)\n\nkable(Tidy_Texas, digits = 2, align = \"ccccccc\", col.names = c(\"Year\", \"Month\", \"Latitude\", \"Longitude\", \"Temperature\", \"Humidity\", \"Precipitation\", \"Surface Pressure\", \"Wind 10 Meters\", \"Wind 50 Meters\", \"Annual\"), caption = \"Amherst Data\") %>%\n  kable_styling(font_size = 16)\n\n\n\nAmherst Data\n \n  \n    Year \n    Month \n    Latitude \n    Longitude \n    Temperature \n    Humidity \n    Precipitation \n    Surface Pressure \n    Wind 10 Meters \n    Wind 50 Meters \n    Annual \n  \n \n\n  \n    1990 \n    NOV \n    29.25 \n    -100.25 \n    16.35 \n    68.49 \n    1.11 \n    97.75 \n    3.91 \n    6.00 \n    97.5 \n  \n  \n    1990 \n    JAN \n    29.25 \n    -100.25 \n    11.95 \n    59.48 \n    0.54 \n    97.73 \n    3.83 \n    5.90 \n    97.5 \n  \n  \n    1990 \n    FEB \n    29.25 \n    -100.25 \n    14.51 \n    57.53 \n    2.57 \n    97.67 \n    4.33 \n    6.40 \n    97.5 \n  \n  \n    1990 \n    MAR \n    29.25 \n    -100.25 \n    17.19 \n    68.09 \n    1.73 \n    97.56 \n    4.81 \n    6.83 \n    97.5 \n  \n  \n    1990 \n    APR \n    29.25 \n    -100.25 \n    20.98 \n    69.78 \n    3.48 \n    97.30 \n    4.92 \n    6.99 \n    97.5 \n  \n  \n    1990 \n    MAY \n    29.25 \n    -100.25 \n    25.52 \n    63.69 \n    2.56 \n    96.99 \n    4.54 \n    6.46 \n    97.5 \n  \n  \n    1990 \n    JUN \n    29.25 \n    -100.25 \n    31.81 \n    45.02 \n    0.03 \n    97.17 \n    5.94 \n    7.84 \n    97.5 \n  \n  \n    1990 \n    JUL \n    29.25 \n    -100.25 \n    27.49 \n    65.36 \n    6.48 \n    97.45 \n    5.04 \n    6.84 \n    97.5 \n  \n  \n    1990 \n    AUG \n    29.25 \n    -100.25 \n    28.14 \n    61.81 \n    0.96 \n    97.49 \n    4.19 \n    6.15 \n    97.5 \n  \n  \n    1990 \n    SEP \n    29.25 \n    -100.25 \n    25.36 \n    70.53 \n    3.77 \n    97.48 \n    3.30 \n    4.91 \n    97.5 \n  \n\n\n\n\n\n\n\nWashington\n\nWashington <- Washington %>%\npivot_longer(\n  cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, DEC),\n  names_to = \"MONTH\",\n  values_to = \"Month_Average\",\n)\nTidy_Washington <- Washington %>%\n  select(PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN) %>%\n  filter(PARAMETER == 'PS')\n\nTidy_Washington <- Tidy_Washington %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nTidy_Washington <- Tidy_Washington %>%\n  select(PS, YEAR, MONTH, LAT, LON, ANN)\n\nt2m <- Washington %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'T2M')\n\nt2m <- t2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nt2m <- t2m %>%\n  select(T2M, YEAR)\n\nTidy_Washington$T2M <- t2m$T2M\n\nrh2m <- Washington %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'RH2M')\n\nrh2m <- rh2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nrh2m <- rh2m %>%\n  select(RH2M, YEAR)\n\nTidy_Washington$RH2M <- rh2m$RH2M\n\nwh10m <- Washington %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS10M')\n\nwh10m <- wh10m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nwh10m <- wh10m %>%\n  select(WS10M, YEAR)\n\nTidy_Washington$WS10M <- wh10m$WS10M\n\n\nwh50m <- Washington %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS50M')\n\nwh50m <- wh50m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nwh50m <- wh50m %>%\n  select(WS50M, YEAR)\n\nTidy_Washington$WS50M <- wh50m$WS50M\n\nPRECTOTCORR <- Washington %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'PRECTOTCORR')\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  select(PRECTOTCORR, YEAR)\n\nTidy_Washington$PRECTOTCORR <- PRECTOTCORR$PRECTOTCORR\n\nTidy_Washington <- Tidy_Washington %>%\n  dplyr::rename(Temperature = T2M) %>%\n  dplyr::rename(Humidity = RH2M) %>%\n  dplyr::rename(Wind_10_meter = WS10M) %>%\n  dplyr::rename(Surface_Pressure = PS) %>%\n  dplyr::rename(Wind_50_meter = WS50M) %>%\n  dplyr::rename(Precipitation = PRECTOTCORR) %>%\n  dplyr::rename(Annual = ANN) %>%\n  dplyr::rename(Latitude = LAT) %>%\n  dplyr::rename(Longitude = LON) %>%\n  dplyr::rename(Month = MONTH) %>%\n  dplyr::rename(Year = YEAR)\n\nTidy_Washington <- Tidy_Washington %>%\n  select(Year, Month, Latitude, Longitude, Temperature, Humidity, Precipitation, Surface_Pressure, Wind_10_meter, Wind_50_meter, Annual)\n\nsummary(Tidy_Washington)\n\n      Year         Month              Latitude       Longitude     \n Min.   :1990   Length:82212       Min.   :41.75   Min.   :-122.8  \n 1st Qu.:1997   Class :character   1st Qu.:43.25   1st Qu.:-120.8  \n Median :2005   Mode  :character   Median :44.75   Median :-118.8  \n Mean   :2005                      Mean   :44.75   Mean   :-118.8  \n 3rd Qu.:2013                      3rd Qu.:46.25   3rd Qu.:-116.8  \n Max.   :2020                      Max.   :47.75   Max.   :-114.8  \n  Temperature         Humidity     Precipitation   Surface_Pressure\n Min.   :-14.040   Min.   :20.81   Min.   : 0.00   Min.   :76.13   \n 1st Qu.:  0.670   1st Qu.:55.59   1st Qu.: 0.63   1st Qu.:84.95   \n Median :  6.970   Median :70.02   Median : 1.35   Median :87.59   \n Mean   :  7.653   Mean   :68.57   Mean   : 1.90   Mean   :88.43   \n 3rd Qu.: 14.840   3rd Qu.:82.60   3rd Qu.: 2.46   3rd Qu.:92.25   \n Max.   : 28.950   Max.   :99.83   Max.   :19.67   Max.   :99.34   \n Wind_10_meter   Wind_50_meter       Annual     \n Min.   :1.180   Min.   :1.960   Min.   :77.07  \n 1st Qu.:2.160   1st Qu.:3.700   1st Qu.:84.96  \n Median :2.860   Median :4.420   Median :87.65  \n Mean   :2.923   Mean   :4.509   Mean   :88.43  \n 3rd Qu.:3.550   3rd Qu.:5.190   3rd Qu.:92.36  \n Max.   :6.830   Max.   :9.480   Max.   :98.78  \n\nTidy_Washington <- Tidy_Washington %>%\n  slice(1:10)\n\nkable(Tidy_Washington, digits = 2, align = \"ccccccc\", col.names = c(\"Year\", \"Month\", \"Latitude\", \"Longitude\", \"Temperature\", \"Humidity\", \"Precipitation\", \"Surface Pressure\", \"Wind 10 Meters\", \"Wind 50 Meters\", \"Annual\"), caption = \"Amherst Data\") %>%\n  kable_styling(font_size = 16)\n\n\n\nAmherst Data\n \n  \n    Year \n    Month \n    Latitude \n    Longitude \n    Temperature \n    Humidity \n    Precipitation \n    Surface Pressure \n    Wind 10 Meters \n    Wind 50 Meters \n    Annual \n  \n \n\n  \n    1990 \n    NOV \n    41.75 \n    -114.75 \n    0.34 \n    59.24 \n    0.73 \n    81.59 \n    4.81 \n    6.77 \n    81.45 \n  \n  \n    1990 \n    JAN \n    41.75 \n    -114.75 \n    -4.07 \n    78.51 \n    1.28 \n    81.30 \n    5.15 \n    7.25 \n    81.45 \n  \n  \n    1990 \n    FEB \n    41.75 \n    -114.75 \n    -4.71 \n    70.26 \n    0.56 \n    81.31 \n    4.92 \n    6.56 \n    81.45 \n  \n  \n    1990 \n    MAR \n    41.75 \n    -114.75 \n    1.91 \n    61.00 \n    0.90 \n    81.29 \n    4.47 \n    6.01 \n    81.45 \n  \n  \n    1990 \n    APR \n    41.75 \n    -114.75 \n    8.08 \n    52.46 \n    1.38 \n    81.25 \n    4.31 \n    5.77 \n    81.45 \n  \n  \n    1990 \n    MAY \n    41.75 \n    -114.75 \n    8.88 \n    49.42 \n    1.40 \n    81.13 \n    4.24 \n    5.68 \n    81.45 \n  \n  \n    1990 \n    JUN \n    41.75 \n    -114.75 \n    16.01 \n    40.19 \n    0.74 \n    81.46 \n    3.93 \n    5.37 \n    81.45 \n  \n  \n    1990 \n    JUL \n    41.75 \n    -114.75 \n    21.67 \n    32.96 \n    0.18 \n    81.65 \n    3.37 \n    4.63 \n    81.45 \n  \n  \n    1990 \n    AUG \n    41.75 \n    -114.75 \n    19.79 \n    34.71 \n    0.86 \n    81.70 \n    3.22 \n    4.41 \n    81.45 \n  \n  \n    1990 \n    SEP \n    41.75 \n    -114.75 \n    17.79 \n    35.25 \n    0.22 \n    81.74 \n    3.07 \n    4.32 \n    81.45 \n  \n\n\n\n\n\n\n\nWest Virgina\n\nWestV <- WestV %>%\npivot_longer(\n  cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, DEC),\n  names_to = \"MONTH\",\n  values_to = \"Month_Average\",\n)\nTidy_WestV <- WestV %>%\n  select(PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN) %>%\n  filter(PARAMETER == 'PS')\n\nTidy_WestV <- Tidy_WestV %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nTidy_WestV <- Tidy_WestV %>%\n  select(PS, YEAR, MONTH, LAT, LON, ANN)\n\nt2m <- WestV %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'T2M')\n\nt2m <- t2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nt2m <- t2m %>%\n  select(T2M, YEAR)\n\nTidy_WestV$T2M <- t2m$T2M\n\nrh2m <- WestV %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'RH2M')\n\nrh2m <- rh2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nrh2m <- rh2m %>%\n  select(RH2M, YEAR)\n\nTidy_WestV$RH2M <- rh2m$RH2M\n\nwh10m <- WestV %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS10M')\n\nwh10m <- wh10m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nwh10m <- wh10m %>%\n  select(WS10M, YEAR)\n\nTidy_WestV$WS10M <- wh10m$WS10M\n\n\nwh50m <- WestV %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS50M')\n\nwh50m <- wh50m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nwh50m <- wh50m %>%\n  select(WS50M, YEAR)\n\nTidy_WestV$WS50M <- wh50m$WS50M\n\nPRECTOTCORR <- WestV %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'PRECTOTCORR')\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  select(PRECTOTCORR, YEAR)\n\nTidy_WestV$PRECTOTCORR <- PRECTOTCORR$PRECTOTCORR\n\nTidy_WestV <- Tidy_WestV %>%\n  dplyr::rename(Temperature = T2M) %>%\n  dplyr::rename(Humidity = RH2M) %>%\n  dplyr::rename(Wind_10_meter = WS10M) %>%\n  dplyr::rename(Surface_Pressure = PS) %>%\n  dplyr::rename(Wind_50_meter = WS50M) %>%\n  dplyr::rename(Precipitation = PRECTOTCORR) %>%\n  dplyr::rename(Annual = ANN) %>%\n  dplyr::rename(Latitude = LAT) %>%\n  dplyr::rename(Longitude = LON) %>%\n  dplyr::rename(Month = MONTH) %>%\n  dplyr::rename(Year = YEAR)\n\nTidy_WestV <- Tidy_WestV %>%\n  select(Year, Month, Latitude, Longitude, Temperature, Humidity, Precipitation, Surface_Pressure, Wind_10_meter, Wind_50_meter, Annual)\n\nsummary(Tidy_WestV)\n\n      Year         Month              Latitude       Longitude     \n Min.   :1990   Length:74400       Min.   :38.75   Min.   :-92.25  \n 1st Qu.:1997   Class :character   1st Qu.:39.75   1st Qu.:-89.88  \n Median :2005   Mode  :character   Median :41.00   Median :-87.50  \n Mean   :2005                      Mean   :41.00   Mean   :-87.50  \n 3rd Qu.:2013                      3rd Qu.:42.25   3rd Qu.:-85.12  \n Max.   :2020                      Max.   :43.25   Max.   :-82.75  \n  Temperature        Humidity     Precipitation    Surface_Pressure\n Min.   :-15.01   Min.   :42.91   Min.   : 0.070   Min.   : 96.84  \n 1st Qu.:  1.16   1st Qu.:74.30   1st Qu.: 1.620   1st Qu.: 98.52  \n Median : 10.68   Median :78.66   Median : 2.470   Median : 98.91  \n Mean   : 10.17   Mean   :78.26   Mean   : 2.712   Mean   : 98.89  \n 3rd Qu.: 19.68   3rd Qu.:82.78   3rd Qu.: 3.500   3rd Qu.: 99.27  \n Max.   : 31.10   Max.   :96.86   Max.   :11.770   Max.   :100.75  \n Wind_10_meter   Wind_50_meter       Annual      \n Min.   :1.230   Min.   : 2.73   Min.   : 97.38  \n 1st Qu.:3.720   1st Qu.: 5.64   1st Qu.: 98.55  \n Median :4.600   Median : 6.69   Median : 98.93  \n Mean   :4.527   Mean   : 6.55   Mean   : 98.89  \n 3rd Qu.:5.280   3rd Qu.: 7.43   3rd Qu.: 99.24  \n Max.   :9.630   Max.   :10.79   Max.   :100.08  \n\nTidy_WestV <- Tidy_WestV %>%\n  slice(1:10)\n\nkable(Tidy_WestV, digits = 2, align = \"ccccccc\", col.names = c(\"Year\", \"Month\", \"Latitude\", \"Longitude\", \"Temperature\", \"Humidity\", \"Precipitation\", \"Surface Pressure\", \"Wind 10 Meters\", \"Wind 50 Meters\", \"Annual\"), caption = \"Amherst Data\") %>%\n  kable_styling(font_size = 16)\n\n\n\nAmherst Data\n \n  \n    Year \n    Month \n    Latitude \n    Longitude \n    Temperature \n    Humidity \n    Precipitation \n    Surface Pressure \n    Wind 10 Meters \n    Wind 50 Meters \n    Annual \n  \n \n\n  \n    1990 \n    NOV \n    38.75 \n    -82.75 \n    7.51 \n    78.61 \n    1.90 \n    99.06 \n    2.12 \n    4.52 \n    98.89 \n  \n  \n    1990 \n    JAN \n    38.75 \n    -82.75 \n    2.18 \n    85.99 \n    2.72 \n    98.83 \n    2.79 \n    5.31 \n    98.89 \n  \n  \n    1990 \n    FEB \n    38.75 \n    -82.75 \n    3.81 \n    84.92 \n    3.60 \n    99.03 \n    2.87 \n    5.39 \n    98.89 \n  \n  \n    1990 \n    MAR \n    38.75 \n    -82.75 \n    7.16 \n    81.56 \n    1.94 \n    99.27 \n    2.28 \n    4.45 \n    98.89 \n  \n  \n    1990 \n    APR \n    38.75 \n    -82.75 \n    10.65 \n    76.54 \n    2.76 \n    98.84 \n    2.13 \n    4.24 \n    98.89 \n  \n  \n    1990 \n    MAY \n    38.75 \n    -82.75 \n    15.35 \n    80.81 \n    6.58 \n    98.51 \n    2.16 \n    4.49 \n    98.89 \n  \n  \n    1990 \n    JUN \n    38.75 \n    -82.75 \n    20.81 \n    80.24 \n    2.98 \n    98.66 \n    1.84 \n    3.98 \n    98.89 \n  \n  \n    1990 \n    JUL \n    38.75 \n    -82.75 \n    23.19 \n    77.11 \n    3.71 \n    98.81 \n    1.52 \n    3.40 \n    98.89 \n  \n  \n    1990 \n    AUG \n    38.75 \n    -82.75 \n    23.23 \n    68.86 \n    3.53 \n    98.85 \n    1.28 \n    2.81 \n    98.89 \n  \n  \n    1990 \n    SEP \n    38.75 \n    -82.75 \n    19.94 \n    70.16 \n    2.86 \n    98.81 \n    1.60 \n    3.48 \n    98.89 \n  \n\n\n\n\n\n\n\nState Economy data\nThe economic data is pulled from the Bureau of Economic Analysis (Analysis, n.d.). This data is the ins, outs, and the difference between the former two in income by state. The data ranges from 1990 to 2020 and covers every state in the US.\n\n# Reading in economic data\n\nEconomy <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/Economy.csv\")\n\n\n# Renaming the columns to remove the X\nEconomy <- Economy %>%\n  dplyr::rename('1990' = X1990) %>%\n  dplyr::rename('1991' = X1991) %>%\n  dplyr::rename('1992' = X1992) %>%\n  dplyr::rename('1993' = X1993) %>%\n  dplyr::rename('1994' = X1994) %>%\n  dplyr::rename('1995' = X1995) %>%\n  dplyr::rename('1996' = X1996) %>%\n  dplyr::rename('1997' = X1997) %>%\n  dplyr::rename('1998' = X1998) %>%\n  dplyr::rename('1999' = X1999) %>%\n  dplyr::rename('2000' = X2000) %>%\n  dplyr::rename('2001' = X2001) %>%\n  dplyr::rename('2002' = X2002) %>%\n  dplyr::rename('2003' = X2003) %>%\n  dplyr::rename('2004' = X2004) %>%\n  dplyr::rename('2005' = X2005) %>%\n  dplyr::rename('2006' = X2006) %>%\n  dplyr::rename('2007' = X2007) %>%\n  dplyr::rename('2008' = X2008) %>%\n  dplyr::rename('2009' = X2009) %>%\n  dplyr::rename('2010' = X2010) %>%\n  dplyr::rename('2011' = X2011) %>%\n  dplyr::rename('2012' = X2012) %>%\n  dplyr::rename('2013' = X2013) %>%\n  dplyr::rename('2014' = X2014) %>%\n  dplyr::rename('2015' = X2015) %>%\n  dplyr::rename('2016' = X2016) %>%\n  dplyr::rename('2017' = X2017) %>%\n  dplyr::rename('2018' = X2018) %>%\n  dplyr::rename('2019' = X2019) %>%\n  dplyr::rename('2020' = X2020) \n\n# Pivoting to combine all the years into one column\nEconomy <- Economy %>%\npivot_longer(\n  cols = c('1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020'),\n  names_to = \"Year\",\n  values_to = \"Yearly_Fianace\",\n)\n\n## Change from char to numeric\nEconomy$Year <- as.numeric(Economy$Year)\n\n# Changing the finance column to be in millions\nEconomy <- Economy %>%\n  mutate(Year_Money_Millions = Yearly_Fianace/1000)\n\nsummary(Economy)\n\n    State           Description             Year      Yearly_Fianace     \n Length:4650        Length:4650        Min.   :1990   Min.   :-82419435  \n Class :character   Class :character   1st Qu.:1997   1st Qu.:   373224  \n Mode  :character   Mode  :character   Median :2005   Median :  1631958  \n                                       Mean   :2005   Mean   :  4146898  \n                                       3rd Qu.:2013   3rd Qu.:  4870305  \n                                       Max.   :2020   Max.   :109468260  \n Year_Money_Millions\n Min.   :-82419.4   \n 1st Qu.:   373.2   \n Median :  1632.0   \n Mean   :  4146.9   \n 3rd Qu.:  4870.3   \n Max.   :109468.3"
  },
  {
    "objectID": "posts/Final pt 1.html",
    "href": "posts/Final pt 1.html",
    "title": "Final Project Proposal",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.4 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.2      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(dplyr)"
  },
  {
    "objectID": "posts/Final pt 1.html#research-question",
    "href": "posts/Final pt 1.html#research-question",
    "title": "Final Project Proposal",
    "section": "Research Question",
    "text": "Research Question\nIn the United States, wage stagnation has become a hot-button issue for many people in various fields of employment. Graduate students have been at the center of this issue in recent years- strikes for wage increases and cost-of-living adjustments have taken place at multiple universities throughout the country. Because PhD students often do not have the time to earn extra income (and their contracts often prohibit them from pursuing work elsewhere), how much they will earn from their stipend is a huge factor in considering where to pursue their research (Powell, 2004; Soar et al., 2022). Knowing how much My research question is: What is the strongest predictor of the value of a PhD stipend?"
  },
  {
    "objectID": "posts/Final pt 1.html#hypothesis",
    "href": "posts/Final pt 1.html#hypothesis",
    "title": "Final Project Proposal",
    "section": "Hypothesis",
    "text": "Hypothesis\nH₀: Cost of living is not the strongest predictor of the value of a PhD stipend.\nH₁: Cost of living is the strongest predictor of the value of a PhD stipend."
  },
  {
    "objectID": "posts/Final pt 1.html#dataset",
    "href": "posts/Final pt 1.html#dataset",
    "title": "Final Project Proposal",
    "section": "Dataset",
    "text": "Dataset\nThis dataset is comprised of self-reported survey data collected by PhDStipends.com. Respondents are asked their university, department, academic year, and year in the program. They are also asked whether they receive a 12-month or 9-month salary, gross pay, and required fees. PhDStipends automatically calculators the LW Ratio (living wage ratio), which is the stipend divided by the living wage of the country the university is located in. I will likely need to add additional information for my own analysis.\nThe variables of interest for me are the university, department, and program year.\n\n\nCode\nlibrary(readr)\ncsv <- read_csv(\"~/School/UMASS/DACSS 603/Final Project/csv.csv\")\n\n\nRows: 13629 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): University, Department, Academic Year, Program Year, Comments\ndbl (6): Overall Pay, LW Ratio, 12 M Gross Pay, 9 M Gross Pay, 3 M Gross Pay...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nsummary(csv)\n\n\n  University         Department         Overall Pay         LW Ratio      \n Length:13629       Length:13629       Min.   :-900000   Min.   :-34.010  \n Class :character   Class :character   1st Qu.:  20000   1st Qu.:  0.880  \n Mode  :character   Mode  :character   Median :  26000   Median :  1.130  \n                                       Mean   :  27549   Mean   :  1.172  \n                                       3rd Qu.:  31500   3rd Qu.:  1.330  \n                                       Max.   :6942069   Max.   :265.030  \n                                       NA's   :64        NA's   :1420     \n Academic Year      Program Year       12 M Gross Pay    9 M Gross Pay    \n Length:13629       Length:13629       Min.   :      1   Min.   :      5  \n Class :character   Class :character   1st Qu.:  24000   1st Qu.:  16209  \n Mode  :character   Mode  :character   Median :  29000   Median :  20000  \n                                       Mean   :  30974   Mean   :  21263  \n                                       3rd Qu.:  33000   3rd Qu.:  24000  \n                                       Max.   :6942069   Max.   :2600030  \n                                       NA's   :3926      NA's   :9749     \n 3 M Gross Pay        Fees           Comments        \n Min.   :    3   Min.   :      1   Length:13629      \n 1st Qu.: 3000   1st Qu.:    500   Class :character  \n Median : 5000   Median :   1050   Mode  :character  \n Mean   : 5242   Mean   :   3000                     \n 3rd Qu.: 6264   3rd Qu.:   2000                     \n Max.   :55816   Max.   :1000000                     \n NA's   :12356   NA's   :8294                        \n\n\n\n\nCode\nprint(summarytools::dfSummary(csv,\n                              varnumbers = FALSE,\n                              plain.ascii  = FALSE,\n                              style        = \"grid\",\n                              graph.magnif = 0.70,\n                              valid.col    = FALSE),\n      method = 'render',\n      table.classes = 'table-condensed')\n\n\n\n\nData Frame Summary\ncsv\nDimensions: 13629 x 11\n  Duplicates: 346\n\n\n  \n    \n      Variable\n      Stats / Values\n      Freqs (% of Valid)\n      Graph\n      Missing\n    \n  \n  \n    \n      University\n[character]\n      1. University of Wisconsin -2. Duke University (DU)3. University of California 4. University of North Carol5. University of California 6. University of Pennsylvani7. University of Michigan - 8. Pennsylvania State Univer9. University of Southern Ca10. University of Minnesota -[ 815 others ]\n      236(1.8%)213(1.6%)213(1.6%)209(1.6%)207(1.6%)206(1.6%)198(1.5%)193(1.5%)192(1.5%)182(1.4%)11135(84.5%)\n      \n      445\n(3.3%)\n    \n    \n      Department\n[character]\n      1. Chemistry2. Psychology3. Computer Science4. Sociology5. Physics6. English7. Political Science8. Biology9. Economics10. Biomedical Engineering[ 3214 others ]\n      559(4.3%)417(3.2%)344(2.6%)331(2.5%)317(2.4%)306(2.4%)298(2.3%)297(2.3%)214(1.6%)205(1.6%)9701(74.7%)\n      \n      640\n(4.7%)\n    \n    \n      Overall Pay\n[numeric]\n      Mean (sd) : 27549.4 (85090.1)min ≤ med ≤ max:-9e+05 ≤ 26000 ≤ 6942069IQR (CV) : 11500 (3.1)\n      3805 distinct values\n      \n      64\n(0.5%)\n    \n    \n      LW Ratio\n[numeric]\n      Mean (sd) : 1.2 (3.8)min ≤ med ≤ max:-34 ≤ 1.1 ≤ 265IQR (CV) : 0.5 (3.2)\n      355 distinct values\n      \n      1420\n(10.4%)\n    \n    \n      Academic Year\n[character]\n      1. 2020-20212. 2016-20173. 2018-20194. 2019-20205. 2021-20226. 2017-20187. 2022-20238. 2014-20159. 2015-201610. 2013-2014[ 14 others ]\n      3024(22.2%)2218(16.3%)1954(14.3%)1468(10.8%)1312(9.6%)1220(9.0%)1130(8.3%)566(4.2%)434(3.2%)102(0.7%)196(1.4%)\n      \n      5\n(0.0%)\n    \n    \n      Program Year\n[character]\n      1. 1st2. 2nd3. 3rd4. 4th5. 5th6. 6th and up\n      6793(56.3%)1674(13.9%)1336(11.1%)1068(8.8%)808(6.7%)395(3.3%)\n      \n      1555\n(11.4%)\n    \n    \n      12 M Gross Pay\n[numeric]\n      Mean (sd) : 30973.5 (95292.1)min ≤ med ≤ max:1 ≤ 29000 ≤ 6942069IQR (CV) : 9000 (3.1)\n      1840 distinct values\n      \n      3926\n(28.8%)\n    \n    \n      9 M Gross Pay\n[numeric]\n      Mean (sd) : 21263.3 (48498)min ≤ med ≤ max:5 ≤ 20000 ≤ 2600030IQR (CV) : 7791 (2.3)\n      1104 distinct values\n      \n      9749\n(71.5%)\n    \n    \n      3 M Gross Pay\n[numeric]\n      Mean (sd) : 5242 (3591.5)min ≤ med ≤ max:3 ≤ 5000 ≤ 55816IQR (CV) : 3264 (0.7)\n      321 distinct values\n      \n      12356\n(90.7%)\n    \n    \n      Fees\n[numeric]\n      Mean (sd) : 2999.8 (15564.2)min ≤ med ≤ max:1 ≤ 1050 ≤ 1e+06IQR (CV) : 1500 (5.2)\n      1078 distinct values\n      \n      8294\n(60.9%)\n    \n    \n      Comments\n[character]\n      1. #NAME?2. Fellowship3. Includes health insurance4. Got paid once a month. Ha5. N/A6. NSF GRFP7. Program covers approximat8. National Science Foundati9. RA10. University fellowship[ 3156 others ]\n      13(0.4%)13(0.4%)8(0.2%)6(0.2%)6(0.2%)6(0.2%)6(0.2%)5(0.1%)5(0.1%)5(0.1%)3312(97.8%)\n      \n      10244\n(75.2%)\n    \n  \n\nGenerated by summarytools 1.0.1 (R version 4.2.1)2022-10-10\n\n\n\nBased on this summary, there are some extreme outliers in need of removal, particularly in the Overall Pay column. Interesting, the mean Overall Pay of $27549.4 does not seem unreasonable,."
  },
  {
    "objectID": "posts/Final pt 1.html#references",
    "href": "posts/Final pt 1.html#references",
    "title": "Final Project Proposal",
    "section": "References",
    "text": "References\nLiving Wage Calculator. (n.d.). Retrieved October 10, 2022, from https://livingwage.mit.edu/\nPowell, K. Stipend survival. Nature 428, 102–103 (2004). https://doi.org/10.1038/nj6978-102a\nEmily Roberts & Kyle Roberts. (2022, October 10). PhD stipends Dataset. http://www.phdstipends.com/csv\nSoar, M., Stewart, L., Nissen, S. et al. Sweat Equity: Student Scholarships in Aotearoa New Zealand’s Universities. NZ J Educ Stud (2022). https://doi.org/10.1007/s40841-022-00244-5"
  },
  {
    "objectID": "posts/finalpart1.html",
    "href": "posts/finalpart1.html",
    "title": "finalpart1",
    "section": "",
    "text": "Are Women and Racial minorities underrepresented in STEM fields (Study & Career)? A predictive analysis of the likelihood of STEM careers.\n\n\nWomen are significantly underrepresented in STEM (science, technology, engineering, and mathematics) fields in the USA, making up less than a quarter of those working in STEM occupations (Noonan, [2017](https://stemeducationjournal.springeropen.com/articles/10.1186/s40594-020-00219-2#ref-CR13 “Noonan, R. Women in STEM: 2017 update (ESA Issue Brief #06-17). Office of the Chief Economist, Economics and Statistics Administration, U.S. Department of Commerce (November 13, 2017). Retrieved from https://www.commerce.gov/news/fact-sheets/2017/11/women-stem-2017-update\n“); Ong, Smith, & Ko, [2018](https://stemeducationjournal.springeropen.com/articles/10.1186/s40594-020-00219-2#ref-CR15”Ong, M., Smith, J. M., & Ko, L. T. (2018). Counterspaces for women of color in STEM higher education: marginal and central spaces for persistence and success. Journal of Research in Science Teaching, 55(2), 206–245. https://doi.org/10.1002/tea.21417\n.”)).\nRepresentation of women of color is even lower, with Hispanic, Asian, and African American women each receiving less than 5% of STEM bachelor's degrees in the USA (Ong et al., [2018](https://stemeducationjournal.springeropen.com/articles/10.1186/s40594-020-00219-2#ref-CR15 “Ong, M., Smith, J. M., & Ko, L. T. (2018). Counterspaces for women of color in STEM higher education: marginal and central spaces for persistence and success. Journal of Research in Science Teaching, 55(2), 206–245. https://doi.org/10.1002/tea.21417\n.”);\nBy the time students reach college, women are significantly underrepresented in STEM majors — for instance, only around 21% of engineering majors are women and only around 19% of computer and information science majors are women.https://www.aauw.org/resources/research/the-stem-gap/\nThe fact that women and racial minorities are still discriminated and underrepresented in the STEM in the 21st century while mankind is stepping foot on other planets is a topic to be given a serious thought.\nThe above mentioned articles are my motivation to perform this analysis in addition to the 2011 survey by US Department of Commerce showing that women and racial minorities are underrpresented in stem fields in two ways: They represent a disproportionatly small percentage of STEM degree holders, as well as STEM workers. These reports are linked below:\n\n“Women in STEM: A Gender Gap to Innovation”\n“Education Supports Racial and Ethnic Equality in STEM”\n\nThe goal of this project is to build a model to predict likelihood of working in a STEM (Science, Technology, Engineering, and Math) career based on basic demographics: Age, sex, race, state of origin."
  },
  {
    "objectID": "posts/finalpart1.html#hypothesis",
    "href": "posts/finalpart1.html#hypothesis",
    "title": "finalpart1",
    "section": "Hypothesis:",
    "text": "Hypothesis:\nMy hypothesis: Women and Racial minorities are underrepresented in STEM fields.\nThe above mentioned hypothesis has been tested and proved by many researchers and government survey analysis already. Bus i wish to perform this study again by modifying it by developing regression models to resume the likelihood of STEM careers.\n---\n\nLoading the libraries\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(stats)\n\nknitr::opts_chunk$set(echo = TRUE)\n\n\n\n\nReading the raw data\n\n\nCode\npop <- read.csv(\"C:/Users/91955/Desktop/603_Fall_2022/ss13pusa.csv\")\nhead(pop)"
  },
  {
    "objectID": "posts/finalpart1.html#descriptive-statistics",
    "href": "posts/finalpart1.html#descriptive-statistics",
    "title": "finalpart1",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\n\n\nCode\nsummary(pop)\n\n\n      RT               SERIALNO          SPORDER            PUMA      \n Length:1613672     Min.   :      1   Min.   : 1.000   Min.   :  100  \n Class :character   1st Qu.: 372368   1st Qu.: 1.000   1st Qu.:  802  \n Mode  :character   Median : 745780   Median : 2.000   Median : 2000  \n                    Mean   : 746221   Mean   : 2.111   Mean   : 3075  \n                    3rd Qu.:1119428   3rd Qu.: 3.000   3rd Qu.: 3762  \n                    Max.   :1492843   Max.   :20.000   Max.   :12704  \n                                                                      \n       ST            ADJINC            PWGTP             AGEP      \n Min.   : 1.00   Min.   :1007549   Min.   :   1.0   Min.   : 0.00  \n 1st Qu.: 6.00   1st Qu.:1007549   1st Qu.:  54.0   1st Qu.:20.00  \n Median :12.00   Median :1007549   Median :  78.0   Median :41.00  \n Mean   :13.91   Mean   :1007549   Mean   : 101.1   Mean   :40.51  \n 3rd Qu.:21.00   3rd Qu.:1007549   3rd Qu.: 122.0   3rd Qu.:59.00  \n Max.   :28.00   Max.   :1007549   Max.   :1830.0   Max.   :95.00  \n                                                                   \n      CIT            CITWP              COW              DDRS      \n Min.   :1.000   Min.   :1928      Min.   :1.0      Min.   :1.00   \n 1st Qu.:1.000   1st Qu.:1987      1st Qu.:1.0      1st Qu.:2.00   \n Median :1.000   Median :1999      Median :1.0      Median :2.00   \n Mean   :1.474   Mean   :1995      Mean   :2.2      Mean   :1.96   \n 3rd Qu.:1.000   3rd Qu.:2007      3rd Qu.:3.0      3rd Qu.:2.00   \n Max.   :5.000   Max.   :2013      Max.   :9.0      Max.   :2.00   \n                 NA's   :1503773   NA's   :669251   NA's   :85453  \n      DEAR            DEYE            DOUT             DPHY      \n Min.   :1.000   Min.   :1.000   Min.   :1.00     Min.   :1.00   \n 1st Qu.:2.000   1st Qu.:2.000   1st Qu.:2.00     1st Qu.:2.00   \n Median :2.000   Median :2.000   Median :2.00     Median :2.00   \n Mean   :1.958   Mean   :1.973   Mean   :1.93     Mean   :1.92   \n 3rd Qu.:2.000   3rd Qu.:2.000   3rd Qu.:2.00     3rd Qu.:2.00   \n Max.   :2.000   Max.   :2.000   Max.   :2.00     Max.   :2.00   \n                                 NA's   :281475   NA's   :85453  \n      DRAT             DRATX              DREM            ENG         \n Min.   :1.0       Min.   :1.0       Min.   :1.00    Min.   :1.0      \n 1st Qu.:2.0       1st Qu.:2.0       1st Qu.:2.00    1st Qu.:1.0      \n Median :3.0       Median :2.0       Median :2.00    Median :1.0      \n Mean   :3.3       Mean   :1.8       Mean   :1.94    Mean   :1.7      \n 3rd Qu.:5.0       3rd Qu.:2.0       3rd Qu.:2.00    3rd Qu.:2.0      \n Max.   :6.0       Max.   :2.0       Max.   :2.00    Max.   :4.0      \n NA's   :1592578   NA's   :1477285   NA's   :85453   NA's   :1307558  \n      FER               GCL              GCM               GCR         \n Min.   :1.0       Min.   :1        Min.   :1.0       Min.   :1.0      \n 1st Qu.:2.0       1st Qu.:2        1st Qu.:3.0       1st Qu.:1.0      \n Median :2.0       Median :2        Median :4.0       Median :2.0      \n Mean   :1.9       Mean   :2        Mean   :3.7       Mean   :1.6      \n 3rd Qu.:2.0       3rd Qu.:2        3rd Qu.:5.0       3rd Qu.:2.0      \n Max.   :2.0       Max.   :2        Max.   :5.0       Max.   :2.0      \n NA's   :1251923   NA's   :584499   NA's   :1599288   NA's   :1576461  \n     HINS1           HINS2           HINS3           HINS4      \n Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   :1.000  \n 1st Qu.:1.000   1st Qu.:2.000   1st Qu.:2.000   1st Qu.:2.000  \n Median :1.000   Median :2.000   Median :2.000   Median :2.000  \n Mean   :1.466   Mean   :1.861   Mean   :1.805   Mean   :1.822  \n 3rd Qu.:2.000   3rd Qu.:2.000   3rd Qu.:2.000   3rd Qu.:2.000  \n Max.   :2.000   Max.   :2.000   Max.   :2.000   Max.   :2.000  \n                                                                \n     HINS5           HINS6           HINS7            INTP       \n Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   : -6300  \n 1st Qu.:2.000   1st Qu.:2.000   1st Qu.:2.000   1st Qu.:     0  \n Median :2.000   Median :2.000   Median :2.000   Median :     0  \n Mean   :1.969   Mean   :1.975   Mean   :1.994   Mean   :  2179  \n 3rd Qu.:2.000   3rd Qu.:2.000   3rd Qu.:2.000   3rd Qu.:     0  \n Max.   :2.000   Max.   :2.000   Max.   :2.000   Max.   :300000  \n                                                 NA's   :281475  \n     JWMNP            JWRIP              JWTR             LANX      \n Min.   :  1.0    Min.   : 1.0      Min.   : 1       Min.   :1.0    \n 1st Qu.: 10.0    1st Qu.: 1.0      1st Qu.: 1       1st Qu.:2.0    \n Median : 20.0    Median : 1.0      Median : 1       Median :2.0    \n Mean   : 26.2    Mean   : 1.2      Mean   : 2       Mean   :1.8    \n 3rd Qu.: 30.0    3rd Qu.: 1.0      3rd Qu.: 1       3rd Qu.:2.0    \n Max.   :167.0    Max.   :10.0      Max.   :12       Max.   :2.0    \n NA's   :943025   NA's   :1004116   NA's   :908560   NA's   :85453  \n      MAR            MARHD            MARHM            MARHT       \n Min.   :1.000   Min.   :1        Min.   :1        Min.   :1.0     \n 1st Qu.:1.000   1st Qu.:2        1st Qu.:2        1st Qu.:1.0     \n Median :3.000   Median :2        Median :2        Median :1.0     \n Mean   :2.961   Mean   :2        Mean   :2        Mean   :1.3     \n 3rd Qu.:5.000   3rd Qu.:2        3rd Qu.:2        3rd Qu.:2.0     \n Max.   :5.000   Max.   :2        Max.   :2        Max.   :3.0     \n                 NA's   :679081   NA's   :679081   NA's   :679081  \n     MARHW            MARHYP            MIG             MIL        \n Min.   :1        Min.   :1933     Min.   :1.000   Min.   :1.0     \n 1st Qu.:2        1st Qu.:1974     1st Qu.:1.000   1st Qu.:4.0     \n Median :2        Median :1989     Median :1.000   Median :4.0     \n Mean   :2        Mean   :1987     Mean   :1.274   Mean   :3.8     \n 3rd Qu.:2        3rd Qu.:2001     3rd Qu.:1.000   3rd Qu.:4.0     \n Max.   :2        Max.   :2013     Max.   :3.000   Max.   :4.0     \n NA's   :679081   NA's   :679081   NA's   :16101   NA's   :323518  \n      MLPA              MLPB             MLPCD              MLPE        \n Min.   :0.0       Min.   :0.0       Min.   :0.0       Min.   :0.0      \n 1st Qu.:0.0       1st Qu.:0.0       1st Qu.:0.0       1st Qu.:0.0      \n Median :0.0       Median :0.0       Median :0.0       Median :0.0      \n Mean   :0.1       Mean   :0.2       Mean   :0.2       Mean   :0.4      \n 3rd Qu.:0.0       3rd Qu.:0.0       3rd Qu.:0.0       3rd Qu.:1.0      \n Max.   :1.0       Max.   :1.0       Max.   :1.0       Max.   :1.0      \n NA's   :1496195   NA's   :1496195   NA's   :1496195   NA's   :1496195  \n     MLPFG              MLPH              MLPI              MLPJ        \n Min.   :0.0       Min.   :0.0       Min.   :0         Min.   :0.0      \n 1st Qu.:0.0       1st Qu.:0.0       1st Qu.:0         1st Qu.:0.0      \n Median :0.0       Median :0.0       Median :0         Median :0.0      \n Mean   :0.2       Mean   :0.1       Mean   :0         Mean   :0.1      \n 3rd Qu.:0.0       3rd Qu.:0.0       3rd Qu.:0         3rd Qu.:0.0      \n Max.   :1.0       Max.   :1.0       Max.   :1         Max.   :1.0      \n NA's   :1496195   NA's   :1496195   NA's   :1496195   NA's   :1496195  \n      MLPK              NWAB             NWAV             NWLA       \n Min.   :0         Min.   :1.00     Min.   :1.00     Min.   :1.00    \n 1st Qu.:0         1st Qu.:2.00     1st Qu.:5.00     1st Qu.:2.00    \n Median :0         Median :3.00     Median :5.00     Median :3.00    \n Mean   :0         Mean   :2.57     Mean   :4.65     Mean   :2.55    \n 3rd Qu.:0         3rd Qu.:3.00     3rd Qu.:5.00     3rd Qu.:3.00    \n Max.   :1         Max.   :3.00     Max.   :5.00     Max.   :3.00    \n NA's   :1496195   NA's   :302343   NA's   :302343   NA's   :302343  \n      NWLK             NWRE             OIP               PAP          \n Min.   :1.00     Min.   :1.00     Min.   :    0.0   Min.   :    0.00  \n 1st Qu.:2.00     1st Qu.:3.00     1st Qu.:    0.0   1st Qu.:    0.00  \n Median :3.00     Median :3.00     Median :    0.0   Median :    0.00  \n Mean   :2.53     Mean   :2.93     Mean   :  674.6   Mean   :   51.37  \n 3rd Qu.:3.00     3rd Qu.:3.00     3rd Qu.:    0.0   3rd Qu.:    0.00  \n Max.   :3.00     Max.   :3.00     Max.   :83000.0   Max.   :30000.00  \n NA's   :302343   NA's   :302343   NA's   :281475    NA's   :281475    \n      RELP             RETP             SCH             SCHG        \n Min.   : 0.000   Min.   :     0   Min.   :1.0     Min.   : 1.0     \n 1st Qu.: 0.000   1st Qu.:     0   1st Qu.:1.0     1st Qu.: 6.0     \n Median : 1.000   Median :     0   Median :1.0     Median :11.0     \n Mean   : 2.605   Mean   :  2383   Mean   :1.3     Mean   : 9.8     \n 3rd Qu.: 2.000   3rd Qu.:     0   3rd Qu.:2.0     3rd Qu.:15.0     \n Max.   :17.000   Max.   :178000   Max.   :3.0     Max.   :16.0     \n                  NA's   :281475   NA's   :49494   NA's   :1211500  \n      SCHL            SEMP             SEX             SSIP        \n Min.   : 1.00   Min.   : -7500   Min.   :1.000   Min.   :    0.0  \n 1st Qu.:14.00   1st Qu.:     0   1st Qu.:1.000   1st Qu.:    0.0  \n Median :17.00   Median :     0   Median :2.000   Median :    0.0  \n Mean   :15.85   Mean   :  1810   Mean   :1.511   Mean   :  273.1  \n 3rd Qu.:20.00   3rd Qu.:     0   3rd Qu.:2.000   3rd Qu.:    0.0  \n Max.   :24.00   Max.   :525000   Max.   :2.000   Max.   :30000.0  \n NA's   :49494   NA's   :281475                   NA's   :281475   \n      SSP              WAGP             WKHP             WKL        \n Min.   :    0    Min.   :     0   Min.   : 1.0     Min.   :1.00    \n 1st Qu.:    0    1st Qu.:     0   1st Qu.:32.0     1st Qu.:1.00    \n Median :    0    Median :  5000   Median :40.0     Median :1.00    \n Mean   : 2925    Mean   : 25569   Mean   :37.8     Mean   :1.67    \n 3rd Qu.:    0    3rd Qu.: 36000   3rd Qu.:41.0     3rd Qu.:3.00    \n Max.   :50000    Max.   :660000   Max.   :99.0     Max.   :3.00    \n NA's   :281475   NA's   :281475   NA's   :802274   NA's   :302343  \n      WKW              WRK              YOEP              ANC      \n Min.   :1.0      Min.   :1.0      Min.   :1921      Min.   :1.00  \n 1st Qu.:1.0      1st Qu.:1.0      1st Qu.:1980      1st Qu.:1.00  \n Median :1.0      Median :1.0      Median :1992      Median :1.00  \n Mean   :1.9      Mean   :1.4      Mean   :1990      Mean   :1.71  \n 3rd Qu.:3.0      3rd Qu.:2.0      3rd Qu.:2002      3rd Qu.:2.00  \n Max.   :6.0      Max.   :2.0      Max.   :2013      Max.   :4.00  \n NA's   :802274   NA's   :431414   NA's   :1382392                 \n     ANC1P           ANC2P           DECADE             DIS       \n Min.   :  1.0   Min.   :  1.0   Min.   :1.0       Min.   :1.000  \n 1st Qu.: 50.0   1st Qu.:939.0   1st Qu.:5.0       1st Qu.:2.000  \n Median :226.0   Median :999.0   Median :6.0       Median :2.000  \n Mean   :465.3   Mean   :796.2   Mean   :5.5       Mean   :1.853  \n 3rd Qu.:924.0   3rd Qu.:999.0   3rd Qu.:7.0       3rd Qu.:2.000  \n Max.   :999.0   Max.   :999.0   Max.   :7.0       Max.   :2.000  \n                                 NA's   :1382392                  \n    DRIVESP             ESP               ESR             FOD1P        \n Min.   :1.0       Min.   :1.0       Min.   :1.00     Min.   :1100     \n 1st Qu.:1.0       1st Qu.:1.0       1st Qu.:1.00     1st Qu.:2405     \n Median :1.0       Median :2.0       Median :1.00     Median :5007     \n Mean   :1.2       Mean   :3.1       Mean   :3.12     Mean   :4320     \n 3rd Qu.:1.0       3rd Qu.:6.0       3rd Qu.:6.00     3rd Qu.:6107     \n Max.   :6.0       Max.   :8.0       Max.   :6.00     Max.   :6403     \n NA's   :1004116   NA's   :1288953   NA's   :302343   NA's   :1257880  \n     FOD2P             HICOV           HISP             INDP       \n Min.   :1100      Min.   :1.00   Min.   : 1.000   Min.   : 170    \n 1st Qu.:2409      1st Qu.:1.00   1st Qu.: 1.000   1st Qu.:4970    \n Median :5007      Median :1.00   Median : 1.000   Median :7390    \n Mean   :4344      Mean   :1.13   Mean   : 1.576   Mean   :6411    \n 3rd Qu.:6006      3rd Qu.:1.00   3rd Qu.: 1.000   3rd Qu.:8270    \n Max.   :6403      Max.   :2.00   Max.   :24.000   Max.   :9920    \n NA's   :1577632                                   NA's   :669251  \n      JWAP             JWDP             LANP            MIGPUMA       \n Min.   :  1.0    Min.   :  1.0    Min.   :601.0     Min.   :    1    \n 1st Qu.: 81.0    1st Qu.: 37.0    1st Qu.:625.0     1st Qu.:  500    \n Median : 92.0    Median : 49.0    Median :625.0     Median : 1800    \n Mean   :103.6    Mean   : 54.7    Mean   :655.8     Mean   : 3231    \n 3rd Qu.:107.0    3rd Qu.: 63.0    3rd Qu.:671.0     3rd Qu.: 3700    \n Max.   :285.0    Max.   :150.0    Max.   :994.0     Max.   :70100    \n NA's   :943025   NA's   :943025   NA's   :1307558   NA's   :1389943  \n     MIGSP              MSP            NAICSP             NATIVITY   \n Min.   :  1.0     Min.   :1.00     Length:1613672     Min.   :1.00  \n 1st Qu.:  6.0     1st Qu.:1.00     Class :character   1st Qu.:1.00  \n Median : 13.0     Median :2.00     Mode  :character   Median :1.00  \n Mean   : 25.9     Mean   :3.05                        Mean   :1.13  \n 3rd Qu.: 25.0     3rd Qu.:6.00                        3rd Qu.:1.00  \n Max.   :555.0     Max.   :6.00                        Max.   :2.00  \n NA's   :1389943   NA's   :281475                                    \n      NOP                OC              OCCP             PAOC       \n Min.   :1.0       Min.   :0.0000   Min.   :  10     Min.   :1.0     \n 1st Qu.:1.0       1st Qu.:0.0000   1st Qu.:2310     1st Qu.:3.0     \n Median :2.0       Median :0.0000   Median :4500     Median :4.0     \n Mean   :3.3       Mean   :0.1844   Mean   :4345     Mean   :3.5     \n 3rd Qu.:6.0       3rd Qu.:0.0000   3rd Qu.:5700     3rd Qu.:4.0     \n Max.   :8.0       Max.   :1.0000   Max.   :9920     Max.   :4.0     \n NA's   :1289567                    NA's   :669251   NA's   :965233  \n     PERNP             PINCP              POBP            POVPIP     \n Min.   :  -7500   Min.   : -11600   Min.   :  1.00   Min.   :  0.0  \n 1st Qu.:      0   1st Qu.:   6400   1st Qu.: 12.00   1st Qu.:157.0  \n Median :   9200   Median :  20300   Median : 21.00   Median :306.0  \n Mean   :  27814   Mean   :  35865   Mean   : 53.83   Mean   :303.8  \n 3rd Qu.:  39000   3rd Qu.:  45300   3rd Qu.: 36.00   3rd Qu.:501.0  \n Max.   :1019000   Max.   :1272000   Max.   :554.00   Max.   :501.0  \n NA's   :302343    NA's   :281475                     NA's   :66398  \n    POWPUMA           POWSP           PRIVCOV          PUBCOV     \n Min.   :    1    Min.   :  1.0    Min.   :1.000   Min.   :1.000  \n 1st Qu.:  600    1st Qu.:  6.0    1st Qu.:1.000   1st Qu.:1.000  \n Median : 1900    Median : 13.0    Median :1.000   Median :2.000  \n Mean   : 3052    Mean   : 14.7    Mean   :1.338   Mean   :1.659  \n 3rd Qu.: 3700    3rd Qu.: 21.0    3rd Qu.:2.000   3rd Qu.:2.000  \n Max.   :70100    Max.   :555.0    Max.   :2.000   Max.   :2.000  \n NA's   :908560   NA's   :908560                                  \n     QTRBIR          RAC1P           RAC2P            RAC3P        \n Min.   :1.000   Min.   :1.000   Min.   : 1.000   Min.   :  1.000  \n 1st Qu.:2.000   1st Qu.:1.000   1st Qu.: 1.000   1st Qu.:  1.000  \n Median :3.000   Median :1.000   Median : 1.000   Median :  1.000  \n Mean   :2.517   Mean   :1.975   Mean   : 8.877   Mean   :  3.022  \n 3rd Qu.:4.000   3rd Qu.:2.000   3rd Qu.: 2.000   3rd Qu.:  2.000  \n Max.   :4.000   Max.   :9.000   Max.   :68.000   Max.   :100.000  \n                                                                   \n    RACAIAN            RACASN            RACBLK           RACNH         \n Min.   :0.00000   Min.   :0.00000   Min.   :0.0000   Min.   :0.000000  \n 1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.000000  \n Median :0.00000   Median :0.00000   Median :0.0000   Median :0.000000  \n Mean   :0.01852   Mean   :0.06935   Mean   :0.1211   Mean   :0.002961  \n 3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.0000   3rd Qu.:0.000000  \n Max.   :1.00000   Max.   :1.00000   Max.   :1.0000   Max.   :1.000000  \n                                                                        \n     RACNUM          RACPI              RACSOR            RACWHT      \n Min.   :1.000   Min.   :0.000000   Min.   :0.00000   Min.   :0.0000  \n 1st Qu.:1.000   1st Qu.:0.000000   1st Qu.:0.00000   1st Qu.:1.0000  \n Median :1.000   Median :0.000000   Median :0.00000   Median :1.0000  \n Mean   :1.033   Mean   :0.002374   Mean   :0.04773   Mean   :0.7712  \n 3rd Qu.:1.000   3rd Qu.:0.000000   3rd Qu.:0.00000   3rd Qu.:1.0000  \n Max.   :5.000   Max.   :1.000000   Max.   :1.00000   Max.   :1.0000  \n                                                                      \n       RC            SCIENGP          SCIENGRLP            SFN         \n Min.   :0.0000   Min.   :1.0       Min.   :1.0       Min.   :1        \n 1st Qu.:0.0000   1st Qu.:1.0       1st Qu.:2.0       1st Qu.:1        \n Median :0.0000   Median :2.0       Median :2.0       Median :1        \n Mean   :0.2079   Mean   :1.6       Mean   :1.9       Mean   :1        \n 3rd Qu.:0.0000   3rd Qu.:2.0       3rd Qu.:2.0       3rd Qu.:1        \n Max.   :1.0000   Max.   :2.0       Max.   :2.0       Max.   :3        \n                  NA's   :1257880   NA's   :1257880   NA's   :1558638  \n      SFR              SOCP                VPS               WAOB      \n Min.   :1.0       Length:1613672     Min.   : 1.0      Min.   :1.000  \n 1st Qu.:3.0       Class :character   1st Qu.: 5.0      1st Qu.:1.000  \n Median :3.0       Mode  :character   Median : 6.0      Median :1.000  \n Mean   :3.6                          Mean   : 7.3      Mean   :1.401  \n 3rd Qu.:5.0                          3rd Qu.:11.0      3rd Qu.:1.000  \n Max.   :6.0                          Max.   :15.0      Max.   :8.000  \n NA's   :1558638                      NA's   :1496195                  \n     FAGEP             FANCP       FCITP             FCITWP       \n Min.   :0.00000   Min.   :0   Min.   :0.00000   Min.   :0.00000  \n 1st Qu.:0.00000   1st Qu.:0   1st Qu.:0.00000   1st Qu.:0.00000  \n Median :0.00000   Median :0   Median :0.00000   Median :0.00000  \n Mean   :0.01298   Mean   :0   Mean   :0.05729   Mean   :0.01474  \n 3rd Qu.:0.00000   3rd Qu.:0   3rd Qu.:0.00000   3rd Qu.:0.00000  \n Max.   :1.00000   Max.   :0   Max.   :1.00000   Max.   :1.00000  \n                                                                  \n     FCOWP             FDDRSP            FDEARP            FDEYEP       \n Min.   :0.00000   Min.   :0.00000   Min.   :0.00000   Min.   :0.00000  \n 1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.00000  \n Median :0.00000   Median :0.00000   Median :0.00000   Median :0.00000  \n Mean   :0.06808   Mean   :0.07084   Mean   :0.06455   Mean   :0.06804  \n 3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.00000  \n Max.   :1.00000   Max.   :1.00000   Max.   :1.00000   Max.   :1.00000  \n                                                                        \n     FDISP             FDOUTP            FDPHYP            FDRATP         \n Min.   :0.00000   Min.   :0.00000   Min.   :0.00000   Min.   :0.0000000  \n 1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.0000000  \n Median :0.00000   Median :0.00000   Median :0.00000   Median :0.0000000  \n Mean   :0.09347   Mean   :0.05903   Mean   :0.07067   Mean   :0.0002504  \n 3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.0000000  \n Max.   :1.00000   Max.   :1.00000   Max.   :1.00000   Max.   :1.0000000  \n                                                                          \n    FDRATXP            FDREMP            FENGP             FESRP        \n Min.   :0.00000   Min.   :0.00000   Min.   :0.00000   Min.   :0.00000  \n 1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.00000  \n Median :0.00000   Median :0.00000   Median :0.00000   Median :0.00000  \n Mean   :0.00573   Mean   :0.07042   Mean   :0.01378   Mean   :0.07072  \n 3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.00000  \n Max.   :1.00000   Max.   :1.00000   Max.   :1.00000   Max.   :1.00000  \n                                                                        \n     FFERP             FFODP             FGCLP              FGCMP         \n Min.   :0.00000   Min.   :0.00000   Min.   :0.000000   Min.   :0.000000  \n 1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.000000   1st Qu.:0.000000  \n Median :0.00000   Median :0.00000   Median :0.000000   Median :0.000000  \n Mean   :0.01653   Mean   :0.02661   Mean   :0.006617   Mean   :0.001508  \n 3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.000000   3rd Qu.:0.000000  \n Max.   :1.00000   Max.   :1.00000   Max.   :1.000000   Max.   :1.000000  \n                                                                          \n     FGCRP             FHINS1P          FHINS2P          FHINS3C       \n Min.   :0.000000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0      \n 1st Qu.:0.000000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0      \n Median :0.000000   Median :0.0000   Median :0.0000   Median :0.0      \n Mean   :0.003639   Mean   :0.1018   Mean   :0.1111   Mean   :0.1      \n 3rd Qu.:0.000000   3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.:0.0      \n Max.   :1.000000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0      \n                                                      NA's   :1299053  \n    FHINS3P           FHINS4C           FHINS4P          FHINS5C       \n Min.   :0.00000   Min.   :0.0       Min.   :0.0000   Min.   :0        \n 1st Qu.:0.00000   1st Qu.:0.0       1st Qu.:0.0000   1st Qu.:0        \n Median :0.00000   Median :0.0       Median :0.0000   Median :0        \n Mean   :0.08933   Mean   :0.1       Mean   :0.1216   Mean   :0        \n 3rd Qu.:0.00000   3rd Qu.:0.0       3rd Qu.:0.0000   3rd Qu.:0        \n Max.   :1.00000   Max.   :1.0       Max.   :1.0000   Max.   :1        \n                   NA's   :1326192                    NA's   :1563658  \n    FHINS5P          FHINS6P          FHINS7P           FHISP        \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.00000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.00000  \n Median :0.0000   Median :0.0000   Median :0.0000   Median :0.00000  \n Mean   :0.1258   Mean   :0.1247   Mean   :0.1308   Mean   :0.02567  \n 3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.:0.00000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.00000  \n                                                                     \n     FINDP             FINTP           FJWDP             FJWMNP       \n Min.   :0.00000   Min.   :0.000   Min.   :0.00000   Min.   :0.00000  \n 1st Qu.:0.00000   1st Qu.:0.000   1st Qu.:0.00000   1st Qu.:0.00000  \n Median :0.00000   Median :0.000   Median :0.00000   Median :0.00000  \n Mean   :0.07119   Mean   :0.109   Mean   :0.07863   Mean   :0.05503  \n 3rd Qu.:0.00000   3rd Qu.:0.000   3rd Qu.:0.00000   3rd Qu.:0.00000  \n Max.   :1.00000   Max.   :1.000   Max.   :1.00000   Max.   :1.00000  \n                                                                      \n     FJWRIP            FJWTRP            FLANP             FLANXP       \n Min.   :0.00000   Min.   :0.00000   Min.   :0.00000   Min.   :0.00000  \n 1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.00000  \n Median :0.00000   Median :0.00000   Median :0.00000   Median :0.00000  \n Mean   :0.04005   Mean   :0.04065   Mean   :0.01637   Mean   :0.06223  \n 3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.00000  \n Max.   :1.00000   Max.   :1.00000   Max.   :1.00000   Max.   :1.00000  \n                                                                        \n    FMARHDP          FMARHMP          FMARHTP          FMARHWP       \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.00000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.00000  \n Median :0.0000   Median :0.0000   Median :0.0000   Median :0.00000  \n Mean   :0.0436   Mean   :0.0381   Mean   :0.0464   Mean   :0.04388  \n 3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.:0.00000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.00000  \n                                                                     \n    FMARHYP            FMARP             FMIGP            FMIGSP       \n Min.   :0.00000   Min.   :0.00000   Min.   :0.0000   Min.   :0.00000  \n 1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.00000  \n Median :0.00000   Median :0.00000   Median :0.0000   Median :0.00000  \n Mean   :0.07043   Mean   :0.04516   Mean   :0.0734   Mean   :0.01839  \n 3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.0000   3rd Qu.:0.00000  \n Max.   :1.00000   Max.   :1.00000   Max.   :1.0000   Max.   :1.00000  \n                                                                       \n     FMILPP             FMILSP            FOCCP              FOIP        \n Min.   :0.000000   Min.   :0.00000   Min.   :0.00000   Min.   :0.00000  \n 1st Qu.:0.000000   1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.00000  \n Median :0.000000   Median :0.00000   Median :0.00000   Median :0.00000  \n Mean   :0.006952   Mean   :0.05872   Mean   :0.07313   Mean   :0.09377  \n 3rd Qu.:0.000000   3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.00000  \n Max.   :1.000000   Max.   :1.00000   Max.   :1.00000   Max.   :1.00000  \n                                                                         \n      FPAP            FPERNP           FPINCP           FPOBP        \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.00000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.00000  \n Median :0.0000   Median :0.0000   Median :0.0000   Median :0.00000  \n Mean   :0.0919   Mean   :0.1476   Mean   :0.1964   Mean   :0.09454  \n 3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.:0.00000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.00000  \n                                                                     \n     FPOWSP          FPRIVCOVP         FPUBCOVP          FRACP        \n Min.   :0.00000   Min.   :0.0000   Min.   :0.0000   Min.   :0.00000  \n 1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.00000  \n Median :0.00000   Median :0.0000   Median :0.0000   Median :0.00000  \n Mean   :0.04919   Mean   :0.1363   Mean   :0.1382   Mean   :0.01852  \n 3rd Qu.:0.00000   3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.:0.00000  \n Max.   :1.00000   Max.   :1.0000   Max.   :1.0000   Max.   :1.00000  \n                                                                      \n     FRELP             FRETP             FSCHGP            FSCHLP      \n Min.   :0.00000   Min.   :0.00000   Min.   :0.00000   Min.   :0.0000  \n 1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.0000  \n Median :0.00000   Median :0.00000   Median :0.00000   Median :0.0000  \n Mean   :0.01029   Mean   :0.09726   Mean   :0.02562   Mean   :0.0822  \n 3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.0000  \n Max.   :1.00000   Max.   :1.00000   Max.   :1.00000   Max.   :1.0000  \n                                                                       \n     FSCHP             FSEMP            FSEXP               FSSIP        \n Min.   :0.00000   Min.   :0.0000   Min.   :0.0000000   Min.   :0.00000  \n 1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.0000000   1st Qu.:0.00000  \n Median :0.00000   Median :0.0000   Median :0.0000000   Median :0.00000  \n Mean   :0.06372   Mean   :0.0821   Mean   :0.0006203   Mean   :0.09111  \n 3rd Qu.:0.00000   3rd Qu.:0.0000   3rd Qu.:0.0000000   3rd Qu.:0.00000  \n Max.   :1.00000   Max.   :1.0000   Max.   :1.0000000   Max.   :1.00000  \n                                                                         \n      FSSP            FWAGP            FWKHP             FWKLP        \n Min.   :0.0000   Min.   :0.0000   Min.   :0.00000   Min.   :0.00000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.00000  \n Median :0.0000   Median :0.0000   Median :0.00000   Median :0.00000  \n Mean   :0.1075   Mean   :0.1423   Mean   :0.05616   Mean   :0.08091  \n 3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.:0.00000   3rd Qu.:0.00000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.00000   Max.   :1.00000  \n                                                                      \n     FWKWP             FWRKP              FYOEP            pwgtp1      \n Min.   :0.00000   Min.   :0.000000   Min.   :0.0000   Min.   : -38.0  \n 1st Qu.:0.00000   1st Qu.:0.000000   1st Qu.:0.0000   1st Qu.:  34.0  \n Median :0.00000   Median :0.000000   Median :0.0000   Median :  73.0  \n Mean   :0.05191   Mean   :0.001824   Mean   :0.0186   Mean   : 101.1  \n 3rd Qu.:0.00000   3rd Qu.:0.000000   3rd Qu.:0.0000   3rd Qu.: 129.0  \n Max.   :1.00000   Max.   :1.000000   Max.   :1.0000   Max.   :2514.0  \n                                                                       \n     pwgtp2           pwgtp3           pwgtp4           pwgtp5      \n Min.   :  -8.0   Min.   : -46.0   Min.   : -96.0   Min.   :-257.0  \n 1st Qu.:  34.0   1st Qu.:  34.0   1st Qu.:  34.0   1st Qu.:  34.0  \n Median :  73.0   Median :  73.0   Median :  73.0   Median :  73.0  \n Mean   : 101.1   Mean   : 101.1   Mean   : 101.1   Mean   : 101.1  \n 3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 129.0  \n Max.   :2420.0   Max.   :2366.0   Max.   :3026.0   Max.   :2024.0  \n                                                                    \n     pwgtp6           pwgtp7           pwgtp8           pwgtp9      \n Min.   : -20.0   Min.   : -74.0   Min.   : -49.0   Min.   : -95.0  \n 1st Qu.:  34.0   1st Qu.:  35.0   1st Qu.:  34.0   1st Qu.:  33.0  \n Median :  73.0   Median :  73.0   Median :  73.0   Median :  72.0  \n Mean   : 101.1   Mean   : 101.1   Mean   : 101.1   Mean   : 101.1  \n 3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 129.0  \n Max.   :2148.0   Max.   :2468.0   Max.   :3107.0   Max.   :3101.0  \n                                                                    \n    pwgtp10          pwgtp11          pwgtp12          pwgtp13      \n Min.   :-112.0   Min.   : -18.0   Min.   :  -4.0   Min.   : -40.0  \n 1st Qu.:  33.0   1st Qu.:  34.0   1st Qu.:  35.0   1st Qu.:  36.0  \n Median :  72.0   Median :  73.0   Median :  73.0   Median :  74.0  \n Mean   : 101.1   Mean   : 101.1   Mean   : 101.1   Mean   : 101.1  \n 3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 128.0  \n Max.   :2987.0   Max.   :2372.0   Max.   :2854.0   Max.   :2349.0  \n                                                                    \n    pwgtp14          pwgtp15          pwgtp16          pwgtp17      \n Min.   : -49.0   Min.   :   0.0   Min.   : -23.0   Min.   :-248.0  \n 1st Qu.:  35.0   1st Qu.:  36.0   1st Qu.:  35.0   1st Qu.:  35.0  \n Median :  73.0   Median :  74.0   Median :  73.0   Median :  73.0  \n Mean   : 101.1   Mean   : 101.1   Mean   : 101.1   Mean   : 101.1  \n 3rd Qu.: 129.0   3rd Qu.: 128.0   3rd Qu.: 128.0   3rd Qu.: 128.0  \n Max.   :3003.0   Max.   :2838.0   Max.   :2471.0   Max.   :2502.0  \n                                                                    \n    pwgtp18          pwgtp19          pwgtp20          pwgtp21      \n Min.   :-107.0   Min.   : -45.0   Min.   :-132.0   Min.   :   0.0  \n 1st Qu.:  35.0   1st Qu.:  37.0   1st Qu.:  34.0   1st Qu.:  36.0  \n Median :  73.0   Median :  74.0   Median :  73.0   Median :  73.0  \n Mean   : 101.1   Mean   : 101.1   Mean   : 101.1   Mean   : 101.1  \n 3rd Qu.: 129.0   3rd Qu.: 128.0   3rd Qu.: 129.0   3rd Qu.: 128.0  \n Max.   :2462.0   Max.   :2198.0   Max.   :3075.0   Max.   :2967.0  \n                                                                    \n    pwgtp22          pwgtp23          pwgtp24          pwgtp25      \n Min.   : -90.0   Min.   :-244.0   Min.   : -73.0   Min.   : -33.0  \n 1st Qu.:  35.0   1st Qu.:  35.0   1st Qu.:  34.0   1st Qu.:  35.0  \n Median :  73.0   Median :  73.0   Median :  73.0   Median :  73.0  \n Mean   : 101.1   Mean   : 101.1   Mean   : 101.1   Mean   : 101.1  \n 3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 129.0  \n Max.   :2782.0   Max.   :2258.0   Max.   :2640.0   Max.   :2452.0  \n                                                                    \n    pwgtp26          pwgtp27          pwgtp28          pwgtp29      \n Min.   : -71.0   Min.   : -50.0   Min.   : -85.0   Min.   :   0.0  \n 1st Qu.:  34.0   1st Qu.:  34.0   1st Qu.:  34.0   1st Qu.:  34.0  \n Median :  73.0   Median :  73.0   Median :  73.0   Median :  73.0  \n Mean   : 101.1   Mean   : 101.1   Mean   : 101.1   Mean   : 101.1  \n 3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 129.0  \n Max.   :2703.0   Max.   :3022.0   Max.   :2164.0   Max.   :2397.0  \n                                                                    \n    pwgtp30          pwgtp31          pwgtp32          pwgtp33      \n Min.   : -24.0   Min.   :-261.0   Min.   :  -7.0   Min.   : -40.0  \n 1st Qu.:  34.0   1st Qu.:  35.0   1st Qu.:  34.0   1st Qu.:  35.0  \n Median :  73.0   Median :  73.0   Median :  73.0   Median :  73.0  \n Mean   : 101.1   Mean   : 101.1   Mean   : 101.1   Mean   : 101.1  \n 3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 129.0  \n Max.   :2378.0   Max.   :2440.0   Max.   :3069.0   Max.   :2354.0  \n                                                                    \n    pwgtp34          pwgtp35          pwgtp36          pwgtp37      \n Min.   : -17.0   Min.   : -28.0   Min.   :  -5.0   Min.   : -38.0  \n 1st Qu.:  34.0   1st Qu.:  35.0   1st Qu.:  34.0   1st Qu.:  34.0  \n Median :  73.0   Median :  73.0   Median :  73.0   Median :  73.0  \n Mean   : 101.1   Mean   : 101.1   Mean   : 101.1   Mean   : 101.1  \n 3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 129.0  \n Max.   :2810.0   Max.   :2226.0   Max.   :2541.0   Max.   :2794.0  \n                                                                    \n    pwgtp38          pwgtp39          pwgtp40          pwgtp41      \n Min.   :-341.0   Min.   : -52.0   Min.   : -66.0   Min.   :-196.0  \n 1st Qu.:  35.0   1st Qu.:  35.0   1st Qu.:  34.0   1st Qu.:  34.0  \n Median :  73.0   Median :  73.0   Median :  73.0   Median :  73.0  \n Mean   : 101.1   Mean   : 101.1   Mean   : 101.1   Mean   : 101.1  \n 3rd Qu.: 129.0   3rd Qu.: 128.0   3rd Qu.: 129.0   3rd Qu.: 129.0  \n Max.   :2278.0   Max.   :3088.0   Max.   :2486.0   Max.   :2237.0  \n                                                                    \n    pwgtp42          pwgtp43          pwgtp44          pwgtp45      \n Min.   : -12.0   Min.   : -47.0   Min.   : -31.0   Min.   : -27.0  \n 1st Qu.:  34.0   1st Qu.:  34.0   1st Qu.:  34.0   1st Qu.:  34.0  \n Median :  73.0   Median :  73.0   Median :  73.0   Median :  73.0  \n Mean   : 101.1   Mean   : 101.1   Mean   : 101.1   Mean   : 101.1  \n 3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 129.0  \n Max.   :2414.0   Max.   :2551.0   Max.   :3238.0   Max.   :2381.0  \n                                                                    \n    pwgtp46          pwgtp47          pwgtp48          pwgtp49      \n Min.   :   0.0   Min.   :-358.0   Min.   :-293.0   Min.   :-119.0  \n 1st Qu.:  34.0   1st Qu.:  35.0   1st Qu.:  34.0   1st Qu.:  34.0  \n Median :  73.0   Median :  73.0   Median :  73.0   Median :  73.0  \n Mean   : 101.1   Mean   : 101.1   Mean   : 101.1   Mean   : 101.1  \n 3rd Qu.: 129.0   3rd Qu.: 128.0   3rd Qu.: 129.0   3rd Qu.: 129.0  \n Max.   :2782.0   Max.   :2680.0   Max.   :3055.0   Max.   :2930.0  \n                                                                    \n    pwgtp50          pwgtp51          pwgtp52          pwgtp53      \n Min.   : -73.0   Min.   : -22.0   Min.   : -79.0   Min.   : -35.0  \n 1st Qu.:  34.0   1st Qu.:  34.0   1st Qu.:  35.0   1st Qu.:  36.0  \n Median :  73.0   Median :  73.0   Median :  73.0   Median :  73.0  \n Mean   : 101.1   Mean   : 101.1   Mean   : 101.1   Mean   : 101.1  \n 3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 128.0  \n Max.   :2903.0   Max.   :2340.0   Max.   :2428.0   Max.   :2485.0  \n                                                                    \n    pwgtp54          pwgtp55          pwgtp56          pwgtp57      \n Min.   :-202.0   Min.   :  -7.0   Min.   : -21.0   Min.   : -31.0  \n 1st Qu.:  35.0   1st Qu.:  36.0   1st Qu.:  35.0   1st Qu.:  35.0  \n Median :  73.0   Median :  74.0   Median :  73.0   Median :  73.0  \n Mean   : 101.1   Mean   : 101.1   Mean   : 101.1   Mean   : 101.1  \n 3rd Qu.: 128.0   3rd Qu.: 128.0   3rd Qu.: 129.0   3rd Qu.: 129.0  \n Max.   :3061.0   Max.   :2507.0   Max.   :2697.0   Max.   :2467.0  \n                                                                    \n    pwgtp58          pwgtp59          pwgtp60          pwgtp61      \n Min.   :  -3.0   Min.   : -37.0   Min.   :  -5.0   Min.   :   0.0  \n 1st Qu.:  35.0   1st Qu.:  36.0   1st Qu.:  34.0   1st Qu.:  36.0  \n Median :  73.0   Median :  74.0   Median :  73.0   Median :  73.0  \n Mean   : 101.1   Mean   : 101.1   Mean   : 101.1   Mean   : 101.1  \n 3rd Qu.: 129.0   3rd Qu.: 128.0   3rd Qu.: 129.0   3rd Qu.: 128.0  \n Max.   :2441.0   Max.   :2419.0   Max.   :3032.0   Max.   :3263.0  \n                                                                    \n    pwgtp62          pwgtp63          pwgtp64          pwgtp65      \n Min.   : -83.0   Min.   : -49.0   Min.   :-116.0   Min.   : -21.0  \n 1st Qu.:  34.0   1st Qu.:  35.0   1st Qu.:  35.0   1st Qu.:  35.0  \n Median :  73.0   Median :  73.0   Median :  73.0   Median :  73.0  \n Mean   : 101.1   Mean   : 101.1   Mean   : 101.1   Mean   : 101.1  \n 3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 128.0  \n Max.   :2428.0   Max.   :2719.0   Max.   :2468.0   Max.   :2959.0  \n                                                                    \n    pwgtp66          pwgtp67          pwgtp68          pwgtp69      \n Min.   :-163.0   Min.   : -13.0   Min.   :   0.0   Min.   : -19.0  \n 1st Qu.:  34.0   1st Qu.:  34.0   1st Qu.:  34.0   1st Qu.:  34.0  \n Median :  73.0   Median :  73.0   Median :  73.0   Median :  73.0  \n Mean   : 101.1   Mean   : 101.1   Mean   : 101.1   Mean   : 101.1  \n 3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 129.0  \n Max.   :2339.0   Max.   :2935.0   Max.   :2695.0   Max.   :2310.0  \n                                                                    \n    pwgtp70          pwgtp71          pwgtp72          pwgtp73      \n Min.   :  -7.0   Min.   : -20.0   Min.   :-494.0   Min.   : -14.0  \n 1st Qu.:  33.0   1st Qu.:  34.0   1st Qu.:  33.0   1st Qu.:  35.0  \n Median :  72.0   Median :  73.0   Median :  72.0   Median :  73.0  \n Mean   : 101.1   Mean   : 101.1   Mean   : 101.1   Mean   : 101.1  \n 3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 128.0  \n Max.   :2442.0   Max.   :3132.0   Max.   :3020.0   Max.   :2374.0  \n                                                                    \n    pwgtp74          pwgtp75          pwgtp76          pwgtp77      \n Min.   : -93.0   Min.   : -10.0   Min.   :   0.0   Min.   :  -4.0  \n 1st Qu.:  34.0   1st Qu.:  35.0   1st Qu.:  35.0   1st Qu.:  35.0  \n Median :  73.0   Median :  73.0   Median :  73.0   Median :  73.0  \n Mean   : 101.1   Mean   : 101.1   Mean   : 101.1   Mean   : 101.1  \n 3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 129.0   3rd Qu.: 129.0  \n Max.   :2347.0   Max.   :2773.0   Max.   :2499.0   Max.   :2313.0  \n                                                                    \n    pwgtp78          pwgtp79          pwgtp80      \n Min.   : -26.0   Min.   :   0.0   Min.   : -22.0  \n 1st Qu.:  35.0   1st Qu.:  36.0   1st Qu.:  33.0  \n Median :  73.0   Median :  73.0   Median :  72.0  \n Mean   : 101.1   Mean   : 101.1   Mean   : 101.1  \n 3rd Qu.: 129.0   3rd Qu.: 128.0   3rd Qu.: 129.0  \n Max.   :2795.0   Max.   :2959.0   Max.   :3018.0  \n                                                   \n\n\nCode\nnrow(pop)\n\n\n[1] 1613672\n\n\nCode\nncol(pop)\n\n\n[1] 283\n\n\nCode\nglimpse(pop)\n\n\nRows: 1,613,672\nColumns: 283\n$ RT        <chr> \"P\", \"P\", \"P\", \"P\", \"P\", \"P\", \"P\", \"P\", \"P\", \"P\", \"P\", \"P\", …\n$ SERIALNO  <int> 84, 154, 154, 154, 154, 156, 160, 160, 160, 231, 286, 312, 3…\n$ SPORDER   <int> 1, 1, 2, 3, 4, 1, 1, 2, 3, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, …\n$ PUMA      <int> 2600, 2500, 2500, 2500, 2500, 1700, 2200, 2200, 2200, 2400, …\n$ ST        <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ ADJINC    <int> 1007549, 1007549, 1007549, 1007549, 1007549, 1007549, 100754…\n$ PWGTP     <int> 65, 51, 62, 232, 97, 449, 16, 30, 7, 52, 77, 46, 33, 37, 42,…\n$ AGEP      <int> 19, 55, 56, 21, 21, 63, 61, 20, 12, 78, 81, 59, 56, 70, 71, …\n$ CIT       <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 1, 1, 1, 1, 1, …\n$ CITWP     <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1996, 19…\n$ COW       <int> NA, 1, 6, NA, NA, 3, NA, 1, NA, 2, NA, 1, 1, NA, NA, NA, 4, …\n$ DDRS      <int> 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ DEAR      <int> 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ DEYE      <int> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ DOUT      <int> 2, 2, 2, 2, 1, 2, 1, 2, NA, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,…\n$ DPHY      <int> 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ DRAT      <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ DRATX     <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ DREM      <int> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ ENG       <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ FER       <int> 2, NA, NA, NA, 2, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ GCL       <int> NA, 2, 2, NA, NA, 2, 1, NA, NA, 2, 2, 2, 2, 2, 2, 2, 2, 2, N…\n$ GCM       <int> NA, NA, NA, NA, NA, NA, 5, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ GCR       <int> NA, NA, NA, NA, NA, NA, 1, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ HINS1     <int> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, …\n$ HINS2     <int> 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, …\n$ HINS3     <int> 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, …\n$ HINS4     <int> 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ HINS5     <int> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ HINS6     <int> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ HINS7     <int> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ INTP      <int> 0, 0, 0, 0, 0, 0, 0, 0, NA, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ JWMNP     <int> NA, 30, NA, NA, NA, 15, NA, NA, NA, NA, NA, 10, 45, NA, NA, …\n$ JWRIP     <int> NA, 1, NA, NA, NA, 1, NA, NA, NA, NA, NA, 2, 2, NA, NA, NA, …\n$ JWTR      <int> NA, 1, 11, NA, NA, 1, NA, NA, NA, NA, NA, 1, 1, NA, NA, NA, …\n$ LANX      <int> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ MAR       <int> 5, 1, 1, 5, 5, 3, 4, 5, 5, 2, 2, 1, 1, 1, 1, 5, 1, 1, 5, 1, …\n$ MARHD     <int> NA, 2, 2, NA, NA, 2, 2, NA, NA, 2, 2, 2, 2, 2, 2, NA, 2, 2, …\n$ MARHM     <int> NA, 2, 2, NA, NA, 2, 2, NA, NA, 2, 2, 2, 2, 2, 2, NA, 2, 2, …\n$ MARHT     <int> NA, 1, 1, NA, NA, 1, 2, NA, NA, 2, 1, 2, 2, 1, 1, NA, 2, 2, …\n$ MARHW     <int> NA, 2, 2, NA, NA, 2, 2, NA, NA, 2, 2, 2, 2, 2, 2, NA, 2, 2, …\n$ MARHYP    <int> NA, 1990, 1990, NA, NA, 1972, 1975, NA, NA, 1970, 1950, 1985…\n$ MIG       <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, …\n$ MIL       <int> 4, 4, 4, 4, 4, 4, 4, 4, NA, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,…\n$ MLPA      <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ MLPB      <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ MLPCD     <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ MLPE      <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ MLPFG     <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ MLPH      <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ MLPI      <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ MLPJ      <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ MLPK      <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ NWAB      <int> 2, 3, 3, 2, 2, 3, 2, 2, NA, 2, 3, 2, 3, 2, 2, 2, 3, 3, 2, 2,…\n$ NWAV      <int> 5, 5, 5, 5, 5, 5, 5, 1, NA, 3, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5,…\n$ NWLA      <int> 2, 3, 3, 2, 2, 3, 2, 2, NA, 2, 3, 2, 3, 2, 2, 2, 3, 3, 2, 2,…\n$ NWLK      <int> 2, 3, 3, 2, 2, 3, 2, 1, NA, 2, 3, 2, 3, 2, 2, 2, 3, 3, 2, 2,…\n$ NWRE      <int> 3, 3, 3, 3, 3, 3, 3, 3, NA, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,…\n$ OIP       <int> 0, 0, 0, 0, 0, 0, 0, 0, NA, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ PAP       <int> 0, 0, 0, 0, 0, 0, 0, 0, NA, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ RELP      <int> 17, 0, 1, 2, 2, 0, 0, 7, 7, 0, 0, 0, 1, 0, 1, 0, 0, 1, 17, 0…\n$ RETP      <int> 0, 0, 0, 0, 0, 0, 0, 0, NA, 0, 0, 0, 0, 20900, 4300, 103000,…\n$ SCH       <int> 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, …\n$ SCHG      <int> 15, NA, NA, 15, 15, NA, NA, NA, 9, NA, NA, NA, NA, NA, NA, N…\n$ SCHL      <int> 19, 20, 16, 19, 19, 21, 14, 16, 9, 1, 10, 16, 18, 17, 17, 19…\n$ SEMP      <int> 0, 0, 99000, 0, 0, 0, 0, 0, NA, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ SEX       <int> 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, …\n$ SSIP      <int> 0, 0, 0, 0, 0, 0, 0, 0, NA, 3900, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ SSP       <int> 0, 0, 0, 0, 0, 930, 10300, 0, NA, 0, 5400, 0, 0, 18600, 8800…\n$ WAGP      <int> 0, 52000, 0, 0, 0, 39000, 0, 1100, NA, 0, 0, 90000, 46000, 0…\n$ WKHP      <int> NA, 40, 40, NA, NA, 40, NA, 15, NA, NA, NA, 48, 40, NA, NA, …\n$ WKL       <int> 3, 1, 1, 3, 3, 1, 3, 1, NA, 2, 3, 1, 1, 3, 3, 3, 1, 1, 1, 3,…\n$ WKW       <int> NA, 1, 1, NA, NA, 1, NA, 6, NA, NA, NA, 1, 1, NA, NA, NA, 1,…\n$ WRK       <int> 2, 1, 1, 2, 2, 1, 2, 2, NA, 2, NA, 1, 1, 2, 2, 2, 1, 1, 1, 2…\n$ YOEP      <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1973, 19…\n$ ANC       <int> 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 2, …\n$ ANC1P     <int> 999, 902, 902, 902, 902, 902, 917, 917, 917, 902, 999, 924, …\n$ ANC2P     <int> 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, …\n$ DECADE    <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 4, 4, NA…\n$ DIS       <int> 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ DRIVESP   <int> NA, 1, NA, NA, NA, 1, NA, NA, NA, NA, NA, 2, 2, NA, NA, NA, …\n$ ESP       <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ ESR       <int> 6, 1, 1, 6, 6, 1, 6, 3, NA, 6, 6, 1, 1, 6, 6, 6, 1, 1, 1, 6,…\n$ FOD1P     <int> NA, NA, NA, NA, NA, 6107, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ FOD2P     <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ HICOV     <int> 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ HISP      <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ INDP      <int> NA, 5380, 8880, NA, NA, 7860, NA, 770, NA, 1880, NA, 6380, 7…\n$ JWAP      <int> NA, 100, NA, NA, NA, 109, NA, NA, NA, NA, NA, 72, 79, NA, NA…\n$ JWDP      <int> NA, 55, NA, NA, NA, 67, NA, NA, NA, NA, NA, 31, 31, NA, NA, …\n$ LANP      <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ MIGPUMA   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ MIGSP     <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ MSP       <int> 6, 1, 1, 6, 6, 4, 5, 6, NA, 3, 3, 1, 1, 1, 1, 6, 1, 1, 6, 1,…\n$ NAICSP    <chr> \"\", \"45211\", \"8114\", \"\", \"\", \"6111\", \"\", \"23\", \"\", \"32221\", …\n$ NATIVITY  <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, …\n$ NOP       <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ OC        <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ OCCP      <int> NA, 4700, 7240, NA, NA, 2310, NA, 6260, NA, 8740, NA, 5510, …\n$ PAOC      <int> NA, 4, NA, NA, 4, 4, 4, NA, NA, 4, 4, NA, 4, NA, 4, 4, NA, 4…\n$ PERNP     <int> 0, 52000, 99000, 0, 0, 39000, 0, 1100, NA, 0, 0, 90000, 4600…\n$ PINCP     <int> 0, 52000, 99000, 0, 0, 39930, 10300, 1100, NA, 3900, 5400, 9…\n$ POBP      <int> 28, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 47, 21, 139, 139, 1, 1, 17…\n$ POVPIP    <int> NA, 501, 501, 501, 501, 330, 61, 61, 61, 35, 48, 501, 501, 3…\n$ POWPUMA   <int> NA, 2500, 2500, NA, NA, 1700, NA, NA, NA, NA, NA, 1300, 1300…\n$ POWSP     <int> NA, 1, 1, NA, NA, 1, NA, NA, NA, NA, NA, 1, 1, NA, NA, NA, 1…\n$ PRIVCOV   <int> 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, …\n$ PUBCOV    <int> 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, …\n$ QTRBIR    <int> 1, 1, 4, 4, 4, 3, 1, 4, 3, 1, 4, 2, 3, 2, 2, 4, 1, 2, 3, 4, …\n$ RAC1P     <int> 1, 2, 2, 2, 2, 2, 3, 3, 3, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, …\n$ RAC2P     <int> 1, 2, 2, 2, 2, 2, 9, 9, 9, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, …\n$ RAC3P     <int> 1, 2, 2, 2, 2, 2, 3, 3, 3, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, …\n$ RACAIAN   <int> 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ RACASN    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ RACBLK    <int> 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, …\n$ RACNH     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ RACNUM    <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ RACPI     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ RACSOR    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ RACWHT    <int> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, …\n$ RC        <int> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ SCIENGP   <int> NA, NA, NA, NA, NA, 2, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ SCIENGRLP <int> NA, NA, NA, NA, NA, 1, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ SFN       <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ SFR       <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ SOCP      <chr> \"\", \"411011\", \"493050\", \"\", \"\", \"252020\", \"\", \"472061\", \"\", …\n$ VPS       <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ WAOB      <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 1, 1, 1, 1, 1, …\n$ FAGEP     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FANCP     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FCITP     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FCITWP    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FCOWP     <int> 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FDDRSP    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FDEARP    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FDEYEP    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FDISP     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FDOUTP    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FDPHYP    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FDRATP    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FDRATXP   <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FDREMP    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FENGP     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FESRP     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FFERP     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FFODP     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FGCLP     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FGCMP     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FGCRP     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FHINS1P   <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FHINS2P   <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, …\n$ FHINS3C   <int> NA, NA, NA, NA, NA, NA, 0, NA, NA, 0, 0, NA, NA, 0, 0, 0, 0,…\n$ FHINS3P   <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FHINS4C   <int> NA, NA, NA, NA, NA, NA, NA, NA, 0, 1, NA, NA, NA, NA, NA, NA…\n$ FHINS4P   <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, …\n$ FHINS5C   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ FHINS5P   <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, …\n$ FHINS6P   <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, …\n$ FHINS7P   <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, …\n$ FHISP     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FINDP     <int> 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FINTP     <int> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FJWDP     <int> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, …\n$ FJWMNP    <int> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, …\n$ FJWRIP    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, …\n$ FJWTRP    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, …\n$ FLANP     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FLANXP    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FMARHDP   <int> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FMARHMP   <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FMARHTP   <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FMARHWP   <int> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FMARHYP   <int> 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FMARP     <int> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FMIGP     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FMIGSP    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FMILPP    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FMILSP    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FOCCP     <int> 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FOIP      <int> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FPAP      <int> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FPERNP    <int> 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ FPINCP    <int> 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ FPOBP     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FPOWSP    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, …\n$ FPRIVCOVP <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, …\n$ FPUBCOVP  <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, …\n$ FRACP     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, …\n$ FRELP     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FRETP     <int> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FSCHGP    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FSCHLP    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FSCHP     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FSEMP     <int> 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FSEXP     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FSSIP     <int> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FSSP      <int> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FWAGP     <int> 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ FWKHP     <int> 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FWKLP     <int> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FWKWP     <int> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FWRKP     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FYOEP     <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ pwgtp1    <int> 5, 45, 66, 244, 106, 481, 21, 37, 8, 74, 84, 83, 69, 10, 9, …\n$ pwgtp2    <int> 127, 51, 67, 211, 97, 575, 15, 29, 5, 49, 69, 58, 49, 13, 13…\n$ pwgtp3    <int> 65, 53, 60, 224, 87, 807, 6, 10, 2, 44, 20, 16, 12, 34, 44, …\n$ pwgtp4    <int> 66, 50, 66, 187, 92, 739, 20, 37, 8, 13, 119, 79, 63, 65, 80…\n$ pwgtp5    <int> 69, 100, 108, 368, 162, 153, 29, 69, 20, 13, 91, 13, 9, 15, …\n$ pwgtp6    <int> 5, 79, 106, 324, 146, 173, 16, 27, 7, 102, 78, 43, 29, 86, 8…\n$ pwgtp7    <int> 120, 78, 102, 335, 184, 722, 5, 7, 1, 80, 20, 48, 40, 34, 41…\n$ pwgtp8    <int> 66, 50, 63, 239, 110, 455, 24, 21, 11, 20, 76, 49, 39, 32, 3…\n$ pwgtp9    <int> 63, 19, 21, 63, 30, 158, 4, 12, 1, 59, 73, 52, 40, 45, 43, 8…\n$ pwgtp10   <int> 5, 57, 72, 321, 99, 671, 27, 56, 19, 97, 180, 37, 29, 41, 42…\n$ pwgtp11   <int> 67, 89, 107, 299, 127, 681, 10, 27, 4, 17, 68, 42, 31, 38, 3…\n$ pwgtp12   <int> 6, 46, 53, 211, 90, 469, 27, 36, 8, 18, 79, 62, 50, 38, 35, …\n$ pwgtp13   <int> 5, 67, 74, 209, 110, 402, 14, 34, 6, 52, 24, 15, 10, 11, 14,…\n$ pwgtp14   <int> 137, 109, 133, 412, 177, 118, 15, 42, 5, 44, 131, 48, 40, 58…\n$ pwgtp15   <int> 124, 50, 61, 230, 113, 339, 27, 47, 8, 96, 136, 48, 33, 32, …\n$ pwgtp16   <int> 65, 18, 19, 63, 29, 436, 41, 77, 17, 56, 73, 13, 10, 30, 28,…\n$ pwgtp17   <int> 66, 17, 22, 93, 29, 443, 32, 62, 14, 46, 142, 12, 10, 66, 62…\n$ pwgtp18   <int> 64, 18, 17, 75, 26, 393, 4, 7, 1, 75, 82, 43, 33, 73, 86, 12…\n$ pwgtp19   <int> 63, 46, 54, 279, 95, 161, 17, 21, 5, 47, 26, 68, 51, 33, 39,…\n$ pwgtp20   <int> 6, 88, 102, 308, 187, 411, 20, 38, 10, 54, 67, 42, 29, 38, 4…\n$ pwgtp21   <int> 131, 49, 57, 206, 102, 467, 8, 20, 4, 16, 21, 51, 38, 31, 40…\n$ pwgtp22   <int> 6, 50, 55, 309, 110, 387, 25, 37, 8, 42, 27, 12, 11, 31, 34,…\n$ pwgtp23   <int> 62, 49, 54, 230, 78, 127, 39, 80, 17, 57, 63, 45, 36, 51, 62…\n$ pwgtp24   <int> 63, 65, 69, 281, 107, 150, 32, 72, 11, 122, 74, 54, 38, 25, …\n$ pwgtp25   <int> 60, 13, 19, 66, 29, 553, 39, 53, 17, 93, 24, 44, 27, 36, 36,…\n$ pwgtp26   <int> 126, 16, 18, 76, 31, 514, 9, 12, 2, 17, 119, 11, 8, 40, 51, …\n$ pwgtp27   <int> 6, 16, 20, 128, 35, 133, 15, 50, 6, 14, 86, 80, 60, 66, 64, …\n$ pwgtp28   <int> 66, 54, 69, 300, 109, 613, 7, 14, 4, 61, 126, 92, 62, 12, 13…\n$ pwgtp29   <int> 68, 85, 101, 421, 145, 562, 19, 30, 7, 58, 131, 82, 56, 9, 1…\n$ pwgtp30   <int> 120, 48, 66, 167, 114, 151, 22, 49, 13, 23, 67, 85, 56, 12, …\n$ pwgtp31   <int> 66, 14, 20, 68, 29, 196, 5, 5, 1, 83, 130, 13, 12, 11, 17, 3…\n$ pwgtp32   <int> 126, 49, 60, 296, 99, 431, 16, 19, 4, 69, 29, 48, 33, 61, 11…\n$ pwgtp33   <int> 115, 50, 58, 221, 83, 576, 4, 11, 2, 49, 78, 52, 35, 34, 39,…\n$ pwgtp34   <int> 5, 11, 17, 71, 37, 710, 27, 43, 10, 55, 80, 87, 61, 36, 39, …\n$ pwgtp35   <int> 5, 56, 58, 264, 101, 378, 21, 34, 8, 20, 71, 14, 10, 11, 13,…\n$ pwgtp36   <int> 63, 83, 107, 393, 154, 481, 33, 47, 12, 59, 20, 45, 30, 55, …\n$ pwgtp37   <int> 66, 71, 91, 294, 155, 504, 14, 31, 5, 62, 93, 51, 34, 33, 48…\n$ pwgtp38   <int> 66, 108, 114, 305, 132, 530, 11, 23, 3, 43, 119, 14, 9, 41, …\n$ pwgtp39   <int> 62, 54, 64, 193, 109, 760, 6, 13, 2, 38, 66, 45, 30, 76, 95,…\n$ pwgtp40   <int> 5, 81, 104, 372, 161, 409, 31, 62, 13, 40, 23, 83, 59, 12, 1…\n$ pwgtp41   <int> 118, 43, 70, 274, 115, 560, 10, 18, 4, 16, 84, 66, 46, 10, 1…\n$ pwgtp42   <int> 6, 52, 66, 222, 114, 403, 20, 33, 11, 47, 82, 45, 28, 9, 11,…\n$ pwgtp43   <int> 64, 50, 58, 261, 83, 638, 22, 43, 8, 40, 23, 11, 8, 36, 34, …\n$ pwgtp44   <int> 66, 63, 72, 236, 125, 516, 11, 27, 4, 108, 112, 84, 59, 54, …\n$ pwgtp45   <int> 62, 17, 19, 110, 32, 100, 9, 14, 3, 88, 69, 13, 11, 11, 11, …\n$ pwgtp46   <int> 124, 15, 16, 65, 22, 150, 23, 49, 8, 15, 73, 43, 32, 82, 84,…\n$ pwgtp47   <int> 6, 15, 21, 63, 39, 660, 27, 63, 9, 14, 22, 42, 30, 47, 44, 9…\n$ pwgtp48   <int> 63, 47, 68, 235, 107, 454, 16, 37, 5, 86, 86, 55, 34, 40, 50…\n$ pwgtp49   <int> 68, 88, 111, 343, 133, 179, 29, 39, 12, 59, 69, 53, 35, 35, …\n$ pwgtp50   <int> 132, 47, 58, 246, 129, 793, 6, 7, 1, 16, 124, 42, 32, 31, 46…\n$ pwgtp51   <int> 62, 13, 19, 77, 32, 723, 28, 47, 17, 92, 92, 42, 31, 31, 37,…\n$ pwgtp52   <int> 119, 51, 59, 197, 98, 450, 10, 18, 4, 112, 74, 99, 71, 31, 3…\n$ pwgtp53   <int> 126, 52, 57, 228, 93, 528, 17, 28, 4, 60, 29, 14, 7, 10, 10,…\n$ pwgtp54   <int> 6, 20, 18, 73, 40, 168, 12, 21, 5, 64, 138, 49, 30, 59, 70, …\n$ pwgtp55   <int> 5, 53, 63, 228, 93, 355, 24, 29, 6, 13, 99, 46, 35, 42, 52, …\n$ pwgtp56   <int> 68, 84, 97, 339, 145, 445, 3, 10, 3, 73, 69, 13, 12, 36, 50,…\n$ pwgtp57   <int> 72, 78, 87, 349, 150, 465, 5, 11, 2, 48, 121, 14, 9, 60, 77,…\n$ pwgtp58   <int> 65, 75, 93, 359, 126, 426, 38, 86, 24, 43, 87, 42, 28, 66, 5…\n$ pwgtp59   <int> 66, 53, 68, 262, 129, 228, 14, 37, 5, 53, 23, 84, 66, 34, 39…\n$ pwgtp60   <int> 125, 15, 19, 68, 38, 575, 17, 58, 6, 51, 67, 47, 39, 34, 31,…\n$ pwgtp61   <int> 5, 55, 59, 193, 102, 386, 32, 57, 12, 83, 18, 46, 35, 44, 37…\n$ pwgtp62   <int> 123, 55, 71, 283, 106, 433, 8, 14, 4, 48, 24, 13, 10, 47, 50…\n$ pwgtp63   <int> 62, 58, 65, 230, 95, 166, 10, 13, 4, 51, 77, 43, 31, 61, 68,…\n$ pwgtp64   <int> 64, 65, 73, 230, 120, 230, 7, 11, 2, 16, 62, 43, 36, 39, 43,…\n$ pwgtp65   <int> 65, 110, 126, 313, 141, 797, 7, 10, 2, 15, 28, 46, 39, 34, 3…\n$ pwgtp66   <int> 6, 82, 94, 355, 131, 571, 21, 37, 8, 92, 125, 13, 11, 30, 40…\n$ pwgtp67   <int> 123, 90, 102, 441, 174, 155, 22, 27, 7, 95, 72, 68, 49, 52, …\n$ pwgtp68   <int> 65, 50, 61, 278, 104, 556, 19, 21, 7, 15, 121, 84, 62, 15, 1…\n$ pwgtp69   <int> 67, 12, 20, 76, 31, 596, 12, 32, 5, 47, 134, 103, 74, 13, 17…\n$ pwgtp70   <int> 6, 55, 60, 151, 123, 170, 11, 21, 4, 106, 100, 86, 75, 10, 1…\n$ pwgtp71   <int> 68, 87, 96, 346, 186, 162, 31, 40, 15, 21, 128, 14, 8, 9, 11…\n$ pwgtp72   <int> 6, 52, 57, 259, 84, 530, 24, 62, 10, 17, 25, 56, 42, 58, 72,…\n$ pwgtp73   <int> 5, 60, 70, 248, 87, 602, 34, 55, 11, 37, 68, 40, 31, 39, 40,…\n$ pwgtp74   <int> 127, 84, 116, 422, 180, 579, 7, 15, 2, 50, 66, 75, 56, 36, 5…\n$ pwgtp75   <int> 119, 50, 60, 284, 88, 341, 7, 8, 3, 103, 80, 13, 9, 9, 10, 9…\n$ pwgtp76   <int> 63, 15, 17, 91, 25, 378, 14, 15, 5, 38, 27, 42, 32, 63, 66, …\n$ pwgtp77   <int> 68, 15, 21, 68, 25, 387, 19, 37, 8, 49, 66, 47, 38, 46, 41, …\n$ pwgtp78   <int> 67, 20, 19, 72, 23, 421, 22, 43, 14, 51, 165, 13, 9, 40, 55,…\n$ pwgtp79   <int> 64, 50, 58, 195, 101, 621, 23, 45, 12, 46, 89, 61, 48, 52, 6…\n$ pwgtp80   <int> 122, 16, 18, 94, 36, 486, 5, 10, 2, 47, 24, 74, 59, 9, 13, 1…\n\n\n\n\nThe data has 1613672 rows and 238 columns. The variables I am interested in are AGEP, SEX, HISP, POBP, RAC1P, SCIENGP, SOCP.\nThe data needs cleaning and rearranging the columns and rows."
  },
  {
    "objectID": "posts/FinalProjectPart1_DonnySnyder.html",
    "href": "posts/FinalProjectPart1_DonnySnyder.html",
    "title": "Final Project Part 1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(dplyr)"
  },
  {
    "objectID": "posts/FinalProjectPart1_DonnySnyder.html#research-question",
    "href": "posts/FinalProjectPart1_DonnySnyder.html#research-question",
    "title": "Final Project Part 1",
    "section": "Research Question",
    "text": "Research Question\nAffective polarization describes a heightened state of animosity between partisans that has steadily grown from the 1970s to today (Iyengar et al., 2019). Identifying antecedents of affective polarization is essential to creating intervention strategies into this negative state of politics. Levendusky (2009) proposes a social model where individuals making sense of simplified elite cues enables people to understand the relevant identities of the political landscape, which may lead to downstream affective polarization. I intend to expand on this model, testing a construct of construal level, or the level of abstraction to concreteness (Trope & Liberman, 2010) with which partisans perceive partisan groups and group cues. Prior studies suggest that lower construal may serve as an antecedent to affective polarization when partisans view issues in more concrete, group terms (Snyder, Unpublished). This study will expand these models into extant, large scale, political science datasets. Additionally, this project will employ supervised machine learning models to qualitatively code a large-n sample of free response questions."
  },
  {
    "objectID": "posts/FinalProjectPart1_DonnySnyder.html#hypotheses",
    "href": "posts/FinalProjectPart1_DonnySnyder.html#hypotheses",
    "title": "Final Project Part 1",
    "section": "Hypotheses",
    "text": "Hypotheses\nI hypothesize that partisans who are qualitatively coded as having a lower construal level will demonstrate higher levels of group/affective polarization, as measured on a feeling thermometer or measures of feelings about political groups - whichever is available in the datasets.\nI hypothesize that using a sentiment analysis, these tendencies may be moderated by valence of their free response, with stronger valence enhancing the effect of construal level on affective polarization."
  },
  {
    "objectID": "posts/FinalProjectPart1_DonnySnyder.html#datasets",
    "href": "posts/FinalProjectPart1_DonnySnyder.html#datasets",
    "title": "Final Project Part 1",
    "section": "Datasets",
    "text": "Datasets\nI intend to use ANES and/or NAES free response data to provide an initial exploratory analysis. I will qualitatively code these data using a novel construal level paradigm (Snyder, unpublished). i will then use this qualitative coding process to train a supervised machine learning algorithm."
  },
  {
    "objectID": "posts/FinalProjectPart1_DonnySnyder.html#references",
    "href": "posts/FinalProjectPart1_DonnySnyder.html#references",
    "title": "Final Project Part 1",
    "section": "References",
    "text": "References\nIyengar, S., Lelkes, Y., Levendusky, M., Malhotra, N., & Westwood, S. J. (2019). The origins and consequences of affective polarization in the United States. Annual Review of Political Science, 22(1), 129-146. Levendusky, M. (2009). The partisan sort: How liberals became Democrats and conservatives became Republicans. University of Chicago Press. Snyder, D. (2022). Keep It Simple Stupid: How Individual Differences in Cue Construal Explain Variations in Affective Polarization. Unpublished Manuscript Trope, Y., & Liberman, N. (2010). Construal-level theory of psychological distance. Psychological review, 117(2), 440."
  },
  {
    "objectID": "posts/FinalProjectProposal_Saaradhaa.html",
    "href": "posts/FinalProjectProposal_Saaradhaa.html",
    "title": "Final Project Proposal",
    "section": "",
    "text": "Prior research literature in the social sciences has continually stressed the need for more research on the Global South. However, few papers actually focus on it. Hence, I am interested to learn more about this region. A data source that lends itself useful for this is the World Values Survey, a global survey with an easily accessible database.\nI am specifically interested in understanding what drives subjective well-being, which can be interpreted via happiness and life satisfaction (Addai et al., 2013).\n\n\n\n\n\n\nResearch Questions\n\n\n\nA. What predicts happiness and life satisfaction in the Global South?\nB. Do predictors of happiness and life satisfaction differ between the Global North and South?\n\n\nThis project will be useful to better understand motivations and desires in the Global South, reduce inter-cultural tensions and enhance cross-cultural cohesion. Governments can also benefit from this research in terms of policy prioritization to maximize citizens’ well-being."
  },
  {
    "objectID": "posts/FinalProjectProposal_Saaradhaa.html#hypothesis",
    "href": "posts/FinalProjectProposal_Saaradhaa.html#hypothesis",
    "title": "Final Project Proposal",
    "section": "Hypothesis",
    "text": "Hypothesis\nPast researchers have studied happiness and life satisfaction in the Global South via the World Values Survey (Addai et al., 2013; Ngamaba, 2016). The studies focused on Ghana and Rwanda respectively. The common predictors of happiness and life satisfaction across both countries were satisfaction with health and income.\nTo the best of my knowledge, few studies comparing well-being in the Global North and South exist. Alba (2019) found that happiness was generally greater in the Global North than the Global South, and indicated that future research should attempt to cover the factors behind this. I think happiness and well-being in the Global North may depend on more subjective measures, given that health and income-related issues should be relatively more accounted for.\nGiven the above, we can frame our hypotheses as follows:\n\n\n\n\n\n\nH0A\n\n\n\nHealth and financial satisfaction will not be statistically significant predictors of happiness and life satisfaction in the Global South.\n\n\n\n\n\n\n\n\nH1A\n\n\n\nHealth and financial satisfaction will be statistically significant predictors of happiness and life satisfaction in the Global South.\n\n\n\n\n\n\n\n\nH0B\n\n\n\nPredictors of happiness and life satisfaction will not differ between the Global North and South.\n\n\n\n\n\n\n\n\nH1B\n\n\n\nPredictors of happiness and life satisfaction will differ between the Global North and South."
  },
  {
    "objectID": "posts/FinalProject_ManiShankerKamarapu.html",
    "href": "posts/FinalProject_ManiShankerKamarapu.html",
    "title": "Final project part 1",
    "section": "",
    "text": "Churning refers to a customer who leaves one company to go to another company. Customer churn introduces not only some loss in income but also other negative effects on the operation of companies. Churn management is the concept of identifying those customers who are intending to move their custom to a competing service provider.\nRisselada et al. (2010) stated that churn management is becoming part of customer relationship management. It is important for companies to consider it as they try to establish long-term relationships with customers and maximize the value of their customer base.\n\n\n\n\n\n\nResearch Questions\n\n\n\nA. Does churn-rate depend on the geographical factors of the customer?\nB. Do non-active members are probable to churn or not?\n\n\nThis project will be useful to better understand more about the customer difficulties and factors and also give us a pretty good idea on the factors effecting the customers to exit and also about the dormant state of the customers."
  },
  {
    "objectID": "posts/FinalProject_ManiShankerKamarapu.html#hypothesis",
    "href": "posts/FinalProject_ManiShankerKamarapu.html#hypothesis",
    "title": "Final project part 1",
    "section": "Hypothesis",
    "text": "Hypothesis\nCustomer churn analysis has become a major concern in almost every industry that offers products and services. The model developed will help banks identify clients who are likely to be churners and develop appropriate marketing actions to retain their valuable clients. And this model also supports information about similar customer group to consider which marketing reactions are to be provided. Thus, due to existing customers are retained, it will provide banks with increased profits and revenues.\nGiven the above, we can frame our hypotheses as follows:\n\n\n\n\n\n\nH0A\n\n\n\nGeographical factors will not be statistically predict the churn-rate.\n\n\n\n\n\n\n\n\nH1A\n\n\n\nGeographical factors will be statistically predict the churn-rate.\n\n\n\n\n\n\n\n\nH0B\n\n\n\nActive members will not churn.\n\n\n\n\n\n\n\n\nH1B\n\n\n\nActive members will churn."
  },
  {
    "objectID": "posts/FinalProject_ManiShankerKamarapu.html#loading-libraries",
    "href": "posts/FinalProject_ManiShankerKamarapu.html#loading-libraries",
    "title": "Final project part 1",
    "section": "Loading libraries",
    "text": "Loading libraries\n\n\nCode\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(stats)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/FinalProject_ManiShankerKamarapu.html#reading-the-data-set",
    "href": "posts/FinalProject_ManiShankerKamarapu.html#reading-the-data-set",
    "title": "Final project part 1",
    "section": "Reading the data set",
    "text": "Reading the data set\n\n\nCode\nChurn <- read_csv(\"~/Desktop/DACSS/603/Churn_Modelling.csv\")\n\n\nError: '~/Desktop/DACSS/603/Churn_Modelling.csv' does not exist.\n\n\nCode\nChurn\n\n\nError in eval(expr, envir, enclos): object 'Churn' not found\n\n\nThis data set includes 10k bank customer data records with 14 attributes including socio-demographic attributes, account level and behavioural attributes.\nAttribute Description 1. Row Number- Number of customers 2. Customer ID- ID of customer 3. Surname- Customer name 4. Credit Score- Score of credit card usage 5. Geography- Location of customer 6. Gender- Customer gender 7. Age- Age of Customer 8. Tenure- The period of having the account in months 9. Balance- Customer main balance 10. NumOfProducts- No of products used by customer 11. HasCrCard- If the customer has a credit card or not 12. IsActiveMember- Customer account is active or not 13. Estimated Salary- Estimated salary of the customer. 14. Exited- Indicate churned or not\n\n\nCode\nstr(Churn)\n\n\nError in str(Churn): object 'Churn' not found"
  },
  {
    "objectID": "posts/FinalProject_ManiShankerKamarapu.html#descriptive-statistics",
    "href": "posts/FinalProject_ManiShankerKamarapu.html#descriptive-statistics",
    "title": "Final project part 1",
    "section": "Descriptive statistics",
    "text": "Descriptive statistics\n\n\nCode\nsummary(Churn)\n\n\nError in summary(Churn): object 'Churn' not found\n\n\n\n\nCode\nglimpse(Churn)\n\n\nError in glimpse(Churn): object 'Churn' not found"
  },
  {
    "objectID": "posts/Final_Project_1.html",
    "href": "posts/Final_Project_1.html",
    "title": "Final_Project_1",
    "section": "",
    "text": "Research Question : examining the relationship between the maximum heart rate one can achieve during exercise and the likelihood of developing heart disease. Using multiple logistic regression, examining handle the confounding effects of age and gender.\nHypothesis Testing : Is there any statistical difference between the gender and age in terms of heart attack prediction.\n#Loading Dataset\n\n\nCode\nlibrary(readr)\nlibrary(tidyverse)\n\n\nWarning: package 'tidyverse' was built under R version 4.1.3\n\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n\n\nv ggplot2 3.3.5     v dplyr   1.0.8\nv tibble  3.1.6     v stringr 1.4.0\nv tidyr   1.2.0     v forcats 0.5.1\nv purrr   0.3.4     \n\n\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\n\nCode\nheart_cleveland_upload <- read_csv(\"heart_cleveland_upload.csv\")\n\n\nRows: 297 Columns: 14\n\n\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\ndbl (14): age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpea...\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nhead(heart_cleveland_upload)\n\n\n\n\n  \n\n\n\n\n\nCode\ndim(heart_cleveland_upload)\n\n\n[1] 297  14\n\n\nData set contains 297 Columns and 14 columns\n\n\nCode\ncolnames(heart_cleveland_upload)\n\n\n [1] \"age\"       \"sex\"       \"cp\"        \"trestbps\"  \"chol\"      \"fbs\"      \n [7] \"restecg\"   \"thalach\"   \"exang\"     \"oldpeak\"   \"slope\"     \"ca\"       \n[13] \"thal\"      \"condition\"\n\n\nhere are 13 attributes\nage: age in years sex: sex (1 = male; 0 = female) cp: chest pain type – Value 0: typical angina – Value 1: atypical angina – Value 2: non-anginal pain – Value 3: asymptomatic trestbps: resting blood pressure (in mm Hg on admission to the hospital) chol: serum cholestoral in mg/dl fbs: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false) restecg: resting electrocardiographic results – Value 0: normal – Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV) – Value 2: showing probable or definite left ventricular hypertrophy by Estes’ criteria thalach: maximum heart rate achieved exang: exercise induced angina (1 = yes; 0 = no) oldpeak = ST depression induced by exercise relative to rest slope: the slope of the peak exercise ST segment – Value 0: upsloping – Value 1: flat – Value 2: downsloping ca: number of major vessels (0-3) colored by flourosopy thal: 0 = normal; 1 = fixed defect; 2 = reversable defect and the label condition: 0 = no disease, 1 = disease\n\nDescriptive statistics\n\n\nCode\nsummary(heart_cleveland_upload)\n\n\n      age             sex               cp           trestbps    \n Min.   :29.00   Min.   :0.0000   Min.   :0.000   Min.   : 94.0  \n 1st Qu.:48.00   1st Qu.:0.0000   1st Qu.:2.000   1st Qu.:120.0  \n Median :56.00   Median :1.0000   Median :2.000   Median :130.0  \n Mean   :54.54   Mean   :0.6768   Mean   :2.158   Mean   :131.7  \n 3rd Qu.:61.00   3rd Qu.:1.0000   3rd Qu.:3.000   3rd Qu.:140.0  \n Max.   :77.00   Max.   :1.0000   Max.   :3.000   Max.   :200.0  \n      chol            fbs            restecg          thalach     \n Min.   :126.0   Min.   :0.0000   Min.   :0.0000   Min.   : 71.0  \n 1st Qu.:211.0   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:133.0  \n Median :243.0   Median :0.0000   Median :1.0000   Median :153.0  \n Mean   :247.4   Mean   :0.1448   Mean   :0.9966   Mean   :149.6  \n 3rd Qu.:276.0   3rd Qu.:0.0000   3rd Qu.:2.0000   3rd Qu.:166.0  \n Max.   :564.0   Max.   :1.0000   Max.   :2.0000   Max.   :202.0  \n     exang           oldpeak          slope              ca        \n Min.   :0.0000   Min.   :0.000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.800   Median :1.0000   Median :0.0000  \n Mean   :0.3266   Mean   :1.056   Mean   :0.6027   Mean   :0.6768  \n 3rd Qu.:1.0000   3rd Qu.:1.600   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :6.200   Max.   :2.0000   Max.   :3.0000  \n      thal         condition     \n Min.   :0.000   Min.   :0.0000  \n 1st Qu.:0.000   1st Qu.:0.0000  \n Median :0.000   Median :0.0000  \n Mean   :0.835   Mean   :0.4613  \n 3rd Qu.:2.000   3rd Qu.:1.0000  \n Max.   :2.000   Max.   :1.0000  \n\n\n\n\nCode\nglimpse(heart_cleveland_upload)\n\n\nRows: 297\nColumns: 14\n$ age       <dbl> 69, 69, 66, 65, 64, 64, 63, 61, 60, 59, 59, 59, 59, 58, 56, ~\n$ sex       <dbl> 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, ~\n$ cp        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~\n$ trestbps  <dbl> 160, 140, 150, 138, 110, 170, 145, 134, 150, 178, 170, 160, ~\n$ chol      <dbl> 234, 239, 226, 282, 211, 227, 233, 234, 240, 270, 288, 273, ~\n$ fbs       <dbl> 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, ~\n$ restecg   <dbl> 2, 0, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 0, 2, ~\n$ thalach   <dbl> 131, 151, 114, 174, 144, 155, 150, 145, 171, 145, 159, 125, ~\n$ exang     <dbl> 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ~\n$ oldpeak   <dbl> 0.1, 1.8, 2.6, 1.4, 1.8, 0.6, 2.3, 2.6, 0.9, 4.2, 0.2, 0.0, ~\n$ slope     <dbl> 1, 0, 2, 1, 1, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, ~\n$ ca        <dbl> 1, 2, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 2, ~\n$ thal      <dbl> 0, 0, 0, 0, 0, 2, 1, 0, 0, 2, 2, 0, 0, 0, 2, 1, 2, 0, 2, 0, ~\n$ condition <dbl> 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, ~"
  },
  {
    "objectID": "posts/Homework 1 LJones.html",
    "href": "posts/Homework 1 LJones.html",
    "title": "Homework 1",
    "section": "",
    "text": "First I’ll load the libraries and read in the data.\n\n\nCode\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(readxl)\nlc <- read_excel(\"_data/LungCapData.xls\")\n\n\n\n\n\n\n\nThe distribution of lung capacity is as follows:\n\n\nCode\nhist(lc$LungCap)\n\n\n\n\n\nThe histogram appears close to the normal distribution.\n\n\n\n\n\nCode\nboxplot(LungCap~Gender, data=lc)\n\n\n\n\n\n\n\n\n\n\nCode\nlc %>%\n  group_by(Smoke) %>%\n  summarize(Mean = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke  Mean\n  <chr> <dbl>\n1 no     7.77\n2 yes    8.65\n\n\nInterestingly, the mean lung capacity is higher for smokers than it is for non-smokers.\n\n\n\n\n\nCode\nlcbyagegrp <- lc %>% \n  mutate(age_group = case_when(\n    Age <=13 ~ \"13 and Under\",\n    Age >=14 & Age <=15 ~\"14-15\",\n    Age >=16 & Age <=17 ~\"16 - 17\",\n    Age >=18 ~\"18+\")) %>% \n  arrange(age_group, Age)\n\nggplot(lcbyagegrp, aes(x = LungCap)) +\n  geom_histogram() +\n  facet_grid(age_group ~ Smoke)\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nCode\nlcbyagegrp %>%\n  group_by(age_group, Smoke) %>%\n  summarize(Mean = mean(LungCap))\n\n\n`summarise()` has grouped output by 'age_group'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 3\n# Groups:   age_group [4]\n  age_group    Smoke  Mean\n  <chr>        <chr> <dbl>\n1 13 and Under no     6.36\n2 13 and Under yes    7.20\n3 14-15        no     9.14\n4 14-15        yes    8.39\n5 16 - 17      no    10.5 \n6 16 - 17      yes    9.38\n7 18+          no    11.1 \n8 18+          yes   10.5 \n\n\n\n\nThe mean lung capacity for smokers aged 13 and under is higher than that of non-smokers in the same age group, which defies expectation. The rest of the age groups meet that expectation. There may be an error or extreme outlier in the data for smokers aged 13 and under.\n\n\n\n\n\n\nCode\nlc %>% cov(Age, LungCap)\n\n\nError in pmatch(use, c(\"all.obs\", \"complete.obs\", \"pairwise.complete.obs\", : object 'LungCap' not found\n\n\n\n\nCode\n#correlation\ncor(lc$LungCap,lc$Age)\n\n\n[1] 0.8196749\n\n\nCode\n#covariance\ncov(lc$LungCap, lc$Age)\n\n\n[1] 8.738289\n\n\nThe correlation is very close to positive 1, indicating a strong positive correlation between between lung capacity and age. The covariance being a positive number indicates a positive relationship.\n\n\n\n\n\n\nCode\nX <- c(0:4)\nFrequency <- c(128, 434, 160, 64, 24)\n\ndf <- data.frame(X, Frequency)\n\ndf\n\n\n  X Frequency\n1 0       128\n2 1       434\n3 2       160\n4 3        64\n5 4        24\n\n\n\n\n\n\nCode\ndf2 <- mutate(df, Probability = Frequency/sum(Frequency))\ndf2\n\n\n  X Frequency Probability\n1 0       128  0.15802469\n2 1       434  0.53580247\n3 2       160  0.19753086\n4 3        64  0.07901235\n5 4        24  0.02962963\n\n\nThe probability is about 19.75%.\n\n\n\n\n\nCode\nb2 <- df2 %>% \n  filter(X < 2)\n\nsum(b2$Probability)\n\n\n[1] 0.6938272\n\n\nThe probability is about 69%.\n\n\n\n\n\nCode\nc2 <- df2 %>% \n  filter(X <= 2)\n\nsum(c2$Probability)\n\n\n[1] 0.891358\n\n\nThe probability is about 89%.\n\n\n\n\n\nCode\nd2 <- df2 %>% \n  filter(X > 2)\n\nsum(d2$Probability)\n\n\n[1] 0.108642\n\n\nThe probability is about 10.9%.\n\n\n\n\n\nCode\ne <- weighted.mean(df2$X, df2$Probability)\ne\n\n\n[1] 1.28642\n\n\nThe expected number of prior convictions is about 1.286.\n\n\n\n\n\nCode\n#variance\nvariance <- (sum(Frequency*((X-e)^2)))/(sum(Frequency)-1)\nvariance\n\n\n[1] 0.8572937\n\n\nCode\n#standard deviation\nsd <- sqrt(variance)\nsd\n\n\n[1] 0.9259016\n\n\nThe variance of prior convictions is about 0.857, and the standard deviation (simply, the square root of the variance) is about 0.926."
  },
  {
    "objectID": "posts/Homework1QH.html",
    "href": "posts/Homework1QH.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readxl)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/Homework1QH.html#a",
    "href": "posts/Homework1QH.html#a",
    "title": "Homework 1",
    "section": "1a",
    "text": "1a\n\n\nCode\nggplot(LungCapData, mapping = aes(LungCap)) +\n  geom_histogram(color = \"black\", fill = \"grey\")+\n  geom_density()+\n  labs(title = \"Distribution of Lung Capacity\", x = \"Lung Capacity\", y = \"Count\")\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nCode\nplot(x = LungCapData$LungCap, y = lungcap_prob_dense)\n\n\n\n\n\nWith these two functions I can see the distribution is normal with both a histogram and regular graph. The second graph more clearly depicts a normal distribution with the probability density points laid throughout. ## 1b\n\n\nCode\nggplot(LungCapData, mapping = aes(x = Gender, y = LungCap)) +\n  geom_boxplot() \n\n\n\n\n\nIt looks like men, on average, have a higher lung capacity than females, but only by a slim margin. Overall, lung capacity is relatively similar among genders. The real comparison will come with smokers and nonsmokers. ## 1c\n\n\nCode\nLungCapData %>% \n  group_by(Smoke) %>% \n  summarise(lung_cap_mean = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke lung_cap_mean\n  <chr>         <dbl>\n1 no             7.77\n2 yes            8.65\n\n\nAbove is the lung capacity mean for smokers and nonsmokers. I’m actually a little surprised the mean lung capacity for nonsmokers is slightly higher than that of nonsmokers. I would think the opposite to be true, but I suspect because there is a range of ages under 18 and the body is not fully developed yet, I imagine a 6 year old nonsmoker will not have the same lung capacity as a 17 year old smoker."
  },
  {
    "objectID": "posts/Homework1QH.html#d",
    "href": "posts/Homework1QH.html#d",
    "title": "Homework 1",
    "section": "1d",
    "text": "1d\nBelow I created a bunch of variables to separate people into certain age groups. I imagine there would be an easier way to separate them.\n\n\nCode\n#LungCapData %>% \n  #group_by(Age) %>% \n  #summarise(lungcap = mean(LungCap))\n  \nage13 <- LungCapData %>% \n  filter(Age <= 13) %>%\n  group_by(Smoke) %>% \n  summarise(lung_cap_mean = mean(LungCap))\n\nage1415 <- LungCapData %>% \n  filter(Age == 14 | Age == 15) %>%\n  group_by(Smoke) %>% \n  summarise(lung_cap_mean = mean(LungCap))\n\nage1617 <- LungCapData %>% \n  filter(Age == 16 | Age == 17) %>%\n  group_by(Smoke) %>% \n  summarise(lung_cap_mean = mean(LungCap))\n\nage18 <- LungCapData %>% \n  filter(Age >= 18) %>%\n  group_by(Smoke) %>% \n  summarise(lung_cap_mean = mean(LungCap))\n\nage13\n\n\n# A tibble: 2 × 2\n  Smoke lung_cap_mean\n  <chr>         <dbl>\n1 no             6.36\n2 yes            7.20\n\n\nCode\nage1415\n\n\n# A tibble: 2 × 2\n  Smoke lung_cap_mean\n  <chr>         <dbl>\n1 no             9.14\n2 yes            8.39\n\n\nCode\nage1617\n\n\n# A tibble: 2 × 2\n  Smoke lung_cap_mean\n  <chr>         <dbl>\n1 no            10.5 \n2 yes            9.38\n\n\nCode\nage18\n\n\n# A tibble: 2 × 2\n  Smoke lung_cap_mean\n  <chr>         <dbl>\n1 no             11.1\n2 yes            10.5"
  },
  {
    "objectID": "posts/Homework1QH.html#e",
    "href": "posts/Homework1QH.html#e",
    "title": "Homework 1",
    "section": "1e",
    "text": "1e\nBased on the variables I created above, it appears the lung capacity for people under 13, and that smoke, is higher than people who do not smoke. As the age brackets increase, so does lung capacity overall, but it begins to show that those who do smoke, generally have a lower lung capacity than those who choose not to smoke. This is what I would expect to happen since a 13 year old still has plenty of growing to do, therefore the lung capacity will be much lower than a grown teenager."
  },
  {
    "objectID": "posts/Homework1QH.html#f",
    "href": "posts/Homework1QH.html#f",
    "title": "Homework 1",
    "section": "1f",
    "text": "1f\n\n\nCode\ncor(LungCapData$LungCap, LungCapData$Age)\n\n\n[1] 0.8196749\n\n\nWith a correlation of 0.81, lung capacity and age have a fairly strong positive relationship. This is what I figured would be the case. As people age, their lung capacities grow larger. A 17 year old will be more developed and most likely have a larger lung capacity than, say, a child the age of 8.\nI created a table of the data frame in question 2\n\n\nCode\nxx <- c(0:4)\n\nfreq <- c(128, 434, 160, 64, 24)\n\ndf <- tibble(xx, freq)"
  },
  {
    "objectID": "posts/Homework1QH.html#a-1",
    "href": "posts/Homework1QH.html#a-1",
    "title": "Homework 1",
    "section": "2a",
    "text": "2a\n\n\nCode\n160/810\n\n\n[1] 0.1975309\n\n\nThe probability of selecting inmates with 2 prior convictions is 19.7%."
  },
  {
    "objectID": "posts/Homework1QH.html#b",
    "href": "posts/Homework1QH.html#b",
    "title": "Homework 1",
    "section": "2b",
    "text": "2b\n\n\nCode\n562/810\n\n\n[1] 0.6938272\n\n\nThe probability of selecting inmates with less than 2 prior convictions is 69%."
  },
  {
    "objectID": "posts/Homework1QH.html#c",
    "href": "posts/Homework1QH.html#c",
    "title": "Homework 1",
    "section": "2c",
    "text": "2c\n\n\nCode\n722/810\n\n\n[1] 0.891358\n\n\nThe probability of selecting inmates with 2 or less prior convictions is 89%."
  },
  {
    "objectID": "posts/Homework1QH.html#d-1",
    "href": "posts/Homework1QH.html#d-1",
    "title": "Homework 1",
    "section": "2d",
    "text": "2d\n\n\nCode\n88/810\n\n\n[1] 0.108642\n\n\nThe probability of selecting inmates with more than 2 prior convictions is 10.8%."
  },
  {
    "objectID": "posts/Homework1QH.html#e-1",
    "href": "posts/Homework1QH.html#e-1",
    "title": "Homework 1",
    "section": "2e",
    "text": "2e\nThe expected value for number of prior convictions is 291.4.\n\n\nCode\ntest <- c(128, 434, 160, 64, 24)\n\ntestprobs <- c(0.15, 0.54, 0.2, 0.08, 0.03)\n\nsum(test*testprobs)\n\n\n[1] 291.4"
  },
  {
    "objectID": "posts/Homework1QH.html#f-1",
    "href": "posts/Homework1QH.html#f-1",
    "title": "Homework 1",
    "section": "2f",
    "text": "2f\nuse rep()\n\n\nCode\nconvictions <- c(rep(0,128), rep(1, 434), rep(2,160), rep(3,64), rep(4,24))\n\nsd(convictions)\n\n\n[1] 0.9259016\n\n\nCode\nvar(convictions)\n\n\n[1] 0.8572937"
  },
  {
    "objectID": "posts/hw1.html",
    "href": "posts/hw1.html",
    "title": "Homework #1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(readxl)\nlibrary (ggplot)\n\n\nError in library(ggplot): there is no package called 'ggplot'\n\n\nCode\nlungcap<- read_excel(\"LungCapData.xls\") \n\n\nError: `path` does not exist: 'LungCapData.xls'\n\n\nCode\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/hw1.html#lungcapdata",
    "href": "posts/hw1.html#lungcapdata",
    "title": "Homework #1",
    "section": "LungCapData",
    "text": "LungCapData\n\n1a. What does the distribution of LungCap look like?\n\n\nCode\nggplot(lungcap, aes(x=LungCap))+ geom_histogram()\n``\nThis is not normally distributed as there are far more observations of lower lung capacity than higher suggesting the distribution is negatively skewed.\n \n### 1b. Compare the probability distribution of the LungCap with respect to Males and Females? \n\n\nError: attempt to use zero-length variable name\n\n\n\n\nCode\nlungcap %>%\ngroup_by(Gender)%>%\nsummarise(mean(LungCap))\n\n\nError in group_by(., Gender): object 'lungcap' not found\n\n\nThe average lung capacity for females is 7.41, lower than the average for males at 8.31.\n\n\n1c. Compare the mean lung capacities for smokers and non-smokers. Does it make sense?\n\n\nCode\nlungcap %>%\ngroup_by(Smoke)%>%\nsummarise(mean(LungCap))\n\n\nError in group_by(., Smoke): object 'lungcap' not found\n\n\nThe mean lung capacity for non-smokers is 7.77, lower than the mean for smokers at 8.65. At first glance, this seems contradictory as one would guess smokers to have a lower lung capacity than non-smokers.The following grid displays non-smokers as having overall higher lung capacity, conflicting with the mean above.\n\n\nCode\nggplot(lungcap, aes(x = LungCap)) +\nfacet_grid(Gender ~ Smoke)+\n  geom_histogram()\n\n\nError in ggplot(lungcap, aes(x = LungCap)): object 'lungcap' not found\n\n\n\n\n1d. Examine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\n\n1e. Compare the lung capacities for smokers and non-smokers within each age group.\nLung capacity for those under age 13 is 6.36 for non-smokers and 7.20 for smokers.\n\n\nCode\nlungcap %>%\n+ filter(Age <= 13)%>%\n+ group_by(Smoke)%>%\n+ summarise(mean(LungCap))\n\nLung capacity for those between the age of 14 to 15\nlungcap%>%\n+ filter(Age=<15 & Age >=14)%>%\n+ group_by(Smoke)%>%\n+ summarise(mean(LungCap))\n\nLung capacity for those between the age of 16 to 17\nlungcap%>%\n+     filter(Age=<17>=16)%>%\n+ group_by(Smoke)%>%\n+ summarise(mean(LungCap))\n\nLung capacity for those 18 and older\nlungcap%>%\n+ filter(Age>=18)%>%\n+ group_by(Smoke)%>%\n+ summarise(mean(LungCap))\n\n\nError: <text>:6:6: unexpected symbol\n5: \n6: Lung capacity\n        ^\n\n\n\n\nIs your answer different from the one in part c? What could possibly be going on here?\n\n\n1f. Calculate the correlation and covariance between Lung Capacity and Age. (use the cov() and cor() functions in R). Interpret results.\n\n\nCode\ncov(lungcap$LungCap, lungcap$Age)\n\n\nError in is.data.frame(y): object 'lungcap' not found\n\n\nCode\ncor(lungcap$LungCap, lungcap$Age)\n\n\nError in is.data.frame(y): object 'lungcap' not found\n\n\nThe covariance between lung capacity and age is 8.74 suggesting a positive relationship in which both variables move in the same direction (i.e. for this data set an increase in lung capacity would suggest an increase in age as well).\nThe correlation between lung capacity and age is 0.82 suggesting a strong positive correlation (0.82 of a potential -1 to +1)."
  },
  {
    "objectID": "posts/hw1.html#inmate-data",
    "href": "posts/hw1.html#inmate-data",
    "title": "Homework #1",
    "section": "Inmate Data",
    "text": "Inmate Data\n\n\nCode\nx<- c(0, 1, 2, 3, 4)\ny<- c(128, 434, 160, 64, 24)\nprison <-data.frame(x,y)\nView(prison)\n\n\n2a. What is the probability that a randomly selected inmate has exactly 2 prior convictions? 20% 2b. What is the probability that a randomly selected inmate has fewer than 2 prior convictions? 69% 2c. What is the probability that a randomly selected inmate has 2 or fewer prior convictions? 89% 2d. What is the probability that a randomly selected inmate has more than 2 prior convictions? 11% 2e. What is the expected value for the number of prior convictions? 84% 2f. Calculate the variance and the standard deviation for the Prior Convictions.\n\n\nCode\nvar(prison, y= NULL)\nsd(rnorm(810))\nThe standard deviation is 1.02.\n\n\nError: <text>:3:5: unexpected symbol\n2: sd(rnorm(810))\n3: The standard\n       ^"
  },
  {
    "objectID": "posts/HW1answers_DonnySnyder.html",
    "href": "posts/HW1answers_DonnySnyder.html",
    "title": "Homework 1 - Donny Snyder",
    "section": "",
    "text": "First, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\ndf <- read_excel(\"_data/LungCapData.xls\")\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(df$LungCap)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\n##b\n\n\nCode\nlibrary(ggplot2)\nggplot(df, aes(x = Gender, y = LungCap)) + geom_boxplot()\n\n\n\n\n\nThe probability distribution suggests that the lung capacity of males tends to be higher.\n##c\n\n\nCode\naggregate(data = df, LungCap~Smoke, mean)\n\n\n  Smoke  LungCap\n1    no 7.770188\n2   yes 8.645455\n\n\nThe mean lung capacity of smokers vs nonsmokers appears to be higher for smokers. This doesn’t really make sense because I’ve been taught to think smokers tend to have reduced lung capacity.\n##d and e\n\n\nCode\nx=1\ndf$AgeGroup <- rep(c(\"NA\"),times=725)\nwhile(x <= 725){\n  if(df$Age[x] <= 13){\n    df$AgeGroup[x] = \"less than or equal to 13\"\n  }\n  else if((df$Age[x] >= 14)&&(df$Age[x] <= 15)){\n    df$AgeGroup[x] = \"14 to 15\"\n  }\n  else if((df$Age[x] >= 16)&&(df$Age[x] <= 17)){\n    df$AgeGroup[x] = \"16 to 17\"\n  }\n  else if(df$Age[x] >= 18){\n    df$AgeGroup[x] = \"greater than 18\"\n  }\nx = x + 1\n}\naggregate(data = df, LungCap~AgeGroup+Smoke, mean)\n\n\n                  AgeGroup Smoke   LungCap\n1                 14 to 15    no  9.138810\n2                 16 to 17    no 10.469805\n3          greater than 18    no 11.068846\n4 less than or equal to 13    no  6.358746\n5                 14 to 15   yes  8.391667\n6                 16 to 17   yes  9.383750\n7          greater than 18   yes 10.513333\n8 less than or equal to 13   yes  7.201852\n\n\nCode\naggregate(data = df,LungCap~AgeGroup+Smoke,length)\n\n\n                  AgeGroup Smoke LungCap\n1                 14 to 15    no     105\n2                 16 to 17    no      77\n3          greater than 18    no      65\n4 less than or equal to 13    no     401\n5                 14 to 15   yes      15\n6                 16 to 17   yes      20\n7          greater than 18   yes      15\n8 less than or equal to 13   yes      27\n\n\nCode\naggregate(data = df,Age~Smoke,mean)\n\n\n  Smoke      Age\n1    no 12.03549\n2   yes 14.77922\n\n\nIt seems like people tend to have a lung capacity that increases with age. However, nonsmokers have a higher lung capacity for each age break down besides less than or equal to 13. It seems like smokers just might tend to be older. I confirmed this by looking at the length and mean ages per group, where you can see a majority of smokers are older, whereas non smokers tend to be younger. The mean age for smokers also tends to be older.\n##f\n\n\nCode\ncor(x= df$LungCap, y = df$Age)\n\n\n[1] 0.8196749\n\n\nCode\ncov(x= df$LungCap, y = df$Age)\n\n\n[1] 8.738289\n\n\nLung capacity appears to be quite correlated with age. This means that Lung capacity tends to go up as age goes up, and vice versa. This is confirmed also by the covariance.\n#Question 2\n##a\n\n\nCode\nprint((160/810) * 100)\n\n\n[1] 19.75309\n\n\nThe probability is 19.75309% that a randomly selected inmate has exactly 2 prior convictions.\n##b\n\n\nCode\nprint(((434+128)/810) * 100)\n\n\n[1] 69.38272\n\n\nThe probability is 69.38272% that a randomly selected inmate has fewer than 2 prior convictions.\n##c\n\n\nCode\nprint(((160+434+128)/810) * 100)\n\n\n[1] 89.1358\n\n\nThe probability is 89.1358% that a randomly selected inmate has 2 or fewer prior convictions.\n##d\n\n\nCode\nprint(((64+24)/810) * 100)\n\n\n[1] 10.8642\n\n\nThe probability is 10.8642% that a randomly selected inmate has more than 2 prior convictions.\n##e\n\n\nCode\nnewDf <- NA\nnewDf[1:128] <- 0\nnewDf[129:562] <- 1\nnewDf[563:722] <- 2\nnewDf[723:786] <- 3\nnewDf[787:810] <- 4\nnewDf <- as.data.frame(newDf)\nmean(newDf$newDf)\n\n\n[1] 1.28642\n\n\nThe expected value, known as the “mean” when it deals in data that are not probability distributions, is 1.28642. Because I created a vector here, I took the mean, though I also could have calculated the expected value by multiplying the probabilities by the numbers. They are both the same value in this case.\n##f\n\n\nCode\nsd(newDf$newDf)\n\n\n[1] 0.9259016\n\n\nCode\nvar(newDf$newDf)\n\n\n[1] 0.8572937\n\n\nThe variance of prior convictions is 0.8572937, the standard deviation of prior convictions is 0.9259016."
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#question-1",
    "href": "posts/HW1_603_Niharikapola.html#question-1",
    "title": "Homework 1",
    "section": "Question 1",
    "text": "Question 1"
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#reading-data",
    "href": "posts/HW1_603_Niharikapola.html#reading-data",
    "title": "Homework 1",
    "section": "Reading data",
    "text": "Reading data\n\n\nCode\nLc <- read_excel(\"LungCapData.xls\")\n\n\nError: `path` does not exist: 'LungCapData.xls'\n\n\nCode\nLc\n\n\nError in eval(expr, envir, enclos): object 'Lc' not found\n\n\nThe data consists of 725 rows and 6 columns. It determines the lung capacity of the based on their age, height and different characteristics. The main key classification that I can see is if they smoke or not."
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#a",
    "href": "posts/HW1_603_Niharikapola.html#a",
    "title": "Homework 1",
    "section": "1a",
    "text": "1a\nThe distribution of LungCap looks as follows:\n\n\nCode\nLc %>%\n  ggplot(aes(LungCap, ..density..)) +\n  geom_histogram(bins= 25, color = \"orange\") +\n  geom_density(color = \"darkblue\") +\n  theme_classic() + \n  labs(title = \"Probability distribution of LungCap\", x = \"Lung Capcity\", y = \"Probability density\")\n\n\nError in ggplot(., aes(LungCap, ..density..)): object 'Lc' not found\n\n\nThe histogram and density plots show that it is pretty close to a normal distribution. Most of the observations are close to the mean."
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#b",
    "href": "posts/HW1_603_Niharikapola.html#b",
    "title": "Homework 1",
    "section": "1b",
    "text": "1b\nThe distribution of LungCap on basis of gender looks as follows:\n\n\nCode\nLc %>%\n  ggplot(aes(y = dnorm(LungCap), color = Gender)) +\n  geom_boxplot() +\n  theme_classic() + \n  labs(title = \"Probability distribution of LungCap based on gender\", y = \"Probability density\")\n\n\nError in ggplot(., aes(y = dnorm(LungCap), color = Gender)): object 'Lc' not found\n\n\nThe box plot shows that the probability density of the male is lesser than the female."
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#c",
    "href": "posts/HW1_603_Niharikapola.html#c",
    "title": "Homework 1",
    "section": "1c",
    "text": "1c\nComparison of mean lung capacities between smokers and non-smokers:\n\n\nCode\nMean_smoke <- Lc %>%\n  group_by(Smoke) %>%\n  summarise(mean = mean(LungCap))\n\n\nError in group_by(., Smoke): object 'Lc' not found\n\n\nCode\nMean_smoke\n\n\nError in eval(expr, envir, enclos): object 'Mean_smoke' not found\n\n\nFrom the above table, we see that the mean lung capacity of those who smoke is greater than those who don’t smoke, but it doesn’t make sense. It also depends on the biological factors of the person who smoke, so we can’t conclude it."
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#d",
    "href": "posts/HW1_603_Niharikapola.html#d",
    "title": "Homework 1",
    "section": "1d",
    "text": "1d\nRelationship between Smoke and Lung capacity on basis of given age categories:\n\n\nCode\nLc <- mutate(Lc, AgeGrp = case_when(Age <= 13 ~ \"less than or equal to 13\",\n                                    Age == 14 | Age == 15 ~ \"14 to 15\",\n                                    Age == 16 | Age == 17 ~ \"16 to 17\",\n                                    Age >= 18 ~ \"greater than or equal to 18\"))\n\n\nError in mutate(Lc, AgeGrp = case_when(Age <= 13 ~ \"less than or equal to 13\", : object 'Lc' not found\n\n\nCode\nLc %>%\n  ggplot(aes(y = LungCap, color = Smoke)) +\n  geom_histogram(bins = 25) +\n  facet_wrap(vars(AgeGrp)) +\n  theme_classic() + \n  labs(title = \"Relationship of LungCap and Smoke based on age categories\", y = \"Lung Capacity\", x = \"Frequency\")\n\n\nError in ggplot(., aes(y = LungCap, color = Smoke)): object 'Lc' not found\n\n\nFrom the above plot, we can derive two important observations: 1. The lung capacity of non smokers is more than smokers. 2. The people who smoke are less in age group of “less than or equal to 13”. So as the result as age increases the lung capacity decreases."
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#e",
    "href": "posts/HW1_603_Niharikapola.html#e",
    "title": "Homework 1",
    "section": "1e",
    "text": "1e\nRelationship between Smoke and Lung capacity on basis of age:\n\n\nCode\nLc %>%\n  ggplot(aes(x = Age, y = LungCap, color = Smoke)) +\n  geom_line() +\n  theme_classic() + \n  facet_wrap(vars(Smoke)) +\n  labs(title = \"Relationship of LungCap and Smoke based on age\", y = \"Lung Capacity\", x = \"Age\")\n\n\nError in ggplot(., aes(x = Age, y = LungCap, color = Smoke)): object 'Lc' not found\n\n\nForm the above data we can compare 1d and 1e and can say the results are pretty similar. Only 10 and above age group smoke."
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#f",
    "href": "posts/HW1_603_Niharikapola.html#f",
    "title": "Homework 1",
    "section": "1f",
    "text": "1f\nCalculating the correlation and covariance between Lung Capacity and Age:\n\n\nCode\nCovariance <- cov(Lc$LungCap, Lc$Age)\n\n\nError in is.data.frame(y): object 'Lc' not found\n\n\nCode\nCorrelation <- cor(Lc$LungCap, Lc$Age)\n\n\nError in is.data.frame(y): object 'Lc' not found\n\n\nCode\nCovariance\n\n\nError in eval(expr, envir, enclos): object 'Covariance' not found\n\n\nCode\nCorrelation\n\n\nError in eval(expr, envir, enclos): object 'Correlation' not found\n\n\nWe can observe from the comparison that the covariance is positive and it indicates that there is a direct relationship between age and lung capacity. And the correlation is also positive, so they move in same direction. We can say from these results that as the age increases, the lung capacity also increases that is they are directly proportional to each other."
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#question-2",
    "href": "posts/HW1_603_Niharikapola.html#question-2",
    "title": "Homework 1",
    "section": "Question 2",
    "text": "Question 2"
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#reading-the-table",
    "href": "posts/HW1_603_Niharikapola.html#reading-the-table",
    "title": "Homework 1",
    "section": "Reading the table",
    "text": "Reading the table\n\n\nCode\nPrior_convitions <- c(0:4)\nInmate_count <- c(128, 434, 160, 64, 24)\nPc <- data_frame(Prior_convitions, Inmate_count)\n\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nPlease use `tibble()` instead.\n\n\nCode\nPc\n\n\n\n\n  \n\n\n\n\n\nCode\nPc <- mutate(Pc, Probability = Inmate_count/sum(Inmate_count))\nPc"
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#a-1",
    "href": "posts/HW1_603_Niharikapola.html#a-1",
    "title": "Homework 1",
    "section": "2a",
    "text": "2a\nProbability that a randomly selected inmate has exactly 2 prior convictions:\n\n\nCode\nPc %>%\n  filter(Prior_convitions == 2) %>%\n  select(Probability)"
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#b-1",
    "href": "posts/HW1_603_Niharikapola.html#b-1",
    "title": "Homework 1",
    "section": "2b",
    "text": "2b\nProbability that a randomly selected inmate has fewer than 2 convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions < 2)\nsum(temp$Probability)\n\n\n[1] 0.6938272"
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#c-1",
    "href": "posts/HW1_603_Niharikapola.html#c-1",
    "title": "Homework 1",
    "section": "2c",
    "text": "2c\nProbability that a randomly selected inmate has 2 or fewer prior convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions <= 2)\nsum(temp$Probability)\n\n\n[1] 0.891358"
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#d-1",
    "href": "posts/HW1_603_Niharikapola.html#d-1",
    "title": "Homework 1",
    "section": "2d",
    "text": "2d\nProbability that a randomly selected inmate has more than 2 prior convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions > 2)\nsum(temp$Probability)\n\n\n[1] 0.108642"
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#e-1",
    "href": "posts/HW1_603_Niharikapola.html#e-1",
    "title": "Homework 1",
    "section": "2e",
    "text": "2e\nExpected value for the number of prior convictions:\n\n\nCode\nPc <- mutate(Pc, Wm = Prior_convitions*Probability)\ne <- sum(Pc$Wm)\ne\n\n\n[1] 1.28642"
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#f-1",
    "href": "posts/HW1_603_Niharikapola.html#f-1",
    "title": "Homework 1",
    "section": "2f",
    "text": "2f\nVariance for the Prior Convictions:\n\n\nCode\nv <-sum(((Pc$Prior_convitions-e)^2)*Pc$Probability)\nv\n\n\n[1] 0.8562353\n\n\nstandard deviation for the Prior Convictions:\n\n\nCode\nsqrt(v)\n\n\n[1] 0.9253298"
  },
  {
    "objectID": "posts/hw1_boonstra.html",
    "href": "posts/hw1_boonstra.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(readxl)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)"
  },
  {
    "objectID": "posts/hw1_boonstra.html#a",
    "href": "posts/hw1_boonstra.html#a",
    "title": "Homework 1",
    "section": "a",
    "text": "a\nFirst, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\nlungcap <- read_excel(\"_data/LungCapData.xls\")\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(lungcap$LungCap)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15)."
  },
  {
    "objectID": "posts/hw1_boonstra.html#b",
    "href": "posts/hw1_boonstra.html#b",
    "title": "Homework 1",
    "section": "b",
    "text": "b\nThese are the boxplots of the distributions for the lung capacity of males and females in the sample:\n\n\nCode\nlungcap %>% \n  ggplot(aes(x=Gender,y=LungCap)) +\n  geom_boxplot()\n\n\n\n\n\nAccording to these boxplots, it appears that males and females have similar median lung capacities, but that males may be more likely to have a higher lung capacity than females."
  },
  {
    "objectID": "posts/hw1_boonstra.html#c",
    "href": "posts/hw1_boonstra.html#c",
    "title": "Homework 1",
    "section": "c",
    "text": "c\n\n\nCode\nlungcap %>% \n  group_by(Smoke) %>% \n  summarise(mean_lungcap=mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke mean_lungcap\n  <chr>        <dbl>\n1 no            7.77\n2 yes           8.65\n\n\nAccording to this sample, it would appear that smokers have a higher lung capacity than non-smokers. This would appear to be counter-intuitive, as one would likely expect smoking to reduce lung functionality and, by extension, capacity."
  },
  {
    "objectID": "posts/hw1_boonstra.html#d",
    "href": "posts/hw1_boonstra.html#d",
    "title": "Homework 1",
    "section": "d",
    "text": "d\nIn order to complete this examination by group, we must create a new nominal variable that groups observations by age; this can be accomplished fairly simply using the mutate() and case_when() functions:\n\n\nCode\nlungcap_age <- lungcap %>% \n  mutate(age_group = case_when(\n    Age <= 13 ~ \"13 and under\",\n    Age == 14 | Age == 15 ~ \"14 to 15\",\n    Age == 16 | Age == 17 ~ \"16 to 17\",\n    Age >= 18 ~ \"18 and older\"\n  ))\n\n\nWith this new dataframe, we can use the group_by() function to calculate mean lung capacity by age group and smoker status:\n\n\nCode\nlungcap_age %>% \n  group_by(age_group,Smoke) %>% \n  summarise(mean(LungCap))\n\n\n# A tibble: 8 × 3\n# Groups:   age_group [4]\n  age_group    Smoke `mean(LungCap)`\n  <chr>        <chr>           <dbl>\n1 13 and under no               6.36\n2 13 and under yes              7.20\n3 14 to 15     no               9.14\n4 14 to 15     yes              8.39\n5 16 to 17     no              10.5 \n6 16 to 17     yes              9.38\n7 18 and older no              11.1 \n8 18 and older yes             10.5 \n\n\nAccording to these data, it appears that lung capacity generally increases with age. Interestingly, lung capacity is worse for smokers than it is for non-smokers in every age group except for “13 and under”. This is surprising on the surface, given that, when the data are ungrouped, smokers have a higher lung capacity than non-smokers (see part c). However, this begins to make more sense when we see how much better the “13 and under” group is represented compared to the others in this dataset:\n\n\nCode\nlungcap_age %>% \n  group_by(age_group) %>% \n  count()\n\n\n# A tibble: 4 × 2\n# Groups:   age_group [4]\n  age_group        n\n  <chr>        <int>\n1 13 and under   428\n2 14 to 15       120\n3 16 to 17        97\n4 18 and older    80\n\n\nThis high number of observations compared to other age groups likely plays a significant role in skewing the mean of the entire dataset."
  },
  {
    "objectID": "posts/hw1_boonstra.html#e",
    "href": "posts/hw1_boonstra.html#e",
    "title": "Homework 1",
    "section": "e",
    "text": "e\nIt is not clear to me how this part is different from part d; from what I do understand, I believe the question being asked here is addressed in that part."
  },
  {
    "objectID": "posts/hw1_boonstra.html#f",
    "href": "posts/hw1_boonstra.html#f",
    "title": "Homework 1",
    "section": "f",
    "text": "f\n\n\nCode\ncov(lungcap$LungCap, lungcap$Age)\n\n\n[1] 8.738289\n\n\nCode\ncor(lungcap$LungCap, lungcap$Age)\n\n\n[1] 0.8196749\n\n\nIt would appear that lung capacity and age covary together positively, such that a higher age means a higher lung capacity. We can confirm this with a simple visualization:\n\n\nCode\nlungcap %>% \n  ggplot(aes(x=Age,y=LungCap)) +\n  geom_point() +\n  geom_smooth(method='lm')"
  },
  {
    "objectID": "posts/hw1_boonstra.html#a-1",
    "href": "posts/hw1_boonstra.html#a-1",
    "title": "Homework 1",
    "section": "a",
    "text": "a\nThe probability that a randomly selected inmate has exactly 2 prior convictions is 160 / 810 = 0.1975309."
  },
  {
    "objectID": "posts/hw1_boonstra.html#b-1",
    "href": "posts/hw1_boonstra.html#b-1",
    "title": "Homework 1",
    "section": "b",
    "text": "b\nThe probability that a randomly selected inmate has less than 2 prior convictions is (128+434) / 810 = 0.6938272."
  },
  {
    "objectID": "posts/hw1_boonstra.html#c-1",
    "href": "posts/hw1_boonstra.html#c-1",
    "title": "Homework 1",
    "section": "c",
    "text": "c\nThe probability that a randomly selected inmate has 2 or fewer prior convictions is (128+434+160) / 810 = 0.891358."
  },
  {
    "objectID": "posts/hw1_boonstra.html#d-1",
    "href": "posts/hw1_boonstra.html#d-1",
    "title": "Homework 1",
    "section": "d",
    "text": "d\nThe probability that a randomly selected inmate has more than 2 prior convictions is (64+24) / 810 = 0.108642."
  },
  {
    "objectID": "posts/hw1_boonstra.html#e-1",
    "href": "posts/hw1_boonstra.html#e-1",
    "title": "Homework 1",
    "section": "e",
    "text": "e\nBefore calculating expected value, we should put together a probability mass function for the prisoners data.\n\n\nCode\nprisoners <- prisoners %>% \n  mutate(prob=freq/810) %>% \n  mutate(expect=prob*priors)\n\nprisoners %>% \n  summarise(sum(expect))\n\n\n  sum(expect)\n1     1.28642\n\n\nThe expected value for the number of prior convictions is about 1.29 priors.\nEDIT: There is a much simpler way to compute this! Rather than using the dataframe I created, storing values and their frequencies, I can create one vector that stores each value a certain number of times, according to the given frequencies:\n\n\nCode\nprisoners_full <- rep(c(0,1,2,3,4),times=c(128,434,160,64,24))\nprisoners_full\n\n\n  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n [38] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n [75] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[112] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[556] 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[593] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[630] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[667] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[704] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n[741] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n[778] 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n\n\nBecause each value now appears as frequently as its “probability” of appearing, taking the mean of this vector also provides the correct expected value.\n\n\nCode\nmean(prisoners_full)\n\n\n[1] 1.28642"
  },
  {
    "objectID": "posts/hw1_boonstra.html#f-1",
    "href": "posts/hw1_boonstra.html#f-1",
    "title": "Homework 1",
    "section": "f",
    "text": "f\nCreating this numerical vector also makes the standard deviation calculation extremely simple in R.\n\n\nCode\nsd(prisoners_full)\n\n\n[1] 0.9259016"
  },
  {
    "objectID": "posts/HW1_EmmaRasmussen.html",
    "href": "posts/HW1_EmmaRasmussen.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlungcap<-read_excel(\"_data/LungCapData.xls\")\nhead(lungcap)\n\n\n# A tibble: 6 × 6\n  LungCap   Age Height Smoke Gender Caesarean\n    <dbl> <dbl>  <dbl> <chr> <chr>  <chr>    \n1    6.48     6   62.1 no    male   no       \n2   10.1     18   74.7 yes   female no       \n3    9.55    16   69.7 no    female yes      \n4   11.1     14   71   no    male   no       \n5    4.8      5   56.9 no    male   no       \n6    6.22    11   58.7 no    female no       \n\n\nCode\n#saving a copy of original dataset\nlungcap_orig<-lungcap\n\n#checking for missing values in LungCap\nwhich(is.na(lungcap$LungCap))\n\n\ninteger(0)\n\n\n\n1a.\nThe distribution of LungCapData is plotted as a histogram below.\n\n\nCode\nggplot(lungcap, aes(x=LungCap))+geom_histogram()\n\n\n\n\n\nThe histogram looks approximately normally distributed\n\n\n1b.\nThe probability distribution of LungCap data for males and females is compared using the boxplots below:\n\n\nCode\nggplot(lungcap, aes(x=LungCap, y=Gender))+geom_boxplot()\n\n\n\n\n\nThe mean lung capacity of males appears slightly higher than that of females. The IQR and range for males and females appears similarly spread with a higher average for males.\n\n\n1c.\nBelow the mean and standard deviation of smokers and non-smokers is compared. They are also plotted as a boxplot to help visualize the distribution.\n\n\nCode\nlungcap%>%\n  group_by(Smoke) %>% \n  summarize(Mean=mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke  Mean\n  <chr> <dbl>\n1 no     7.77\n2 yes    8.65\n\n\nCode\nlungcap%>%\n  group_by(Smoke) %>% \n  summarize(stdev=sd(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke stdev\n  <chr> <dbl>\n1 no     2.73\n2 yes    1.88\n\n\nCode\nggplot(lungcap, aes(x=LungCap, y=Smoke))+geom_boxplot()\n\n\n\n\n\nThe mean lung capacity for smokers (8.645) in this sample is higher than that of non-smokers (7.770). This does not make sense. However, the standard deviation of non-smokers (2.726) is much higher than smokers (1.883) so there might be something else going on (see boxplot).\n\n\n1d.\nBelow, means are taken by age groups of smokers/non-smokers. I also created a new age category variable (“AgeCat”) to plot the data by smoking status and age category.\n\n\nCode\n#Mean under 13 and nonsmoker\nlungcap %>% \n  filter(Age<=13 & Smoke==\"no\") %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 6.358746\n\n\nCode\n#Mean under 13 and smoker\nlungcap %>% \n  filter(Age<=13 & Smoke==\"yes\") %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 7.201852\n\n\nCode\n#Mean 14-15 and nonsmoker\nlungcap %>% \n  filter(Age==14 | Age==15 & Smoke==\"no\") %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 9.068018\n\n\nCode\n#Mean 14-15 and smoker\nlungcap %>% \n  filter(Age==14 | Age==15 & Smoke==\"yes\") %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 8.689231\n\n\nCode\n#Mean 16-17 and nonsmoker\nlungcap %>% \n  filter(Age==16 | Age==17 & Smoke==\"no\") %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 10.30523\n\n\nCode\n#Mean 16-17 and smoker\nlungcap %>% \n  filter(Age==16 | Age==17 & Smoke==\"yes\") %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 9.850385\n\n\nCode\n#Mean over 18 and nonsmoker\nlungcap %>% \n  filter(Age>=18 & Smoke==\"no\") %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 11.06885\n\n\nCode\n#Mean over 18 and smoker\nlungcap %>% \n  filter(Age>=18 & Smoke==\"yes\") %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 10.51333\n\n\nCode\n#creating new variable AgeCat to create boxplots\nlungcap<-lungcap %>% \n  mutate(AgeCat= as.factor(case_when(Age <= 13 ~ \"13 and under\", \n                           Age == 14 |Age ==15 ~ \"14-15\", \n                           Age == 16 | Age==17 ~ \"16-17\",\n                           Age >= 18 ~ \"18 or over\"\n                           )))\n\n#new Category AgeCat is the last column\nlungcap\n\n\n# A tibble: 725 × 7\n   LungCap   Age Height Smoke Gender Caesarean AgeCat      \n     <dbl> <dbl>  <dbl> <chr> <chr>  <chr>     <fct>       \n 1    6.48     6   62.1 no    male   no        13 and under\n 2   10.1     18   74.7 yes   female no        18 or over  \n 3    9.55    16   69.7 no    female yes       16-17       \n 4   11.1     14   71   no    male   no        14-15       \n 5    4.8      5   56.9 no    male   no        13 and under\n 6    6.22    11   58.7 no    female no        13 and under\n 7    4.95     8   63.3 no    male   yes       13 and under\n 8    7.32    11   70.4 no    male   no        13 and under\n 9    8.88    15   70.5 no    male   no        14-15       \n10    6.8     11   59.2 no    male   no        13 and under\n# … with 715 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\nCode\nggplot(lungcap, aes(x=LungCap))+geom_boxplot()+facet_grid(Smoke ~ AgeCat)\n\n\n\n\n\n\n\n1e.\nComparing the lung capacities for smokers and non-smokers in different age categories:\nNow we can see that the mean lung capacity for smokers by age group is generally lower than that of nonsmokers. This is true in all categories except for Under 13, which is likely because smokers in that category are going to be older than nonsmokers in that category (i.e. it is more likely that a 12 year old smokes than a 6 year old, and a 12 year old has a larger lung capacity than a 6 year old regardless of smoking status)\nThis explains the first calculation of mean by smoking status (before finding the mean by age categories). Smokers are generally going to be older than non-smokers for this sample (the oldest participant in the sample is 19- see code below), which explains why the mean for smokers versus non-smokers (not separated by age categories) makes it look like smokers have a higher average lung capacity.\n\n\nCode\n#checking how old participants in the sample are\nlungcap %>% \n  summarize(range(Age))\n\n\n# A tibble: 2 × 1\n  `range(Age)`\n         <dbl>\n1            3\n2           19\n\n\n\n\n1f.\nCalculating the correlation and covariance between Lung Capacity and Age:\n\n\nCode\n#Creating vectors of Age and Lung Capacity from df (lungcap) to apply cov() and cor() functions to\nx<-c(lungcap$Age)\ny<-c(lungcap$LungCap)\n\n\n#Calculating covariance\ncov(x, y)\n\n\n[1] 8.738289\n\n\nCode\n#calculating correlation\ncor(x, y)\n\n\n[1] 0.8196749\n\n\nThe covariance, 8.738 is fairly high and positive, meaning as age increases, so does lung capacity (i.e. age and lung capacity co-vary). The correlation (0.82) is fairly close to one and positive, indicating they correlate fairly closely.\n\n\n2a-f.\nPrior Conviction Data\n\n\nCode\n#creating a data frame\nX<-c(0, 1, 2, 3, 4)\nFrequency<-c(128, 434, 160, 64, 24)\nprison<- data.frame(X, Frequency)\nprison\n\n\n  X Frequency\n1 0       128\n2 1       434\n3 2       160\n4 3        64\n5 4        24\n\n\nCode\nprison<-rename(prison, PriorConvictions=X)\nprison\n\n\n  PriorConvictions Frequency\n1                0       128\n2                1       434\n3                2       160\n4                3        64\n5                4        24\n\n\nCode\n#visualizing df using bar chart\nggplot(prison, aes(x=PriorConvictions, y=Frequency))+geom_bar(stat=\"identity\")+geom_text(aes(label = Frequency), vjust = -.3)\n\n\n\n\n\nCode\n#There are 810 obs in df\nsum(Frequency)\n\n\n[1] 810\n\n\nAnswering the Questions\n\n\nCode\n#creating a vector of probabilities\nprobs<-Frequency/810\nprobs\n\n\n[1] 0.15802469 0.53580247 0.19753086 0.07901235 0.02962963\n\n\nCode\n#A\n# P(x=2)=160/810\n160/810\n\n\n[1] 0.1975309\n\n\nCode\n#B\n#P(x<2)=P(0)+P(1)\n(128+434)/810\n\n\n[1] 0.6938272\n\n\nCode\n#C\n#P(x<=2)=P(0)+P(1)+P(2)\n(128+434+160)/810\n\n\n[1] 0.891358\n\n\nCode\n#D\n#1-P(above)\n1-((128+434+160)/810)\n\n\n[1] 0.108642\n\n\nCode\n#E\n#Expected value=sum of probabilities*each value (0, 1, 2, 3 or 4)\nweighted.mean(X, probs)\n\n\n[1] 1.28642\n\n\nCode\n#F\n#Calculating the Variance using the formula for variance\n(sum(Frequency*((X-1.28642)^2)))/(sum(Frequency)-1)\n\n\n[1] 0.8572937\n\n\nCode\n#Calculating the sample standard deviation from the variance\nsqrt(0.8572937)\n\n\n[1] 0.9259016\n\n\n\nWhat is the probability that a randomly selected inmate has exactly 2 prior convictions? 19.75% probability (or 0.1975)\nWhat is the probability that a randomly selected inmate has fewer than 2 prior convictions? 69.38% probability\nWhat is the probability that a randomly selected inmate has 2 or fewer prior convictions? 89.14% probability\nWhat is the probability that a randomly selected inmate has more than 2 prior convictions? 10.86% probability\nWhat is the expected value for the number of prior convictions? 1.28642 prior convictions\nCalculate the variance and the standard deviation for the Prior Convictions. variance: 0.8572937 standard deviation: 0.9259016 prior convictions"
  },
  {
    "objectID": "posts/HW1_EthanCampbell.html",
    "href": "posts/HW1_EthanCampbell.html",
    "title": "Homework 1",
    "section": "",
    "text": "First, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\n\n\nWarning: package 'readxl' was built under R version 4.1.3\n\n\nCode\nlibrary(tidyverse)\n\n\nWarning: package 'tidyverse' was built under R version 4.1.3\n\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.2 --\nv ggplot2 3.3.6     v purrr   0.3.4\nv tibble  3.1.8     v dplyr   1.0.9\nv tidyr   1.2.0     v stringr 1.4.1\nv readr   2.1.2     v forcats 0.5.2\n\n\nWarning: package 'ggplot2' was built under R version 4.1.3\n\n\nWarning: package 'tibble' was built under R version 4.1.3\n\n\nWarning: package 'tidyr' was built under R version 4.1.3\n\n\nWarning: package 'readr' was built under R version 4.1.3\n\n\nWarning: package 'dplyr' was built under R version 4.1.3\n\n\nWarning: package 'stringr' was built under R version 4.1.3\n\n\nWarning: package 'forcats' was built under R version 4.1.3\n\n\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(dplyr)\ndf <- read_excel(\"_data/LungCapData.xls\")\n\n\n\n\n(The distribution of LungCap looks as follows:)\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\n\n\nCode\nhead(df)\n\n\n# A tibble: 6 x 6\n  LungCap   Age Height Smoke Gender Caesarean\n    <dbl> <dbl>  <dbl> <chr> <chr>  <chr>    \n1    6.48     6   62.1 no    male   no       \n2   10.1     18   74.7 yes   female no       \n3    9.55    16   69.7 no    female yes      \n4   11.1     14   71   no    male   no       \n5    4.8      5   56.9 no    male   no       \n6    6.22    11   58.7 no    female no       \n\n\nCode\nhist(df$LungCap)\n\n\n\n\n\n\n\n\n(Comparing lung cap by gender)\nHere we notice that males tend to have a higher lung cap compared to females. Females average tends to sit around 8 while males seems to sit closer to 9\n\n\nCode\nboxplot(df$LungCap~df$Gender)\n\n\n\n\n\n\n\n\n(smoker vs non-smoker lung cap)\nInterestingly, none smokers tend to have a lower lung capacity however, I believe this might be due to age. No this does not make sense at first glance and does betray my expectation.\n\n\nCode\ndf %>%\n  group_by(Smoke) %>%\n  summarize_at(vars(LungCap), list(mean = mean))\n\n\n# A tibble: 2 x 2\n  Smoke  mean\n  <chr> <dbl>\n1 no     7.77\n2 yes    8.65\n\n\n\n\n\n(relation between smoking and lung cap at different age groups)\nThe lung cap starts off higher but takes and dip then rises as the age continues to grow. I believe the trend is the higher age grows the higher the lung cap until it reaches a certain point.\n\n\nCode\n# lung cap is 9.62\ndf %>%\n  select(Age, LungCap) %>%\n  filter(Age >= 13) %>%\n  colMeans()\n\n\n      Age   LungCap \n15.609290  9.628757 \n\n\nCode\n# lung cap is 9.04\ndf %>%\n  select(Age, LungCap) %>%\n  filter(Age >= 14 & Age <= 15) %>%\n  colMeans()\n\n\n      Age   LungCap \n14.533333  9.045417 \n\n\nCode\n# lung cap is 10.24\ndf %>%\n  select(Age, LungCap) %>%\n  filter(Age >= 16 & Age <= 17) %>%\n  colMeans()\n\n\n     Age  LungCap \n16.44330 10.24588 \n\n\nCode\n# lung cap is 11.26\ndf %>%\n  select(Age, LungCap) %>%\n  filter(Age > 18) %>%\n  colMeans()\n\n\n     Age  LungCap \n19.00000 11.26149 \n\n\n\n\n\n(lung cap for smokers and non smokers broken into age groups)\nWe notice a clear trend that smokers have a lower lung capacity compared to non-smokers\n\n\nCode\ndf %>%\n  select(Age, LungCap, Smoke) %>%\n  group_by(Smoke) %>%\n  filter(Age >= 13) %>%\n  summarize_at(vars(LungCap), list(mean = mean))\n\n\n# A tibble: 2 x 2\n  Smoke  mean\n  <chr> <dbl>\n1 no     9.71\n2 yes    9.21\n\n\nCode\ndf %>%\n  select(Age, LungCap, Smoke) %>%\n  group_by(Smoke) %>%\n  filter(Age >= 14 & Age <= 15) %>%\n  summarize_at(vars(LungCap), list(mean = mean))\n\n\n# A tibble: 2 x 2\n  Smoke  mean\n  <chr> <dbl>\n1 no     9.14\n2 yes    8.39\n\n\nCode\ndf %>%\n  select(Age, LungCap, Smoke) %>%\n  group_by(Smoke) %>%\n  filter(Age >= 16 & Age <= 17) %>%\n  summarize_at(vars(LungCap), list(mean = mean))\n\n\n# A tibble: 2 x 2\n  Smoke  mean\n  <chr> <dbl>\n1 no    10.5 \n2 yes    9.38\n\n\nCode\ndf %>%\n  select(Age, LungCap, Smoke) %>%\n  group_by(Smoke) %>%\n  filter(Age > 18) %>%\n  summarize_at(vars(LungCap), list(mean = mean))\n\n\n# A tibble: 2 x 2\n  Smoke  mean\n  <chr> <dbl>\n1 no     11.3\n2 yes    11.3\n\n\n\n\n\n(correlation and covariance between lung capacity and age)\ncorrelation is at .819 meaning they have a positive correlation of about 82%. This means that there is a connection between the two and when one goes up so does the other.\n\n\nCode\ncov(df$LungCap, df$Age)\n\n\n[1] 8.738289\n\n\nCode\ncor(df$LungCap, df$Age)\n\n\n[1] 0.8196749"
  },
  {
    "objectID": "posts/HW1_EthanCampbell.html#a-1",
    "href": "posts/HW1_EthanCampbell.html#a-1",
    "title": "Homework 1",
    "section": "2.a",
    "text": "2.a\nprobability of exactly 2 convictions probability = 19.7%\n\n\nCode\ndf1 %>%\n  select(X, Freq, Probability) %>%\n  filter(X == 2)\n\n\n# A tibble: 1 x 3\n      X  Freq Probability\n  <dbl> <dbl>       <dbl>\n1     2   160       0.197"
  },
  {
    "objectID": "posts/HW1_EthanCampbell.html#b-1",
    "href": "posts/HW1_EthanCampbell.html#b-1",
    "title": "Homework 1",
    "section": "2.b",
    "text": "2.b\nprobability of fewer than 2 convictions probability = 69.2%\n\n\nCode\nsum(df1$Probability[1:2])\n\n\n[1] 0.6921182"
  },
  {
    "objectID": "posts/HW1_EthanCampbell.html#c-1",
    "href": "posts/HW1_EthanCampbell.html#c-1",
    "title": "Homework 1",
    "section": "2.c",
    "text": "2.c\nProbability of having 2 or fewer convictions probability = 88.9%\n\n\nCode\nsum(df1$Probability[1:3])\n\n\n[1] 0.8891626"
  },
  {
    "objectID": "posts/HW1_EthanCampbell.html#d-1",
    "href": "posts/HW1_EthanCampbell.html#d-1",
    "title": "Homework 1",
    "section": "2.d",
    "text": "2.d\nprobability of having more than 2 convictions probability = 11.08%\n\n\nCode\nsum(df1$Probability[4:5])\n\n\n[1] 0.1108374"
  },
  {
    "objectID": "posts/HW1_EthanCampbell.html#e-1",
    "href": "posts/HW1_EthanCampbell.html#e-1",
    "title": "Homework 1",
    "section": "2.e",
    "text": "2.e\nWhat is the expected value expected value is 1.29 convictions\n\n\nCode\ndf1 %>%\n  select(X, Freq, Probability) %>%\n  mutate(expected_value = (0*0.15763547)+(1*0.53448276)+(2*0.19704433)+(3*0.07881773)+(4*0.03201970))\n\n\n# A tibble: 5 x 4\n      X  Freq Probability expected_value\n  <dbl> <dbl>       <dbl>          <dbl>\n1     0   128      0.158            1.29\n2     1   434      0.534            1.29\n3     2   160      0.197            1.29\n4     3    64      0.0788           1.29\n5     4    26      0.0320           1.29"
  },
  {
    "objectID": "posts/HW1_EthanCampbell.html#f-1",
    "href": "posts/HW1_EthanCampbell.html#f-1",
    "title": "Homework 1",
    "section": "2.f",
    "text": "2.f\nWhat is the variance and standard deviation of the prior convictions Variance = 25810.8 standard deviation = 160.6574\n\n\nCode\nvar(df$Freq)\n\n\n[1] 25810.8\n\n\nCode\nsd(df$Freq)\n\n\n[1] 160.6574"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html",
    "href": "posts/HW1_KarenDetter.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#plot-histogram-with-probability-density-on-the-y-axis",
    "href": "posts/HW1_KarenDetter.html#plot-histogram-with-probability-density-on-the-y-axis",
    "title": "Homework 1",
    "section": "Plot histogram with probability density on the y axis",
    "text": "Plot histogram with probability density on the y axis\n\n\nCode\nhist(LungCapData$LungCap, freq = FALSE)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution - most of the observations are close to the mean, with very few close to the margins (0 and 15)."
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#create-boxplots-separated-by-gender",
    "href": "posts/HW1_KarenDetter.html#create-boxplots-separated-by-gender",
    "title": "Homework 1",
    "section": "Create boxplots separated by gender",
    "text": "Create boxplots separated by gender\n\n\nCode\nboxplot(LungCap ~ Gender, data = LungCapData, horizontal = TRUE)\n\n\n\n\n\nThe boxplots show that male lung capacity has a wider range than that of females; however, the minimum, median, and maximum values are all higher than those of females. This implies that, as a group, men are likely to have higher lung capacity than women."
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#group-by-smoking-status-and-summarize-mean-lung-capacities",
    "href": "posts/HW1_KarenDetter.html#group-by-smoking-status-and-summarize-mean-lung-capacities",
    "title": "Homework 1",
    "section": "Group by smoking status and summarize mean lung capacities",
    "text": "Group by smoking status and summarize mean lung capacities\n\n\nCode\nlibrary(dplyr)\nLungCapData %>%\ngroup_by(Smoke) %>%\nsummarize(mean = mean(LungCap), n = n())\n\n\n# A tibble: 2 × 3\n  Smoke  mean     n\n  <chr> <dbl> <int>\n1 no     7.77   648\n2 yes    8.65    77\n\n\nIn this dataset, the mean lung capacity of smokers is actually higher than that of non-smokers. Since this is counter to what would be expected, there is likely another variable exerting a confounding effect on lung capacity."
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#create-new-data-frame-with-age-group-category-variables",
    "href": "posts/HW1_KarenDetter.html#create-new-data-frame-with-age-group-category-variables",
    "title": "Homework 1",
    "section": "Create new data frame with age group category variables",
    "text": "Create new data frame with age group category variables\n\n\nCode\nLungCapData_AgeGroups <- LungCapData %>%\nmutate(AgeGroup = case_when(Age <= 13 ~ \"less than or equal to 13\", \n            Age == 14 | Age == 15 ~ \"14 to 15\",\n            Age == 16 | Age == 17 ~ \"16 to 17\",\n            Age >= 18 ~ \"greater than or equal to 18\"))"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#summarize-mean-lung-capacities-by-age-group-and-smoking-status",
    "href": "posts/HW1_KarenDetter.html#summarize-mean-lung-capacities-by-age-group-and-smoking-status",
    "title": "Homework 1",
    "section": "Summarize mean lung capacities by age group and smoking status",
    "text": "Summarize mean lung capacities by age group and smoking status\n\n\nCode\nLungCapData_AgeGroups %>%\ngroup_by(AgeGroup, Smoke) %>%\nsummarize(MeanLungCap = mean(LungCap), n = n())\n\n\n`summarise()` has grouped output by 'AgeGroup'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 4\n# Groups:   AgeGroup [4]\n  AgeGroup                    Smoke MeanLungCap     n\n  <chr>                       <chr>       <dbl> <int>\n1 14 to 15                    no           9.14   105\n2 14 to 15                    yes          8.39    15\n3 16 to 17                    no          10.5     77\n4 16 to 17                    yes          9.38    20\n5 greater than or equal to 18 no          11.1     65\n6 greater than or equal to 18 yes         10.5     15\n7 less than or equal to 13    no           6.36   401\n8 less than or equal to 13    yes          7.20    27"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#calculate-correlation-and-covariance-between-lung-capacity-and-age",
    "href": "posts/HW1_KarenDetter.html#calculate-correlation-and-covariance-between-lung-capacity-and-age",
    "title": "Homework 1",
    "section": "Calculate correlation and covariance between lung capacity and age",
    "text": "Calculate correlation and covariance between lung capacity and age\n\n\nCode\ncor(LungCapData$LungCap, LungCapData$Age)\n\n\n[1] 0.8196749\n\n\nCode\ncov(LungCapData$LungCap, LungCapData$Age)\n\n\n[1] 8.738289\n\n\nSince the correlation coefficient is close to 1, there is a high degree of correlation between lung capacity and age. The covariance of 8.7, being a positive number, indicates that as age increases, lung capacity increases."
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#create-data-frame",
    "href": "posts/HW1_KarenDetter.html#create-data-frame",
    "title": "Homework 1",
    "section": "Create data frame",
    "text": "Create data frame\n\n\nCode\nPriorConv <- c(0,1,2,3,4)\nFreq <- c(128,434,160,64,24)\nPrisonerData <- data.frame (PriorConv, Freq)\nPrisonerData\n\n\n  PriorConv Freq\n1         0  128\n2         1  434\n3         2  160\n4         3   64\n5         4   24"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#calculate-probability-that-an-inmate-has-2-prior-convictions",
    "href": "posts/HW1_KarenDetter.html#calculate-probability-that-an-inmate-has-2-prior-convictions",
    "title": "Homework 1",
    "section": "Calculate probability that an inmate has == 2 prior convictions",
    "text": "Calculate probability that an inmate has == 2 prior convictions\nprobability = frequency/n\n\n\nCode\n160/810\n\n\n[1] 0.1975309"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#calculate-probability-that-an-inmate-has-2-prior-convictions-1",
    "href": "posts/HW1_KarenDetter.html#calculate-probability-that-an-inmate-has-2-prior-convictions-1",
    "title": "Homework 1",
    "section": "Calculate probability that an inmate has < 2 prior convictions",
    "text": "Calculate probability that an inmate has < 2 prior convictions\nprobability = frequency(0)/n + frequency(1)/n\n\n\nCode\n(128/810) + (434/810)\n\n\n[1] 0.6938272"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#calculate-probability-that-an-inmate-has-2-prior-convictions-2",
    "href": "posts/HW1_KarenDetter.html#calculate-probability-that-an-inmate-has-2-prior-convictions-2",
    "title": "Homework 1",
    "section": "Calculate probability that an inmate has <= 2 prior convictions",
    "text": "Calculate probability that an inmate has <= 2 prior convictions\nprobability = frequency(0)/n + frequency(1)/n + frequency(2)/n\n\n\nCode\n(128/810) + (434/810) + (160/810)\n\n\n[1] 0.891358"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#calculate-probability-that-an-inmate-has-2-prior-convictions-3",
    "href": "posts/HW1_KarenDetter.html#calculate-probability-that-an-inmate-has-2-prior-convictions-3",
    "title": "Homework 1",
    "section": "Calculate probability that an inmate has > 2 prior convictions",
    "text": "Calculate probability that an inmate has > 2 prior convictions\nprobability = frequency(3)/n + frequency(4)/n\n\n\nCode\n(64/810) + (24/810)\n\n\n[1] 0.108642"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#calculate-expected-value-for-number-of-prior-convictions",
    "href": "posts/HW1_KarenDetter.html#calculate-expected-value-for-number-of-prior-convictions",
    "title": "Homework 1",
    "section": "Calculate expected value for number of prior convictions",
    "text": "Calculate expected value for number of prior convictions"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#create-a-matrix-of-prior-conviction-values-and-their-probabilities",
    "href": "posts/HW1_KarenDetter.html#create-a-matrix-of-prior-conviction-values-and-their-probabilities",
    "title": "Homework 1",
    "section": "Create a matrix of prior conviction values and their probabilities",
    "text": "Create a matrix of prior conviction values and their probabilities\n\n\nCode\nPriorConv <- c(0,1,2,3,4)\nProbs <- c(0.1580247, 0.5358025, 0.1975309, 0.07901235, 0.02962963)"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#calculate-expected-value",
    "href": "posts/HW1_KarenDetter.html#calculate-expected-value",
    "title": "Homework 1",
    "section": "Calculate expected value",
    "text": "Calculate expected value\n\n\nCode\nc(PriorConv %*% Probs)\n\n\n[1] 1.28642"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#calculate-variance-and-standard-deviation-for-prior-convictions",
    "href": "posts/HW1_KarenDetter.html#calculate-variance-and-standard-deviation-for-prior-convictions",
    "title": "Homework 1",
    "section": "Calculate variance and standard deviation for prior convictions",
    "text": "Calculate variance and standard deviation for prior convictions\n\n\nCode\nvar(PriorConv)\n\n\n[1] 2.5\n\n\nCode\nsd(PriorConv)\n\n\n[1] 1.581139"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#double-check-values",
    "href": "posts/HW1_KarenDetter.html#double-check-values",
    "title": "Homework 1",
    "section": "Double-check values",
    "text": "Double-check values\n\n\nCode\nsqrt(var(PriorConv)) == sd(PriorConv)\n\n\n[1] TRUE"
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html",
    "href": "posts/HW1_ManiShankerKamarapu.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(stats)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#question-1",
    "href": "posts/HW1_ManiShankerKamarapu.html#question-1",
    "title": "Homework 1",
    "section": "Question 1",
    "text": "Question 1"
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#reading-data",
    "href": "posts/HW1_ManiShankerKamarapu.html#reading-data",
    "title": "Homework 1",
    "section": "Reading data",
    "text": "Reading data\n\n\nCode\nLc <- read_excel(\"_data/LungCapData.xls\")\nLc\n\n\n\n\n  \n\n\n\nThe data consists of 725 rows and 6 columns. It determines the lung capacity of the based on their age, height and different characteristics. The main key classification that I can see is if they smoke or not."
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#a",
    "href": "posts/HW1_ManiShankerKamarapu.html#a",
    "title": "Homework 1",
    "section": "1a",
    "text": "1a\nThe distribution of LungCap looks as follows:\n\n\nCode\nLc %>%\n  ggplot(aes(LungCap, ..density..)) +\n  geom_histogram(bins= 25, color = \"orange\") +\n  geom_density(color = \"darkblue\") +\n  theme_classic() + \n  labs(title = \"Probability distribution of LungCap\", x = \"Lung Capcity\", y = \"Probability density\")\n\n\n\n\n\nThe histogram and density plots show that it is pretty close to a normal distribution. Most of the observations are close to the mean."
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#b",
    "href": "posts/HW1_ManiShankerKamarapu.html#b",
    "title": "Homework 1",
    "section": "1b",
    "text": "1b\nThe distribution of LungCap on basis of gender looks as follows:\n\n\nCode\nLc %>%\n  ggplot(aes(y = dnorm(LungCap), color = Gender)) +\n  geom_boxplot() +\n  theme_classic() + \n  labs(title = \"Probability distribution of LungCap based on gender\", y = \"Probability density\")\n\n\n\n\n\nThe box plot shows that the probability density of the male is lesser than the female."
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#c",
    "href": "posts/HW1_ManiShankerKamarapu.html#c",
    "title": "Homework 1",
    "section": "1c",
    "text": "1c\nComparison of mean lung capacities between smokers and non-smokers:\n\n\nCode\nMean_smoke <- Lc %>%\n  group_by(Smoke) %>%\n  summarise(mean = mean(LungCap))\nMean_smoke\n\n\n\n\n  \n\n\n\nFrom the above table, we see that the mean lung capacity of those who smoke is greater than those who don’t smoke, but it doesn’t make sense. It also depends on the biological factors of the person who smoke, so we can’t conclude it."
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#d",
    "href": "posts/HW1_ManiShankerKamarapu.html#d",
    "title": "Homework 1",
    "section": "1d",
    "text": "1d\nRelationship between Smoke and Lung capacity on basis of given age categories:\n\n\nCode\nLc <- mutate(Lc, AgeGrp = case_when(Age <= 13 ~ \"less than or equal to 13\",\n                                    Age == 14 | Age == 15 ~ \"14 to 15\",\n                                    Age == 16 | Age == 17 ~ \"16 to 17\",\n                                    Age >= 18 ~ \"greater than or equal to 18\"))\n\nLc %>%\n  ggplot(aes(y = LungCap, color = Smoke)) +\n  geom_histogram(bins = 25) +\n  facet_wrap(vars(AgeGrp)) +\n  theme_classic() + \n  labs(title = \"Relationship of LungCap and Smoke based on age categories\", y = \"Lung Capacity\", x = \"Frequency\")\n\n\n\n\n\nFrom the above plot, we can derive two important observations: 1. The lung capacity of non smokers is more than smokers. 2. The people who smoke are less in age group of “less than or equal to 13”. So as the result as age increases the lung capacity decreases."
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#e",
    "href": "posts/HW1_ManiShankerKamarapu.html#e",
    "title": "Homework 1",
    "section": "1e",
    "text": "1e\nRelationship between Smoke and Lung capacity on basis of age:\n\n\nCode\nLc %>%\n  ggplot(aes(x = Age, y = LungCap, color = Smoke)) +\n  geom_line() +\n  theme_classic() + \n  facet_wrap(vars(Smoke)) +\n  labs(title = \"Relationship of LungCap and Smoke based on age\", y = \"Lung Capacity\", x = \"Age\")\n\n\n\n\n\nForm the above data we can compare 1d and 1e and can say the results are pretty similar. Only 10 and above age group smoke."
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#f",
    "href": "posts/HW1_ManiShankerKamarapu.html#f",
    "title": "Homework 1",
    "section": "1f",
    "text": "1f\nCalculating the correlation and covariance between Lung Capacity and Age:\n\n\nCode\nCovariance <- cov(Lc$LungCap, Lc$Age)\nCorrelation <- cor(Lc$LungCap, Lc$Age)\nCovariance\n\n\n[1] 8.738289\n\n\nCode\nCorrelation\n\n\n[1] 0.8196749\n\n\nWe can observe from the comparison that the covariance is positive and it indicates that there is a direct relationship between age and lung capacity. And the correlation is also positive, so they move in same direction. We can say from these results that as the age increases, the lung capacity also increases that is they are directly proportional to each other."
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#question-2",
    "href": "posts/HW1_ManiShankerKamarapu.html#question-2",
    "title": "Homework 1",
    "section": "Question 2",
    "text": "Question 2"
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#reading-the-table",
    "href": "posts/HW1_ManiShankerKamarapu.html#reading-the-table",
    "title": "Homework 1",
    "section": "Reading the table",
    "text": "Reading the table\n\n\nCode\nPrior_convitions <- c(0:4)\nInmate_count <- c(128, 434, 160, 64, 24)\nPc <- data_frame(Prior_convitions, Inmate_count)\n\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nPlease use `tibble()` instead.\nThis warning is displayed once every 8 hours.\nCall `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.\n\n\nCode\nPc\n\n\n\n\n  \n\n\n\n\n\nCode\nPc <- mutate(Pc, Probability = Inmate_count/sum(Inmate_count))\nPc"
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#a-1",
    "href": "posts/HW1_ManiShankerKamarapu.html#a-1",
    "title": "Homework 1",
    "section": "2a",
    "text": "2a\nProbability that a randomly selected inmate has exactly 2 prior convictions:\n\n\nCode\nPc %>%\n  filter(Prior_convitions == 2) %>%\n  select(Probability)"
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#b-1",
    "href": "posts/HW1_ManiShankerKamarapu.html#b-1",
    "title": "Homework 1",
    "section": "2b",
    "text": "2b\nProbability that a randomly selected inmate has fewer than 2 convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions < 2)\nsum(temp$Probability)\n\n\n[1] 0.6938272"
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#c-1",
    "href": "posts/HW1_ManiShankerKamarapu.html#c-1",
    "title": "Homework 1",
    "section": "2c",
    "text": "2c\nProbability that a randomly selected inmate has 2 or fewer prior convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions <= 2)\nsum(temp$Probability)\n\n\n[1] 0.891358"
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#d-1",
    "href": "posts/HW1_ManiShankerKamarapu.html#d-1",
    "title": "Homework 1",
    "section": "2d",
    "text": "2d\nProbability that a randomly selected inmate has more than 2 prior convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions > 2)\nsum(temp$Probability)\n\n\n[1] 0.108642"
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#e-1",
    "href": "posts/HW1_ManiShankerKamarapu.html#e-1",
    "title": "Homework 1",
    "section": "2e",
    "text": "2e\nExpected value for the number of prior convictions:\n\n\nCode\nPc <- mutate(Pc, Wm = Prior_convitions*Probability)\ne <- sum(Pc$Wm)\ne\n\n\n[1] 1.28642"
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#f-1",
    "href": "posts/HW1_ManiShankerKamarapu.html#f-1",
    "title": "Homework 1",
    "section": "2f",
    "text": "2f\nVariance for the Prior Convictions:\n\n\nCode\nv <-sum(((Pc$Prior_convitions-e)^2)*Pc$Probability)\nv\n\n\n[1] 0.8562353\n\n\nstandard deviation for the Prior Convictions:\n\n\nCode\nsqrt(v)\n\n\n[1] 0.9253298"
  },
  {
    "objectID": "posts/HW1_PrahithaMovva.html",
    "href": "posts/HW1_PrahithaMovva.html",
    "title": "Homework 1 - Prahitha Movva",
    "section": "",
    "text": "First, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\ndf <- read_excel(\"_data/LungCapData.xls\")\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(df$LungCap)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\n\n\n\n\n\nCode\nboxplot(LungCap~Gender, data = df)\n\n\n\n\n\nFrom the boxplots for gender above, we can see that males seem to have (slightly) higher lung capacity than females.\n\n\n\n\n\nCode\naggregate(data = df, LungCap~Smoke, mean)\n\n\n  Smoke  LungCap\n1    no 7.770188\n2   yes 8.645455\n\n\nThe mean lung capacity for smokers and nonsmokers seems to be higher for smokers. This does not make sense as we generally expect smokers to have a reduced lung capacity due to the damage from smoking.\n\n\n\n\n\nCode\ndf_ageGroups <- mutate(df, AgeGroup = case_when(Age <= 13 ~ \"13 and below\", Age == 14 | Age == 15 ~ \"14 to 15\", Age == 16 | Age == 17 ~ \"16 to 17\", Age >= 18 ~ \"18 and above\"))\n\n\nError in mutate(df, AgeGroup = case_when(Age <= 13 ~ \"13 and below\", Age == : could not find function \"mutate\"\n\n\nCode\nggplot(df_ageGroups, aes(x = LungCap)) +\n  geom_histogram() +\n  facet_grid(AgeGroup~Smoke)\n\n\nError in ggplot(df_ageGroups, aes(x = LungCap)): could not find function \"ggplot\"\n\n\nWe see non-smokers to have a higher lung capacity than smokers, as expected.\n\n\n\nLung capacity seems to be directly proportional to age and after breaking down the data by age groups, we see that the lung capacities for non-smokers are higher than those of smokers in the same age group (except for less than or equal to 13). This could be because of the total number of observations in each age group. The age group less than or equal to 13 has the highest number of observations - thereby skewing the results (here, mean) for the entire distribution.\n\n\n\n\n\nCode\ncor(x= df$LungCap, y = df$Age)\n\n\n[1] 0.8196749\n\n\nCode\ncov(x= df$LungCap, y = df$Age)\n\n\n[1] 8.738289\n\n\nLung capacity seems to be positively correlated with age i.e., as age increases, lung capacity increases. Same is the case with covariance."
  },
  {
    "objectID": "posts/HW1_PrahithaMovva.html#a-1",
    "href": "posts/HW1_PrahithaMovva.html#a-1",
    "title": "Homework 1 - Prahitha Movva",
    "section": "a",
    "text": "a\n\n\nCode\na <- 160/810\n\n\nThe probability that a randomly selected inmate has exactly 2 prior convictions is 0.1975309."
  },
  {
    "objectID": "posts/HW1_PrahithaMovva.html#b-1",
    "href": "posts/HW1_PrahithaMovva.html#b-1",
    "title": "Homework 1 - Prahitha Movva",
    "section": "b",
    "text": "b\n\n\nCode\nb <- (128+434)/810\n\n\nThe probability that a randomly selected inmate has fewer than 2 prior convictions is 0.6938272."
  },
  {
    "objectID": "posts/HW1_PrahithaMovva.html#c-1",
    "href": "posts/HW1_PrahithaMovva.html#c-1",
    "title": "Homework 1 - Prahitha Movva",
    "section": "c",
    "text": "c\n\n\nCode\nc <- (128+434+160)/810\n\n\nThe probability that a randomly selected inmate has 2 or fewer prior convictions is 0.891358."
  },
  {
    "objectID": "posts/HW1_PrahithaMovva.html#d-1",
    "href": "posts/HW1_PrahithaMovva.html#d-1",
    "title": "Homework 1 - Prahitha Movva",
    "section": "d",
    "text": "d\n\n\nCode\nd <- (64+24)/810\n\n\nThe probability that a randomly selected inmate has more than 2 prior convictions is 0.108642."
  },
  {
    "objectID": "posts/HW1_PrahithaMovva.html#e-1",
    "href": "posts/HW1_PrahithaMovva.html#e-1",
    "title": "Homework 1 - Prahitha Movva",
    "section": "e",
    "text": "e\n\n\nCode\ne <- (0*(128/810)) + (1*(434/810)) + (2*(160/810)) + (3*(64/810)) + (4*(24/810))\n\n\nThe expected value for the number of prior convictions is 1.2864198 or 1, as the number of convictions cannot be a float."
  },
  {
    "objectID": "posts/HW1_PrahithaMovva.html#f-1",
    "href": "posts/HW1_PrahithaMovva.html#f-1",
    "title": "Homework 1 - Prahitha Movva",
    "section": "f",
    "text": "f\n\n\nCode\nvar_0 <- ((0-e)^2) * (128/810)\nvar_1 <- ((1-e)^2) * (434/810)\nvar_2 <- ((2-e)^2) * (160/810)\nvar_3 <- ((3-e)^2) * (64/810)\nvar_4 <- ((4-e)^2) * (24/810)\n\nvar <- var_0 + var_1 + var_2 + var_3 + var_4\n\nsd <- sqrt(var)\n\n\nFor prior convictions, the variance is 0.8562353 and the standard deviation is 0.9253298."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html",
    "href": "posts/HW1_Saaradhaa.html",
    "title": "Homework 1",
    "section": "",
    "text": "knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)"
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#a",
    "href": "posts/HW1_Saaradhaa.html#a",
    "title": "Homework 1",
    "section": "1 (a)",
    "text": "1 (a)\nReading in the data:\n\n# load packages.\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(lsr)\n\n# read in data.\ndf <- read_excel(\"_data/LungCapData.xls\")\n\nDistribution of LungCap:\n\nhist(df$LungCap)\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15)."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#b",
    "href": "posts/HW1_Saaradhaa.html#b",
    "title": "Homework 1",
    "section": "1 (b)",
    "text": "1 (b)\nThe boxplots below show the probability distributions grouped by gender.\n\nboxplot(LungCap~Gender, data = df)\n\n\n\n\nMales appear to have a slightly greater lung capacity than females."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#c",
    "href": "posts/HW1_Saaradhaa.html#c",
    "title": "Homework 1",
    "section": "1 (c)",
    "text": "1 (c)\n\n# check class of Smoke.\nclass(df$Smoke)\n\n[1] \"character\"\n\n# convert Smoke to factor type.\ndf$Smoke <- as.factor(df$Smoke)\n\n# mean lung capacity for smokers.\ndf %>% select(Smoke, LungCap) %>% group_by(Smoke) %>% summarise(mean(LungCap))\n\n\n\n  \n\n\n\nIt does not make sense, as I did not expect smokers to have greater mean lung capacities than non-smokers."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#d",
    "href": "posts/HW1_Saaradhaa.html#d",
    "title": "Homework 1",
    "section": "1 (d)",
    "text": "1 (d)\n\n# check class of Age.\nclass(df$Age)\n\n[1] \"numeric\"\n\n# convert Age to categorical variable.\ndf <- mutate(df, AgeGroup = case_when(Age <= 13 ~ \"13 and below\", Age == 14 | Age == 15 ~ \"14 to 15\", Age == 16 | Age == 17 ~ \"16 to 17\", Age >= 18 ~ \"18 and above\"))\n\n# construct histogram.\nggplot(df, aes(x = LungCap)) +\n  geom_histogram() +\n  facet_grid(AgeGroup~Smoke)\n\n\n\n\nMost people seem to be non-smokers, and non-smokers seem to have greater lung capacity."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#e",
    "href": "posts/HW1_Saaradhaa.html#e",
    "title": "Homework 1",
    "section": "1 (e)",
    "text": "1 (e)\n\n# check class of AgeGroup.\nclass(df$AgeGroup)\n\n[1] \"character\"\n\n# convert AgeGroup to factor.\ndf$AgeGroup <- as.factor(df$AgeGroup)\n\n# construct table.\ndf %>% select(Smoke, LungCap, AgeGroup) %>% group_by(AgeGroup, Smoke) %>% summarise(mean(LungCap))\n\n\n\n  \n\n\n\nNon-smokers have greater mean lung capacity for ages 14-15, 16-17 and 18 and above. Smokers have greater mean lung capacity for age 13 and below, which is different from 1(d). There might be some extreme outliers affecting the results for those age 13 and below."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#f",
    "href": "posts/HW1_Saaradhaa.html#f",
    "title": "Homework 1",
    "section": "1 (f)",
    "text": "1 (f)\n\n# correlation.\ncor(df$LungCap,df$Age)\n\n[1] 0.8196749\n\n# covariance.\ncov(df$LungCap,df$Age)\n\n[1] 8.738289\n\n\nThe value of 0.82 for correlation indicates a strong positive relationship between lung capacity and age - as age increases, lung capacity increases. The covariance is a little harder to interpret - the positive value reflects a positive relationship between lung capacity and age, but it is hard to assess the strength of the relationship, given that covariance ranges from negative infinity to infinity. I would prefer to use correlation in most cases."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#a-1",
    "href": "posts/HW1_Saaradhaa.html#a-1",
    "title": "Homework 1",
    "section": "2 (a)",
    "text": "2 (a)\n\na <- 160/810\n\nThe probability that a randomly selected inmate has exactly 2 prior convictions is 0.1975309."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#b-1",
    "href": "posts/HW1_Saaradhaa.html#b-1",
    "title": "Homework 1",
    "section": "2 (b)",
    "text": "2 (b)\n\nb <- (128+434)/810\n\nThe probability that a randomly selected inmate has fewer than 2 prior convictions is 0.6938272."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#c-1",
    "href": "posts/HW1_Saaradhaa.html#c-1",
    "title": "Homework 1",
    "section": "2 (c)",
    "text": "2 (c)\n\nc <- (128+434+160)/810\n\nThe probability that a randomly selected inmate has 2 or fewer prior convictions is 0.891358."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#d-1",
    "href": "posts/HW1_Saaradhaa.html#d-1",
    "title": "Homework 1",
    "section": "2 (d)",
    "text": "2 (d)\n\nd <- (64+24)/810\n\nThe probability that a randomly selected inmate has more than 2 prior convictions is 0.108642."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#e-1",
    "href": "posts/HW1_Saaradhaa.html#e-1",
    "title": "Homework 1",
    "section": "2 (e)",
    "text": "2 (e)\n\n# multiply each value of X by its probability and add the products.\ne <- (0*(128/810)) + (1*(434/810)) + (2*(160/810)) + (3*(64/810)) + (4*(24/810))\n\nThe expected value for the number of prior convictions is 1.2864198. To be more precise, since number of prior convictions should not have decimal places, we can round this down to 1, which is what the line graph showed us as well."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#f-1",
    "href": "posts/HW1_Saaradhaa.html#f-1",
    "title": "Homework 1",
    "section": "2 (f)",
    "text": "2 (f)\n\n# calculate required formula for each value of X.\nf1_0 <- ((0-e)^2) * (128/810)\nf1_1 <- ((1-e)^2) * (434/810)\nf1_2 <- ((2-e)^2) * (160/810)\nf1_3 <- ((3-e)^2) * (64/810)\nf1_4 <- ((4-e)^2) * (24/810)\n\n# sum up the above for variance.\nf1 <- f1_0 + f1_1 + f1_2 + f1_3 + f1_4\n\n# square root for SD.\nf2 <- sqrt(f1)\n\nFor prior convictions, the variance is 0.8562353 and the standard deviation is 0.9253298. In general, I think it might be more meaningful to calculate mode and proportions when generating descriptive statistics for number of prior convictions."
  },
  {
    "objectID": "posts/HW1_Solutions_OmerYalcin.html",
    "href": "posts/HW1_Solutions_OmerYalcin.html",
    "title": "Homework 1",
    "section": "",
    "text": "First, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr, warn.conflicts = F)\nlibrary(magrittr)\ndf <- read_excel(\"_data/LungCapData.xls\")\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(df$LungCap, xlab = 'Lung Capacity', main = '', freq = F)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\n\n\n\n\n\nCode\nboxplot(LungCap ~ Gender, data = df)\n\n\n\n\n\nThe shape of the distribution is similar for males and females. The median, first quartile, third quartile lung capacity values all seem to be somewhat higher for males.\n\n\n\n\n\nCode\ndf %>%\n  group_by(Smoke) %>%\n  summarize(LungCap = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke LungCap\n  <chr>   <dbl>\n1 no       7.77\n2 yes      8.65\n\n\nThe lung capacity for smokers seems to be higher than non-smokers. It goes against the common idea that smoking would hurt lung capacity.\n\n\n\n\nLess than or equal to 13\n\n\n\nCode\ndf %>%\n  filter(Age <= 13) %>%\n  group_by(Smoke) %>%\n  summarize(LungCap = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke LungCap\n  <chr>   <dbl>\n1 no       6.36\n2 yes      7.20\n\n\n\n14 to 15\n\n\n\nCode\ndf %>%\n  filter(Age == 14 | Age == 15) %>%\n  group_by(Smoke) %>%\n  summarize(LungCap = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke LungCap\n  <chr>   <dbl>\n1 no       9.14\n2 yes      8.39\n\n\n\n16 to 17\n\n\n\nCode\ndf %>%\n  filter(Age == 16 | Age == 17) %>%\n  group_by(Smoke) %>%\n  summarize(LungCap = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke LungCap\n  <chr>   <dbl>\n1 no      10.5 \n2 yes      9.38\n\n\n\nGreater than or equal to 18\n\n\n\nCode\ndf %>%\n  filter(Age >= 18) %>%\n  group_by(Smoke) %>%\n  summarize(LungCap = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke LungCap\n  <chr>   <dbl>\n1 no       11.1\n2 yes      10.5\n\n\n\n\n\nFor three out of the four groups, lung capacity if smaller for smokers. This makes another explanation plausible. Smoking is inversely related to lung capacity, but older people both smoke more and have more lung capacity. Thus, considering the relationship between smoking and lung capacity without looking at age makes the relationship look the opposite of what it is.\n\n\n\n\n\nCode\ncov(df$LungCap, df$Age)\n\n\n[1] 8.738289\n\n\nCode\ncor(df$LungCap, df$Age)\n\n\n[1] 0.8196749\n\n\nBoth the correlation and the covariance are positive (when one of them is the other has to). Positive values suggest that people who are older tend to have higher lung capacity, confirming what we found. Since correlation is standardized (needs to be between -1 and 1), its absolute value tells us about the strength of the relationship. 0.82 suggests a pretty strong relationship."
  },
  {
    "objectID": "posts/HW1_Solutions_OmerYalcin.html#a-1",
    "href": "posts/HW1_Solutions_OmerYalcin.html#a-1",
    "title": "Homework 1",
    "section": "a",
    "text": "a\n\n\nCode\ntb %>%\n  filter(X == 2) %>%\n  pull(Frequency) %>%\n  divide_by(n)\n\n\n[1] 0.1975309"
  },
  {
    "objectID": "posts/HW1_Solutions_OmerYalcin.html#b-1",
    "href": "posts/HW1_Solutions_OmerYalcin.html#b-1",
    "title": "Homework 1",
    "section": "b",
    "text": "b\n\n\nCode\ntb %>%\n  filter(X < 2) %>%\n  pull(Frequency) %>%\n  sum() %>%\n  divide_by(n)\n\n\n[1] 0.6938272"
  },
  {
    "objectID": "posts/HW1_Solutions_OmerYalcin.html#c-1",
    "href": "posts/HW1_Solutions_OmerYalcin.html#c-1",
    "title": "Homework 1",
    "section": "c",
    "text": "c\n\n\nCode\ntb %>%\n  filter(X <= 2) %>%\n  pull(Frequency) %>%\n  sum() %>%\n  divide_by(n)\n\n\n[1] 0.891358"
  },
  {
    "objectID": "posts/HW1_Solutions_OmerYalcin.html#d-1",
    "href": "posts/HW1_Solutions_OmerYalcin.html#d-1",
    "title": "Homework 1",
    "section": "d",
    "text": "d\n\n\nCode\ntb %>%\n  filter(X > 2) %>%\n  pull(Frequency) %>%\n  sum() %>%\n  divide_by(n)\n\n\n[1] 0.108642"
  },
  {
    "objectID": "posts/HW1_Solutions_OmerYalcin.html#e-1",
    "href": "posts/HW1_Solutions_OmerYalcin.html#e-1",
    "title": "Homework 1",
    "section": "e",
    "text": "e\nExpected number of prior convictions is just a weighted average of the number of prior convictions.\n\nMethod 1: Multiply every value with their frequency, then divide by total frequency i.e. (0 * 128 + 1 * 434 + 2 * 160 ……) / 810.\n\n\n\nCode\nsum(tb$X * tb$Frequency) / n\n\n\n[1] 1.28642\n\n\n\nMethod 2: Multiply every value with their probility, sum them up.\n\n\n\nCode\ntb %>%\n  mutate(probability = Frequency / n) -> tb\n\nprint(tb)\n\n\n# A tibble: 5 × 3\n      X Frequency probability\n  <dbl>     <dbl>       <dbl>\n1     0       128      0.158 \n2     1       434      0.536 \n3     2       160      0.198 \n4     3        64      0.0790\n5     4        24      0.0296\n\n\n\n\nCode\nsum(tb$X * tb$probability)\n\n\n[1] 1.28642\n\n\n\nMethod 3: Recreate the whole sample (a vector that has 128 zeroes, 434 ones, 160 twos, ….) with a total length/size of 810. Take the mean.\n\n\n\nCode\nsample <- c(rep(0, 128), rep(1, 434), rep(2, 160), rep(3, 64), rep(4, 24))\nmean(sample)\n\n\n[1] 1.28642"
  },
  {
    "objectID": "posts/HW1_Solutions_OmerYalcin.html#f-1",
    "href": "posts/HW1_Solutions_OmerYalcin.html#f-1",
    "title": "Homework 1",
    "section": "f",
    "text": "f\n\nMethod 1: Let’s start from the end: we have the sample, just call var() and sd()\n\n\n\nCode\ncat('Variance:', var(sample))\n\n\nVariance: 0.8572937\n\n\nCode\ncat('\\nStandard Deviation:', sd(sample))\n\n\n\nStandard Deviation: 0.9259016\n\n\nMethod 2: Manually apply the formula using weights.\nStandard deviation is square root of variance. So let’s calculate variance first. For that we need the mean. Let’s pull the expected value from the previous section:\n\n\nCode\nm <- sum(tb$X * tb$Frequency) / n\n\n\nFor every observation, we’ll need the squared difference from mean (squared deviation from mean).\n\n\nCode\ntb %>%\n  mutate(sq_deviation = (X - m)^2) -> tb \nprint(tb)\n\n\n# A tibble: 5 × 4\n      X Frequency probability sq_deviation\n  <dbl>     <dbl>       <dbl>        <dbl>\n1     0       128      0.158        1.65  \n2     1       434      0.536        0.0820\n3     2       160      0.198        0.509 \n4     3        64      0.0790       2.94  \n5     4        24      0.0296       7.36  \n\n\nThen, we can now multiply them with probability.\n\n\nCode\nsum(tb$sq_deviation * tb$probability)\n\n\n[1] 0.8562353\n\n\nThis gives us the ‘population’ variance. If we wanted the ‘sample’ variance, what the var() function does, we could manually apply the Bessel’s correction:\n\n\nCode\nvariance <- sum(tb$sq_deviation * tb$probability) * (n / (n-1))\nprint(variance)\n\n\n[1] 0.8572937\n\n\nStandard deviation is then just the square root:\n\n\nCode\nsqrt(variance)\n\n\n[1] 0.9259016\n\n\nThis replicated what we found directly using the sample."
  },
  {
    "objectID": "posts/HW1_SteveONeill.html",
    "href": "posts/HW1_SteveONeill.html",
    "title": "Homework 1",
    "section": "",
    "text": "Question 2\nI will make a dataframe from the values provided:\n\n\nCode\nprior_convictions=c(0,1,2,3,4)\nfreq=c(128, 434, 160, 64, 24)\nprisondata <- data.frame(prior_convictions, freq)\nprisondata\n\n\n  prior_convictions freq\n1                 0  128\n2                 1  434\n3                 2  160\n4                 3   64\n5                 4   24\n\n\nAnd add a probability column:\n\n\nCode\nprison_prob <- prisondata %>% mutate(prob = freq/sum(freq))\nprison_prob\n\n\n  prior_convictions freq       prob\n1                 0  128 0.15802469\n2                 1  434 0.53580247\n3                 2  160 0.19753086\n4                 3   64 0.07901235\n5                 4   24 0.02962963\n\n\n\n2a.\nWhat is the probability that a randomly selected inmate has exactly 2 prior convictions?\nFrom the table above, the probability is 0.19753086, nearly 20 percent.\n\n\n2b.\nWhat is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\n\nCode\nhead(prison_prob,2) %>% summarise(sum(prob))\n\n\n  sum(prob)\n1 0.6938272\n\n\nThe probability a randomly selected inmate has has fewer than 2 prior convictions is ~69%.\n\n\n2c.\nWhat is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\n\nCode\nhead(prison_prob,3) %>% summarise(sum(prob))\n\n\n  sum(prob)\n1  0.891358\n\n\nThe probability a randomly selected inmate has 2 or fewer convictions is ~89%\n\n\n2d.\nWhat is the probability that a randomly selected inmate has more than 2 prior convictions?\n\n\nCode\ntail(prison_prob,3) %>% summarise(sum(prob))\n\n\n  sum(prob)\n1 0.3061728\n\n\nThe probability a randomly selected inmate has more than 2 prior convictions is ~30.6%\n\n\n2e.\nWhat is the expected value of the number of prior convictions?\n\n\nCode\nsum(prison_prob$prior_convictions*prison_prob$prob)\n\n\n[1] 1.28642\n\n\nCode\n#Or another way,\n\nweighted.mean(prison_prob$prior_convictions,prison_prob$prob)\n\n\n[1] 1.28642\n\n\nThe expected value of prior convictions is 1.28642\n\n\n2f\n\n\nCode\nprison_prob\n\n\n  prior_convictions freq       prob\n1                 0  128 0.15802469\n2                 1  434 0.53580247\n3                 2  160 0.19753086\n4                 3   64 0.07901235\n5                 4   24 0.02962963\n\n\nCode\nvar(prison_prob$freq)\n\n\n[1] 25948\n\n\nCode\nsd(prison_prob$freq)\n\n\n[1] 161.0838\n\n\nThe variance among all prior convictions is 25948. The standard deviation among all prior convictions is 161.0838."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html",
    "href": "posts/HW1_ToryBartelloni.html",
    "title": "DACSS 603: Homework 1",
    "section": "",
    "text": "First, let’s load our packages and read in the data.\n\n\nCode\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(readxl)\n\nlcdata <- read_xls(\"_data/LungCapData.xls\")"
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q1a",
    "href": "posts/HW1_ToryBartelloni.html#q1a",
    "title": "DACSS 603: Homework 1",
    "section": "Q1a",
    "text": "Q1a\nWhat does the distribution of LungCap look like?\n\n\nCode\nlcdata %>% \n  ggplot(aes(x=LungCap)) +\n  geom_histogram(bins=45) +\n  theme_bw() +\n  labs(x=\"Lung Capacity\", y=\"Frequency\", \n       title = \"Lung Capacity Distribution\")\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15)."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q1b",
    "href": "posts/HW1_ToryBartelloni.html#q1b",
    "title": "DACSS 603: Homework 1",
    "section": "Q1b",
    "text": "Q1b\nCompare the probability density of the LungCap with respect to Males and Females.\n\n\nCode\nlcdata %>%\n  ggplot(aes(x=LungCap)) +\n  geom_boxplot(aes(group=Gender, fill=Gender)) +\n  theme_bw() +\n  theme (axis.text.y = element_blank ()) +\n  labs(x=\"Lung Capacity\", title = \"Lung Capacity Distribution\",\n       subtitle = \"Comparing lung capacity between genders\")\n\n\n\n\n\nThe boxplot comparison indicates that on average males have larger lung capacity, but it also shows that the range and IQR for each gender are similar and have a significant amount of overlap."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q1c",
    "href": "posts/HW1_ToryBartelloni.html#q1c",
    "title": "DACSS 603: Homework 1",
    "section": "Q1c",
    "text": "Q1c\nCompare the mean lung capacities for smokers and non-smokers. Does it make sense?\n\n\nCode\nlcdata %>% \n  ggplot(aes(x=LungCap)) +\n  geom_boxplot(aes(fill=Smoke)) +\n  scale_fill_discrete(labels=c(\"Non-Smoker\", \"Smoker\")) +\n  theme_bw() +\n  theme (axis.text.y = element_blank ()) +\n  labs(title=\"Lung Capacity Distribution\", \n       subtitle = \"Comparing smokers and non-smokers\")\n\n\n\n\n\nComparing the distributions shows that Smokers have a higher mean lung capacity and a significantly smaller range and IQR. This does not make sense intuitively so I would want to investigate the data a bit more to understand the possible reasons."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q1d",
    "href": "posts/HW1_ToryBartelloni.html#q1d",
    "title": "DACSS 603: Homework 1",
    "section": "Q1d",
    "text": "Q1d\nExamine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\n\nCode\nlc_with_age_groups <- lcdata %>%\n  mutate(Age_Group = factor(case_when(\n    Age <= 13 ~ \"<=13\",\n    Age %in% c(14,15) ~ \"14-15\",\n    Age %in% c(16,17) ~ \"16-17\",\n    Age >= 18 ~ \">=18\"\n      ),\n    levels = c(\"<=13\",\"14-15\",\"16-17\",\">=18\")\n    )\n  )\n\nlc_with_age_groups %>% \n  ggplot(aes(x=Age_Group,y=LungCap)) +\n  geom_boxplot() +\n  theme_bw() +\n  labs(title=\"Lung Capacity Distribution\", \n       subtitle = \"Comparing age groups\",\n       x=\"Age Group\",\n       y=\"Lung Capacity\")\n\n\n\n\n\nComparing age groups shows a consistent and clear increase in lung capacity as ages increase up to and over 18 years old."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q1e",
    "href": "posts/HW1_ToryBartelloni.html#q1e",
    "title": "DACSS 603: Homework 1",
    "section": "Q1e",
    "text": "Q1e\nCompare the lung capacities for smokers and non-smokers within each age group. Is your answer different from the one in part c? What could possibly be going on here?\n\n\nCode\nlc_with_age_groups %>%\n  ggplot(aes(x=Smoke, y=LungCap)) +\n  geom_boxplot(aes(fill=Smoke)) +\n  scale_fill_discrete(labels=c(\"Non-Smoker\", \"Smoker\")) +\n  facet_wrap(~Age_Group) +\n  theme_bw() +\n  labs(title=\"Lung Capacity Distribution\", \n       subtitle = \"Comparing smokers and non-smokers within age groups\",\n       x=\"Age Group\",\n       y=\"Lung Capacity\")\n\n\n\n\n\nOutside of ages 13 and under all ages groups show higher average, range, and IRQ for non-smokers. It seems likely that the youngest age group, 13 and under, has the largest number of observations of non-smokers which is bringing down the overall average and lower end of the range. This effect is what is causing us to see the higher lung capacity in smokers overall, but we can infer that the causal factor is more likely age than smoking."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q1f",
    "href": "posts/HW1_ToryBartelloni.html#q1f",
    "title": "DACSS 603: Homework 1",
    "section": "Q1f",
    "text": "Q1f\nCalculate the correlation and covariance between Lung Capacity and Age (use the cov() and cor() functions in R). Interpret your results.\n\n\nCode\nknitr::kable(\n  lcdata %>% summarise(Covariance = cov(LungCap, Age),\n                     Correlation = cor(LungCap, Age)),\n  caption = \"Relationship between lung capacity and age.\"\n)\n\n\n\nRelationship between lung capacity and age.\n\n\nCovariance\nCorrelation\n\n\n\n\n8.738289\n0.8196749\n\n\n\n\n\nThe covariance shows us that the relationship is positive and the correlation coefficient shows us that the relationship is a strong, positive relationship. So the older the people in the data the larger the lung capacity was observed, on average."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q2a",
    "href": "posts/HW1_ToryBartelloni.html#q2a",
    "title": "DACSS 603: Homework 1",
    "section": "Q2a",
    "text": "Q2a\nWhat is the probability that a randomly selected inmate has exactly 2 prior convictions?\n\n\nCode\nprison_props <-  prison_data %>% group_by(X) %>%\n    summarise(Frequency = Frequency,\n      Proportion = Frequency / sum(prison_data$Frequency))\nknitr::kable(prison_props,\n  caption=\"Proportion of Inmates\"\n\n)\n\n\n\nProportion of Inmates\n\n\nX\nFrequency\nProportion\n\n\n\n\n0\n128\n0.1580247\n\n\n1\n434\n0.5358025\n\n\n2\n160\n0.1975309\n\n\n3\n64\n0.0790123\n\n\n4\n24\n0.0296296\n\n\n\n\n\nBy calculating the proportion of inmates with each number of prior convictions we can see that the probability of randomly selecting an inmate with 2 prior convictions is 0.1975 or about 19.8%."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q2b",
    "href": "posts/HW1_ToryBartelloni.html#q2b",
    "title": "DACSS 603: Homework 1",
    "section": "Q2b",
    "text": "Q2b\nWhat is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\n\nCode\nprint(paste(\"Probability of fewer than 2 prior convictions:\",\nsum(filter(prison_props, X < 2)$Proportion)))\n\n\n[1] \"Probability of fewer than 2 prior convictions: 0.693827160493827\"\n\n\nSumming prisoners with zero and one prior conviction provides us a probability that 0.6938 or about 69.4% chance that a randomly selected inmate would have less than 2 prior convictions."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q2c",
    "href": "posts/HW1_ToryBartelloni.html#q2c",
    "title": "DACSS 603: Homework 1",
    "section": "Q2c",
    "text": "Q2c\nWhat is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\n\nCode\nprint(paste(\"Probability of 2 or fewer prior convictions:\",\n            sum(filter(prison_props, X <=2)$Proportion)))\n\n\n[1] \"Probability of 2 or fewer prior convictions: 0.891358024691358\"\n\n\nSumming the prisoners with two or fewer prior convictions gives us the probability that 0.89 or about 89% probability that a randomly selected inmate would have two prior convictions or fewer."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q2d",
    "href": "posts/HW1_ToryBartelloni.html#q2d",
    "title": "DACSS 603: Homework 1",
    "section": "Q2d",
    "text": "Q2d\nWhat is the probability that a randomly selected inmate has more than two prior convictions?\n\n\nCode\nprint(paste(\"Probability of more than 2 prior convictions:\",\nsum(filter(prison_props, X > 2)$Proportion)))\n\n\n[1] \"Probability of more than 2 prior convictions: 0.108641975308642\"\n\n\nThe probability found for either 3 or 4 prior convictions (there is no inmate with more than 4 prior convictions) is 0.1084 or about 10.8% probability."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q2e",
    "href": "posts/HW1_ToryBartelloni.html#q2e",
    "title": "DACSS 603: Homework 1",
    "section": "Q2e",
    "text": "Q2e\nWhat is the expected value for the number of prior convictions?\n\n\nCode\nprint(paste(\"The expected value for prior convictions:\", mean(prison_indi_data$X)))\n\n\n[1] \"The expected value for prior convictions: 1.28641975308642\"\n\n\nBy taking a weighted average or an average of all possible observations to select from the expected value is 1.28642 or about 1.3 prior convictions."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q2f",
    "href": "posts/HW1_ToryBartelloni.html#q2f",
    "title": "DACSS 603: Homework 1",
    "section": "Q2f",
    "text": "Q2f\nCalculate the variance and standard deviation for Prior Convictions.\n\n\nCode\nknitr::kable(\n  prison_indi_data %>% summarise(Variance = var(X),\n                     \"Standard Deviation\" = sd(X)),\n  caption = \"Spread of Inmate Prior Convictions\"\n)\n\n\n\nSpread of Inmate Prior Convictions\n\n\nVariance\nStandard Deviation\n\n\n\n\n0.8572937\n0.9259016"
  },
  {
    "objectID": "posts/HW1_Yakub Rabiutheen.html",
    "href": "posts/HW1_Yakub Rabiutheen.html",
    "title": "Homework 1",
    "section": "",
    "text": "First, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\ndf <- read_excel(\"_data/LungCapData.xls\")\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(df$LungCap,freq = FALSE)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\n\n\n\nComparison of the Genders for both Men and Women using a Boxplot.\n\n\nCode\nboxplot(df$LungCap ~ df$Gender)\n\n\n\n\n\n\n\n\nHere is the capacity of Smokers vs Non-Smokers\n\n\nCode\nboxplot(df$LungCap~df$Smoke,\n        ylab = \"Capacity\", \n        main = \"Lung Capacity of Smokers Vs Non-Smokers\",\n        las = 1)\n\n\n\n\n\n\n\n\nLet’s break it down even further, this is the Lung Capacity by Age Group\n\n\nCode\ndf$Agegroups<-cut(df$Age,breaks=c(-Inf, 13, 15, 17, 20), labels=c(\"0-13 years\", \"14-15 years\", \"16-17 years\", \"18+ years\"))\n\n\nBelow is the overall Lung Capacity of Age Groups without including Smokers.\n\n\nCode\nlibrary(ggplot2)\nggplot(df, aes(x = LungCap, y = Agegroups, fill = Gender)) +\n          geom_bar(stat = \"identity\") +\n          coord_flip() +\n          theme_classic()\n\n\n\n\n\n#e\nHere is a comparision of AgeGroup Lung Capacity in comparison with Smoker vs Non-Smoker.\n\n\nCode\nggplot(df, aes(x = LungCap, y = Agegroups, fill = Smoke)) +\n    geom_bar(stat = \"identity\") +\n    coord_flip() +\n    theme_classic()\n\n\n\n\n\n\n\n\nBased on the comparison of lung capacities between Smoker and Non-Smoker the results are pretty similar.\n\n\nCode\ncov(df$LungCap, df$Age)\n\n\n[1] 8.738289\n\n\nCode\ncor(df$LungCap, df$Age)\n\n\n[1] 0.8196749\n\n\nQuestion 2\n\n\nCode\nX <- c(0:4)\nFrequency <- c(128, 434, 160, 64, 24)\ndf <- data.frame(X, Frequency)\ndf\n\n\n  X Frequency\n1 0       128\n2 1       434\n3 2       160\n4 3        64\n5 4        24\n\n\nAs shown below, the most common Prior Convictions is 1.\n\n\nCode\ndf\n\n\n  X Frequency\n1 0       128\n2 1       434\n3 2       160\n4 3        64\n5 4        24\n\n\nDividing by the total among 810 we can determine the probability for each. 810 is the Sum of the Frequency which I checked manually.\n\n\nCode\ndf2 <- mutate(df, Probability = Frequency/sum(Frequency))\n\n\nError in mutate(df, Probability = Frequency/sum(Frequency)): could not find function \"mutate\"\n\n\nCode\ndf2\n\n\nError in eval(expr, envir, enclos): object 'df2' not found\n\n\n\nFilter for Probability of 2 Convictions\n\n\n\nCode\nb2 <- df2 %>% \n  filter(X < 2)\n\n\nError in df2 %>% filter(X < 2): could not find function \"%>%\"\n\n\nCode\nsum(b2$Probability)\n\n\nError in eval(expr, envir, enclos): object 'b2' not found\n\n\n\nFilter for Probability of Less than 2 Convictions\n\n\n\nCode\nc2 <- df2 %>% \n  filter(X <= 2)\n\n\nError in df2 %>% filter(X <= 2): could not find function \"%>%\"\n\n\nCode\nsum(c2$Probability)\n\n\nError in eval(expr, envir, enclos): object 'c2' not found\n\n\n\n\n\nFilter for Probability of greater than 2 convictions.\n\n\nCode\nd2 <- df2 %>% \n  filter(X > 2)\n\n\nError in df2 %>% filter(X > 2): could not find function \"%>%\"\n\n\nCode\nsum(d2$Probability)\n\n\nError in eval(expr, envir, enclos): object 'd2' not found\n\n\nWhat is the expected value of the number of prior convictions?\n\n\nCode\ne <- weighted.mean(df2$X, df2$Probability)\n\n\nError in weighted.mean(df2$X, df2$Probability): object 'df2' not found\n\n\nCode\ne\n\n\nError in eval(expr, envir, enclos): object 'e' not found\n\n\n\n\n\nVariance and Standard Deviation for Question.\n\n\nCode\nvar(df$X)\n\n\n[1] 2.5\n\n\n\n\nCode\nsd(df$X)\n\n\n[1] 1.581139"
  },
  {
    "objectID": "posts/HW_1_603.html",
    "href": "posts/HW_1_603.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(stats)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/HW_1_603.html#question-1",
    "href": "posts/HW_1_603.html#question-1",
    "title": "Homework 1",
    "section": "Question 1",
    "text": "Question 1\n\n\nCode\nLung_data<- read_excel(\"C:/Users/manik/Desktop/LungCapData.xls\")\nLung_data\n\n\n\n\n  \n\n\n\nGiven data consists of 725 rows and 6 columns\n\nWhat does the distribution of LungCap look like?\n\n\n\nCode\nLung_data %>%\n  ggplot(aes(LungCap, ..density..)) +\n  geom_histogram() +\n  geom_density(color = \"Red\") +\n  theme_classic() + \n  labs(title = \"Probability distribution of LungCap\", x = \"Lung Capcity\", y = \"Probability density\")\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nBased on above histogram , we can say the distribution is very close to the normal distribution\nCompare the probability distribution of the LungCap with respect to Males and Females?\n\n\nCode\nLung_data %>%\n  ggplot(aes(y = dnorm(LungCap), color = Gender)) +\n  geom_boxplot() +\n  labs(title = \"Probability distribution of LungCap based on gender\", y = \"Probability density\")\n\n\n\n\n\nCompare the mean lung capacities for smokers and non-smokers. Does it make sense?\n\n\nCode\nMean_smokers <- Lung_data %>%\n  group_by(Smoke) %>%\n  summarise(mean = mean(LungCap))\nMean_smokers\n\n\n\n\n  \n\n\n\nThe mean of the lung capacity who smokes is greater than the people who doesnt smoke which doesnt make any sense in practical\nExamine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\n\nCode\nLung_data <- mutate(Lung_data, AgeGrp = case_when(Age <= 13 ~ \"less than or equal to 13\",\n                                    Age == 14 | Age == 15 ~ \"14 to 15\",\n                                    Age == 16 | Age == 17 ~ \"16 to 17\",\n                                    Age >= 18 ~ \"greater than or equal to 18\"))\n\nLung_data %>%\n  ggplot(aes(y = LungCap, color = Smoke)) +\n  geom_histogram(bins = 25) +\n  facet_wrap(vars(AgeGrp)) +\n  theme_classic() + coord_flip()\n\n\n\n\n\nCode\n  labs(title = \"Relationship of LungCap and Smoke based on age categories\", y = \"Lung Capacity\", x = \"Frequency\")\n\n\n$y\n[1] \"Lung Capacity\"\n\n$x\n[1] \"Frequency\"\n\n$title\n[1] \"Relationship of LungCap and Smoke based on age categories\"\n\nattr(,\"class\")\n[1] \"labels\"\n\n\nCompare the lung capacities for smokers and non-smokers within each age group. Is your answer different from the one in part d. What could possibly be going on here?\n\n\nCode\nLung_data %>%\n  ggplot(aes(x = Age, y = LungCap, color = Smoke)) +\n  geom_line() +\n  theme_classic() + \n  facet_wrap(vars(Smoke)) +\n  labs(title = \"Relationship of LungCap and Smoke based on age\", y = \"Lung Capacity\", x = \"Age\")\n\n\n\n\n\nForm the above data we can compare 1d and 1e and can say the results are pretty similar. Only 10 and above age group smoke.\nCalculate the correlation and covariance between Lung Capacity and Age. (use the cov() and cor() functions in R). Interpret your results.\n\n\nCode\nCovariance_LA <- cov(Lung_data$LungCap, Lung_data$Age)\nCorrelation_LA <- cor(Lung_data$LungCap, Lung_data$Age)\nCovariance_LA\n\n\n[1] 8.738289\n\n\nCode\nCorrelation_LA\n\n\n[1] 0.8196749\n\n\nFrom the above result we can say that both covariance and correlation is positive and which indicates direct relationship that means Lungcapacity increases as age increases"
  },
  {
    "objectID": "posts/HW_1_603.html#question-2",
    "href": "posts/HW_1_603.html#question-2",
    "title": "Homework 1",
    "section": "Question 2",
    "text": "Question 2\n\n\nCode\nPrior_convitions <- c(0:4)\nInmate_count <- c(128, 434, 160, 64, 24)\nIP<- data_frame(Prior_convitions, Inmate_count)\n\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nPlease use `tibble()` instead.\nThis warning is displayed once every 8 hours.\nCall `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.\n\n\nCode\nIP\n\n\n\n\n  \n\n\n\n\n\nCode\nIP <- mutate(IP, Probability = Inmate_count/sum(Inmate_count))\nIP\n\n\n\n\n  \n\n\n\nWhat is the probability that a randomly selected inmate has exactly 2 prior convictions?\n\n\nCode\nIP %>%\n  filter(Prior_convitions == 2) %>%\n  select(Probability)\n\n\n\n\n  \n\n\n\nWhat is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\n\nCode\np_2 <- IP %>%\n  filter(Prior_convitions < 2)\nsum(p_2$Probability)\n\n\n[1] 0.6938272\n\n\nWhat is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\n\nCode\np <- IP %>%\n  filter(Prior_convitions <= 2)\nsum(p$Probability)\n\n\n[1] 0.891358\n\n\nWhat is the probability that a randomly selected inmate has more than 2 prior convictions?\n\n\nCode\nP_3 <- IP %>%\n  filter(Prior_convitions > 2)\nsum(P_3$Probability)\n\n\n[1] 0.108642\n\n\nWhat is the expected value for the number of prior convictions?\n\n\nCode\nIP <- mutate(IP, Wm = Prior_convitions*Probability)\nexpe<- sum(IP$Wm)\nexpe\n\n\n[1] 1.28642\n\n\nCalculate the variance and the standard deviation for the Prior Convictions.\n\n\nCode\nvar_ <-sum(((IP$Prior_convitions-expe)^2)*IP$Probability)\nvar_\n\n\n[1] 0.8562353\n\n\nstandard deviation:\n\n\nCode\nsqrt(var_)\n\n\n[1] 0.9253298"
  },
  {
    "objectID": "posts/HW_1_QH.html",
    "href": "posts/HW_1_QH.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readxl)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/HW_1_QH.html#a",
    "href": "posts/HW_1_QH.html#a",
    "title": "Homework 1",
    "section": "1a",
    "text": "1a\n\n\nCode\nggplot(LungCapData, mapping = aes(LungCap)) +\n  geom_histogram(color = \"black\", fill = \"grey\")+\n  geom_density()+\n  labs(title = \"Distribution of Lung Capacity\", x = \"Lung Capacity\", y = \"Count\")\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nCode\nplot(x = LungCapData$LungCap, y = lungcap_prob_dense)\n\n\n\n\n\nWith these two functions I can see the distribution is normal with both a histogram and regular graph. The second graph more clearly depicts a normal distribution with the probability density points laid throughout. ## 1b\n\n\nCode\nggplot(LungCapData, mapping = aes(x = Gender, y = LungCap)) +\n  geom_boxplot() \n\n\n\n\n\nIt looks like men, on average, have a higher lung capacity than females, but only by a slim margin. Overall, lung capacity is relatively similar among genders. The real comparison will come with smokers and nonsmokers. ## 1c\n\n\nCode\nLungCapData %>% \n  group_by(Smoke) %>% \n  summarise(lung_cap_mean = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke lung_cap_mean\n  <chr>         <dbl>\n1 no             7.77\n2 yes            8.65\n\n\nAbove is the lung capacity mean for smokers and nonsmokers. I’m actually a little surprised the mean lung capacity for nonsmokers is slightly higher than that of nonsmokers. I would think the opposite to be true, but I suspect because there is a range of ages under 18 and the body is not fully developed yet, I imagine a 6 year old nonsmoker will not have the same lung capacity as a 17 year old smoker."
  },
  {
    "objectID": "posts/HW_1_QH.html#d",
    "href": "posts/HW_1_QH.html#d",
    "title": "Homework 1",
    "section": "1d",
    "text": "1d\nBelow I created a bunch of variables to separate people into certain age groups. I imagine there would be an easier way to separate them.\n\n\nCode\n#LungCapData %>% \n  #group_by(Age) %>% \n  #summarise(lungcap = mean(LungCap))\n  \nage13 <- LungCapData %>% \n  filter(Age <= 13) %>%\n  group_by(Smoke) %>% \n  summarise(lung_cap_mean = mean(LungCap))\n\nage1415 <- LungCapData %>% \n  filter(Age == 14 | Age == 15) %>%\n  group_by(Smoke) %>% \n  summarise(lung_cap_mean = mean(LungCap))\n\nage1617 <- LungCapData %>% \n  filter(Age == 16 | Age == 17) %>%\n  group_by(Smoke) %>% \n  summarise(lung_cap_mean = mean(LungCap))\n\nage18 <- LungCapData %>% \n  filter(Age >= 18) %>%\n  group_by(Smoke) %>% \n  summarise(lung_cap_mean = mean(LungCap))\n\nage13\n\n\n# A tibble: 2 × 2\n  Smoke lung_cap_mean\n  <chr>         <dbl>\n1 no             6.36\n2 yes            7.20\n\n\nCode\nage1415\n\n\n# A tibble: 2 × 2\n  Smoke lung_cap_mean\n  <chr>         <dbl>\n1 no             9.14\n2 yes            8.39\n\n\nCode\nage1617\n\n\n# A tibble: 2 × 2\n  Smoke lung_cap_mean\n  <chr>         <dbl>\n1 no            10.5 \n2 yes            9.38\n\n\nCode\nage18\n\n\n# A tibble: 2 × 2\n  Smoke lung_cap_mean\n  <chr>         <dbl>\n1 no             11.1\n2 yes            10.5"
  },
  {
    "objectID": "posts/HW_1_QH.html#e",
    "href": "posts/HW_1_QH.html#e",
    "title": "Homework 1",
    "section": "1e",
    "text": "1e\nBased on the variables I created above, it appears the lung capacity for people under 13, and that smoke, is higher than people who do not smoke. As the age brackets increase, so does lung capacity overall, but it begins to show that those who do smoke, generally have a lower lung capacity than those who choose not to smoke. This is what I would expect to happen since a 13 year old still has plenty of growing to do, therefore the lung capacity will be much lower than a grown teenager."
  },
  {
    "objectID": "posts/HW_1_QH.html#f",
    "href": "posts/HW_1_QH.html#f",
    "title": "Homework 1",
    "section": "1f",
    "text": "1f\n\n\nCode\ncor(LungCapData$LungCap, LungCapData$Age)\n\n\n[1] 0.8196749\n\n\nWith a correlation of 0.81, lung capacity and age have a fairly strong positive relationship. This is what I figured would be the case. As people age, their lung capacities grow larger. A 17 year old will be more developed and most likely have a larger lung capacity than, say, a child the age of 8.\nI created a table of the data frame in question 2\n\n\nCode\nxx <- c(0:4)\n\nfreq <- c(128, 434, 160, 64, 24)\n\ndf <- tibble(xx, freq)"
  },
  {
    "objectID": "posts/HW_1_QH.html#a-1",
    "href": "posts/HW_1_QH.html#a-1",
    "title": "Homework 1",
    "section": "2a",
    "text": "2a\n\n\nCode\n160/810\n\n\n[1] 0.1975309\n\n\nThe probability of selecting inmates with 2 prior convictions is 19.7%."
  },
  {
    "objectID": "posts/HW_1_QH.html#b",
    "href": "posts/HW_1_QH.html#b",
    "title": "Homework 1",
    "section": "2b",
    "text": "2b\n\n\nCode\n562/810\n\n\n[1] 0.6938272\n\n\nThe probability of selecting inmates with less than 2 prior convictions is 69%."
  },
  {
    "objectID": "posts/HW_1_QH.html#c",
    "href": "posts/HW_1_QH.html#c",
    "title": "Homework 1",
    "section": "2c",
    "text": "2c\n\n\nCode\n722/810\n\n\n[1] 0.891358\n\n\nThe probability of selecting inmates with 2 or less prior convictions is 89%."
  },
  {
    "objectID": "posts/HW_1_QH.html#d-1",
    "href": "posts/HW_1_QH.html#d-1",
    "title": "Homework 1",
    "section": "2d",
    "text": "2d\n\n\nCode\n88/810\n\n\n[1] 0.108642\n\n\nThe probability of selecting inmates with more than 2 prior convictions is 10.8%."
  },
  {
    "objectID": "posts/HW_1_QH.html#e-1",
    "href": "posts/HW_1_QH.html#e-1",
    "title": "Homework 1",
    "section": "2e",
    "text": "2e\nThe expected value for number of prior convictions is 291.4.\n\n\nCode\ntest <- c(128, 434, 160, 64, 24)\n\ntestprobs <- c(0.15, 0.54, 0.2, 0.08, 0.03)\n\nsum(test*testprobs)\n\n\n[1] 291.4"
  },
  {
    "objectID": "posts/HW_1_QH.html#f-1",
    "href": "posts/HW_1_QH.html#f-1",
    "title": "Homework 1",
    "section": "2f",
    "text": "2f\nuse rep()\n\n\nCode\nconvictions <- c(rep(0,128), rep(1, 434), rep(2,160), rep(3,64), rep(4,24))\n\nsd(convictions)\n\n\n[1] 0.9259016\n\n\nCode\nvar(convictions)\n\n\n[1] 0.8572937"
  },
  {
    "objectID": "posts/KarenDetter_FinalPt1.html",
    "href": "posts/KarenDetter_FinalPt1.html",
    "title": "Final Project Proposal",
    "section": "",
    "text": "Background / Research Question\nWhat predicts support for government regulation of ‘Big Tech’?\nIn 2001, Google piloted a program to boost profits, which were sinking as the “dot-com bubble” burst, by collecting data generated from users’ search queries and using it to sell precisely targeted advertising. The company’s ad revenues grew so quickly that they expanded their data collection tools with tracking “cookies” and predictive algorithms. Other technology firms took notice of Google’s soaring profits, and the sale of passively-collected data from people’s online activities soon became the predominant business model of the internet economy (Zuboff, 2015).\nAs the data-collection practices of ‘Big Tech’ firms, including Google, Amazon, Facebook (Meta), Apple, and Microsoft, have gradually been exposed, the public is now aware that the ‘free’ platforms that have become essential to daily life are actually harvesting personal information as payment. Despite consumers being essentially extorted into accepting this arrangement, regulatory intervention of ‘surveillance capitalism’ has remained limited.\nOver the two decades since passive data collection began commercializing the internet, survey research has shown the American public’s increasing concern about the dominance Big Tech has been allowed to exert. A 2019 study conducted by Pew Research Center found that 81% of Democrats and 70% of Republicans think there should be more government regulation of corporate data-use practices (Pew Research Center, 2019). It is very unusual to find majorities of both Republicans and Democrats agreeing on any policy position, since party affiliation is known to be a main predictor of any political stance, especially in the current polarized climate. The natural question that arises, then, is what other factors predict support for increased regulation of data-collection practices?\n\n\nHypothesis\nAlthough few studies have directly examined the mechanisms behind public support for regulation of passive data collection, a good amount of research has been done on factors influencing individual adoption of privacy protection measures (Barth et al., 2019; Boerman et al., 2021; Turow et al., 2015). It seems a reasonable extrapolation that these factors would similarly influence support for additional data privacy regulation, leading to these hypotheses:\n\nA higher level of awareness of data collection issues predicts support for increased ‘Big Tech’ regulation.\nGreater understanding of how companies use passively collected data predicts support for increased regulation.\nThe feeling of having no personal control over online tracking ‘digital resignation’ predicts support for increased regulation.\nCertain demographics (age group, education level, and political ideology) have an effect on attitudes toward ‘Big Tech’ regulation.\n\nSince there are currently dozens of data privacy bills pending in Congress, pinpointing the forces driving support for this type of legislation can help with both shaping the regulatory framework needed and appealing for broader support from voters.\n\n\nDescriptive Statistics\nPew Research Center’s American Trends Panel (Wave 49) data set can provide insight into which of these factors are predictive of support for greater regulation of technology company data practices. In June 2019, an online survey covering a wide variety of topics was conducted and 4,272 separate observations for 144 variables were collected from adults age 18 and over. The margin of error (at the 95% confidence level) is given as +/- 1.87 percentage points.\nThe data set was compiled in SPSS and all pertinent variables are categorical.\n\n\nCode\n#read in data from SPSS file\nwav49 <- read_sav(\"_data/ATPW49.sav\")\nwav49\n\n\n# A tibble: 4,272 × 144\n     QKEY DEVICE_TYPE_…¹ LANG_…² FORM_…³ SOCME…⁴ SOCME…⁵ SOCME…⁶ SOCME…⁷ SNSUS…⁸\n    <dbl> <dbl+lbl>      <dbl+l> <dbl+l> <dbl+l> <dbl+l> <dbl+l> <dbl+l> <dbl+l>\n 1 100260 2 [Tablet]     9 [Eng… 2 [For… 2 [No,… 2 [No,… 2 [No,… 2 [No,… 0 [Doe…\n 2 100588 1 [Mobile pho… 9 [Eng… 1 [For… 1 [Yes… 1 [Yes… 1 [Yes… 2 [No,… 1 [Soc…\n 3 100637 3 [Desktop]    9 [Eng… 1 [For… 1 [Yes… 2 [No,… 2 [No,… 2 [No,… 1 [Soc…\n 4 101224 1 [Mobile pho… 9 [Eng… 2 [For… 1 [Yes… 2 [No,… 2 [No,… 2 [No,… 1 [Soc…\n 5 101322 1 [Mobile pho… 9 [Eng… 1 [For… 1 [Yes… 2 [No,… 2 [No,… 2 [No,… 1 [Soc…\n 6 101437 3 [Desktop]    9 [Eng… 2 [For… 1 [Yes… 2 [No,… 2 [No,… 2 [No,… 1 [Soc…\n 7 101472 1 [Mobile pho… 9 [Eng… 1 [For… 1 [Yes… 2 [No,… 1 [Yes… 2 [No,… 1 [Soc…\n 8 101493 3 [Desktop]    9 [Eng… 1 [For… 1 [Yes… 2 [No,… 2 [No,… 1 [Yes… 1 [Soc…\n 9 102198 1 [Mobile pho… 9 [Eng… 1 [For… 1 [Yes… 1 [Yes… 2 [No,… 1 [Yes… 1 [Soc…\n10 103094 1 [Mobile pho… 9 [Eng… 1 [For… 1 [Yes… 1 [Yes… 1 [Yes… 1 [Yes… 1 [Soc…\n# … with 4,262 more rows, 135 more variables: ELECTFTGSNSINT_W49 <dbl+lbl>,\n#   TALKDISASNSINT_W49 <dbl+lbl>, TALKCMNSNSINT_W49 <dbl+lbl>,\n#   SECUR1_W49 <dbl+lbl>, PRIVACYNEWS1_W49 <dbl+lbl>,\n#   HOMEASSIST1_W49 <dbl+lbl>, HOMEASSIST2_W49 <dbl+lbl>,\n#   HOMEASSIST3_W49 <dbl+lbl>, HOMEASSIST4_W49 <dbl+lbl>,\n#   HOMEASSIST5a_W49 <dbl+lbl>, HOMEASSIST5b_W49 <dbl+lbl>,\n#   HOMEIOT_W49 <dbl+lbl>, FITTRACK_W49 <dbl+lbl>, LOYALTY_W49 <dbl+lbl>, …\n\n\nSince there are so many variables in the data set, selecting the variables of interest into a new data frame will make it easier to manage:\n\n\nCode\nsel_vars <- c('PRIVACYNEWS1_W49', 'TRACKCO1a_W49', 'CONTROLCO_W49', 'UNDERSTANDCO_W49', 'ANONYMOUS1CO_W49', 'PP4_W49', 'PRIVACYREG_W49', 'GOVREGV1_W49', 'PROFILE4_W49', 'F_AGECAT', 'F_EDUCCAT', 'F_PARTYSUM_FINAL', 'F_IDEO')\nwav49_selected <- wav49[sel_vars]\nwav49_selected\n\n\n# A tibble: 4,272 × 13\n   PRIVACYNEWS1_…¹ TRACKC…² CONTRO…³ UNDERS…⁴ ANONYM…⁵ PP4_W49  PRIVA…⁶ GOVREG…⁷\n   <dbl+lbl>       <dbl+lb> <dbl+lb> <dbl+lb> <dbl+lb> <dbl+lb> <dbl+l> <dbl+lb>\n 1 4 [Not at all … NA       NA       NA       NA       NA       3 [Ver… NA      \n 2 3 [Not too clo…  3 [Som…  2 [Som…  3 [Ver…  1 [Yes…  3 [Ver… 3 [Ver…  1 [Mor…\n 3 3 [Not too clo…  3 [Som…  3 [Ver…  3 [Ver…  1 [Yes…  2 [Som… 3 [Ver…  1 [Mor…\n 4 4 [Not at all … NA       NA       NA       NA        3 [Ver… 3 [Ver… NA      \n 5 4 [Not at all …  1 [All…  4 [No …  4 [Not…  2 [No,… NA       4 [Not…  1 [Mor…\n 6 2 [Somewhat cl… NA       NA       NA       NA        3 [Ver… 3 [Ver… NA      \n 7 2 [Somewhat cl…  2 [Mos…  3 [Ver…  3 [Ver…  2 [No,…  2 [Som… 2 [Som…  3 [Abo…\n 8 1 [Very closel…  1 [All…  4 [No …  4 [Not…  2 [No,… NA       3 [Ver…  3 [Abo…\n 9 3 [Not too clo…  1 [All…  3 [Ver…  2 [Som…  2 [No,…  3 [Ver… 3 [Ver…  1 [Mor…\n10 3 [Not too clo…  3 [Som…  2 [Som…  1 [A g…  1 [Yes…  2 [Som… 2 [Som…  2 [Les…\n# … with 4,262 more rows, 5 more variables: PROFILE4_W49 <dbl+lbl>,\n#   F_AGECAT <dbl+lbl>, F_EDUCCAT <dbl+lbl>, F_PARTYSUM_FINAL <dbl+lbl>,\n#   F_IDEO <dbl+lbl>, and abbreviated variable names ¹​PRIVACYNEWS1_W49,\n#   ²​TRACKCO1a_W49, ³​CONTROLCO_W49, ⁴​UNDERSTANDCO_W49, ⁵​ANONYMOUS1CO_W49,\n#   ⁶​PRIVACYREG_W49, ⁷​GOVREGV1_W49\n\n\nThe variable labels contain the survey questions asked:\n\n\nCode\n#summary of $variable names and their [labels]\nvar_label(wav49_selected)\n\n\n$PRIVACYNEWS1_W49\n[1] \"PRIVACYNEWS1. How closely, if at all, do you follow news about privacy issues?\"\n\n$TRACKCO1a_W49\n[1] \"TRACKCO1a. As far as you know, how much of what you do ONLINE or on your cellphone is being tracked by advertisers, technology firms or other companies?\"\n\n$CONTROLCO_W49\n[1] \"CONTROLCO. How much control do you think you have over the data that companies collect about you?\"\n\n$UNDERSTANDCO_W49\n[1] \"UNDERSTANDCO. How much do you feel you understand what companies are doing with the data they collect about you?\"\n\n$ANONYMOUS1CO_W49\n[1] \"ANONYMOUS1CO. Do you think it is possible to go about daily life today without having companies collect data about you?\"\n\n$PP4_W49\n[1] \"PP4. How much do you typically understand the privacy policies you read?\"\n\n$PRIVACYREG_W49\n[1] \"PRIVACYREG. How much do you feel you understand the laws and regulations that are currently in place to protect your data privacy?\"\n\n$GOVREGV1_W49\n[1] \"GOVREGV1. How much government regulation of what companies can do with their customers’ personal information do you think there should be?\"\n\n$PROFILE4_W49\n[1] \"PROFILE4. How much, if at all, do you understand what data about you is being used to create these advertisements?\"\n\n$F_AGECAT\n[1] \"Age category\"\n\n$F_EDUCCAT\n[1] \"Education level category\"\n\n$F_PARTYSUM_FINAL\n[1] \"Party summary\"\n\n$F_IDEO\n[1] \"Ideology\"\n\n\nBecause the data set is made up of categorical variables, transformation is required before computing any statistics:\n\n\nCode\n#convert all variables to factors\nwav49_factored <- wav49_selected %>%\n  mutate_all(as_factor)\n#convert user-defined missing values to regular missing values\nzap_missing(wav49_factored)\n\n\n# A tibble: 4,272 × 13\n   PRIVACYNEWS…¹ TRACK…² CONTR…³ UNDER…⁴ ANONY…⁵ PP4_W49 PRIVA…⁶ GOVRE…⁷ PROFI…⁸\n   <fct>         <fct>   <fct>   <fct>   <fct>   <fct>   <fct>   <fct>   <fct>  \n 1 Not at all c… <NA>    <NA>    <NA>    <NA>    <NA>    Very l… <NA>    <NA>   \n 2 Not too clos… Some o… Some c… Very l… Yes, i… Very l… Very l… More r… <NA>   \n 3 Not too clos… Some o… Very l… Very l… Yes, i… Some    Very l… More r… Somewh…\n 4 Not at all c… <NA>    <NA>    <NA>    <NA>    Very l… Very l… <NA>    <NA>   \n 5 Not at all c… All or… No con… Nothing No, it… <NA>    Not at… More r… Not to…\n 6 Somewhat clo… <NA>    <NA>    <NA>    <NA>    Very l… Very l… <NA>    Not to…\n 7 Somewhat clo… Most o… Very l… Very l… No, it… Some    Some    About … Somewh…\n 8 Very closely  All or… No con… Nothing No, it… <NA>    Very l… About … Somewh…\n 9 Not too clos… All or… Very l… Some    No, it… Very l… Very l… More r… Somewh…\n10 Not too clos… Some o… Some c… A grea… Yes, i… Some    Some    Less r… Somewh…\n# … with 4,262 more rows, 4 more variables: F_AGECAT <fct>, F_EDUCCAT <fct>,\n#   F_PARTYSUM_FINAL <fct>, F_IDEO <fct>, and abbreviated variable names\n#   ¹​PRIVACYNEWS1_W49, ²​TRACKCO1a_W49, ³​CONTROLCO_W49, ⁴​UNDERSTANDCO_W49,\n#   ⁵​ANONYMOUS1CO_W49, ⁶​PRIVACYREG_W49, ⁷​GOVREGV1_W49, ⁸​PROFILE4_W49\n\n\nAfter the variables are converted to meaningful factors, a summary of response frequencies can be generated:\n\n\nCode\nsummary(wav49_factored)\n\n\n           PRIVACYNEWS1_W49                 TRACKCO1a_W49 \n Very closely      : 461    All or almost all of it: 881  \n Somewhat closely  :2046    Most of it             : 703  \n Not too closely   :1397    Some of it             : 381  \n Not at all closely: 359    Very little of it      :  88  \n Refused           :   9    None of it             :  76  \n                            Refused                :  11  \n                            NA's                   :2132  \n                 CONTROLCO_W49      UNDERSTANDCO_W49\n A great deal of control:  68   A great deal: 132   \n Some control           : 313   Some        : 716   \n Very little control    :1134   Very little :1040   \n No control             : 621   Nothing     : 242   \n Refused                :   4   Refused     :  10   \n NA's                   :2132   NA's        :2132   \n                                                    \n               ANONYMOUS1CO_W49         PP4_W49          PRIVACYREG_W49\n Yes, it is possible   : 772    A great deal: 328   A great deal: 136  \n No, it is not possible:1357    Some        :1405   Some        :1380  \n Refused               :  11    Very little : 751   Very little :2153  \n NA's                  :2132    Not at all  :  82   Not at all  : 593  \n                                Refused     :   5   Refused     :  10  \n                                NA's        :1701                      \n                                                                       \n                GOVREGV1_W49        PROFILE4_W49    F_AGECAT   \n More regulation      :1631   A great deal: 384   18-29 : 671  \n Less regulation      : 145   Somewhat    :1410   30-49 :1314  \n About the same amount: 331   Not too much: 900   50-64 :1308  \n Refused              :  33   Not at all  : 113   65+   : 977  \n NA's                 :2132   Refused     :   9   DK/REF:   2  \n                              NA's        :1456                \n                                                               \n                 F_EDUCCAT              F_PARTYSUM_FINAL\n College graduate+    :1600   Rep/Lean Rep      :1823   \n Some College         :1182   Dem/Lean Dem      :2296   \n H.S. graduate or less:1483   DK/Refused/No lean: 153   \n Don't know/Refused   :   7                             \n                                                        \n                                                        \n                                                        \n               F_IDEO    \n Very conservative: 353  \n Conservative     : 977  \n Moderate         :1615  \n Liberal          : 828  \n Very liberal     : 386  \n Refused          : 113  \n                         \n\n\n*High NA value indicates that the question was not presented to all respondents\nThe data set is now primed for examining correlations and testing hypotheses.\n\n\nReferences\nBarth, S., de Jong, M. D. T., Junger, M., Hartel, P. H. & Roppelt, J. C. (2019). Putting the privacy paradox to the test: Online privacy and security behaviors among users with technical knowledge, privacy awareness, and financial resources. Telematics and Informatics, 41, 55–69. doi:10.1016/j.tele.2019.03.003\nBoerman, S. C., Kruikemeier, S., & Zuiderveen Borgesius, F. J. (2021). Exploring Motivations for Online Privacy Protection Behavior: Insights From Panel Data. Communication Research, 48(7), 953–977. https://doi.org/10.1177/0093650218800915\nPew Research Center. (2019). Americans and privacy: Concerned, confused and feeling lack of control over their personal information. https://www.pewresearch.org/internet/2019/11/15/americans-and-privacy-concerned-confused-and- feeling-lack-of-control-over-their-personal-information/\nPew Research Center. (2020). Wave 49 American trends panel [Data set]. https://www.pewresearch.org/internet/dataset/american-trends-panel-wave-49/\nTurow, J., Hennessy, M. & Draper, N. (2015). The tradeoff fallacy – How marketers are misrepresenting American consumers and opening them up to exploitation. Annenberg School for Communication.\nZuboff, S. (2015). Big other: Surveillance capitalism and the prospects of an information civilization. Journal of Information Technology, 30(1), 75–89. doi:10.1057/jit.2015.5"
  },
  {
    "objectID": "posts/KarenDetter_HW2.html",
    "href": "posts/KarenDetter_HW2.html",
    "title": "Blog Post Template",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/KarenDetter_HW2.html#instructions",
    "href": "posts/KarenDetter_HW2.html#instructions",
    "title": "Blog Post Template",
    "section": "Instructions",
    "text": "Instructions\nThis document provides yaml header inforamtion you will need to replicate each week to submit your homework or other blog posts. Please observe the following conventions:\n\nSave your own copy of this template as a blog post in the posts folder, naming it FirstLast_hwX.qmd\nEdit the yaml header to change your author name - use the same name each week\ninclude a description that is reader friendly\nupdate the category list to indicate the type of submission, the data used, the main packages or techniques, your name, or any thing else to make your document easy to find\nedit as a normal qmd/rmd file\n\n\n\nCode\nx <- c(2,3,4,5)\nmean(x)\n\n\n[1] 3.5"
  },
  {
    "objectID": "posts/KarenDetter_HW2.html#rendering-your-post",
    "href": "posts/KarenDetter_HW2.html#rendering-your-post",
    "title": "Blog Post Template",
    "section": "Rendering your post",
    "text": "Rendering your post\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code.\n\n\n\n\n\n\nWarning\n\n\n\nBe sure that you have moved your *.qmd file into the posts folder BEFORE you render it, so that all files are stored in the correct location.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nOnly render a single file - don’t try to render the whole website!\n\n\n\n\n\n\n\n\nPilot Student Blogs\n\n\n\nWe are piloting a workflow including individual student websites with direted and limited pull requests back to course blogs. Please let us know if you would like to participate."
  },
  {
    "objectID": "posts/KarenDetter_HW2.html#reading-in-data-files",
    "href": "posts/KarenDetter_HW2.html#reading-in-data-files",
    "title": "Blog Post Template",
    "section": "Reading in data files",
    "text": "Reading in data files\nThe easiest data source to use - at least initially - is to choose something easily accessible, either from our _data folder provided, or from an online source that is publicly available.\n\n\n\n\n\n\nUsing Other Data\n\n\n\nIf you would like to use a source that you have access to and it is small enough and you don’t mind making it public, you can copy it into the _data file and include in your commit and pull request.\n\n\n\n\n\n\n\n\nUsing Private Data\n\n\n\nIf you would like to use a proprietary source of data, that should be possible using the same process outlined above. There may initially be a few issues. We hope to have this feature working smoothly soon!"
  },
  {
    "objectID": "posts/KenDocekal_finalproject1.html",
    "href": "posts/KenDocekal_finalproject1.html",
    "title": "Final Project 1",
    "section": "",
    "text": "Research Question\nHow much does state policy intervention impact future social and economic value preferences in residents?\nWhile political values often explicitly inform social and economic policy actions taken by governments, policy actions themselves can also affect the development of the values of both program recipients and the greater public. Low-income recipients are assumed to benefit from, and therefore favor, state intervention and redistributive policies while upper income groups are assumed to be against but this is not always true, especially at the program level (Bueno et al.). Authors like Holland note that “the poor only have an economic interest in supporting social expenditures in contexts where they expect policies to redistribute resources or risks in their favor”.\nThis study seeks to better understand the relationship between policy action and value formation at the sub-national level by looking at the effect of US state policy interventions on residents’ subsequent policy preferences. By looking at how differences in US states’ social and economic policy intervention from 1936 to 2000 we can see how these factors may shape the subsequent policy values of residents. The dataset “Correlates of State Policy” includes variables which also allow us to better understand the role of differences in policy design and implementation by controlling for variables that may moderate impact, such as the length of policy implementation (Soss) and differences in economic interest (Ansell).\nSources:\nAnsell, Ben. 2014. “The Political Economy of Ownership.” American Political Science Review 108(02):383{402.\nBoehmke, Frederick J., and Paul Skinner. 2012. “State Policy Innovativeness Revisited.” State Politics and Policy Quarterly, 12(3):303-29.\nBueno, Natalia and Nunes, Felipe and Zucco, Cesar, Making the bourgeoisie? Values, voice, and state-provided homeownership (January 7, 2022). SSRN.\nCaughey, Devin, and Christopher Warshaw. 2015. “The Dynamics of State Policy Liberalism, 1936–2014.” American Journal of Political Science, September. doi: 10.1111/ajps.12219.\nHolland, Alisha C. 2018. “Diminished Expectations: Redistributive preferences in truncated welfare states.” World Politics 70(4):555{594\nJacoby, William G., and Saundra K. Schneider. 2008. “A New Measure of Policy Spending Priorities in the American States.”\nJordan, Marty P. and Matt Grossmann. 2016. The Correlates of State Policy Project v.1.10. East Lansing, MI: Institute for Public Policy and Social Research (IPPSR).\nRigby, Elizabeth and Gerald C. Wright. 2013. “Political Parties and Representation of the Poor in the American States.” American Journal of Political Science 57(3): 552-565.\nSoss, Joe. 1999. “Lessons of Welfare: Policy Design, Political Learning, and Political Action.” The American Political Science Review 93(2):363{380.\n\n\nHypothesis\nIncreased state intervention increases US state residents’ preference for future interventions in social and economic policy.\nThis study proposes to build on Bueno et al.’s exploration of the effects of state-provided home ownership on political values and policy preferences by exploring that relationship at the level of US states. Additionally, instead of focusing on a single social program, we will examine the cumulative effects of multiple policy interventions across 65 years in 50 US states. This will provide insights into the effect of public policy on value differences at the sub-national level and on different subgroups including program non-participants. We will be able to see how this relationship may vary according to state and population characteristics despite differences in policy design and implementation.\n\n\nDescriptive Statistics\nThis dataset is from the Correlates of State Policy Project by the Institute for Public Policy and Social Research at Michigan State University. The full dataset, which contains 928 variables and covers data from 1900 to 2016, draws from multiple sources including government agencies and peer-reviewed articles listed in the Sources section. Due to limited data coverage across all years however, this study will focus on the period from 1935 to 2000. We will examining the following 25 variables (listed with description and years available):\nIndependent-\nYear 1935 - 2000\nState 1935 - 2000\nEcondev - Did State adopt Strategic Planning for Economic Development? 1981 – 1992\nPldvpag - Did State adopt Planning/Development Agency? 1935 – 1978\nUrbrenen - Did State adopt Urban Renewal ? 1941 – 1952\nPollib_median - State Policy Liberalism Score – Median 1936 – 2014\nPolicypriorityscore - State Policy Priority Score - collective goods (e.g., education and highways) v particularized benefits (e.g., health care and welfare) 1982-2005\nPoptotal - Population Total 1900 – 2008\nPopfemale - Female Population 1994 – 2010\nNonwhite - Proportion of the population that is nonwhite 1974 - 2011\nSoc_capital_ma - Hawes et al. Weighted Moving Average Measure of Social Capital 1984 - 2011\nEvangelical_pop - Evangelical Population 1975 - 2013\nNewimmig - New Immigrant Green Card Holders 1988 – 2011\nPopdensity - Population Density 1975 – 1999\nGsp_q - Gross State Product Combined in Millions of 2016 Dollars 1963 – 2010\nGini_coef - Gini Coefficient 1917 - 2013\nHsdiploma - High School Diploma 1975 – 2006\nEducspend - State Education Spending 1975 – 2001\nNofelons - Number of Felons Ineligible to Vote 1980 – 2010\nCo2emissions - Total CO2 emissions from fossil-fuels (metric tons) 1960 – 2001\nIdeo - State Ideology Score 1976 – 2011\nDependent-\nVst_ec - Mean Economic Liberalism- All Voters 2000\nVst_soc - Mean Social Liberalism- All Voters 2000\nVavgec_low - Mean Economic Liberalism Score for Low Income Voting Citizens 2000\nVavgsoc_low - Mean Social Liberalism Score for Low Income Voting Citizens 2000\nReading in dataset\n\n\nCode\nlibrary(readr)\nlibrary(readxl)\n\n\nstatedata <- read.csv(\"_data/correlatesofstatepolicyprojectv1_10.csv\")\n\n\nWarning in file(file, \"rt\"): cannot open file '_data/\ncorrelatesofstatepolicyprojectv1_10.csv': No such file or directory\n\n\nError in file(file, \"rt\"): cannot open the connection\n\n\nSpecifying variables\n\n\nCode\nstatedata1 = subset(statedata, select = c(policypriorityscore, econdev, pldvpag, urbrenen, year, state, poptotal, popfemale, nonwhite, soc_capital_ma, evangelical_pop, newimmig, popdensity, gsp_q, gini_coef, hsdiploma, educspend, nofelons, co2emissions, ideo, pollib_median,vst_ec, vst_soc, vavgec_low, vavgsoc_low))\n\n\nError in subset(statedata, select = c(policypriorityscore, econdev, pldvpag, : object 'statedata' not found\n\n\nSpecifying date range\n\n\nCode\nsd <- subset(statedata1, year>1934 & year<2001, na.rm = TRUE ) \n\n\nError in subset(statedata1, year > 1934 & year < 2001, na.rm = TRUE): object 'statedata1' not found\n\n\nDescriptive statistics\n\n\nCode\nstr(sd)\n\n\nfunction (x, na.rm = FALSE)  \n\n\nCode\nglimpse(sd)\n\n\nfunction (x, na.rm = FALSE)  \n\n\nCode\nsummary(sd)\n\n\nError in object[[i]]: object of type 'closure' is not subsettable"
  },
  {
    "objectID": "posts/KenDocekal_HW1.html",
    "href": "posts/KenDocekal_HW1.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#a",
    "href": "posts/KenDocekal_HW1.html#a",
    "title": "Homework 1",
    "section": "a",
    "text": "a\nRead in the data from the Excel file:\n\n\nCode\nlibrary(readr)\nlibrary(readxl)\n\nLungCapData <- read_excel(\"_data/LungCapData.xls\")\nView(LungCapData)\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(LungCapData$LungCap)"
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#b",
    "href": "posts/KenDocekal_HW1.html#b",
    "title": "Homework 1",
    "section": "b",
    "text": "b\nProbability distribution of the LungCap, Males and Females, in a box plot:\n\n\nCode\nboxplot(LungCapData$LungCap ~ LungCapData$Gender)"
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#c",
    "href": "posts/KenDocekal_HW1.html#c",
    "title": "Homework 1",
    "section": "c",
    "text": "c\nLung capacities for smokers and non-smokers, mean and standard deviation:\n\n\nCode\nLungCapData %>% \n  group_by(Smoke) %>% \n  summarise(mean = mean(LungCap, na.rm = TRUE), sd = sd(LungCap, na.rm = TRUE))\n\n\n# A tibble: 2 × 3\n  Smoke  mean    sd\n  <chr> <dbl> <dbl>\n1 no     7.77  2.73\n2 yes    8.65  1.88\n\n\nResults seem to point to smokers having greater lung capacity which is odd and could indicate factors other than age are influencing lung capacity"
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#d",
    "href": "posts/KenDocekal_HW1.html#d",
    "title": "Homework 1",
    "section": "d",
    "text": "d\nThe relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”:\nage 13 and lower:\n\n\nCode\nLungCapData %>% \n  group_by(Smoke) %>% \n dplyr::filter(Age <=13)%>% \n  summarise(mean = mean(LungCap, na.rm = TRUE),sd = sd(LungCap, na.rm = TRUE))\n\n\n# A tibble: 2 × 3\n  Smoke  mean    sd\n  <chr> <dbl> <dbl>\n1 no     6.36  2.21\n2 yes    7.20  1.58\n\n\nage 14 to 15:\n\n\nCode\nLungCapData %>% \n  group_by(Smoke) %>% \n dplyr::filter(Age == 14:15)%>% \n  summarise(mean = mean(LungCap, na.rm = TRUE),sd = sd(LungCap, na.rm = TRUE))\n\n\nWarning in Age == 14:15: longer object length is not a multiple of shorter\nobject length\n\n\n# A tibble: 2 × 3\n  Smoke  mean    sd\n  <chr> <dbl> <dbl>\n1 no     8.84 1.36 \n2 yes    8.91 0.865\n\n\nage 16 to 17:\n\n\nCode\nLungCapData %>% \n  group_by(Smoke) %>% \n dplyr::filter(Age == 16:17)%>% \n  summarise(mean = mean(LungCap, na.rm = TRUE),sd = sd(LungCap, na.rm = TRUE))\n\n\nWarning in Age == 16:17: longer object length is not a multiple of shorter\nobject length\n\n\n# A tibble: 2 × 3\n  Smoke  mean    sd\n  <chr> <dbl> <dbl>\n1 no    10.4   1.73\n2 yes    9.60  1.41\n\n\nage 18 and over:\n\n\nCode\nLungCapData %>% \n  group_by(Smoke) %>% \n dplyr::filter(Age >=18)%>% \n  summarise(mean = mean(LungCap, na.rm = TRUE),sd = sd(LungCap, na.rm = TRUE))\n\n\n# A tibble: 2 × 3\n  Smoke  mean    sd\n  <chr> <dbl> <dbl>\n1 no     11.1  1.56\n2 yes    10.5  1.25"
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#e",
    "href": "posts/KenDocekal_HW1.html#e",
    "title": "Homework 1",
    "section": "e",
    "text": "e\nWhen looking at mean lung capacity of smokers versus non-smokers by age groups we can see lung capacity increasing consistently as age increases. For the two lowest age groups mean capacity is lower for non-smokers although the difference decreases as age increases; this trend is reversed from age 16 onwards as non-smokers overtake smokers in lung capacity. Across all age groups non-smokers also have a greater standard deviation in lung capacity compared to smokers with the age 13 and under non-smoker group having the greatest standard deviation. It is likely that the greater number of age 13 and under respondents is the reason why overall results mirror the distribution seen in the youngest age group."
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#f",
    "href": "posts/KenDocekal_HW1.html#f",
    "title": "Homework 1",
    "section": "f",
    "text": "f\nCovariance between lung capacity and age:\n\n\nCode\ncov(LungCapData$Age,LungCapData$LungCap)\n\n\n[1] 8.738289\n\n\nA positive covariance is shown which lets us know that as age increases lung capacity also increases.\nCorrelation between lung capacity and age:\n\n\nCode\ncor(LungCapData$Age,LungCapData$LungCap)\n\n\n[1] 0.8196749\n\n\nThe correlation coefficient is also positive; similar to the covariance this lets us know that there is a positive relationship between age and lung capacity. Additionally, since .819 is a relatively high score, as a score of 1 would indicate a perfect positive relationship, we know there is a strong relationship where a older respondent would be highly likely to have higher lung capacity and a younger respondent would likely have lower lung capacity."
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#a-1",
    "href": "posts/KenDocekal_HW1.html#a-1",
    "title": "Homework 1",
    "section": "a",
    "text": "a\nThe probability that a randomly selected inmate has exactly 2 prior convictions:\nCreate data frame:\n\n\nCode\nconvictions<- c(0,1,2,3,4)\nprisoners<- c(128, 434, 160, 64, 24)\n\ndf <- data.frame(convictions, prisoners)\n\ntibble(df)\n\n\n# A tibble: 5 × 2\n  convictions prisoners\n        <dbl>     <dbl>\n1           0       128\n2           1       434\n3           2       160\n4           3        64\n5           4        24\n\n\nProbability of exactly 2 prior convictions:\n\n\nCode\n160/sum(prisoners)\n\n\n[1] 0.1975309"
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#b-1",
    "href": "posts/KenDocekal_HW1.html#b-1",
    "title": "Homework 1",
    "section": "b",
    "text": "b\nProbability of fewer than 2 prior convictions (total # of prisoners with less than 2 prior convictions = 562):\n\n\nCode\n562/sum(prisoners)\n\n\n[1] 0.6938272"
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#c-1",
    "href": "posts/KenDocekal_HW1.html#c-1",
    "title": "Homework 1",
    "section": "c",
    "text": "c\nProbability of 2 or fewer prior convictions (total # of prisoners with 2 or fewer prior convictions = 722):\n\n\nCode\n722/sum(prisoners)\n\n\n[1] 0.891358"
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#d-1",
    "href": "posts/KenDocekal_HW1.html#d-1",
    "title": "Homework 1",
    "section": "d",
    "text": "d\nProbability of more than 2 prior convictions (total # of prisoners with more than 2 prior convictions = 88):\n\n\nCode\n88/sum(prisoners)\n\n\n[1] 0.108642"
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#e-1",
    "href": "posts/KenDocekal_HW1.html#e-1",
    "title": "Homework 1",
    "section": "e",
    "text": "e\nThe expected value for the number of prior convictions (using the probability of observing each prisoner prior conviction group):\n\n\nCode\ncon1<- c(0,1,2,3,4)\npprob<- c(.158,.536,.198,.079,.028)\n\n\nsum(con1*pprob)\n\n\n[1] 1.281"
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#f-1",
    "href": "posts/KenDocekal_HW1.html#f-1",
    "title": "Homework 1",
    "section": "f",
    "text": "f\nVariance and standard deviation for prior convictions:\n\n\nCode\nvar(prisoners)\n\n\n[1] 25948\n\n\nCode\nsd(prisoners)\n\n\n[1] 161.0838"
  },
  {
    "objectID": "posts/KPopiela_HW1.html",
    "href": "posts/KPopiela_HW1.html",
    "title": "HW1",
    "section": "",
    "text": "library(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(lsr)\n#Question 1"
  },
  {
    "objectID": "posts/KPopiela_HW1.html#a1b.-what-does-the-distribution-of-lungcap-look-like",
    "href": "posts/KPopiela_HW1.html#a1b.-what-does-the-distribution-of-lungcap-look-like",
    "title": "HW1",
    "section": "1a/1b. What does the distribution of LungCap look like?",
    "text": "1a/1b. What does the distribution of LungCap look like?\n\nHint: Plot a histogram with probability density on the y axis\n\n\nHint: make boxplots separated by gender using the boxplot() function\n\nLungCap <- read_xls(\"_data/LungCapData.xls\")\nhead(LungCap)\n\n# A tibble: 6 × 6\n  LungCap   Age Height Smoke Gender Caesarean\n    <dbl> <dbl>  <dbl> <chr> <chr>  <chr>    \n1    6.48     6   62.1 no    male   no       \n2   10.1     18   74.7 yes   female no       \n3    9.55    16   69.7 no    female yes      \n4   11.1     14   71   no    male   no       \n5    4.8      5   56.9 no    male   no       \n6    6.22    11   58.7 no    female no       \n\n\n\nhist(LungCap$LungCap)\n\n\n\n\n\nLungCap_MF <- LungCap %>%\n  arrange(LungCap, Gender) %>%\n  group_by(Gender)\nboxplot(LungCap_MF$LungCap ~ LungCap_MF$Gender)\n\n\n\n#I wanted to change the axis labels to \"Gender\" (x) and \"Lung Capacity\" (y), but after an hour and a half of trying to no avail, I had to call it for my own sanity.\n\n\ncolnames(LungCap)\n\n[1] \"LungCap\"   \"Age\"       \"Height\"    \"Smoke\"     \"Gender\"    \"Caesarean\""
  },
  {
    "objectID": "posts/KPopiela_HW1.html#c.-compare-the-mean-lung-capacities-for-smokers-and-non-smokers.-does-it-make-sense",
    "href": "posts/KPopiela_HW1.html#c.-compare-the-mean-lung-capacities-for-smokers-and-non-smokers.-does-it-make-sense",
    "title": "HW1",
    "section": "1c. Compare the mean lung capacities for smokers and non-smokers. Does it make sense?",
    "text": "1c. Compare the mean lung capacities for smokers and non-smokers. Does it make sense?\n\nLungCap_smoke <- LungCapData %>%\n  select(LungCap, Smoke) %>%\n  group_by(Smoke)\n\nError in select(., LungCap, Smoke): object 'LungCapData' not found\n\nhead(LungCap_smoke)\n\nError in head(LungCap_smoke): object 'LungCap_smoke' not found\n\n\n\nsummarise(LungCap_smoke, mean(LungCap))\n\nError in summarise(LungCap_smoke, mean(LungCap)): object 'LungCap_smoke' not found\n\n#The mean lung capacities for non-smokers and smokers is 7.77 and 8.65 respectively. Does this make sense? No. One would expect that the mean lung capacity for non-smokers would be higher, but that is not the case here. Let's do some digging to see what the range of values for smokers' and non-smokers' lung capacity. I also want to look at how many people voted \"yes\" or \"no\"; it could be that fewer people (with higher lung capacity) voted \"yes,\" contributing to the higher mean.\n\n\nLCS2 <- LungCap_smoke %>%\n  filter(Smoke == \"yes\")\n\nError in filter(., Smoke == \"yes\"): object 'LungCap_smoke' not found\n\nrange(LCS2$LungCap)\n\nError in eval(expr, envir, enclos): object 'LCS2' not found\n\nLCS2 <- LungCap_smoke %>%\n  filter(Smoke == \"no\")\n\nError in filter(., Smoke == \"no\"): object 'LungCap_smoke' not found\n\nrange(LCS2$LungCap)\n\nError in eval(expr, envir, enclos): object 'LCS2' not found\n\n##Lung capacity for smokers ranges from 3.850 to 13.325, while the range for non-smokers is 0.507 to 14.675. Right off the bat, smokers have a higher minimum value, which prevents the mean from being dragged down during calculation. Non-smokers' minimum value is 0.507, an outlier which does seem to have an effect on this category's mean. \n\n\nLungCap_smoke %>%\n  count(Smoke)\n\nError in count(., Smoke): object 'LungCap_smoke' not found\n\n#Out of 725 respondents only 77 voted yes and 648 voted no, so I was right with my guess as to what caused the difference in mean lung capacity between smokers and non-smokers."
  },
  {
    "objectID": "posts/KPopiela_HW1.html#d.-examine-the-relationship-between-smoking-and-lung-capacity-within-age-groups-less-than-or-equal-to-13-14-to-15-16-to-17-and-greater-than-or-equal-to-18.",
    "href": "posts/KPopiela_HW1.html#d.-examine-the-relationship-between-smoking-and-lung-capacity-within-age-groups-less-than-or-equal-to-13-14-to-15-16-to-17-and-greater-than-or-equal-to-18.",
    "title": "HW1",
    "section": "1d. Examine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.",
    "text": "1d. Examine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\n#To start, I'm going to calculate the range and mean of each of the above age groups, as well as a tally of how many are and aren't smokers.\n\n#a) Less than or equal to 13\nLC_Age13 <- LungCap %>%\n  select(LungCap, Age, Smoke) %>%\n  filter(Age <= 13)\nrange(LC_Age13$LungCap)\n\n[1]  0.507 12.050\n\n#The range of lung capacity values for children under the age of 13 is 0.507 to 12.050. The mean is 6.412.\n\n\nsummarise(LC_Age13, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            6.41\n\n\n\nLC_Age13 %>%\n  count(Smoke)\n\n# A tibble: 2 × 2\n  Smoke     n\n  <chr> <int>\n1 no      401\n2 yes      27\n\n#401 individuals 13 and under responded that they don't smoke, while 27 said they do. Compared to the initial calculations for the whole survey, the mean value is slightly lower, which is likely indicative of the fact that children have smaller lungs than adults and therefore have less lung capacity. Something important to note, however, is that this age group accounts for 428 of the total 725 responses (about 59%).\n\n\n#b) 14 to 15 \nLC_Age145 <- LungCap %>%\n  select(LungCap, Age, Smoke) %>%\n  filter(Age == 14:15)\n\nWarning in Age == 14:15: longer object length is not a multiple of shorter\nobject length\n\nrange(LC_Age145$LungCap)\n\n[1]  5.625 12.900\n\n#The minimum and maximum lung capacity values for individuals aged 14-15 are 5.625 and 12.900. The mean is 8.842.\n\n\nsummarise(LC_Age145, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            8.84\n\n\n\nLC_Age145 %>%\n  count(Smoke)\n\n# A tibble: 2 × 2\n  Smoke     n\n  <chr> <int>\n1 no       44\n2 yes       8\n\n#Out of the 52 respondents in this age group, 44 stated that they don't smoke and 8 said that they do. The 14-15y/o age group is MUCH smaller than the \"13 and under\" one (it makes up only 12% of total responses). The percentage of smokers to non-smokers in each of the above age groups,is 7% and 18% respectively. If you were to take these percentages at face value without taking sample size into account, it would look as if the 14-15 y/o age group makes up 18% of the total 725 responses. In reality, this sample accounts for 6% of the total, making its impact relatively low.\n\n\n#c) 16 to 17\nLC_Age167 <- LungCap %>%\n  select(LungCap, Age, Smoke) %>%\n  filter(Age == 16:17)\n\nWarning in Age == 16:17: longer object length is not a multiple of shorter\nobject length\n\nrange(LC_Age167$LungCap)\n\n[1]  5.675 13.375\n\n#The minimum and maximum lung capacity values for individuals ages 16 to 17 are 5.675 and 13.375. The mean is 10.058.\n\n\nsummarise(LC_Age167, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            10.1\n\n\n\nLC_Age167 %>%\n  count(Smoke)\n\n# A tibble: 2 × 2\n  Smoke     n\n  <chr> <int>\n1 no       40\n2 yes       8\n\n#This sample is similar in size to the previous (14-15 year olds) with only 48 responses, and smokers make up 20% of the responses. Now lets discuss the other figures.  \n\n#The mean lung capacity for 16-17 year olds is 10.058, 1.216 units higher than the previous age group, and 3.646 units higher than the \"13 and under\" age group. As of this point in my calculations, the only relationship seems to be between age and lung capacity rather than smoking and lung capacity; this is due to the facts that: 1) not that many people ages 0-17 smoke, and 2) the sample sizes for the 14-17 age group is 100 compared to the 428 responses in the \"13 and under\" group.\n\n\nLC_Age18p <- LungCap %>%\n  select(LungCap, Age, Smoke) %>%\n  filter(Age >= 18)\nrange(LC_Age18p$LungCap)\n\n[1]  7.750 14.675\n\n#The minimum and maximum range values for the 18+ age group are 7.750 and 14.675. The mean is 10.965.\n\n\nsummarise(LC_Age18p, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            11.0\n\n\n\nLC_Age18p %>%\n  count(Smoke)\n\n# A tibble: 2 × 2\n  Smoke     n\n  <chr> <int>\n1 no       65\n2 yes      15\n\n#Ok so what we've learned here is that this survey was HEAVILY focused on kids 13 and younger; although the sample for this age group is larger than the previous 2, it's still only 80 out of 725 responses (about 11% of total respondents). The mean lung capacity for this group is the highest of all of them at 10.965, but this still doesn't seem to show a relationship between smoking and lung capacity. Rather, at least to me, it shows a relationship between age and lung capacity (i.e. stage of lung development and lung capacity).\n\n##1e. Compare the lung capacities for smokers and non-smokers within each age group. Is your answer different from the one in part d. What could possibly be going on here?\n\n#I will place a comparison of all values produced by the following calculations at the bottom. (I will go through the smoker and non-smoker calculations first)\n\nLCu13 <- LC_Age13 %>%\n  filter(Smoke == \"yes\")\nrange(LCu13$LungCap)\n\n[1]  3.850 10.275\n\n\n\nsummarise(LCu13, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            7.20\n\n\n\nLCu145 <- LC_Age145 %>%\n  filter(Smoke == \"yes\")\nrange(LCu145$LungCap)\n\n[1]  6.225 11.025\n\n\n\nsummarise(LCu145, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            8.36\n\n\n\nLCu167 <- LC_Age167 %>%\n  filter(Smoke == \"yes\")\nrange(LCu167$LungCap)\n\n[1]  7.550 11.775\n\n\n\nsummarise(LCu167, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            9.06\n\n\n\nLCu18p <- LC_Age18p %>%\n  filter(Smoke == \"yes\")\nrange(LCu18p$LungCap)\n\n[1]  8.200 13.325\n\n\n\nsummarise(LCu18p, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            10.5\n\n\n\n#Now for the non-smoker calculations.\n\nLCu13 <- LC_Age13 %>%\n  filter(Smoke == \"no\")\nrange(LCu13$LungCap)\n\n[1]  0.507 12.050\n\n\n\nsummarise(LCu13, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            6.36\n\n\n\nLCu145 <- LC_Age145 %>%\n  filter(Smoke == \"no\")\nrange(LCu145$LungCap)\n\n[1]  5.625 12.900\n\n\n\nsummarise(LCu145, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            8.93\n\n\n\nLCu167 <- LC_Age167 %>%\n  filter(Smoke == \"no\")\nrange(LCu167$LungCap)\n\n[1]  5.675 13.375\n\n\n\nsummarise(LCu167, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            10.3\n\n\n\nLCu18p <- LC_Age18p %>%\n  filter(Smoke == \"no\")\nrange(LCu18p$LungCap)\n\n[1]  7.750 14.675\n\n\n\nsummarise(LC_Age18p, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            11.0\n\n\n\n#Comparison!!  \n  # 13 and under smokers: range = 3.850 to 10.275, mean = 7.202\n  # 13 and under non-smokers: range = 0.507 and 12.050, mean = 6.359 \n    \n  # 14-15 smokers: range = 6.225 and 11.025, mean = 8.359\n  # 14-15 non-smokers: range = 5.625 and 12.900, mean = 8.930  \n  \n  # 16-17 smokers: range = 7.550 and 11.775, mean = 9.063\n  # 16-17 non-smokers: range = 5.675 and 13.375, mean = 10.257  \n    \n  # 18+ smokers: range = 8.200 and 13.325,mean = 10.513 \n  # 18+ non-smokers: range = 7.750 and 14.675, mean = 10.965\n\n\n#The answers I got for smokers vs. non-smokers are obviously different, but I wouldn't say they necessarily convey something different to what I interpreted from 1d. I don't see a relationship between smoking and lung capacity, and I certainly don't see a massive difference in the values comparing the lung capacity of smokers and non-smokers."
  },
  {
    "objectID": "posts/KPopiela_HW1.html#f.-calculate-the-correlation-and-covariance-between-lung-capacity-and-age.-use-the-cov-and-cor-functions-in-r.-interpret-your-results.",
    "href": "posts/KPopiela_HW1.html#f.-calculate-the-correlation-and-covariance-between-lung-capacity-and-age.-use-the-cov-and-cor-functions-in-r.-interpret-your-results.",
    "title": "HW1",
    "section": "1f. Calculate the correlation and covariance between Lung Capacity and Age. (use the cov() and cor() functions in R). Interpret your results.",
    "text": "1f. Calculate the correlation and covariance between Lung Capacity and Age. (use the cov() and cor() functions in R). Interpret your results.\n\ncov(LungCap$LungCap, LungCap$Age)\n\n[1] 8.738289\n\n\n\ncor(LungCap$LungCap, LungCap$Age)\n\n[1] 0.8196749\n\n\n\n#Covariance between lung capacity and age: 8.738.  \n#Correlation between lung capacity and age: 0.820  \n\n#I'm not totally confident in my understanding of covariance yet, but from what I know, it's the positive or negative relationship between two variables and the further the value is from 0, the stronger the relationship is. And the covariance between lung capacity and age is 8.738. Correlation gets stronger the closer the value gets to 1 or -1; the correlation between lung capacity and age for 'LungCap' dataset is 0.820, a figure relatively close to 1, so I would say there is a moderate to strong correlation between the two variables in question here.\n\n#Question 2\n###Let X=number of prior convictions for prisoners at a state prison at which there are 810 inmates."
  },
  {
    "objectID": "posts/KPopiela_HW1.html#a.-what-is-the-probability-that-a-randomly-selected-inmate-has-fewer-than-2-prior-convictions",
    "href": "posts/KPopiela_HW1.html#a.-what-is-the-probability-that-a-randomly-selected-inmate-has-fewer-than-2-prior-convictions",
    "title": "HW1",
    "section": "2a. What is the probability that a randomly selected inmate has fewer than 2 prior convictions?",
    "text": "2a. What is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\nconrange <- rep(c(0,1,2,3,4),times=c(128,434,160,64,24))\nconrange\n\n  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n [38] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n [75] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[112] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[556] 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[593] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[630] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[667] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[704] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n[741] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n[778] 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n\n#To start I just wanted to present a visualization of the frequency of each categorical variable.  \n  # 0 prior convictions = 128  \n  # 1 prior conviction = 434  \n  # 2 prior convictions = 160  \n  # 3 prior convictions = 64  \n  # 4 prior convictions = 24\n\n\nprop.table(table(conrange))[0:2]\n\nconrange\n        0         1 \n0.1580247 0.5358025 \n\n#By combining the probability values for 0 and 1, we can see that the probability of a randomly selected inmate having fewer than 2 prior convictions is 0.694."
  },
  {
    "objectID": "posts/KPopiela_HW1.html#b.-what-is-the-probability-that-a-randomly-selected-inmate-has-2-or-fewer-prior-convictions",
    "href": "posts/KPopiela_HW1.html#b.-what-is-the-probability-that-a-randomly-selected-inmate-has-2-or-fewer-prior-convictions",
    "title": "HW1",
    "section": "2b. What is the probability that a randomly selected inmate has 2 or fewer prior convictions?",
    "text": "2b. What is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\nprop.table(table(conrange))[0:3]\n\nconrange\n        0         1         2 \n0.1580247 0.5358025 0.1975309 \n\n#By using the same math above, the probability that a randomly selected inmate has 2 or fewer prior convictions is 0.891."
  },
  {
    "objectID": "posts/KPopiela_HW1.html#c.-what-is-the-probability-that-a-randomly-selected-inmate-has-more-than-2-prior-convictions",
    "href": "posts/KPopiela_HW1.html#c.-what-is-the-probability-that-a-randomly-selected-inmate-has-more-than-2-prior-convictions",
    "title": "HW1",
    "section": "2c. What is the probability that a randomly selected inmate has more than 2 prior convictions?",
    "text": "2c. What is the probability that a randomly selected inmate has more than 2 prior convictions?\n\nprop.table(table(conrange))[4:5]\n\nconrange\n         3          4 \n0.07901235 0.02962963 \n\n#The probability that a randomly selected inmate has more than 2 prior convictions is 0.108."
  },
  {
    "objectID": "posts/KPopiela_HW1.html#d.-what-is-the-expected-value-for-the-number-of-prior-convictions",
    "href": "posts/KPopiela_HW1.html#d.-what-is-the-expected-value-for-the-number-of-prior-convictions",
    "title": "HW1",
    "section": "2d. What is the expected value for the number of prior convictions?",
    "text": "2d. What is the expected value for the number of prior convictions?\n\nprior_con_range <- c(0,1,2,3,4)\nprobs <- c(0.158,0.535,0.197,0.079,0.029)\nc(prior_con_range %*% probs)\n\n[1] 1.282\n\n#The expected value for the number of prior convictions is 1.282"
  },
  {
    "objectID": "posts/KPopiela_HW1.html#e.-calculate-the-variance-and-the-standard-deviation-for-the-prior-convictions.",
    "href": "posts/KPopiela_HW1.html#e.-calculate-the-variance-and-the-standard-deviation-for-the-prior-convictions.",
    "title": "HW1",
    "section": "2e. Calculate the variance and the standard deviation for the Prior Convictions.",
    "text": "2e. Calculate the variance and the standard deviation for the Prior Convictions.\n\nvar(conrange)\n\n[1] 0.8572937\n\nsd(conrange)\n\n[1] 0.9259016\n\n#The variance and standard deviation for prior convictions are 0.857 and 0.925 respectively."
  },
  {
    "objectID": "posts/MEGHA JOSEPH_BLOG1.html",
    "href": "posts/MEGHA JOSEPH_BLOG1.html",
    "title": "Project Proposal",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.4 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(dplyr)"
  },
  {
    "objectID": "posts/MEGHA JOSEPH_BLOG1.html#research-question",
    "href": "posts/MEGHA JOSEPH_BLOG1.html#research-question",
    "title": "Project Proposal",
    "section": "Research Question",
    "text": "Research Question\nAccording to statistics,Cardiovascular diseases (CVDs) kill approximately 17 million people globally every year.Most cardiovascular diseases can be prevented by addressing behavioural risk factors such as tobacco use, unhealthy diet and obesity, physical inactivity and harmful use of alcohol using population-wide strategies. People with cardiovascular disease or who are at high cardiovascular risk (due to the presence of one or more risk factors such as hypertension, diabetes, hyperlipidaemia or already established disease) need early detection and management. Research question is: Which clinical feature will lead to high cardiovascular risk?"
  },
  {
    "objectID": "posts/MEGHA JOSEPH_BLOG1.html#hypothesis",
    "href": "posts/MEGHA JOSEPH_BLOG1.html#hypothesis",
    "title": "Project Proposal",
    "section": "Hypothesis",
    "text": "Hypothesis\n1:Behavioral risk factors will not underline significant predictors of predicting Heart Failure.\n2:Behavioral risk factors will underline significant predictors of predicting Heart Failure ."
  },
  {
    "objectID": "posts/MEGHA JOSEPH_BLOG1.html#descriptive-statistics",
    "href": "posts/MEGHA JOSEPH_BLOG1.html#descriptive-statistics",
    "title": "Project Proposal",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\nI am going to analyze a dataset of 299 patients with heart failure collected in 2015.This dataset is comprised of self-reported survey, with 13 clinical features. data.https://www.kaggle.com/datasets/whenamancodes/heart-failure-clinical-records. The important variables of research are ejection fraction, serum creatinine, and smoking.\n.\n\n\nCode\nlibrary(readr)\nmf <- read_csv(\"C:/Users/user/Downloads/Heart Failure Clinical Records.csv\")\nsummary(mf)\n``\n\n\nError: attempt to use zero-length variable name"
  },
  {
    "objectID": "posts/MEGHA JOSEPH_BLOG1.html#references",
    "href": "posts/MEGHA JOSEPH_BLOG1.html#references",
    "title": "Project Proposal",
    "section": "References",
    "text": "References\n\nSurvival prediction of heart failure patients using machine learning techniques *. (n.d.). Retrieved October 11, 2022, from https://www.sciencedirect.com/science/article/pii/S2352914821002458\n\nMachine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone. https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-020-1023-5"
  },
  {
    "objectID": "posts/MeghaJoseph_hw1.html",
    "href": "posts/MeghaJoseph_hw1.html",
    "title": "HOME WORK1 603",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(stats)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/MeghaJoseph_hw1.html#answer-1",
    "href": "posts/MeghaJoseph_hw1.html#answer-1",
    "title": "HOME WORK1 603",
    "section": "Answer 1",
    "text": "Answer 1\n\n\nCode\nreadD <- read_excel(\"_data/LungCapData.xls\")\nreadD\n\n\n# A tibble: 725 × 6\n   LungCap   Age Height Smoke Gender Caesarean\n     <dbl> <dbl>  <dbl> <chr> <chr>  <chr>    \n 1    6.48     6   62.1 no    male   no       \n 2   10.1     18   74.7 yes   female no       \n 3    9.55    16   69.7 no    female yes      \n 4   11.1     14   71   no    male   no       \n 5    4.8      5   56.9 no    male   no       \n 6    6.22    11   58.7 no    female no       \n 7    4.95     8   63.3 no    male   yes      \n 8    7.32    11   70.4 no    male   no       \n 9    8.88    15   70.5 no    male   no       \n10    6.8     11   59.2 no    male   no       \n# … with 715 more rows"
  },
  {
    "objectID": "posts/MeghaJoseph_hw1.html#answer-1-a",
    "href": "posts/MeghaJoseph_hw1.html#answer-1-a",
    "title": "HOME WORK1 603",
    "section": "Answer 1 (a)",
    "text": "Answer 1 (a)\nDistribution of LungCap:\n\n\nCode\nhist(readD$LungCap)\n\n\n\n\n\nThe distribution is a normal distribution. ## Answer 1 (b)\n\n\nCode\nboxplot(readD$LungCap ~ readD$Gender)\n\n\n\n\n\nThe mean of males appear higher than females."
  },
  {
    "objectID": "posts/MeghaJoseph_hw1.html#answer-1-c",
    "href": "posts/MeghaJoseph_hw1.html#answer-1-c",
    "title": "HOME WORK1 603",
    "section": "Answer 1 (c)",
    "text": "Answer 1 (c)\n\n\nCode\nreadD%>%\n  group_by(Smoke) %>% \n  summarize(Mean=mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke  Mean\n  <chr> <dbl>\n1 no     7.77\n2 yes    8.65\n\n\nCode\nreadD%>%\n  group_by(Smoke) %>% \n  summarize(stdev=sd(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke stdev\n  <chr> <dbl>\n1 no     2.73\n2 yes    1.88\n\n\nCode\nggplot(readD, aes(x=LungCap, y=Smoke))+geom_boxplot()\n\n\n\n\n\nThe mean of smokers is higher than the mean of non smokers and therefore it is not sensible."
  },
  {
    "objectID": "posts/MeghaJoseph_hw1.html#answer-1-d",
    "href": "posts/MeghaJoseph_hw1.html#answer-1-d",
    "title": "HOME WORK1 603",
    "section": "Answer 1 (d)",
    "text": "Answer 1 (d)\n\n\nCode\nclass(readD$Age)\n\n\n[1] \"numeric\"\n\n\nCode\nreadD <- mutate(readD, AgeGroup = case_when(Age <= 13 ~ \"13 and below\", \n                                            Age == 14 | Age == 15 ~ \"14 to 15\", \n                                            Age == 16 | Age == 17 ~ \"16 to 17\", \n                                            Age >= 18 ~ \"18 and above\"))\nggplot(readD, aes(x = LungCap)) +\n  geom_histogram() +\n  facet_grid(AgeGroup~Smoke)\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nCode\nreadD %>%\n  ggplot(aes(x = Age, y = LungCap, color = Smoke)) +\n  geom_line() +\n  facet_wrap(vars(Smoke)) +\n  labs(y = \"Lung Capacity\", x = \"Age\")\n\n\n\n\n\nFrom the above results we can say that people from age group 10 and above smoke."
  },
  {
    "objectID": "posts/MeghaJoseph_hw1.html#answer-1-f",
    "href": "posts/MeghaJoseph_hw1.html#answer-1-f",
    "title": "HOME WORK1 603",
    "section": "Answer 1 (f)",
    "text": "Answer 1 (f)\n\n\nCode\ncor(readD$LungCap,readD$Age)\n\n\n[1] 0.8196749\n\n\nCode\ncov(readD$LungCap,readD$Age)\n\n\n[1] 8.738289\n\n\nFrom the data we can see that the covariance is positive and it shows that there is a direct relationship between age and lung capacity. And the correlation is also positive, so they move in same direction. Therefore as the age increases, the lung capacity also increases that is they are directly proportional to each other."
  },
  {
    "objectID": "posts/MeghaJoseph_hw1.html#answer-2",
    "href": "posts/MeghaJoseph_hw1.html#answer-2",
    "title": "HOME WORK1 603",
    "section": "Answer 2",
    "text": "Answer 2\n\n\nCode\nX<-c(0, 1, 2, 3, 4)\nFrequency<-c(128, 434, 160, 64, 24)\nC<- data.frame(X, Frequency)\nC\n\n\n  X Frequency\n1 0       128\n2 1       434\n3 2       160\n4 3        64\n5 4        24\n\n\nCode\nC<-rename(C, PriorConvictions=X)\nC\n\n\n  PriorConvictions Frequency\n1                0       128\n2                1       434\n3                2       160\n4                3        64\n5                4        24\n\n\nCode\n#visualizing df using bar chart\nggplot(C, aes(x=PriorConvictions, y=Frequency))+geom_bar(stat=\"identity\")+geom_text(aes(label = Frequency), vjust = -.3)\n\n\n\n\n\nCode\n#There are 810 obs in df\nsum(Frequency)\n\n\n[1] 810\n\n\n\n\nCode\nPO<-Frequency/810\nPO\n\n\n[1] 0.15802469 0.53580247 0.19753086 0.07901235 0.02962963\n\n\nCode\n#A\n# P(x=2)=160/810\n160/810\n\n\n[1] 0.1975309\n\n\nCode\n#B\n#P(x<2)=P(0)+P(1)\n(128+434)/810\n\n\n[1] 0.6938272\n\n\nCode\n#C\n#P(x<=2)=P(0)+P(1)+P(2)\n(128+434+160)/810\n\n\n[1] 0.891358\n\n\nCode\n#D\n#1-P(above)\n1-((128+434+160)/810)\n\n\n[1] 0.108642\n\n\nCode\n#E\n#Expected value=sum of probabilities*each value (0, 1, 2, 3 or 4)\nweighted.mean(X, PO)\n\n\n[1] 1.28642\n\n\nCode\n#F\n#Calculating the Variance using the formula for variance\n(sum(Frequency*((X-1.28642)^2)))/(sum(Frequency)-1)\n\n\n[1] 0.8572937\n\n\nCode\n#Calculating the sample standard deviation from the variance\nsqrt(0.8572937)\n\n\n[1] 0.9259016\n\n\nAnswer\na: 19.75% b :9.38% c :89.14% d :10.86% e :1.28642 f: variance: 0.8572937 standard deviation: 0.9259016"
  },
  {
    "objectID": "posts/Niharika_HW1.html#question-1",
    "href": "posts/Niharika_HW1.html#question-1",
    "title": "Homework 1",
    "section": "Question 1",
    "text": "Question 1"
  },
  {
    "objectID": "posts/Niharika_HW1.html#reading-data",
    "href": "posts/Niharika_HW1.html#reading-data",
    "title": "Homework 1",
    "section": "Reading data",
    "text": "Reading data\n\n\nCode\nLc <- read_excel(\"LungCapData.xls\")\n\n\nError: `path` does not exist: 'LungCapData.xls'\n\n\nCode\nLc\n\n\nError in eval(expr, envir, enclos): object 'Lc' not found\n\n\nThe data consists of 725 rows and 6 columns. It determines the lung capacity of the based on their age, height and different characteristics. The main key classification that I can see is if they smoke or not."
  },
  {
    "objectID": "posts/Niharika_HW1.html#a",
    "href": "posts/Niharika_HW1.html#a",
    "title": "Homework 1",
    "section": "1a",
    "text": "1a\nThe distribution of LungCap looks as follows:\n\n\nCode\nLc %>%\n  ggplot(aes(LungCap, ..density..)) +\n  geom_histogram(bins= 25, color = \"orange\") +\n  geom_density(color = \"darkblue\") +\n  theme_classic() + \n  labs(title = \"Probability distribution of LungCap\", x = \"Lung Capcity\", y = \"Probability density\")\n\n\nError in ggplot(., aes(LungCap, ..density..)): object 'Lc' not found\n\n\nThe histogram and density plots show that it is pretty close to a normal distribution. Most of the observations are close to the mean."
  },
  {
    "objectID": "posts/Niharika_HW1.html#b",
    "href": "posts/Niharika_HW1.html#b",
    "title": "Homework 1",
    "section": "1b",
    "text": "1b\nThe distribution of LungCap on basis of gender looks as follows:\n\n\nCode\nLc %>%\n  ggplot(aes(y = dnorm(LungCap), color = Gender)) +\n  geom_boxplot() +\n  theme_classic() + \n  labs(title = \"Probability distribution of LungCap based on gender\", y = \"Probability density\")\n\n\nError in ggplot(., aes(y = dnorm(LungCap), color = Gender)): object 'Lc' not found\n\n\nThe box plot shows that the probability density of the male is lesser than the female."
  },
  {
    "objectID": "posts/Niharika_HW1.html#c",
    "href": "posts/Niharika_HW1.html#c",
    "title": "Homework 1",
    "section": "1c",
    "text": "1c\nComparison of mean lung capacities between smokers and non-smokers:\n\n\nCode\nMean_smoke <- Lc %>%\n  group_by(Smoke) %>%\n  summarise(mean = mean(LungCap))\n\n\nError in group_by(., Smoke): object 'Lc' not found\n\n\nCode\nMean_smoke\n\n\nError in eval(expr, envir, enclos): object 'Mean_smoke' not found\n\n\nFrom the above table, we see that the mean lung capacity of those who smoke is greater than those who don’t smoke, but it doesn’t make sense. It also depends on the biological factors of the person who smoke, so we can’t conclude it."
  },
  {
    "objectID": "posts/Niharika_HW1.html#d",
    "href": "posts/Niharika_HW1.html#d",
    "title": "Homework 1",
    "section": "1d",
    "text": "1d\nRelationship between Smoke and Lung capacity on basis of given age categories:\n\n\nCode\nLc <- mutate(Lc, AgeGrp = case_when(Age <= 13 ~ \"less than or equal to 13\",\n                                    Age == 14 | Age == 15 ~ \"14 to 15\",\n                                    Age == 16 | Age == 17 ~ \"16 to 17\",\n                                    Age >= 18 ~ \"greater than or equal to 18\"))\n\n\nError in mutate(Lc, AgeGrp = case_when(Age <= 13 ~ \"less than or equal to 13\", : object 'Lc' not found\n\n\nCode\nLc %>%\n  ggplot(aes(y = LungCap, color = Smoke)) +\n  geom_histogram(bins = 25) +\n  facet_wrap(vars(AgeGrp)) +\n  theme_classic() + \n  labs(title = \"Relationship of LungCap and Smoke based on age categories\", y = \"Lung Capacity\", x = \"Frequency\")\n\n\nError in ggplot(., aes(y = LungCap, color = Smoke)): object 'Lc' not found\n\n\nFrom the above plot, we can derive two important observations: 1. The lung capacity of non smokers is more than smokers. 2. The people who smoke are less in age group of “less than or equal to 13”. So as the result as age increases the lung capacity decreases."
  },
  {
    "objectID": "posts/Niharika_HW1.html#e",
    "href": "posts/Niharika_HW1.html#e",
    "title": "Homework 1",
    "section": "1e",
    "text": "1e\nRelationship between Smoke and Lung capacity on basis of age:\n\n\nCode\nLc %>%\n  ggplot(aes(x = Age, y = LungCap, color = Smoke)) +\n  geom_line() +\n  theme_classic() + \n  facet_wrap(vars(Smoke)) +\n  labs(title = \"Relationship of LungCap and Smoke based on age\", y = \"Lung Capacity\", x = \"Age\")\n\n\nError in ggplot(., aes(x = Age, y = LungCap, color = Smoke)): object 'Lc' not found\n\n\nForm the above data we can compare 1d and 1e and can say the results are pretty similar. Only 10 and above age group smoke."
  },
  {
    "objectID": "posts/Niharika_HW1.html#f",
    "href": "posts/Niharika_HW1.html#f",
    "title": "Homework 1",
    "section": "1f",
    "text": "1f\nCalculating the correlation and covariance between Lung Capacity and Age:\n\n\nCode\nCovariance <- cov(Lc$LungCap, Lc$Age)\n\n\nError in is.data.frame(y): object 'Lc' not found\n\n\nCode\nCorrelation <- cor(Lc$LungCap, Lc$Age)\n\n\nError in is.data.frame(y): object 'Lc' not found\n\n\nCode\nCovariance\n\n\nError in eval(expr, envir, enclos): object 'Covariance' not found\n\n\nCode\nCorrelation\n\n\nError in eval(expr, envir, enclos): object 'Correlation' not found\n\n\nWe can observe from the comparison that the covariance is positive and it indicates that there is a direct relationship between age and lung capacity. And the correlation is also positive, so they move in same direction. We can say from these results that as the age increases, the lung capacity also increases that is they are directly proportional to each other."
  },
  {
    "objectID": "posts/Niharika_HW1.html#question-2",
    "href": "posts/Niharika_HW1.html#question-2",
    "title": "Homework 1",
    "section": "Question 2",
    "text": "Question 2"
  },
  {
    "objectID": "posts/Niharika_HW1.html#reading-the-table",
    "href": "posts/Niharika_HW1.html#reading-the-table",
    "title": "Homework 1",
    "section": "Reading the table",
    "text": "Reading the table\n\n\nCode\nPrior_convitions <- c(0:4)\nInmate_count <- c(128, 434, 160, 64, 24)\nPc <- data_frame(Prior_convitions, Inmate_count)\n\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nPlease use `tibble()` instead.\n\n\nCode\nPc\n\n\n\n\n  \n\n\n\n\n\nCode\nPc <- mutate(Pc, Probability = Inmate_count/sum(Inmate_count))\nPc"
  },
  {
    "objectID": "posts/Niharika_HW1.html#a-1",
    "href": "posts/Niharika_HW1.html#a-1",
    "title": "Homework 1",
    "section": "2a",
    "text": "2a\nProbability that a randomly selected inmate has exactly 2 prior convictions:\n\n\nCode\nPc %>%\n  filter(Prior_convitions == 2) %>%\n  select(Probability)"
  },
  {
    "objectID": "posts/Niharika_HW1.html#b-1",
    "href": "posts/Niharika_HW1.html#b-1",
    "title": "Homework 1",
    "section": "2b",
    "text": "2b\nProbability that a randomly selected inmate has fewer than 2 convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions < 2)\nsum(temp$Probability)\n\n\n[1] 0.6938272"
  },
  {
    "objectID": "posts/Niharika_HW1.html#c-1",
    "href": "posts/Niharika_HW1.html#c-1",
    "title": "Homework 1",
    "section": "2c",
    "text": "2c\nProbability that a randomly selected inmate has 2 or fewer prior convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions <= 2)\nsum(temp$Probability)\n\n\n[1] 0.891358"
  },
  {
    "objectID": "posts/Niharika_HW1.html#d-1",
    "href": "posts/Niharika_HW1.html#d-1",
    "title": "Homework 1",
    "section": "2d",
    "text": "2d\nProbability that a randomly selected inmate has more than 2 prior convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions > 2)\nsum(temp$Probability)\n\n\n[1] 0.108642"
  },
  {
    "objectID": "posts/Niharika_HW1.html#e-1",
    "href": "posts/Niharika_HW1.html#e-1",
    "title": "Homework 1",
    "section": "2e",
    "text": "2e\nExpected value for the number of prior convictions:\n\n\nCode\nPc <- mutate(Pc, Wm = Prior_convitions*Probability)\ne <- sum(Pc$Wm)\ne\n\n\n[1] 1.28642"
  },
  {
    "objectID": "posts/Niharika_HW1.html#f-1",
    "href": "posts/Niharika_HW1.html#f-1",
    "title": "Homework 1",
    "section": "2f",
    "text": "2f\nVariance for the Prior Convictions:\n\n\nCode\nv <-sum(((Pc$Prior_convitions-e)^2)*Pc$Probability)\nv\n\n\n[1] 0.8562353\n\n\nstandard deviation for the Prior Convictions:\n\n\nCode\nsqrt(v)\n\n\n[1] 0.9253298"
  },
  {
    "objectID": "posts/NiyatiSharma_blog1.html",
    "href": "posts/NiyatiSharma_blog1.html",
    "title": "Final Project Proposal",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.4 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.2      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(dplyr)\n\nlibrary(ggplot2)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/NiyatiSharma_blog1.html#introduction",
    "href": "posts/NiyatiSharma_blog1.html#introduction",
    "title": "Final Project Proposal",
    "section": "Introduction",
    "text": "Introduction\nCredit risk is defined as the risk of loss resulting from the failure by a borrower to repay the principal and interest owed to the leader.So the purpose of credit analysis is to determine the creditworthiness of borrowers by measuring the risk of loss that the lender is exposed to.When calculating the credit risk of a particular borrower, lenders consider various factors like analyze different documents, such as the borrower’s income statement, balance sheet, credit reports, and other documents that reveal the financial situation of the borrower. to evaluate the characteristics of the borrower and conditions of the loan to estimate the probability of default and the subsequent risk of financial loss."
  },
  {
    "objectID": "posts/NiyatiSharma_blog1.html#research-question",
    "href": "posts/NiyatiSharma_blog1.html#research-question",
    "title": "Final Project Proposal",
    "section": "Research Question",
    "text": "Research Question\nQ1. How credit risk depends on the age of the person. Q2. Dominating factor on which credit risk depends. Q3. Is credit risk depends on loan_intent?"
  },
  {
    "objectID": "posts/NiyatiSharma_blog1.html#hypothesis",
    "href": "posts/NiyatiSharma_blog1.html#hypothesis",
    "title": "Final Project Proposal",
    "section": "Hypothesis",
    "text": "Hypothesis\nAccording to research credit risk of a particular borrower, lenders consider various factors include the borrower’s capacity to repay are income, character, house ownership, and credit history. Check the relationship between the age, income with credit risk with new dataset."
  },
  {
    "objectID": "posts/NiyatiSharma_blog1.html#dataset",
    "href": "posts/NiyatiSharma_blog1.html#dataset",
    "title": "Final Project Proposal",
    "section": "Dataset",
    "text": "Dataset\nThis dataset contains columns simulating credit bureau data, factors on which credit risk depends. The variables of interest for me are income, age, employment length and home ownership.\n\n\nCode\nlibrary(readr)\ndf <- read_csv(\"C:/Users/Lenovo/Downloads/credit_risk_dataset_1.csv\")\n\n\nRows: 32581 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): person_home_ownership, loan_intent, loan_grade, cb_person_default_o...\ndbl (8): person_age, person_income, person_emp_length, loan_amnt, loan_int_r...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nsummary(df)\n\n\n   person_age     person_income     person_home_ownership person_emp_length\n Min.   : 20.00   Min.   :   4000   Length:32581          Min.   :  0.00   \n 1st Qu.: 23.00   1st Qu.:  38500   Class :character      1st Qu.:  2.00   \n Median : 26.00   Median :  55000   Mode  :character      Median :  4.00   \n Mean   : 27.73   Mean   :  66075                         Mean   :  4.79   \n 3rd Qu.: 30.00   3rd Qu.:  79200                         3rd Qu.:  7.00   \n Max.   :144.00   Max.   :6000000                         Max.   :123.00   \n                                                          NA's   :895      \n loan_intent         loan_grade          loan_amnt     loan_int_rate  \n Length:32581       Length:32581       Min.   :  500   Min.   : 5.42  \n Class :character   Class :character   1st Qu.: 5000   1st Qu.: 7.90  \n Mode  :character   Mode  :character   Median : 8000   Median :10.99  \n                                       Mean   : 9589   Mean   :11.01  \n                                       3rd Qu.:12200   3rd Qu.:13.47  \n                                       Max.   :35000   Max.   :23.22  \n                                                       NA's   :3116   \n  loan_status     loan_percent_income cb_person_default_on_file\n Min.   :0.0000   Min.   :0.0000      Length:32581             \n 1st Qu.:0.0000   1st Qu.:0.0900      Class :character         \n Median :0.0000   Median :0.1500      Mode  :character         \n Mean   :0.2182   Mean   :0.1702                               \n 3rd Qu.:0.0000   3rd Qu.:0.2300                               \n Max.   :1.0000   Max.   :0.8300                               \n                                                               \n cb_person_cred_hist_length\n Min.   : 2.000            \n 1st Qu.: 3.000            \n Median : 4.000            \n Mean   : 5.804            \n 3rd Qu.: 8.000            \n Max.   :30.000"
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html",
    "href": "posts/NiyatiSharma_HW1.html",
    "title": "HW1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(stats)\n\n\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#question-1",
    "href": "posts/NiyatiSharma_HW1.html#question-1",
    "title": "HW1",
    "section": "Question 1",
    "text": "Question 1"
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#read-the-data-from-xls-file",
    "href": "posts/NiyatiSharma_HW1.html#read-the-data-from-xls-file",
    "title": "HW1",
    "section": "Read the data from xls file",
    "text": "Read the data from xls file\n\n\nCode\nRE <- read_excel(\"_data/LungCapData.xls\")\nRE\n\n\n# A tibble: 725 × 6\n   LungCap   Age Height Smoke Gender Caesarean\n     <dbl> <dbl>  <dbl> <chr> <chr>  <chr>    \n 1    6.48     6   62.1 no    male   no       \n 2   10.1     18   74.7 yes   female no       \n 3    9.55    16   69.7 no    female yes      \n 4   11.1     14   71   no    male   no       \n 5    4.8      5   56.9 no    male   no       \n 6    6.22    11   58.7 no    female no       \n 7    4.95     8   63.3 no    male   yes      \n 8    7.32    11   70.4 no    male   no       \n 9    8.88    15   70.5 no    male   no       \n10    6.8     11   59.2 no    male   no       \n# … with 715 more rows\n\n\n##A\n\n\nCode\nRE %>% \n  ggplot(aes(LungCap))+\n  geom_histogram(bins=20)\n\n\n\n\n\nThe histogram looks close to normal distributed."
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#b",
    "href": "posts/NiyatiSharma_HW1.html#b",
    "title": "HW1",
    "section": "B",
    "text": "B\n\n\nCode\nRE %>%\n  ggplot(aes (LungCap, color=Gender)) +\n  geom_boxplot() +\n  theme_classic() \n\n\n\n\n\nThe probability density of the female is higher than the males."
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#c",
    "href": "posts/NiyatiSharma_HW1.html#c",
    "title": "HW1",
    "section": "C",
    "text": "C\n\n\nCode\nMean_Smoker <- RE %>%\n  group_by(Smoke) %>%\n  summarise(mean = mean(LungCap))\nMean_Smoker\n\n\n# A tibble: 2 × 2\n  Smoke  mean\n  <chr> <dbl>\n1 no     7.77\n2 yes    8.65\n\n\nCode\nggplot(RE, aes(LungCap,Smoke))+\n  geom_boxplot()\n\n\n\n\n\nFrom this sample, it appears that smokers have a higher mean lung capacity than non-smokers."
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#d",
    "href": "posts/NiyatiSharma_HW1.html#d",
    "title": "HW1",
    "section": "D",
    "text": "D\n\n\nCode\nRE<-RE %>% \n  mutate(Category = as.factor(case_when(Age <= 13 ~ \"13 and under\", \n                           Age == 14 |Age ==15 ~ \"14-15\", \n                           Age == 16 | Age==17 ~ \"16-17\",\n                           Age >= 18 ~ \"18 or over\"\n                           )))\nRE\n\n\n# A tibble: 725 × 7\n   LungCap   Age Height Smoke Gender Caesarean Category    \n     <dbl> <dbl>  <dbl> <chr> <chr>  <chr>     <fct>       \n 1    6.48     6   62.1 no    male   no        13 and under\n 2   10.1     18   74.7 yes   female no        18 or over  \n 3    9.55    16   69.7 no    female yes       16-17       \n 4   11.1     14   71   no    male   no        14-15       \n 5    4.8      5   56.9 no    male   no        13 and under\n 6    6.22    11   58.7 no    female no        13 and under\n 7    4.95     8   63.3 no    male   yes       13 and under\n 8    7.32    11   70.4 no    male   no        13 and under\n 9    8.88    15   70.5 no    male   no        14-15       \n10    6.8     11   59.2 no    male   no        13 and under\n# … with 715 more rows\n\n\nCode\nRE %>%\n  ggplot(aes( LungCap, color = Smoke)) +\n  geom_histogram()+\n  facet_grid(Smoke ~ Category)\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nThe people who smoke are few in age group of “less than or equal to 13”. From the result we can say age is inversely proportional to the lung capacity."
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#e",
    "href": "posts/NiyatiSharma_HW1.html#e",
    "title": "HW1",
    "section": "E",
    "text": "E\nForm the above data we can say the output are pretty similar that smokers have a lower lung capacity compared to non-smokers"
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#f",
    "href": "posts/NiyatiSharma_HW1.html#f",
    "title": "HW1",
    "section": "F",
    "text": "F\ncorrelation and covariance between lung capacity and age\n\n\nCode\ncov(RE$LungCap,RE$Age)\n\n\n[1] 8.738289\n\n\nCode\ncor(RE$LungCap,RE$Age)\n\n\n[1] 0.8196749\n\n\nCovariance is positive and indicates that age and lung capacity are directly related. Correlation is also positive,from these results we can conclude that the lung capacity increases with age."
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#question-2",
    "href": "posts/NiyatiSharma_HW1.html#question-2",
    "title": "HW1",
    "section": "Question 2",
    "text": "Question 2\n\n\nCode\nx <- c(0:4)\nfreq <- c(128, 434, 160, 64, 24)\nconvictions <- data_frame(x, freq)\n\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nPlease use `tibble()` instead.\n\n\nCode\nconvictions\n\n\n# A tibble: 5 × 2\n      x  freq\n  <int> <dbl>\n1     0   128\n2     1   434\n3     2   160\n4     3    64\n5     4    24\n\n\n\n\nCode\nconvictions <- convictions %>% mutate(probability = freq/sum(freq))\nconvictions\n\n\n# A tibble: 5 × 3\n      x  freq probability\n  <int> <dbl>       <dbl>\n1     0   128      0.158 \n2     1   434      0.536 \n3     2   160      0.198 \n4     3    64      0.0790\n5     4    24      0.0296"
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#a",
    "href": "posts/NiyatiSharma_HW1.html#a",
    "title": "HW1",
    "section": "A",
    "text": "A\nProbability of exactly 2 is 19.75%"
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#b-1",
    "href": "posts/NiyatiSharma_HW1.html#b-1",
    "title": "HW1",
    "section": "B",
    "text": "B\n\n\nCode\na <-head(convictions,2)\nsum(a$probability)\n\n\n[1] 0.6938272\n\n\nProbability that a randomly selected inmate has fewer than 2 prior convictions : 69.38%"
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#c-1",
    "href": "posts/NiyatiSharma_HW1.html#c-1",
    "title": "HW1",
    "section": "C",
    "text": "C\n\n\nCode\na <-head(convictions,3)\nsum(a$probability)\n\n\n[1] 0.891358\n\n\nThe probability that a randomly selected inmate has 2 or fewer prior convictions : 89.13%"
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#d-1",
    "href": "posts/NiyatiSharma_HW1.html#d-1",
    "title": "HW1",
    "section": "D",
    "text": "D\n\n\nCode\na <-tail(convictions,2)\nsum(a$probability)\n\n\n[1] 0.108642\n\n\nThe probability that a randomly selected inmate has more than 2 prior convictions? : 10.86%"
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#e-1",
    "href": "posts/NiyatiSharma_HW1.html#e-1",
    "title": "HW1",
    "section": "E",
    "text": "E\n\n\nCode\nWE <- weighted.mean(convictions$x,convictions$probability)\nWE\n\n\n[1] 1.28642\n\n\nThe expected value for the number of prior convictions : 1.28"
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#f-1",
    "href": "posts/NiyatiSharma_HW1.html#f-1",
    "title": "HW1",
    "section": "F",
    "text": "F\nThe variance is 0.857 and the standard deviation is 0.925\n\n\nCode\nAB <- (sum(freq*((x-WE)^2)))/(sum(freq)-1)\nAB\n\n\n[1] 0.8572937\n\n\nCode\nsqrt(AB)\n\n\n[1] 0.9259016"
  },
  {
    "objectID": "posts/Project_Yakub Rabiutheen.html",
    "href": "posts/Project_Yakub Rabiutheen.html",
    "title": "Project Rough Draft Proposal",
    "section": "",
    "text": "Hypopthesis\nThis research project will be testing two hypothesis regarding Britain and France.\n#Colonial Powers Hypopthesis. 1. The Years that France and Britain had more Exports is when the rate of colonization increased. 2. The Years that France and Britain had more Iron Production correlates to the years France and Britain increased levels of colonization.\n\n\nCode\nlibrary(readxl)\nlibrary(readr)\nColonial_Years <- read_excel(\"C:/Users/yakub/Documents/GitHub/603_Fall_2022/posts/_data/Colonial_transformation_data.xls\")\n\n\nError: `path` does not exist: 'C:/Users/yakub/Documents/GitHub/603_Fall_2022/posts/_data/Colonial_transformation_data.xls'\n\n\nCode\nImports_Exports<-read_csv(\"C:/Users/yakub/Documents/GitHub/603_Fall_2022/posts/_data/Countries_Imports_Exports.csv\")\n\n\nError: 'C:/Users/yakub/Documents/GitHub/603_Fall_2022/posts/_data/Countries_Imports_Exports.csv' does not exist.\n\n\nCode\nmilitary_raw_metals<-read_csv(\"C:/Users/yakub/Documents/GitHub/603_Fall_2022/posts/_data/NMC_v4_0.csv\")\n\n\nError: 'C:/Users/yakub/Documents/GitHub/603_Fall_2022/posts/_data/NMC_v4_0.csv' does not exist.\n\n\n#Descriptive Statistics.\nAs shown below, I tried finding Data regarding when colonialism began by France and Uk and seeing whether France and UK had more Trade Surpluses as they expanded their colonial empire. However, I was proven wrong as it appears that the UK has been running a Trade Deficit and has never had a Trade Surplus during their Colonial era pre-1960s. As such, I will have to change the approach of this research study. It appears the Balance of Trade has no relationship to Colonialism.\n\n\nCode\ncolnames(Colonial_Years)[3] <- \"Colonizing Country\"\n\n\nError in colnames(Colonial_Years)[3] <- \"Colonizing Country\": object 'Colonial_Years' not found\n\n\nCode\ncolnames(Colonial_Years)[4]<- \"Year_Colonization_Began\"\n\n\nError in colnames(Colonial_Years)[4] <- \"Year_Colonization_Began\": object 'Colonial_Years' not found\n\n\n\n\nCode\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nColonial_Years<-select(Colonial_Years,\"Colonizing Country\",\"Year_Colonization_Began\")\n\n\nError in select(Colonial_Years, \"Colonizing Country\", \"Year_Colonization_Began\"): object 'Colonial_Years' not found\n\n\nCode\nColonial_Years<-filter(Colonial_Years,`Colonizing Country` %in% c(\"F\",\"UK\"))\n\n\nError in filter(Colonial_Years, `Colonizing Country` %in% c(\"F\", \"UK\")): object 'Colonial_Years' not found\n\n\nCode\ntable(Colonial_Years)\n\n\nError in table(Colonial_Years): object 'Colonial_Years' not found\n\n\n\n\nCode\nImports_Exports%>% filter(year < '1960') \n\n\nError in filter(., year < \"1960\"): object 'Imports_Exports' not found\n\n\n\n\nCode\ncolonial_trade<-filter(Imports_Exports,`stateabb` %in% c(\"FRN\",\"UKG\"))\n\n\nError in filter(Imports_Exports, stateabb %in% c(\"FRN\", \"UKG\")): object 'Imports_Exports' not found\n\n\n\n\nCode\noptions(scipen = 999)    \n\n\nCreated a Forumula to calculate Trade Surplus and Deficits.\n\n\nCode\ncolonial_trade$trade_balance<-(colonial_trade$exports-colonial_trade$imports)\n\n\nError in eval(expr, envir, enclos): object 'colonial_trade' not found\n\n\nFound a better way to find years that France and Britain were running Trade Deficits.\n\n\nCode\nprint(colonial_trade[colonial_trade$exports < colonial_trade$imports,] )\n\n\nError in print(colonial_trade[colonial_trade$exports < colonial_trade$imports, : object 'colonial_trade' not found\n\n\nI did the inverse to find that the UK has always had a Trade Deficit\n\n\nCode\nprint(colonial_trade[colonial_trade$exports > colonial_trade$imports,] )\n\n\nError in print(colonial_trade[colonial_trade$exports > colonial_trade$imports, : object 'colonial_trade' not found\n\n\nMy finding has found that there is no relationship between Trade Deficits and Colonialism as the UK has never had a positive trade balance.\n##Conclusion\nI think that the approach of my research has to be changed as my initial theory about trade deficits and Colonialism has been disapprove. As such, I think I will shift this project towards a different approach. I will try exploring the historical prices of commodity goods when France and U.K. were colonial powers.\n\n\nReferences\nMcWhinney, E. (1960, December 14). Declaration on the granting of Independence to colonial countries and Peoples. United Nations. Retrieved October 10, 2022, from https://legal.un.org/avl/ha/dicc/dicc.html\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::{#quarto-navigation-envelope .hidden}\n[Project Rough Draft Proposal]{.hidden render-id=\"quarto-int-sidebar-title\"}\n[Project Rough Draft Proposal]{.hidden render-id=\"quarto-int-navbar-title\"}\n[Fall 2022 Posts]{.hidden render-id=\"quarto-int-navbar:Fall 2022 Posts\"}\n[Contributors]{.hidden render-id=\"quarto-int-navbar:Contributors\"}\n[DACSS]{.hidden render-id=\"quarto-int-navbar:DACSS\"}\n:::\n\n\n\n:::{#quarto-meta-markdown .hidden}\n[ - Project Rough Draft Proposal]{.hidden render-id=\"quarto-metatitle\"}\n[International Trade's influence on War]{.hidden render-id=\"quarto-metadesc\"}\n:::\n\n\n\n\n<!-- -->\n\n::: {.quarto-embedded-source-code}\n```````````````````{.markdown shortcodes=\"false\"}\n---\ntitle: \"Project Rough Draft Proposal\"\nauthor: \"Yakub Rabiutheen\"\ndescription: \"International Trade's influence on War\"\ndate: \"10/11/2022\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - finalproject1\n  - desriptive statistics \n  - probability\n---\n\n# Research Question\n\nHow has international trade influenced how countries interact with each other? This research project looks specifically at  France and Britain which  are grouped together as Colonial Powers to explore the relationship of Colonialism and international trade. This research project will be looking at data from the Correlates Of War Project, which has international trade data from 1870 to 2015. The cut-off year for this research project will be 1960, as  on December 14,1960, the UN declared Colonialism was a human's right's violation and legally declared Colonialism was over(McWhinney,1960).   \n\n\n# Hypopthesis\n\nThis research project will be testing two hypothesis regarding Britain and France.\n\n#Colonial Powers Hypopthesis.\n1. The Years that France and Britain had more Exports is when the rate of colonization increased.\n2. The Years that France and Britain had more Iron Production correlates to the years France and Britain increased levels of colonization.\n\n\n\nquarto-executable-code-5450563D\n\n```r\nlibrary(readxl)\nlibrary(readr)\nColonial_Years <- read_excel(\"C:/Users/yakub/Documents/GitHub/603_Fall_2022/posts/_data/Colonial_transformation_data.xls\")\nImports_Exports<-read_csv(\"C:/Users/yakub/Documents/GitHub/603_Fall_2022/posts/_data/Countries_Imports_Exports.csv\")\nmilitary_raw_metals<-read_csv(\"C:/Users/yakub/Documents/GitHub/603_Fall_2022/posts/_data/NMC_v4_0.csv\")\n#Descriptive Statistics.\nAs shown below, I tried finding Data regarding when colonialism began by France and Uk and seeing whether France and UK had more Trade Surpluses as they expanded their colonial empire. However, I was proven wrong as it appears that the UK has been running a Trade Deficit and has never had a Trade Surplus during their Colonial era pre-1960s. As such, I will have to change the approach of this research study. It appears the Balance of Trade has no relationship to Colonialism.\nquarto-executable-code-5450563D\ncolnames(Colonial_Years)[3] <- \"Colonizing Country\"\ncolnames(Colonial_Years)[4]<- \"Year_Colonization_Began\"\nquarto-executable-code-5450563D\nlibrary(dplyr)\nColonial_Years<-select(Colonial_Years,\"Colonizing Country\",\"Year_Colonization_Began\")\nColonial_Years<-filter(Colonial_Years,`Colonizing Country` %in% c(\"F\",\"UK\"))\ntable(Colonial_Years)\nquarto-executable-code-5450563D\nImports_Exports%>% filter(year < '1960') \nquarto-executable-code-5450563D\ncolonial_trade<-filter(Imports_Exports,`stateabb` %in% c(\"FRN\",\"UKG\"))\nquarto-executable-code-5450563D\noptions(scipen = 999)    \nCreated a Forumula to calculate Trade Surplus and Deficits.\nquarto-executable-code-5450563D\ncolonial_trade$trade_balance<-(colonial_trade$exports-colonial_trade$imports)\nFound a better way to find years that France and Britain were running Trade Deficits. quarto-executable-code-5450563D\nprint(colonial_trade[colonial_trade$exports < colonial_trade$imports,] )\nI did the inverse to find that the UK has always had a Trade Deficit quarto-executable-code-5450563D\nprint(colonial_trade[colonial_trade$exports > colonial_trade$imports,] )\nMy finding has found that there is no relationship between Trade Deficits and Colonialism as the UK has never had a positive trade balance.\n##Conclusion\nI think that the approach of my research has to be changed as my initial theory about trade deficits and Colonialism has been disapprove. As such, I think I will shift this project towards a different approach. I will try exploring the historical prices of commodity goods when France and U.K. were colonial powers.\n\n\nReferences\nMcWhinney, E. (1960, December 14). Declaration on the granting of Independence to colonial countries and Peoples. United Nations. Retrieved October 10, 2022, from https://legal.un.org/avl/ha/dicc/dicc.html\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "posts/Quarkume HW1.html#lungcapdate",
    "href": "posts/Quarkume HW1.html#lungcapdate",
    "title": "HW1 Quat",
    "section": "LungCapDate",
    "text": "LungCapDate\n\nUse the LungCapData to answer the following questions. (Hint: Using dplyr, especially group_by() and summarize() can help you answer the following questions relatively efficiently.)\n\nInstall Libraries\n\n#install.packages(\"dplyr\")\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n#install.packages(\"ggplot2\")\nlibrary(ggplot2)\n#install.packages(\"readxl\")\nlibrary(readxl)\n#install.packages(\"magrittr\")\nlibrary(magrittr)\n\n\nWhat does the distribution of LungCap look like?\nThe distribution of Lung Capacity in the data set looks normally distributed.\n\n\n#histogram of LungCap\nhist(LungCapData$LungCap, xlab = 'LungCap', main = '', freq = F)\n\nError in hist(LungCapData$LungCap, xlab = \"LungCap\", main = \"\", freq = F): object 'LungCapData' not found\n\n\n\nCompare the probability distribution of the LungCap with respect to Males and Females?\nLooking at the comparative boxplot males have a higher lung capacity than females.\n\n\nboxplot(LungCapData$LungCap ~ LungCapData$Gender,\n        col = c(\"#FFE0B2\", \"#FFA726\"))\n\nError in eval(predvars, data, env): object 'LungCapData' not found\n\n\nc. Compare the mean lung capacities for smokers and non-smokers. Does it make sense? In comparing the means, the lung capacity for smokers is higher than for nonsmokers.\n\n#Mean Lung capacities of smokers\nLungCapData %>%\n  filter(Smoke == 'yes') %>%\n  pull(LungCap) %>%\n  mean()\n\nError in filter(., Smoke == \"yes\"): object 'LungCapData' not found\n\n#Mean Lung capacities of non-smokers\nLungCapData %>%\n  filter(Smoke == 'no') %>%\n  pull(LungCap) %>%\n  mean()\n\nError in filter(., Smoke == \"no\"): object 'LungCapData' not found\n\n\nd. Examine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\n#new var for Age Groups\nLungCapData$Age_Cat <- cut(LungCapData$Age,\n                           breaks = c(0,13,15,17,25),\n                           labels = c('less than or equal to 13','14 to 15','16 to 17','greater than or equal to 18'))\n\nError in cut(LungCapData$Age, breaks = c(0, 13, 15, 17, 25), labels = c(\"less than or equal to 13\", : object 'LungCapData' not found\n\nggplot(LungCapData, aes(x=Smoke, y=LungCap)) + \n    geom_boxplot() +\n  facet_wrap(~Age_Cat, scale=\"free\")\n\nError in ggplot(LungCapData, aes(x = Smoke, y = LungCap)): object 'LungCapData' not found\n\n\ne. Compare the lung capacities for smokers and non-smokers within each age group. Is your answer different from the one in part c. What could possibly be going on here? We see an intervening relationship with age. Where most young children either don’t smoke ar all and have smaller lung capacities because of their size.\n\nggplot(LungCapData, aes(x=Smoke, y=LungCap)) + \n    geom_boxplot() +\n  facet_wrap(~Age, scale=\"free\")\n\n--\n  \n\nError: <text>:7:0: unexpected end of input\n5: --\n6:   \n  ^\n\n\nf.Calculate the correlation and correlation between Lung Capacity and Age. (use the cov() and cor() functions in R).\n\n#correlation\nLungCapData %>% \n  summarize(correlation = cor(LungCap, Age))\n\nError in summarize(., correlation = cor(LungCap, Age)): object 'LungCapData' not found\n\n#correlation\nLungCapData %>% \n  summarize(covariance = cov(LungCap, Age))\n\nError in summarize(., covariance = cov(LungCap, Age)): object 'LungCapData' not found"
  },
  {
    "objectID": "posts/Quarkume HW1.html#examination-of-prison-convictions",
    "href": "posts/Quarkume HW1.html#examination-of-prison-convictions",
    "title": "HW1 Quat",
    "section": "1. Examination of Prison Convictions",
    "text": "1. Examination of Prison Convictions"
  },
  {
    "objectID": "posts/Quarkume HW1.html#prisondata",
    "href": "posts/Quarkume HW1.html#prisondata",
    "title": "HW1 Quat",
    "section": "PrisonData",
    "text": "PrisonData\nData\n\nPrisonData <- tibble(\n  prior_convictions = c(0,1,2,3,4),\n  freq = c(128,434,160,64,24))\n\nPrisonData\n\n# A tibble: 5 × 2\n  prior_convictions  freq\n              <dbl> <dbl>\n1                 0   128\n2                 1   434\n3                 2   160\n4                 3    64\n5                 4    24\n\nnum <- sum (PrisonData$freq)\nnum\n\n[1] 810\n\n\n\nWhat is the probability that a randomly selected inmate has exactly 2 prior convictions?\n\n\nPrisonData %>% \n  filter(prior_convictions == 2) %>% \n  pull (freq) %>% \n  divide_by (num)\n\n[1] 0.1975309\n\n\nb. What is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\nPrisonData %>% \n  filter(prior_convictions < 2) %>% \n  pull (freq) %>% \n  sum() %>%\n  divide_by (num)\n\n[1] 0.6938272\n\n\nc. What is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\nPrisonData %>% \n  filter(prior_convictions <= 2) %>% \n  pull (freq) %>% \n  sum() %>%\n  divide_by (num)\n\n[1] 0.891358\n\n\nd.What is the probability that a randomly selected inmate has more than 2 prior convictions?\n\nPrisonData %>% \n  filter(prior_convictions > 2) %>% \n  pull (freq) %>% \n  sum() %>%\n  divide_by (num)\n\n[1] 0.108642\n\n\ne. What is the expected value for the number of prior convictions?\n\nsum(prior_convictions*freq)\n\nError in eval(expr, envir, enclos): object 'prior_convictions' not found\n\n\nf. Calculate the variance and the standard deviation for the Prior Convictions.\n\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html",
    "href": "posts/RahulGundeti_DACSS603_HW1.html",
    "title": "DACSS603_HW1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(stats)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#question-1",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#question-1",
    "title": "DACSS603_HW1",
    "section": "Question 1",
    "text": "Question 1"
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#reading-data",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#reading-data",
    "title": "DACSS603_HW1",
    "section": "Reading data",
    "text": "Reading data\n\n\nCode\nlung <- read_excel(\"C:/Users/gunde/Downloads/LungCapData.xls\")\nlung\n\n\n\n\n  \n\n\n\nThe Lung Capacity data contains 725 rows and 6 columns that determine age, height etc., The key classification parameter is based on smoker vs non-smoker."
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#a",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#a",
    "title": "DACSS603_HW1",
    "section": "1_A",
    "text": "1_A\nThe distribution of LungCap looks as follows:\n\n\nCode\nlung %>%\n  ggplot(aes(LungCap, ..density..)) +\n  geom_histogram(bins= 40, color = \"red\") +\n  geom_density(color = \"green\") +\n  theme_classic() + \n  labs(title = \"LungCap Probability Distribution\", x = \"Lung Capcity\", y = \"Probability Density\")\n\n\n\n\n\nThe observations plotted by histogram are closer to mean which suggests that it is a normal distribution."
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#b",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#b",
    "title": "DACSS603_HW1",
    "section": "1_B",
    "text": "1_B\nThe distribution of LungCap on basis of gender looks as follows:\n\n\nCode\nlung %>%\n  ggplot(aes(y = dnorm(LungCap), color = Gender)) +\n  geom_boxplot() +\n  theme_classic() + \n  labs(title = \"LungCap Probability Distribution based on gender\", y = \"Probability Density\")\n\n\n\n\n\nThe box plot shows that the probability density of the male < female."
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#c",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#c",
    "title": "DACSS603_HW1",
    "section": "1_C",
    "text": "1_C\nComparison of mean lung capacities between smokers and non-smokers:\n\n\nCode\nMean_smoke <- lung %>%\n  group_by(Smoke) %>%\n  summarise(mean = mean(LungCap))\nMean_smoke\n\n\n\n\n  \n\n\n\nThe table contains the mean lung capacity. The observations suggest that the mean value is higher for smokers than non-smokers. This isn’t entirely correct as the individual biological factors plays a main role. So the data is inadequate to form an opinion."
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#d",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#d",
    "title": "DACSS603_HW1",
    "section": "1_D",
    "text": "1_D\nRelationship between Smoke and Lung capacity on basis of given age categories:\n\n\nCode\nlung <- mutate(lung, AgeGrp = case_when(Age <= 13 ~ \"less than or equal to 13\",\n                                    Age == 14 | Age == 15 ~ \"14 to 15\",\n                                    Age == 16 | Age == 17 ~ \"16 to 17\",\n                                    Age >= 18 ~ \"greater than or equal to 18\"))\n\nlung %>%\n  ggplot(aes(y = LungCap, color = Smoke)) +\n  geom_histogram(bins = 40) +\n  facet_wrap(vars(AgeGrp)) +\n  theme_classic() + \n  labs(title = \"Relationship of LungCap and Smoke based on age categories\", y = \"Lung Capacity\", x = \"Frequency\")\n\n\n\n\n\nFrom the above plot, we can derive two important observations: 1. The lung capacity of non-smokers is more than smokers. 2. The people who smoke are less in age group of “less than or equal to 13”. So as the result as age increases the lung capacity decreases."
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#e",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#e",
    "title": "DACSS603_HW1",
    "section": "1_E",
    "text": "1_E\nRelationship between Smoke and Lung capacity on basis of age:\n\n\nCode\nlung %>%\n  ggplot(aes(x = Age, y = LungCap, color = Smoke)) +\n  geom_line() +\n  theme_classic() + \n  facet_wrap(vars(Smoke)) +\n  labs(title = \"Relationship of LungCap and Smoke based on age\", y = \"Lung Capacity\", x = \"Age\")\n\n\n\n\n\nComparing 1_D and 1_E we can find similarity which points that only 10 and above age group smoke."
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#f",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#f",
    "title": "DACSS603_HW1",
    "section": "1_F",
    "text": "1_F\nCalculating the correlation and covariance between Lung Capacity and Age:\n\n\nCode\nCovariance <- cov(lung$LungCap, lung$Age)\nCorrelation <- cor(lung$LungCap, lung$Age)\nCovariance\n\n\n[1] 8.738289\n\n\nCode\nCorrelation\n\n\n[1] 0.8196749\n\n\nThe comparison shows that the covariance is positive, indicating that lung capacity and age have a direct relationship. As a result, they are moving in the same direction due to the positive correlation as well. This means that as age increases, lung capacity increases as well, which means they are directly proportional."
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#question-2",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#question-2",
    "title": "DACSS603_HW1",
    "section": "Question 2",
    "text": "Question 2"
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#reading-the-table",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#reading-the-table",
    "title": "DACSS603_HW1",
    "section": "Reading the table",
    "text": "Reading the table\n\n\nCode\nPrior_convitions <- c(0:4)\nInmate_count <- c(128, 434, 160, 64, 24)\nprior <- data_frame(Prior_convitions, Inmate_count)\n\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nPlease use `tibble()` instead.\nThis warning is displayed once every 8 hours.\nCall `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.\n\n\nCode\nprior\n\n\n\n\n  \n\n\n\n\n\nCode\nprior <- mutate(prior, Probability = Inmate_count/sum(Inmate_count))\nprior"
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#a-1",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#a-1",
    "title": "DACSS603_HW1",
    "section": "2_A",
    "text": "2_A\nProbability that a randomly selected inmate has exactly 2 prior convictions:\n\n\nCode\nprior %>%\n  filter(Prior_convitions == 2) %>%\n  select(Probability)"
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#b-1",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#b-1",
    "title": "DACSS603_HW1",
    "section": "2_B",
    "text": "2_B\nProbability that a randomly selected inmate has fewer than 2 convictions:\n\n\nCode\nrandom <- prior %>%\n  filter(Prior_convitions < 2)\nsum(random$Probability)\n\n\n[1] 0.6938272"
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#c-1",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#c-1",
    "title": "DACSS603_HW1",
    "section": "2_C",
    "text": "2_C\nProbability that a randomly selected inmate has 2 or fewer prior convictions:\n\n\nCode\nrandom <- prior %>%\n  filter(Prior_convitions <= 2)\nsum(random$Probability)\n\n\n[1] 0.891358"
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#d-1",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#d-1",
    "title": "DACSS603_HW1",
    "section": "2_D",
    "text": "2_D\nProbability that a randomly selected inmate has more than 2 prior convictions:\n\n\nCode\nrandom <- prior %>%\n  filter(Prior_convitions > 2)\nsum(random$Probability)\n\n\n[1] 0.108642"
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#e-1",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#e-1",
    "title": "DACSS603_HW1",
    "section": "2_E",
    "text": "2_E\nExpected value for the number of prior convictions:\n\n\nCode\nprior <- mutate(prior, Wm = Prior_convitions*Probability)\nev <- sum(prior$Wm)\nev\n\n\n[1] 1.28642"
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#f-1",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#f-1",
    "title": "DACSS603_HW1",
    "section": "2_F",
    "text": "2_F\nVariance for the Prior Convictions:\n\n\nCode\nvariance <-sum(((prior$Prior_convitions-ev)^2)*prior$Probability)\nvariance\n\n\n[1] 0.8562353\n\n\nstandard deviation for the Prior Convictions:\n\n\nCode\nsqrt(variance)\n\n\n[1] 0.9253298"
  },
  {
    "objectID": "posts/shelton_HW1.html",
    "href": "posts/shelton_HW1.html",
    "title": "Homework 1 Solution",
    "section": "",
    "text": "1.) Using LungCapData, answer descriptive questions about the data and its distributions.\n2.) Use the given distribution to answer questions about the probability of discrete events.\n\n\n\n\n\n\nCode\n#| include: false\n#| label: Loading in LungCap\n\n og_lungcap <- readxl::read_xls(\"_data/LungCapData.xls\")\n\n# Quick look at dataset\n# glimpse(og_lungcap)\n\n# Variables - 3<dbl> ratio 3<char> (can coerce to logical if needed), \n\n# length(which(is.na(og_lungcap)))\n\n# No missing values to consider\n\n# Descriptive\n# summarytools::dfSummary(og_lungcap)\n\n\nLungCapData: Describes the lung capacity of a population of 725 children aged 3 - 19. It further categorizes the subjects by height, sex, smoking habits, and whether they were birthed using the Caesarean section technique.\nIn the following sections, we’ll use select(), group_by(), filter(), and summarize() to further explore the data and find important relations between variables.\n\n\n\n\n\n\n\n\nLungCap looks to be approximately normally distributed (unimodal, symmetric) with most observations centered around the mean (7.86).\n\n\n\n\n\nCode\nhist_gender <- ggplot(og_lungcap, aes(x=LungCap, y=..density.., fill=Gender)) +\n  geom_histogram(alpha=.5, position=\"identity\", bins=20)+\n  geom_vline(aes(xintercept=mean(LungCap)))\nhist_gender\n\n\n\n\n\nPackage ggplot2 functions ggplot() and geom_histogram() are used to display the LungCap distribution filled by the Gender variable. Both density plots center on the mean, indicating both male and female lung capacity observations are highly concentrated around the mean. The male distribution is shifted slightly to the right of the female distribution, meaning male observations had a higher upper range value than female observations. Males had more observations concentrated to the right of the mean, and the female distribution reciprocated this effect to the left of the mean.\n\n\n\n\n\nCode\nsmokers <- group_by(og_lungcap, Smoke)\nsmokers %>%\n  summarize(mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke `mean(LungCap)`\n  <chr>           <dbl>\n1 no               7.77\n2 yes              8.65\n\n\nAfter creating a new dataset smokers by using group_by() on our original data, smokers is piped into a summarize() call. The results surprisingly show that the smoking group had a higher mean lung capacity than the nonsmoking group. This is likely due to a mean age difference within the groups.\n\n\n\n\n\nCode\n# Creating Age Groups Using Case When\n\nsmokers_age <- smokers %>%\n  mutate(AgeGroup = case_when(Age >= 18 ~ \"18+\", \n            Age == 16 | Age == 17 ~ \"16-17\",\n            Age == 14 | Age == 15 ~ \"14-15\",\n            Age <= 13~ \"Under 13\"))\n\n# Mean LungCap by Age and Smoke\n# Must regroup by Smoke again\nsmokers_age %>%\n  group_by(AgeGroup, Smoke) %>%\n    summarize(mean(LungCap))\n\n\n# A tibble: 8 × 3\n# Groups:   AgeGroup [4]\n  AgeGroup Smoke `mean(LungCap)`\n  <chr>    <chr>           <dbl>\n1 14-15    no               9.14\n2 14-15    yes              8.39\n3 16-17    no              10.5 \n4 16-17    yes              9.38\n5 18+      no              11.1 \n6 18+      yes             10.5 \n7 Under 13 no               6.36\n8 Under 13 yes              7.20\n\n\nAfter using mutate() to add a column AgeGroup to a copy of smokers, group_by() groups the new dataset by AgeGroup and Smoke before piping it into a summarize() command to find the grouped means of LungCap by AgeGroup and Smoke.\nThe results show that for children above the age of 13, smokers had a lower mean lung capacity than non-smokers. However, for the 13 and under group, we again see results that imply smokers have greater lung capacity than nonsmokers. Let’s investigate further into the relationship between age and lung capacity to explain this quizzical result.\n\n\n\n\n\nCode\ncov(og_lungcap$Age, og_lungcap$LungCap)\n\n\n[1] 8.738289\n\n\nCode\ncor(og_lungcap$Age, og_lungcap$LungCap)\n\n\n[1] 0.8196749\n\n\nCode\n#GGPlot of Age vs Lung\nggplot(og_lungcap, aes(x=Age, y=LungCap)) + geom_point()\n\n\n\n\n\nAge and LungCap have a high covariance which leads to a high correlation (p=0.82). This strong positive value (-1<p<1) indicates these variables “vary greatly” together: when Age is high in the data, so is LungCap. We cannot say that an increase in Age causes an increase Lung capacity without first showing this through regression; however, our results show the variables are highly correlated.\nWe can use knowledge of the human body to infer that as our body ages, our lungs mature. The ages of smokers of the Under 13 group are likely highly left skewed, as I don’t expect many children under 10 to be smoking. This underlying age distribution explains our puzzling results from the previous section.\n\n\nCode\nsmokers_age%>%\n  group_by(AgeGroup, Smoke) %>%\n    summarize(mean(Age))\n\n\n`summarise()` has grouped output by 'AgeGroup'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 3\n# Groups:   AgeGroup [4]\n  AgeGroup Smoke `mean(Age)`\n  <chr>    <chr>       <dbl>\n1 14-15    no          14.5 \n2 14-15    yes         14.6 \n3 16-17    no          16.4 \n4 16-17    yes         16.6 \n5 18+      no          18.5 \n6 18+      yes         18.1 \n7 Under 13 no           9.49\n8 Under 13 yes         11.7 \n\n\n\n\n\n\nFirst, let’s create two vectors: x_val and freq. Then, we’ll use rbind() to create a table.\n\n\nCode\nx_val <-c(0,1,2,3,4)\nfreq <- c(128,434,160,64,24)\nprob <- freq/sum(freq)\n\nxdist <- rbind(x_val,prob)\n\nxdist\n\n\n           [,1]      [,2]      [,3]       [,4]       [,5]\nx_val 0.0000000 1.0000000 2.0000000 3.00000000 4.00000000\nprob  0.1580247 0.5358025 0.1975309 0.07901235 0.02962963\n\n\n\n\n\n\nCode\n# Finding probability of inmate having exactly 2 prior convictions\n\n#Column Index is 3 as the first column is 0\n\n#Surely there is a cleaner way to do this using tidyverse functions rather than base?\n\n# a\na <- xdist['prob',3] \na\n\n\n     prob \n0.1975309 \n\n\n\n\n\n\n\nCode\n#b\nb <- sum(xdist['prob',1:2])\nb\n\n\n[1] 0.6938272\n\n\n\n\n\n\n\nCode\n# c\nc <- a + b\nc\n\n\n    prob \n0.891358 \n\n\n\n\n\n\n\nCode\n#d\nd <- 1 - c\nd\n\n\n    prob \n0.108642 \n\n\n\n\n\n\n\n[1] 1.28642\n\n\n\n\n\n\n\n\n\nCode\n# Var= E(X^2) - E(X)^2\n# Again using brute force because cannot use var() function on the object xdist correctly\nvar_x <-sum((x_val^2)*prob) - ex^2\nvar_x\n\n\n[1] 0.8562353\n\n\n\n\n\n\n\n[1] 0.9253298"
  },
  {
    "objectID": "posts/ShoshanaBuck- HW1.html",
    "href": "posts/ShoshanaBuck- HW1.html",
    "title": "ShoshanaBuck-HW1",
    "section": "",
    "text": "Question 1\nUse the LungCapData to answer the following questions.\n\n\nCode\n# read in data\nlung_cap<- read_xls(\"_data/LungCapData.xls\")\nlung_cap\n\n\n# A tibble: 725 × 6\n   LungCap   Age Height Smoke Gender Caesarean\n     <dbl> <dbl>  <dbl> <chr> <chr>  <chr>    \n 1    6.48     6   62.1 no    male   no       \n 2   10.1     18   74.7 yes   female no       \n 3    9.55    16   69.7 no    female yes      \n 4   11.1     14   71   no    male   no       \n 5    4.8      5   56.9 no    male   no       \n 6    6.22    11   58.7 no    female no       \n 7    4.95     8   63.3 no    male   yes      \n 8    7.32    11   70.4 no    male   no       \n 9    8.88    15   70.5 no    male   no       \n10    6.8     11   59.2 no    male   no       \n# … with 715 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\na. What does the distribution of LungCap look like?\n\n\nCode\n#plot histogram\nhist(lung_cap$LungCap)\n\n\n\n\n\nThe histogram shows that the distribution is pretty close to a normal distribution, with an almost a bell shaped curve. Meaning that the data near the mean are more of a frequent occurrence which is true because there are fewer observations near the margins.\n\n\nb. compare the probability distribution of the LungCap with respect to Males and Females?\n\n\nCode\n#Box plot\nggplot(lung_cap, aes (Gender,LungCap)) + geom_boxplot()\n\n\n\n\n\nThe box plot shows that male’s have a slightly higher lung capacity than females. Female’s have more values in the first quartile range and a lower minimum value than male’s. On the other hand male’s have a higher max value and more values in the 3rd quartile range.\n\n\nc. Compare the mean lung capacities for smokers and non-smokers. Does it make sense?\n\n\nCode\nlung_cap %>% \n  group_by(Smoke) %>% \n  summarise(avg_lung_cap = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke avg_lung_cap\n  <chr>        <dbl>\n1 no            7.77\n2 yes           8.65\n\n\nThis does not make sense. Smokers have a higher sample mean than non-smokers which intuitively does not make sense because we would assume non-smokers would have a higher lung capacity.\n\n\nd. Examine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\n\nCode\n#categorical variable of age_groups \ndf<- lung_cap %>% \ngroup_by(Smoke,LungCap) %>% \n  summarise(age_group = case_when(Age<=13 ~ \"13 & under\",Age ==14 | Age == 15 ~ \"14 to 15\",Age== 16 | Age == 17 ~ \"16 to 17\", Age>=18 ~ \"18 & older\")) \n\n\n`summarise()` has grouped output by 'Smoke', 'LungCap'. You can override using\nthe `.groups` argument.\n\n\nCode\n#mean of lung capacity with new variable\ndf %>% \n  group_by(Smoke, age_group) %>% \n  summarise(avg_lung_cap = mean(LungCap)) %>% \n  arrange(desc(avg_lung_cap))\n\n\n`summarise()` has grouped output by 'Smoke'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 3\n# Groups:   Smoke [2]\n  Smoke age_group  avg_lung_cap\n  <chr> <chr>             <dbl>\n1 no    18 & older        11.1 \n2 yes   18 & older        10.5 \n3 no    16 to 17          10.5 \n4 yes   16 to 17           9.38\n5 no    14 to 15           9.14\n6 yes   14 to 15           8.39\n7 yes   13 & under         7.20\n8 no    13 & under         6.36\n\n\nCode\n#histogram\nggplot(df, aes(x = LungCap)) + facet_grid(Smoke ~age_group) +geom_histogram()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nUsing the package ggplot I used the function facet_grids to show a good visualization of the lung capacity between non-smokers and smokers within each age group. Looking at the histograms all age_groups that are non-smokers have a higher sample mean proving that non-smokers have\n\n\ne. Compare the lung capacities for smokers and non-smokers within each age group. Is your answer different from the one in part d. What could possibly be going on here?\n\n\nCode\n# Mean of non-smokers 13 & younger\ndf %>% \n  filter(Smoke == 'no' & age_group == '13 & under') %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 6.358746\n\n\nCode\n# Mean of smokers 13 & younger\ndf %>% \n  filter(Smoke == 'yes' & age_group == '13 &under') %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] NaN\n\n\nCode\n#Mean of non-smokers 14 to 15\ndf %>% \n  filter(Smoke == 'no' & age_group == '14 to 15') %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 9.13881\n\n\nCode\n#Mean of smokers 14 to 15\ndf %>% \n  filter(Smoke == 'yes' & age_group == '14 to 15') %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 8.391667\n\n\nCode\n#Mean of non-smokers 16 to 17\ndf %>% \n  filter(Smoke == 'no' & age_group == '16 to 17') %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 10.46981\n\n\nCode\n#Mean of smokers 16 to 17\ndf %>% \n  filter(Smoke == 'yes' & age_group == '16 to 17') %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 9.38375\n\n\nCode\n#Mean of non-smokers 18 & older\ndf %>% \n  filter(Smoke == 'no' & age_group == '18 & older') %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 11.06885\n\n\nCode\n# Mean of smokers 18 & older\ndf %>% \n  filter(Smoke == 'yes' & age_group == '18 & older') %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 10.51333\n\n\nCode\nlung_cap\n\n\n# A tibble: 725 × 6\n   LungCap   Age Height Smoke Gender Caesarean\n     <dbl> <dbl>  <dbl> <chr> <chr>  <chr>    \n 1    6.48     6   62.1 no    male   no       \n 2   10.1     18   74.7 yes   female no       \n 3    9.55    16   69.7 no    female yes      \n 4   11.1     14   71   no    male   no       \n 5    4.8      5   56.9 no    male   no       \n 6    6.22    11   58.7 no    female no       \n 7    4.95     8   63.3 no    male   yes      \n 8    7.32    11   70.4 no    male   no       \n 9    8.88    15   70.5 no    male   no       \n10    6.8     11   59.2 no    male   no       \n# … with 715 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\n\nf. Calculate the correlation and covariance between Lung Capacity and Age. (use the cov() and cor() functions in R). Interpret your results.\n\n\nCode\n#Correlation\ncor(lung_cap$LungCap, lung_cap$Age)\n\n\n[1] 0.8196749\n\n\nCode\n#Covariance\ncov(lung_cap$LungCap, lung_cap$Age)\n\n\n[1] 8.738289\n\n\nThe correlation is 0.81 which is pretty close to +1, meaning that the there is a positive relationship between lung capacity and age. The covariance is also high which shows that the two variables of lung capacity and age have a positive relationship. #2 Let X = number of prior convictions for prisoners at a state prison at which there are 810 prisoners.\n\n\nCode\n# x= prior convictions \nx<-c(0, 1, 2, 3, 4)\nfrequency<-c(128, 434, 160, 64, 24)\nstate_prison<- data_frame(x,frequency)\n\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nPlease use `tibble()` instead.\nThis warning is displayed once every 8 hours.\nCall `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.\n\n\nCode\nstate_prison\n\n\n# A tibble: 5 × 2\n      x frequency\n  <dbl>     <dbl>\n1     0       128\n2     1       434\n3     2       160\n4     3        64\n5     4        24\n\n\n\n\na. What is the probability that a randomly selected inmate has exactly 2 prior convictions?\n\n\nCode\n# 2 prior convictions.P(2)/total\n160/810\n\n\n[1] 0.1975309\n\n\nThere is a 1.9% probability that a randomly selected inmate has exactly 2 prior convictions.\n\n\nb. What is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\n\nCode\n#  less than 2 prior convictions. (P(0) + P(1))/total \n(128+434)/810\n\n\n[1] 0.6938272\n\n\nThere is a 6.9% probability that a randomly selected inmate has fewer than 2 prior convictions.\n\n\nc. What is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\n\nCode\n# 2 or fewer prior convictions. (P(0) + P(1) + P(2)) +total\n(128+434+160)/810\n\n\n[1] 0.891358\n\n\nThere is a 8.9% probability that a randomly selected inmate has 2 or fewer prior convictions.\n\n\nd. What is the probability that a randomly selected inmate has more than 2 prior convictions?\n\n\nCode\n# More than 2 prior convictions. (P(3) +P(4)) + total\n(64+24)/810\n\n\n[1] 0.108642\n\n\nThere is a 10.8% probability that a randomly selected inmate has more than 2 prior convictions.\n\n\ne. What is the expected value for the number of prior convictions?\n\n\nCode\n#Prior convictions. ((0*P(0)) +(1*(P(1)) + (2*P(2)) + (3*P(3)) + (4*P(4)))\ndf<-((128*0/810) +(434*1/810) +(160*2/810) +(64*3/810) +(24*4/810)) \nmean(df)\n\n\n[1] 1.28642\n\n\nThe expected value for number of prior convictions is 1.28\n\n\nf. Calculate the variance and the standard deviation for the Prior Convictions.\n\n\nCode\n# variance\nv<- ((0-1.28)^2) *(128/810) +((1-1.28)^2) * (434/810)+((2-1.28)^2) * (160/810)+((3-1.28)^2) *(64/810) +((4-1.28)^2) * (24/810)\nv\n\n\n[1] 0.8562765\n\n\nCode\n# standard deviation\nsd<- sqrt(v)\nsd\n\n\n[1] 0.9253521\n\n\nThe variance is 0.856 and the standard deviation is 0.925."
  },
  {
    "objectID": "posts/StephRobertsHW1.html",
    "href": "posts/StephRobertsHW1.html",
    "title": "Homework 1",
    "section": "",
    "text": "Homework 1\n##1. Use the LungCapData to answer the following questions. (Hint: Using dplyr, especiallygroup_by() and summarize() can help you answer the following questions relatively efficiently.)\n\n\nCode\ndf<- read_excel(\"LungCapData.xls\")\n\n\nError: `path` does not exist: 'LungCapData.xls'\n\n\nCode\nhead(df)\n\n\n                                              \n1 function (x, df1, df2, ncp, log = FALSE)    \n2 {                                           \n3     if (missing(ncp))                       \n4         .Call(C_df, x, df1, df2, log)       \n5     else .Call(C_dnf, x, df1, df2, ncp, log)\n6 }                                           \n\n\n#Summarize\n\n\nCode\nsummary(df)\n\n\nError in object[[i]]: object of type 'closure' is not subsettable\n\n\n\n\nCode\nmean(df$LungCap)\n\n\nError in df$LungCap: object of type 'closure' is not subsettable\n\n\n\n\nCode\nmedian(df$LungCap)\n\n\nError in df$LungCap: object of type 'closure' is not subsettable\n\n\n\n\nCode\nvar(df$LungCap)\n\n\nError in df$LungCap: object of type 'closure' is not subsettable\n\n\n\n\nCode\nsd(df$LungCap)\n\n\nError in df$LungCap: object of type 'closure' is not subsettable\n\n\n\n\nCode\nmin(df$LungCap)\n\n\nError in df$LungCap: object of type 'closure' is not subsettable\n\n\nCode\nmax(df$LungCap)\n\n\nError in df$LungCap: object of type 'closure' is not subsettable\n\n\n#a. What does the distribution of LungCap look like? (Hint: Plot a histogram with probability density on the y axis)\n\n\nCode\nggplot(df, aes(x=LungCap)) + \n  geom_histogram(binwidth=0.5,col='black',fill='gray')\n\n\nError in `ggplot()`:\n!   You're passing a function as global data.\n  Have you misspelled the `data` argument in `ggplot()`\n\n\nThe histogram follows a distribution close to normal distibution. In fact, if we change binwidth slightly, it appears even closer to normal distribution.\n\n\nCode\nggplot(df, aes(x=LungCap)) + \n  geom_histogram(binwidth=1,col='black',fill='gray')\n\n\nError in `ggplot()`:\n!   You're passing a function as global data.\n  Have you misspelled the `data` argument in `ggplot()`\n\n\nThis helps illustrate the importance of binwidth and what it can do to our visualization interpretations.\n#b. Compare the probability distribution of the LungCap with respect to Males and Females? (Hint: make boxplots separated by gender using the boxplot() function)\n\n\nCode\nggplot(df, aes(x = LungCap, y = Gender)) +        \n  geom_boxplot()\n\n\nError in `ggplot()`:\n!   You're passing a function as global data.\n  Have you misspelled the `data` argument in `ggplot()`\n\n\nThe distribution of male lung capacity is larger and longer than females’.\n#c. Compare the mean lung capacities for smokers and non-smokers. Does it make sense?\n\n\nCode\ndf %>%\n  filter(Smoke == 'yes') %>%\n  pull(LungCap) %>%\n  mean() \n\n\nError in UseMethod(\"filter\"): no applicable method for 'filter' applied to an object of class \"function\"\n\n\nCode\ndf %>%\n  filter(Smoke == 'no') %>%\n  pull(LungCap) %>%\n  mean()\n\n\nError in UseMethod(\"filter\"): no applicable method for 'filter' applied to an object of class \"function\"\n\n\nIt does not make sense at face value. In this sample, smokers have a higher mean lung capacity than non-smokers. Let’s check how big each subsample is.\n\n\nCode\nlength(which(df$Smoke == 'yes'))\n\n\nError in df$Smoke: object of type 'closure' is not subsettable\n\n\nCode\nlength(which(df$Smoke == 'no'))\n\n\nError in df$Smoke: object of type 'closure' is not subsettable\n\n\nAs suspected, there are far more, almost 10 times as many, non-smokers. If we could gather data from all the smokers, perhaps our means would look a lot different. Maybe our sample was taken from young people whose lungs have not been long affected by the smoking.\n\n\nCode\ndf %>%\n  filter(Smoke == 'yes') %>%\n  pull(Age) %>%\n  median() \n\n\nError in UseMethod(\"filter\"): no applicable method for 'filter' applied to an object of class \"function\"\n\n\nAgain, as suspected, our sample of smokers is a young age. Therefore, the lack of difference in lung capacity between smokers and non-smokers is not too surprising.\n#d. Examine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\n\nCode\n#Create age groups\ndf <- df %>% \n  mutate(agegroup = case_when(\n    Age <= 13  ~ \"less than or equal to 13\",\n    Age >= 14 & Age <= 15 ~ \"14 to 15\",\n    Age >= 16 & Age <= 17 ~ \"16 TO 17\",\n    Age >= 18 ~ \"greater than or equal to 18\"))\n\n\nError in UseMethod(\"mutate\"): no applicable method for 'mutate' applied to an object of class \"function\"\n\n\nCode\ntable(df$agegroup)\n\n\nError in df$agegroup: object of type 'closure' is not subsettable\n\n\nCode\ndf %>%\n  filter(Smoke == 'yes') %>%\n  ggplot(aes(x=LungCap)) + \n  geom_histogram(binwidth=1,col='black',fill='gray')+\n  facet_wrap(~agegroup)\n\n\nError in UseMethod(\"filter\"): no applicable method for 'filter' applied to an object of class \"function\"\n\n\nThese histograms suggest that participants 13 or younger have smaller lung capacity. The Lung capacity seems to generally increase with age as children grow.\n#e. Compare the lung capacities for smokers and non-smokers within each age group. Is your answer different from the one in part c. What could possibly be going on here?\n\n\nCode\nggplot(df, aes(x = LungCap, \n           fill = agegroup)) +\n  geom_density(alpha = 0.4)+\n  facet_wrap(~Smoke)\n\n\nError in `ggplot()`:\n!   You're passing a function as global data.\n  Have you misspelled the `data` argument in `ggplot()`\n\n\nThis visualization starts to explain furthermore why there is an unexpected result for lung capacity in smokers vs. non-smokers. As we have deducted, lung capacity generally improves with age (in growing years). However, teenagers approaching adulthood are also a group more likely to have access or influence to smoking cigarettes. It is likely that our smokers account for some of the older participants, who happen to be closer to normal smoking age.\n#f. Calculate the correlation and covariance between Lung Capacity and Age. (use the cov() and cor() functions in R). Interpret your results.\n\n\nCode\ncov(df$LungCap, df$Age) #calculate covariance\n\n\nError in df$Age: object of type 'closure' is not subsettable\n\n\nCode\ncor(df$LungCap, df$Age) #calculate correlation\n\n\nError in df$Age: object of type 'closure' is not subsettable\n\n\nA positive coraviance (8.74) indicates lung capacity and age tend to increase together. The positive correlation relatively close to 1 (0.82) indicates there is a fairly strong correlation between the variables.\n##2. Let X = number of prior convictions for prisoners at a state prison at which there are 810 prisoners.\n\n\nCode\n#create the sample\nx<-rep(c(0,1,2,3,4),times=c(128, 434, 160, 64, 24))\nsample(x, 10)\n\n\n [1] 1 1 1 1 4 1 4 1 1 1\n\n\nCode\n#Verify n of sample\nsum(128, 434, 160, 64, 24)\n\n\n[1] 810\n\n\n\n\nCode\n#Calculate the mean\nmean(x)\n\n\n[1] 1.28642\n\n\nCode\n#Verify the mean\nsample_mean <- (((128*0)+(434*1)+(160*2)+(64*3)+(24*4))/810)\nprint(sample_mean)\n\n\n[1] 1.28642\n\n\n\n\nCode\n#Calculate the sd\nsd(x)\n\n\n[1] 0.9259016\n\n\n#a. What is the probability that a randomly selected inmate has exactly 2 prior convictions?\n\n\nCode\n#probability of 2 convictions?\ndnorm.convict <- dnorm(2, mean(x), sd(x))\nprint(dnorm.convict)\n\n\n[1] 0.3201613\n\n\nThe probability of 2 convications in 0.32.\n#b. What is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\n\nCode\n#probability of <2 convictions\nless.than <- pnorm(2, mean(x), sd(x)) - dnorm.convict\nprint(less.than)\n\n\n[1] 0.4593924\n\n\nThe probability of <2 convictions is 0.46.\n#c. What is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\n\nCode\n#probability of =<2 convictions?\npnorm.convict <- pnorm(2, mean(x), sd(x))\nprint(pnorm.convict)\n\n\n[1] 0.7795537\n\n\nThe probability of less than or equal to 2 convictions is 0.78.\n#d. What is the probability that a randomly selected inmate has more than 2 prior convictions?\n\n\nCode\n#probability of >2 convictions?\ngreater.than <- 1 - pnorm.convict\nprint(greater.than)\n\n\n[1] 0.2204463\n\n\nThe probability of greater than 2 convictions is 0.22.\n\n\nCode\n#Verify all probabilities add to 1\nless.than + dnorm.convict + greater.than\n\n\n[1] 1\n\n\n#e. What is the expected value for the number of prior convictions?\n\n\nCode\n# Expected value of a probability distribution  can be found with μ = Σx * P(x), where x = data value and P(x) = probability of data. \n\n#Calculate probabilities of data\np0 <- dnorm(0, mean(x), sd(x))\np0\n\n\n[1] 0.1641252\n\n\nCode\np1 <- dnorm(1, mean(x), sd(x))\np1\n\n\n[1] 0.410739\n\n\nCode\np2 <- dnorm(2, mean(x), sd(x))\np2\n\n\n[1] 0.3201613\n\n\nCode\np3 <- dnorm(3, mean(x), sd(x))\np3\n\n\n[1] 0.07772916\n\n\nCode\np4 <- dnorm(4, mean(x), sd(x))\np4\n\n\n[1] 0.005877753\n\n\nCode\n#Calculate expected value\nev <- sum((0*p0), (1*p1), (2*p2), (3*p3), (4*p4))\nev\n\n\n[1] 1.30776\n\n\nCode\n#The expected value should be close to the mean in a normal distribution\nmean(x)\n\n\n[1] 1.28642\n\n\nThe expected value is 1.31.\n#f. Calculate the variance and the standard deviation for the Prior Convictions.\n\n\nCode\n#Calculate variance\nvar(x)\n\n\n[1] 0.8572937\n\n\n\n\nCode\n#Calculate the sd\nsd(x)\n\n\n[1] 0.9259016"
  },
  {
    "objectID": "posts/Untitled.html",
    "href": "posts/Untitled.html",
    "title": "Blog Post Template",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/Untitled.html#instructions",
    "href": "posts/Untitled.html#instructions",
    "title": "Blog Post Template",
    "section": "Instructions",
    "text": "Instructions\nThis document provides yaml header inforamtion you will need to replicate each week to submit your homework or other blog posts. Please observe the following conventions:\n\nSave your own copy of this template as a blog post in the posts folder, naming it FirstLast_hwX.qmd\nEdit the yaml header to change your author name - use the same name each week\ninclude a description that is reader friendly\nupdate the category list to indicate the type of submission, the data used, the main packages or techniques, your name, or any thing else to make your document easy to find\nedit as a normal qmd/rmd file\n\n\n\nCode\nx <- c(2,3,4,5)\nmean(x)\n\n\n[1] 3.5"
  },
  {
    "objectID": "posts/Untitled.html#rendering-your-post",
    "href": "posts/Untitled.html#rendering-your-post",
    "title": "Blog Post Template",
    "section": "Rendering your post",
    "text": "Rendering your post\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code.\n\n\n\n\n\n\nWarning\n\n\n\nBe sure that you have moved your *.qmd file into the posts folder BEFORE you render it, so that all files are stored in the correct location.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nOnly render a single file - don’t try to render the whole website!\n\n\n\n\n\n\n\n\nPilot Student Blogs\n\n\n\nWe are piloting a workflow including individual student websites with direted and limited pull requests back to course blogs. Please let us know if you would like to participate."
  },
  {
    "objectID": "posts/Untitled.html#reading-in-data-files",
    "href": "posts/Untitled.html#reading-in-data-files",
    "title": "Blog Post Template",
    "section": "Reading in data files",
    "text": "Reading in data files\nThe easiest data source to use - at least initially - is to choose something easily accessible, either from our _data folder provided, or from an online source that is publicly available.\n\n\n\n\n\n\nUsing Other Data\n\n\n\nIf you would like to use a source that you have access to and it is small enough and you don’t mind making it public, you can copy it into the _data file and include in your commit and pull request.\n\n\n:::{.callout-tip} ## Using Private Data\nIf you would like to use a proprietary source of data, that should be possible using the same process outlined above. There may initially be a few issues. We hope to have this feature working smoothly soon!"
  }
]