[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DACSS 603 Introduction to Quantitative Analysis Fall 2022",
    "section": "",
    "text": "The blog posts here are contributed by students enrolled in DACSS 603, Introduction to Quantitative Analysis.\n\n\n\n\n\n\n\n\n\n\nHW1 Quat\n\n\n\n\n\n\n\n\n\n\n\n\nAmy Quarkume\n\n\n\n\n\n\n\n\nKPopiela_final p1\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\nHW1\n\n\n\n\n\n\n\n\n\n\n\n\nKatie Popiela\n\n\n\n\n\n\n\n\nHomework 2\n\n\n\n\n\n\n\nhw2\n\n\n\n\nThe second homework\n\n\n\n\n\n\nOct 15, 2022\n\n\nEthan Campbell\n\n\n\n\n\n\n\n\nHomework 2\n\n\n\n\n\n\n\nhw2\n\n\n\n\nThe second homework assignment\n\n\n\n\n\n\nOct 13, 2022\n\n\nEmma Rasmussen\n\n\n\n\n\n\n\n\nVoter Turnout and Partisan Bias in U.S. Presidential Elections\n\n\nDACSS 602 Final Project Proposal - Fall 2022\n\n\n\n\nfinalpart1\n\n\nnboonstra\n\n\n\n\nOn the surface, my research question is fairly straightforward: Does higher turnout in U.S. presidential elections benefit Democratic candidates? However, this question can be assessed in a number of ways, particularly when it comes to measurement.\n\n\n\n\n\n\nOct 12, 2022\n\n\nNicholas Boonstra\n\n\n\n\n\n\n\n\nFinal Project Proposal\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\n\n\n\n\n\n\n\nOct 11, 2022\n\n\nKaren Detter\n\n\n\n\n\n\n\n\nFinal Project Part 1\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\n\n\n\n\n\n\n\nOct 11, 2022\n\n\nEmma Rasmussen\n\n\n\n\n\n\n\n\nFinal Project Submission 1\n\n\n\n\n\n\n\n\n\n\n\n\nOct 11, 2022\n\n\nKaushika Potluri\n\n\n\n\n\n\n\n\nFinal_Project_1\n\n\n\n\n\n\n\nProject Proposal\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nProject Proposal\n\n\n\n\n\n\nOct 11, 2022\n\n\nMani Kanta Gogula & Rahul Gundeti\n\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\n\n\n\n\n\n\n\n\nOct 11, 2022\n\n\nShoshana Buck & Roy Yoon\n\n\n\n\n\n\n\n\nFinal project part 1\n\n\n\n\n\n\n\nfinalpart1\n\n\nBank Customer Churn Prediction\n\n\nMani Shanker Kamarapu\n\n\n\n\nThe first part of final project\n\n\n\n\n\n\nOct 11, 2022\n\n\nMani Shanker Kamarapu\n\n\n\n\n\n\n\n\nProject Proposal\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\nProject proposal part1\n\n\n\n\n\n\nOct 11, 2022\n\n\nMEGHA JOSEPH\n\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\nPart 1 of my final project\n\n\n\n\n\n\nOct 11, 2022\n\n\nNiharika Pola\n\n\n\n\n\n\n\n\nFinal Project Proposal\n\n\n\n\n\n\n\nfinalpart1\n\n\nNiyati Sharma\n\n\n\n\nInitial proposal for my final project\n\n\n\n\n\n\nOct 11, 2022\n\n\nNiyati Sharma\n\n\n\n\n\n\n\n\nProject Rough Draft Proposal\n\n\n\n\n\n\n\nfinalproject1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nInternational Trade’s influence on War\n\n\n\n\n\n\nOct 11, 2022\n\n\nYakub Rabiutheen\n\n\n\n\n\n\n\n\nFinal Project 1\n\n\n\n\n\n\n\nfinalpart1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\n\n\n\n\n\n\n\nOct 10, 2022\n\n\nKen Docekal\n\n\n\n\n\n\n\n\nFinal Project\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\n\n\n\n\n\n\n\nOct 10, 2022\n\n\nEthan Campbell\n\n\n\n\n\n\n\n\nFinal Project Proposal\n\n\n\n\n\n\n\nfinal project\n\n\nproposal\n\n\nEmily Duryea\n\n\ndataset\n\n\nggplot2\n\n\n\n\n\n\n\n\n\n\n\nOct 10, 2022\n\n\nEmily Duryea\n\n\n\n\n\n\n\n\nFinal Project Proposal\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\nPart 1\n\n\n\n\n\n\nOct 9, 2022\n\n\nSaaradhaa M\n\n\n\n\n\n\n\n\nFinal Project Part 1\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\n\n\n\n\n\n\n\nOct 7, 2022\n\n\nDonny Snyder\n\n\n\n\n\n\n\n\nDACSS 603 Final Project - Proposal\n\n\n\n\n\n\n\n\n\n\n\n\nOct 7, 2022\n\n\n\n\n\n\n\n\nFinal Project Proposal\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\nInitial proposal for my final project\n\n\n\n\n\n\nOct 7, 2022\n\n\nLindsay Jones\n\n\n\n\n\n\n\n\nHomework 1 - Prahitha Movva\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThe first homework on descriptive statistics and probability\n\n\n\n\n\n\nOct 5, 2022\n\n\nPrahitha Movva\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\nnboonstra\n\n\n\n\nThe first homework on descriptive statistics and probability\n\n\n\n\n\n\nOct 5, 2022\n\n\nNick Boonstra\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThe first homework on descriptive statistics and probability\n\n\n\n\n\n\nOct 4, 2022\n\n\nOmer Yalcin\n\n\n\n\n\n\n\n\nHW1\n\n\n\n\n\n\n\nhw1\n\n\nNiyati Sharma\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2022\n\n\nNiyati Sharma\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2022\n\n\nQuinn He\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2022\n\n\nQuinn He\n\n\n\n\n\n\n\n\nHOME WORK1 603\n\n\n\n\n\n\n\nhw1\n\n\ndescriptive statistics\n\n\nmegha joseph\n\n\nprobability\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2022\n\n\nMegha Joseph\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\nchallenge1\n\n\nSteph Roberts\n\n\ndataset\n\n\nggplot2\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2022\n\n\nSteph Roberts\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2022\n\n\nKen Docekal\n\n\n\n\n\n\n\n\nDuryea Homework 1\n\n\n\n\n\n\n\nhw1\n\n\ndescriptive statistics\n\n\nprobability\n\n\n\n\nHomework 1 for DACSS 603\n\n\n\n\n\n\nOct 3, 2022\n\n\nEmily Duryea\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nHomework_1_603\n\n\n\n\n\n\nOct 3, 2022\n\n\nMani Kanta Gogula\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndescriptive statistics\n\n\nprobability\n\n\n\n\nThe first homework on descriptive statistics and probability\n\n\n\n\n\n\nOct 3, 2022\n\n\nKaren Detter\n\n\n\n\n\n\n\n\nHomework #1\n\n\n\n\n\n\n\nHW1\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2022\n\n\nKalimah Muhammad\n\n\n\n\n\n\n\n\nDACSS 603 HW 1 Kimble\n\n\n\n\n\nHW 1 for DACSS 603\n\n\n\n\n\n\nOct 3, 2022\n\n\nKaren Kimble\n\n\n\n\n\n\n\n\nShoshanaBuck-HW1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nFirst homeowrk on descriptive statistics and probability\n\n\n\n\n\n\nOct 3, 2022\n\n\nShoshana Buck\n\n\n\n\n\n\n\n\nDACSS 603: Homework 1\n\n\n\n\n\n\n\nhw1\n\n\nTory Bartelloni\n\n\nLungCap\n\n\ndplyr\n\n\nggplot2\n\n\nEDA\n\n\nDescriptive Statistics\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2022\n\n\nTory Bartelloni\n\n\n\n\n\n\n\n\nDACSS603_HW1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nDescriptive Statistics and Probability functions\n\n\n\n\n\n\nOct 2, 2022\n\n\nRahul Gundeti\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThe first homework on descriptive statistics and probability\n\n\n\n\n\n\nOct 2, 2022\n\n\nMani Shanker Kamarapu\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThe homework-1 on descriptive statistics and probability\n\n\n\n\n\n\nOct 2, 2022\n\n\nNiharika Pola\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThe first homework on descriptive statistics and probability.\n\n\n\n\n\n\nOct 2, 2022\n\n\nLindsay Jones\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThe homework-1 on descriptive statistics and probability\n\n\n\n\n\n\nOct 2, 2022\n\n\nNiharika Pola\n\n\n\n\n\n\n\n\nFinal Part 1\n\n\n\n\n\n\n\nfinalpart1\n\n\ncaleb.hill\n\n\n\n\n\n\n\n\n\n\n\nOct 2, 2022\n\n\nCaleb Hill\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndescriptive statistics\n\n\nprobability\n\n\n\n\n\n\n\n\n\n\n\nOct 2, 2022\n\n\nCaleb Hill\n\n\n\n\n\n\n\n\nHomework 1 - Donny Snyder\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThe first homework on descriptive statistics and probability\n\n\n\n\n\n\nOct 1, 2022\n\n\nDonny Snyder\n\n\n\n\n\n\n\n\nHomework 1 Solution\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nIntro to Quant Analysis Homework 1\n\n\n\n\n\n\nOct 1, 2022\n\n\nDane Shelton\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2022\n\n\nSaaradhaa M\n\n\n\n\n\n\n\n\nFinal Part 1\n\n\n\n\n\n\n\nfinalpart1\n\n\n\n\nFinal Project - Check-in\n\n\n\n\n\n\nOct 1, 2022\n\n\nSteve O’Neill\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThe first homework on descriptive statistics and probability\n\n\n\n\n\n\nSep 29, 2022\n\n\nEmma Rasmussen\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThe first homework on descriptive statistics and probability\n\n\n\n\n\n\nSep 21, 2022\n\n\nEthan Campbell\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThe first homework on descriptive statistics and probability\n\n\n\n\n\n\nSep 20, 2022\n\n\nYakub Rabiutheen\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\ndesriptive statistics\n\n\nprobability\n\n\n\n\nThe first homework on descriptive statistics and probability\n\n\n\n\n\n\nSep 20, 2022\n\n\nSteve O’Neill\n\n\n\n\n\n\n\n\nHomework 1\n\n\n\n\n\n\n\nhw1\n\n\nchallenge1\n\n\nmy name\n\n\ndataset\n\n\nggplot2\n\n\n\n\n\n\n\n\n\n\n\nAug 2, 2022\n\n\nKaushika Potluri\n\n\n\n\n\n\n\n\nBlog Post Template\n\n\n\n\n\n\n\nhw1\n\n\nchallenge1\n\n\nmy name\n\n\ndataset\n\n\nggplot2\n\n\n\n\n\n\n\n\n\n\n\nAug 2, 2022\n\n\nYour Name\n\n\n\n\n\n\n\n\nBlog Post Template\n\n\n\n\n\n\n\nhw1\n\n\nchallenge1\n\n\nmy name\n\n\ndataset\n\n\nggplot2\n\n\n\n\n\n\n\n\n\n\n\nAug 2, 2022\n\n\nYour Name\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Contributors",
    "section": "",
    "text": "Your Name\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html",
    "href": "posts/Blog Post 2_Kaushika Potluri.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#a-distribution-of-lungcap",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#a-distribution-of-lungcap",
    "title": "Homework 1",
    "section": "1(a) Distribution of LungCap:",
    "text": "1(a) Distribution of LungCap:\n\n\nCode\nhist(df$LungCap)\n\n\n\n\n\nThe distribution appears to be very similar to a normal distribution, according to the histogram."
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#b",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#b",
    "title": "Homework 1",
    "section": "1(b)",
    "text": "1(b)\nThe boxplots below show the probability distributions grouped by Gender.\n\n\nCode\nboxplot(LungCap~Gender, data=df)\n\n\n\n\n\nLooks like males have a slightly higher lung capacity than females."
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#c",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#c",
    "title": "Homework 1",
    "section": "1 (c)",
    "text": "1 (c)\n\n\nCode\ndf %>%\n  group_by(Smoke) %>%\n  summarize(Mean = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke  Mean\n  <chr> <dbl>\n1 no     7.77\n2 yes    8.65\n\n\nSurprisingly, the mean lung capacity is higher for smokers than it is for non-smokers."
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#d",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#d",
    "title": "Homework 1",
    "section": "1 (d)",
    "text": "1 (d)\n\n\nCode\n# convert Age to categorical variable.\ndf <- mutate(df, AgeGroup = case_when(Age <= 13 ~ \"13 and lower\", Age == 14 | Age == 15 ~ \"14-15\", Age == 16 | Age == 17 ~ \"16-17\", Age >= 18 ~ \"18 and above\"))\narrange(df, Age)\n\n\n# A tibble: 725 × 7\n   LungCap   Age Height Smoke Gender Caesarean AgeGroup    \n     <dbl> <dbl>  <dbl> <chr> <chr>  <chr>     <chr>       \n 1   5.88      3   55.9 no    male   no        13 and lower\n 2   0.507     3   51.6 no    female yes       13 and lower\n 3   1.18      3   51.9 no    male   no        13 and lower\n 4   4.7       3   52.7 no    male   no        13 and lower\n 5   5.48      3   52.9 no    male   no        13 and lower\n 6   1.02      3   47   no    female no        13 and lower\n 7   2         3   51   no    female no        13 and lower\n 8   1.68      3   51.9 no    male   no        13 and lower\n 9   4.08      3   53.6 no    male   yes       13 and lower\n10   1.45      3   45.3 no    female no        13 and lower\n# … with 715 more rows\n\n\nCode\n# construct histogram.\nggplot(df, aes(x = LungCap)) +\n  geom_histogram() +\n  facet_grid(AgeGroup~Smoke)\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nMajority seem to be non-smokers, and looks like non-smokers seem to have higher lung capacity."
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#e",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#e",
    "title": "Homework 1",
    "section": "1 (e)",
    "text": "1 (e)\n\n\nCode\nclass(df$AgeGroup)\n\n\n[1] \"character\"\n\n\n\n\nCode\ndf$AgeGroup <- as.factor(df$AgeGroup) #converting to factor\n\n# construct table.\ndf %>% select(Smoke, LungCap, AgeGroup) %>% group_by(AgeGroup, Smoke) %>% summarise(mean(LungCap))\n\n\n`summarise()` has grouped output by 'AgeGroup'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 3\n# Groups:   AgeGroup [4]\n  AgeGroup     Smoke `mean(LungCap)`\n  <fct>        <chr>           <dbl>\n1 13 and lower no               6.36\n2 13 and lower yes              7.20\n3 14-15        no               9.14\n4 14-15        yes              8.39\n5 16-17        no              10.5 \n6 16-17        yes              9.38\n7 18 and above no              11.1 \n8 18 and above yes             10.5 \n\n\nThe mean lung capacity for smokers aged 13 and under is greater than that of non-smokers in the same age group which is different from expectation. Non-smokers have higher mean lung capacity for ages 14-15, 16-17 and 18 and above. Either there may be an error or extreme outlier in the data for smokers aged 13 and under."
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#f",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#f",
    "title": "Homework 1",
    "section": "1 (f)",
    "text": "1 (f)\n\n\nCode\ncor(df$LungCap,df$Age)\n\n\n[1] 0.8196749\n\n\n\n\nCode\ncov(df$LungCap,df$Age)\n\n\n[1] 8.738289\n\n\nLung capacity and age have a high positive correlation of 0.82, meaning that as age increases, lung capacity also does. The covariance is a little more challenging to interpret; the positive number indicates a positive association between lung capacity and age, but because covariance varies from negative infinity to infinity, it is difficult to judge the strength of the relationship. In most situations, I would choose to employ correlation."
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#section",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#section",
    "title": "Homework 1",
    "section": "2",
    "text": "2\n\n\nCode\ndf1 <- c(0:4)\nInmate_count <- c(128, 434, 160, 64, 24)\nIP<- data_frame(df1, Inmate_count)\n\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nℹ Please use `tibble()` instead."
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#a",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#a",
    "title": "Homework 1",
    "section": "2(a)",
    "text": "2(a)\n\n\nCode\nIP <- mutate(IP, Probability = Inmate_count/sum(Inmate_count))\nIP\n\n\n# A tibble: 5 × 3\n    df1 Inmate_count Probability\n  <int>        <dbl>       <dbl>\n1     0          128      0.158 \n2     1          434      0.536 \n3     2          160      0.198 \n4     3           64      0.0790\n5     4           24      0.0296\n\n\n\n\nCode\nIP %>%\n  filter(df1 == 2) %>%\n  select(Probability)\n\n\n# A tibble: 1 × 1\n  Probability\n        <dbl>\n1       0.198\n\n\nThe probability is about 19.75%."
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#b-1",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#b-1",
    "title": "Homework 1",
    "section": "(b)",
    "text": "(b)\n\n\nCode\ndf2 <- IP %>%\n  filter(df1 < 2)\nsum(df2$Probability)\n\n\n[1] 0.6938272\n\n\nThe probability that a randomly selected inmate has fewer than 2 prior convictions is 0.6938272"
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#c-1",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#c-1",
    "title": "Homework 1",
    "section": "2(c)",
    "text": "2(c)\n\n\nCode\ndf3 <- IP %>%\n  filter(df1 <= 2)\nsum(df3$Probability)\n\n\n[1] 0.891358\n\n\nThe probability that a randomly selected inmate has 2 or fewer prior convictions is 0.891358."
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#d-1",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#d-1",
    "title": "Homework 1",
    "section": "2(d)",
    "text": "2(d)\n\n\nCode\ndf4 <- IP %>%\n  filter(df1 > 2)\nsum(df4$Probability)\n\n\n[1] 0.108642\n\n\nThe probability that a randomly selected inmate has more than 2 prior convictions is 0.108642."
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#e-1",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#e-1",
    "title": "Homework 1",
    "section": "2(e)",
    "text": "2(e)\n\n\nCode\nIP <- mutate(IP, X = df1*Probability)\nexpectedvalue<- sum(IP$X)\nexpectedvalue\n\n\n[1] 1.28642\n\n\nThe expected value for the number of prior convictions is 1.2864198. We can round this to 1."
  },
  {
    "objectID": "posts/Blog Post 2_Kaushika Potluri.html#f-1",
    "href": "posts/Blog Post 2_Kaushika Potluri.html#f-1",
    "title": "Homework 1",
    "section": "2(f)",
    "text": "2(f)\n\n\nCode\nvar1 <-sum(((IP$df1-expectedvalue)^2)*IP$Probability)\nvar1\n\n\n[1] 0.8562353\n\n\n\n\nCode\nsqrt(var1)\n\n\n[1] 0.9253298\n\n\nThe variance and the standard deviation for prior convictions are 0.8562353 and 0.9253298 respectively."
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html",
    "href": "posts/NiyatiSharma_HW1.html",
    "title": "HW1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(stats)\n\n\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#question-1",
    "href": "posts/NiyatiSharma_HW1.html#question-1",
    "title": "HW1",
    "section": "Question 1",
    "text": "Question 1"
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#read-the-data-from-xls-file",
    "href": "posts/NiyatiSharma_HW1.html#read-the-data-from-xls-file",
    "title": "HW1",
    "section": "Read the data from xls file",
    "text": "Read the data from xls file\n\n\nCode\nRE <- read_excel(\"_data/LungCapData.xls\")\nRE\n\n\n# A tibble: 725 × 6\n   LungCap   Age Height Smoke Gender Caesarean\n     <dbl> <dbl>  <dbl> <chr> <chr>  <chr>    \n 1    6.48     6   62.1 no    male   no       \n 2   10.1     18   74.7 yes   female no       \n 3    9.55    16   69.7 no    female yes      \n 4   11.1     14   71   no    male   no       \n 5    4.8      5   56.9 no    male   no       \n 6    6.22    11   58.7 no    female no       \n 7    4.95     8   63.3 no    male   yes      \n 8    7.32    11   70.4 no    male   no       \n 9    8.88    15   70.5 no    male   no       \n10    6.8     11   59.2 no    male   no       \n# … with 715 more rows\n\n\n##A\n\n\nCode\nRE %>% \n  ggplot(aes(LungCap))+\n  geom_histogram(bins=20)\n\n\n\n\n\nThe histogram looks close to normal distributed."
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#b",
    "href": "posts/NiyatiSharma_HW1.html#b",
    "title": "HW1",
    "section": "B",
    "text": "B\n\n\nCode\nRE %>%\n  ggplot(aes (LungCap, color=Gender)) +\n  geom_boxplot() +\n  theme_classic() \n\n\n\n\n\nThe probability density of the female is higher than the males."
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#c",
    "href": "posts/NiyatiSharma_HW1.html#c",
    "title": "HW1",
    "section": "C",
    "text": "C\n\n\nCode\nMean_Smoker <- RE %>%\n  group_by(Smoke) %>%\n  summarise(mean = mean(LungCap))\nMean_Smoker\n\n\n# A tibble: 2 × 2\n  Smoke  mean\n  <chr> <dbl>\n1 no     7.77\n2 yes    8.65\n\n\nCode\nggplot(RE, aes(LungCap,Smoke))+\n  geom_boxplot()\n\n\n\n\n\nFrom this sample, it appears that smokers have a higher mean lung capacity than non-smokers."
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#d",
    "href": "posts/NiyatiSharma_HW1.html#d",
    "title": "HW1",
    "section": "D",
    "text": "D\n\n\nCode\nRE<-RE %>% \n  mutate(Category = as.factor(case_when(Age <= 13 ~ \"13 and under\", \n                           Age == 14 |Age ==15 ~ \"14-15\", \n                           Age == 16 | Age==17 ~ \"16-17\",\n                           Age >= 18 ~ \"18 or over\"\n                           )))\nRE\n\n\n# A tibble: 725 × 7\n   LungCap   Age Height Smoke Gender Caesarean Category    \n     <dbl> <dbl>  <dbl> <chr> <chr>  <chr>     <fct>       \n 1    6.48     6   62.1 no    male   no        13 and under\n 2   10.1     18   74.7 yes   female no        18 or over  \n 3    9.55    16   69.7 no    female yes       16-17       \n 4   11.1     14   71   no    male   no        14-15       \n 5    4.8      5   56.9 no    male   no        13 and under\n 6    6.22    11   58.7 no    female no        13 and under\n 7    4.95     8   63.3 no    male   yes       13 and under\n 8    7.32    11   70.4 no    male   no        13 and under\n 9    8.88    15   70.5 no    male   no        14-15       \n10    6.8     11   59.2 no    male   no        13 and under\n# … with 715 more rows\n\n\nCode\nRE %>%\n  ggplot(aes( LungCap, color = Smoke)) +\n  geom_histogram()+\n  facet_grid(Smoke ~ Category)\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nThe people who smoke are few in age group of “less than or equal to 13”. From the result we can say age is inversely proportional to the lung capacity."
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#e",
    "href": "posts/NiyatiSharma_HW1.html#e",
    "title": "HW1",
    "section": "E",
    "text": "E\nForm the above data we can say the output are pretty similar that smokers have a lower lung capacity compared to non-smokers"
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#f",
    "href": "posts/NiyatiSharma_HW1.html#f",
    "title": "HW1",
    "section": "F",
    "text": "F\ncorrelation and covariance between lung capacity and age\n\n\nCode\ncov(RE$LungCap,RE$Age)\n\n\n[1] 8.738289\n\n\nCode\ncor(RE$LungCap,RE$Age)\n\n\n[1] 0.8196749\n\n\nCovariance is positive and indicates that age and lung capacity are directly related. Correlation is also positive,from these results we can conclude that the lung capacity increases with age."
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#question-2",
    "href": "posts/NiyatiSharma_HW1.html#question-2",
    "title": "HW1",
    "section": "Question 2",
    "text": "Question 2\n\n\nCode\nx <- c(0:4)\nfreq <- c(128, 434, 160, 64, 24)\nconvictions <- data_frame(x, freq)\n\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nℹ Please use `tibble()` instead.\n\n\nCode\nconvictions\n\n\n# A tibble: 5 × 2\n      x  freq\n  <int> <dbl>\n1     0   128\n2     1   434\n3     2   160\n4     3    64\n5     4    24\n\n\n\n\nCode\nconvictions <- convictions %>% mutate(probability = freq/sum(freq))\nconvictions\n\n\n# A tibble: 5 × 3\n      x  freq probability\n  <int> <dbl>       <dbl>\n1     0   128      0.158 \n2     1   434      0.536 \n3     2   160      0.198 \n4     3    64      0.0790\n5     4    24      0.0296"
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#a",
    "href": "posts/NiyatiSharma_HW1.html#a",
    "title": "HW1",
    "section": "A",
    "text": "A\nProbability of exactly 2 is 19.75%"
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#b-1",
    "href": "posts/NiyatiSharma_HW1.html#b-1",
    "title": "HW1",
    "section": "B",
    "text": "B\n\n\nCode\na <-head(convictions,2)\nsum(a$probability)\n\n\n[1] 0.6938272\n\n\nProbability that a randomly selected inmate has fewer than 2 prior convictions : 69.38%"
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#c-1",
    "href": "posts/NiyatiSharma_HW1.html#c-1",
    "title": "HW1",
    "section": "C",
    "text": "C\n\n\nCode\na <-head(convictions,3)\nsum(a$probability)\n\n\n[1] 0.891358\n\n\nThe probability that a randomly selected inmate has 2 or fewer prior convictions : 89.13%"
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#d-1",
    "href": "posts/NiyatiSharma_HW1.html#d-1",
    "title": "HW1",
    "section": "D",
    "text": "D\n\n\nCode\na <-tail(convictions,2)\nsum(a$probability)\n\n\n[1] 0.108642\n\n\nThe probability that a randomly selected inmate has more than 2 prior convictions? : 10.86%"
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#e-1",
    "href": "posts/NiyatiSharma_HW1.html#e-1",
    "title": "HW1",
    "section": "E",
    "text": "E\n\n\nCode\nWE <- weighted.mean(convictions$x,convictions$probability)\nWE\n\n\n[1] 1.28642\n\n\nThe expected value for the number of prior convictions : 1.28"
  },
  {
    "objectID": "posts/NiyatiSharma_HW1.html#f-1",
    "href": "posts/NiyatiSharma_HW1.html#f-1",
    "title": "HW1",
    "section": "F",
    "text": "F\nThe variance is 0.857 and the standard deviation is 0.925\n\n\nCode\nAB <- (sum(freq*((x-WE)^2)))/(sum(freq)-1)\nAB\n\n\n[1] 0.8572937\n\n\nCode\nsqrt(AB)\n\n\n[1] 0.9259016"
  },
  {
    "objectID": "posts/KarenDetter_HW2.html",
    "href": "posts/KarenDetter_HW2.html",
    "title": "Blog Post Template",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/KarenDetter_HW2.html#instructions",
    "href": "posts/KarenDetter_HW2.html#instructions",
    "title": "Blog Post Template",
    "section": "Instructions",
    "text": "Instructions\nThis document provides yaml header inforamtion you will need to replicate each week to submit your homework or other blog posts. Please observe the following conventions:\n\nSave your own copy of this template as a blog post in the posts folder, naming it FirstLast_hwX.qmd\nEdit the yaml header to change your author name - use the same name each week\ninclude a description that is reader friendly\nupdate the category list to indicate the type of submission, the data used, the main packages or techniques, your name, or any thing else to make your document easy to find\nedit as a normal qmd/rmd file\n\n\n\nCode\nx <- c(2,3,4,5)\nmean(x)\n\n\n[1] 3.5"
  },
  {
    "objectID": "posts/KarenDetter_HW2.html#rendering-your-post",
    "href": "posts/KarenDetter_HW2.html#rendering-your-post",
    "title": "Blog Post Template",
    "section": "Rendering your post",
    "text": "Rendering your post\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code.\n\n\n\n\n\n\nWarning\n\n\n\nBe sure that you have moved your *.qmd file into the posts folder BEFORE you render it, so that all files are stored in the correct location.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nOnly render a single file - don’t try to render the whole website!\n\n\n\n\n\n\n\n\nPilot Student Blogs\n\n\n\nWe are piloting a workflow including individual student websites with direted and limited pull requests back to course blogs. Please let us know if you would like to participate."
  },
  {
    "objectID": "posts/KarenDetter_HW2.html#reading-in-data-files",
    "href": "posts/KarenDetter_HW2.html#reading-in-data-files",
    "title": "Blog Post Template",
    "section": "Reading in data files",
    "text": "Reading in data files\nThe easiest data source to use - at least initially - is to choose something easily accessible, either from our _data folder provided, or from an online source that is publicly available.\n\n\n\n\n\n\nUsing Other Data\n\n\n\nIf you would like to use a source that you have access to and it is small enough and you don’t mind making it public, you can copy it into the _data file and include in your commit and pull request.\n\n\n\n\n\n\n\n\nUsing Private Data\n\n\n\nIf you would like to use a proprietary source of data, that should be possible using the same process outlined above. There may initially be a few issues. We hope to have this feature working smoothly soon!"
  },
  {
    "objectID": "posts/HW1_Solutions_OmerYalcin.html",
    "href": "posts/HW1_Solutions_OmerYalcin.html",
    "title": "Homework 1",
    "section": "",
    "text": "First, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr, warn.conflicts = F)\nlibrary(magrittr)\ndf <- read_excel(\"_data/LungCapData.xls\")\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(df$LungCap, xlab = 'Lung Capacity', main = '', freq = F)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\n\n\n\n\n\nCode\nboxplot(LungCap ~ Gender, data = df)\n\n\n\n\n\nThe shape of the distribution is similar for males and females. The median, first quartile, third quartile lung capacity values all seem to be somewhat higher for males.\n\n\n\n\n\nCode\ndf %>%\n  group_by(Smoke) %>%\n  summarize(LungCap = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke LungCap\n  <chr>   <dbl>\n1 no       7.77\n2 yes      8.65\n\n\nThe lung capacity for smokers seems to be higher than non-smokers. It goes against the common idea that smoking would hurt lung capacity.\n\n\n\n\nLess than or equal to 13\n\n\n\nCode\ndf %>%\n  filter(Age <= 13) %>%\n  group_by(Smoke) %>%\n  summarize(LungCap = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke LungCap\n  <chr>   <dbl>\n1 no       6.36\n2 yes      7.20\n\n\n\n14 to 15\n\n\n\nCode\ndf %>%\n  filter(Age == 14 | Age == 15) %>%\n  group_by(Smoke) %>%\n  summarize(LungCap = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke LungCap\n  <chr>   <dbl>\n1 no       9.14\n2 yes      8.39\n\n\n\n16 to 17\n\n\n\nCode\ndf %>%\n  filter(Age == 16 | Age == 17) %>%\n  group_by(Smoke) %>%\n  summarize(LungCap = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke LungCap\n  <chr>   <dbl>\n1 no      10.5 \n2 yes      9.38\n\n\n\nGreater than or equal to 18\n\n\n\nCode\ndf %>%\n  filter(Age >= 18) %>%\n  group_by(Smoke) %>%\n  summarize(LungCap = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke LungCap\n  <chr>   <dbl>\n1 no       11.1\n2 yes      10.5\n\n\n\n\n\nFor three out of the four groups, lung capacity if smaller for smokers. This makes another explanation plausible. Smoking is inversely related to lung capacity, but older people both smoke more and have more lung capacity. Thus, considering the relationship between smoking and lung capacity without looking at age makes the relationship look the opposite of what it is.\n\n\n\n\n\nCode\ncov(df$LungCap, df$Age)\n\n\n[1] 8.738289\n\n\nCode\ncor(df$LungCap, df$Age)\n\n\n[1] 0.8196749\n\n\nBoth the correlation and the covariance are positive (when one of them is the other has to). Positive values suggest that people who are older tend to have higher lung capacity, confirming what we found. Since correlation is standardized (needs to be between -1 and 1), its absolute value tells us about the strength of the relationship. 0.82 suggests a pretty strong relationship."
  },
  {
    "objectID": "posts/HW1_Solutions_OmerYalcin.html#a-1",
    "href": "posts/HW1_Solutions_OmerYalcin.html#a-1",
    "title": "Homework 1",
    "section": "a",
    "text": "a\n\n\nCode\ntb %>%\n  filter(X == 2) %>%\n  pull(Frequency) %>%\n  divide_by(n)\n\n\n[1] 0.1975309"
  },
  {
    "objectID": "posts/HW1_Solutions_OmerYalcin.html#b-1",
    "href": "posts/HW1_Solutions_OmerYalcin.html#b-1",
    "title": "Homework 1",
    "section": "b",
    "text": "b\n\n\nCode\ntb %>%\n  filter(X < 2) %>%\n  pull(Frequency) %>%\n  sum() %>%\n  divide_by(n)\n\n\n[1] 0.6938272"
  },
  {
    "objectID": "posts/HW1_Solutions_OmerYalcin.html#c-1",
    "href": "posts/HW1_Solutions_OmerYalcin.html#c-1",
    "title": "Homework 1",
    "section": "c",
    "text": "c\n\n\nCode\ntb %>%\n  filter(X <= 2) %>%\n  pull(Frequency) %>%\n  sum() %>%\n  divide_by(n)\n\n\n[1] 0.891358"
  },
  {
    "objectID": "posts/HW1_Solutions_OmerYalcin.html#d-1",
    "href": "posts/HW1_Solutions_OmerYalcin.html#d-1",
    "title": "Homework 1",
    "section": "d",
    "text": "d\n\n\nCode\ntb %>%\n  filter(X > 2) %>%\n  pull(Frequency) %>%\n  sum() %>%\n  divide_by(n)\n\n\n[1] 0.108642"
  },
  {
    "objectID": "posts/HW1_Solutions_OmerYalcin.html#e-1",
    "href": "posts/HW1_Solutions_OmerYalcin.html#e-1",
    "title": "Homework 1",
    "section": "e",
    "text": "e\nExpected number of prior convictions is just a weighted average of the number of prior convictions.\n\nMethod 1: Multiply every value with their frequency, then divide by total frequency i.e. (0 * 128 + 1 * 434 + 2 * 160 ……) / 810.\n\n\n\nCode\nsum(tb$X * tb$Frequency) / n\n\n\n[1] 1.28642\n\n\n\nMethod 2: Multiply every value with their probility, sum them up.\n\n\n\nCode\ntb %>%\n  mutate(probability = Frequency / n) -> tb\n\nprint(tb)\n\n\n# A tibble: 5 × 3\n      X Frequency probability\n  <dbl>     <dbl>       <dbl>\n1     0       128      0.158 \n2     1       434      0.536 \n3     2       160      0.198 \n4     3        64      0.0790\n5     4        24      0.0296\n\n\n\n\nCode\nsum(tb$X * tb$probability)\n\n\n[1] 1.28642\n\n\n\nMethod 3: Recreate the whole sample (a vector that has 128 zeroes, 434 ones, 160 twos, ….) with a total length/size of 810. Take the mean.\n\n\n\nCode\nsample <- c(rep(0, 128), rep(1, 434), rep(2, 160), rep(3, 64), rep(4, 24))\nmean(sample)\n\n\n[1] 1.28642"
  },
  {
    "objectID": "posts/HW1_Solutions_OmerYalcin.html#f-1",
    "href": "posts/HW1_Solutions_OmerYalcin.html#f-1",
    "title": "Homework 1",
    "section": "f",
    "text": "f\n\nMethod 1: Let’s start from the end: we have the sample, just call var() and sd()\n\n\n\nCode\ncat('Variance:', var(sample))\n\n\nVariance: 0.8572937\n\n\nCode\ncat('\\nStandard Deviation:', sd(sample))\n\n\n\nStandard Deviation: 0.9259016\n\n\nMethod 2: Manually apply the formula using weights.\nStandard deviation is square root of variance. So let’s calculate variance first. For that we need the mean. Let’s pull the expected value from the previous section:\n\n\nCode\nm <- sum(tb$X * tb$Frequency) / n\n\n\nFor every observation, we’ll need the squared difference from mean (squared deviation from mean).\n\n\nCode\ntb %>%\n  mutate(sq_deviation = (X - m)^2) -> tb \nprint(tb)\n\n\n# A tibble: 5 × 4\n      X Frequency probability sq_deviation\n  <dbl>     <dbl>       <dbl>        <dbl>\n1     0       128      0.158        1.65  \n2     1       434      0.536        0.0820\n3     2       160      0.198        0.509 \n4     3        64      0.0790       2.94  \n5     4        24      0.0296       7.36  \n\n\nThen, we can now multiply them with probability.\n\n\nCode\nsum(tb$sq_deviation * tb$probability)\n\n\n[1] 0.8562353\n\n\nThis gives us the ‘population’ variance. If we wanted the ‘sample’ variance, what the var() function does, we could manually apply the Bessel’s correction:\n\n\nCode\nvariance <- sum(tb$sq_deviation * tb$probability) * (n / (n-1))\nprint(variance)\n\n\n[1] 0.8572937\n\n\nStandard deviation is then just the square root:\n\n\nCode\nsqrt(variance)\n\n\n[1] 0.9259016\n\n\nThis replicated what we found directly using the sample."
  },
  {
    "objectID": "posts/KenDocekal_finalproject1.html",
    "href": "posts/KenDocekal_finalproject1.html",
    "title": "Final Project 1",
    "section": "",
    "text": "Research Question\nHow much does state policy intervention impact future social and economic value preferences in residents?\nWhile political values often explicitly inform social and economic policy actions taken by governments, policy actions themselves can also affect the development of the values of both program recipients and the greater public. Low-income recipients are assumed to benefit from, and therefore favor, state intervention and redistributive policies while upper income groups are assumed to be against but this is not always true, especially at the program level (Bueno et al.). Authors like Holland note that “the poor only have an economic interest in supporting social expenditures in contexts where they expect policies to redistribute resources or risks in their favor”.\nThis study seeks to better understand the relationship between policy action and value formation at the sub-national level by looking at the effect of US state policy interventions on residents’ subsequent policy preferences. By looking at how differences in US states’ social and economic policy intervention from 1936 to 2000 we can see how these factors may shape the subsequent policy values of residents. The dataset “Correlates of State Policy” includes variables which also allow us to better understand the role of differences in policy design and implementation by controlling for variables that may moderate impact, such as the length of policy implementation (Soss) and differences in economic interest (Ansell).\nSources:\nAnsell, Ben. 2014. “The Political Economy of Ownership.” American Political Science Review 108(02):383{402.\nBoehmke, Frederick J., and Paul Skinner. 2012. “State Policy Innovativeness Revisited.” State Politics and Policy Quarterly, 12(3):303-29.\nBueno, Natalia and Nunes, Felipe and Zucco, Cesar, Making the bourgeoisie? Values, voice, and state-provided homeownership (January 7, 2022). SSRN.\nCaughey, Devin, and Christopher Warshaw. 2015. “The Dynamics of State Policy Liberalism, 1936–2014.” American Journal of Political Science, September. doi: 10.1111/ajps.12219.\nHolland, Alisha C. 2018. “Diminished Expectations: Redistributive preferences in truncated welfare states.” World Politics 70(4):555{594\nJacoby, William G., and Saundra K. Schneider. 2008. “A New Measure of Policy Spending Priorities in the American States.”\nJordan, Marty P. and Matt Grossmann. 2016. The Correlates of State Policy Project v.1.10. East Lansing, MI: Institute for Public Policy and Social Research (IPPSR).\nRigby, Elizabeth and Gerald C. Wright. 2013. “Political Parties and Representation of the Poor in the American States.” American Journal of Political Science 57(3): 552-565.\nSoss, Joe. 1999. “Lessons of Welfare: Policy Design, Political Learning, and Political Action.” The American Political Science Review 93(2):363{380.\n\n\nHypothesis\nIncreased state intervention increases US state residents’ preference for future interventions in social and economic policy.\nThis study proposes to build on Bueno et al.’s exploration of the effects of state-provided home ownership on political values and policy preferences by exploring that relationship at the level of US states. Additionally, instead of focusing on a single social program, we will examine the cumulative effects of multiple policy interventions across 65 years in 50 US states. This will provide insights into the effect of public policy on value differences at the sub-national level and on different subgroups including program non-participants. We will be able to see how this relationship may vary according to state and population characteristics despite differences in policy design and implementation.\n\n\nDescriptive Statistics\nThis dataset is from the Correlates of State Policy Project by the Institute for Public Policy and Social Research at Michigan State University. The full dataset, which contains 928 variables and covers data from 1900 to 2016, draws from multiple sources including government agencies and peer-reviewed articles listed in the Sources section. Due to limited data coverage across all years however, this study will focus on the period from 1935 to 2000. We will examining the following 25 variables (listed with description and years available):\nIndependent-\nYear 1935 - 2000\nState 1935 - 2000\nEcondev - Did State adopt Strategic Planning for Economic Development? 1981 – 1992\nPldvpag - Did State adopt Planning/Development Agency? 1935 – 1978\nUrbrenen - Did State adopt Urban Renewal ? 1941 – 1952\nPollib_median - State Policy Liberalism Score – Median 1936 – 2014\nPolicypriorityscore - State Policy Priority Score - collective goods (e.g., education and highways) v particularized benefits (e.g., health care and welfare) 1982-2005\nPoptotal - Population Total 1900 – 2008\nPopfemale - Female Population 1994 – 2010\nNonwhite - Proportion of the population that is nonwhite 1974 - 2011\nSoc_capital_ma - Hawes et al. Weighted Moving Average Measure of Social Capital 1984 - 2011\nEvangelical_pop - Evangelical Population 1975 - 2013\nNewimmig - New Immigrant Green Card Holders 1988 – 2011\nPopdensity - Population Density 1975 – 1999\nGsp_q - Gross State Product Combined in Millions of 2016 Dollars 1963 – 2010\nGini_coef - Gini Coefficient 1917 - 2013\nHsdiploma - High School Diploma 1975 – 2006\nEducspend - State Education Spending 1975 – 2001\nNofelons - Number of Felons Ineligible to Vote 1980 – 2010\nCo2emissions - Total CO2 emissions from fossil-fuels (metric tons) 1960 – 2001\nIdeo - State Ideology Score 1976 – 2011\nDependent-\nVst_ec - Mean Economic Liberalism- All Voters 2000\nVst_soc - Mean Social Liberalism- All Voters 2000\nVavgec_low - Mean Economic Liberalism Score for Low Income Voting Citizens 2000\nVavgsoc_low - Mean Social Liberalism Score for Low Income Voting Citizens 2000\nReading in dataset\n\n\nCode\nlibrary(readr)\nlibrary(readxl)\n\n\nstatedata <- read.csv(\"_data/correlatesofstatepolicyprojectv1_10.csv\")\n\n\nWarning in file(file, \"rt\"): cannot open file '_data/\ncorrelatesofstatepolicyprojectv1_10.csv': No such file or directory\n\n\nError in file(file, \"rt\"): cannot open the connection\n\n\nSpecifying variables\n\n\nCode\nstatedata1 = subset(statedata, select = c(policypriorityscore, econdev, pldvpag, urbrenen, year, state, poptotal, popfemale, nonwhite, soc_capital_ma, evangelical_pop, newimmig, popdensity, gsp_q, gini_coef, hsdiploma, educspend, nofelons, co2emissions, ideo, pollib_median,vst_ec, vst_soc, vavgec_low, vavgsoc_low))\n\n\nError in subset(statedata, select = c(policypriorityscore, econdev, pldvpag, : object 'statedata' not found\n\n\nSpecifying date range\n\n\nCode\nsd <- subset(statedata1, year>1934 & year<2001, na.rm = TRUE ) \n\n\nError in subset(statedata1, year > 1934 & year < 2001, na.rm = TRUE): object 'statedata1' not found\n\n\nDescriptive statistics\n\n\nCode\nstr(sd)\n\n\nfunction (x, na.rm = FALSE)  \n\n\nCode\nglimpse(sd)\n\n\nfunction (x, na.rm = FALSE)  \n\n\nCode\nsummary(sd)\n\n\nError in object[[i]]: object of type 'closure' is not subsettable"
  },
  {
    "objectID": "posts/KarenDetter_FinalPt1.html",
    "href": "posts/KarenDetter_FinalPt1.html",
    "title": "Final Project Proposal",
    "section": "",
    "text": "Background / Research Question\nWhat predicts support for government regulation of ‘Big Tech’?\nIn 2001, Google piloted a program to boost profits, which were sinking as the “dot-com bubble” burst, by collecting data generated from users’ search queries and using it to sell precisely targeted advertising. The company’s ad revenues grew so quickly that they expanded their data collection tools with tracking “cookies” and predictive algorithms. Other technology firms took notice of Google’s soaring profits, and the sale of passively-collected data from people’s online activities soon became the predominant business model of the internet economy (Zuboff, 2015).\nAs the data-collection practices of ‘Big Tech’ firms, including Google, Amazon, Facebook (Meta), Apple, and Microsoft, have gradually been exposed, the public is now aware that the ‘free’ platforms that have become essential to daily life are actually harvesting personal information as payment. Despite consumers being essentially extorted into accepting this arrangement, regulatory intervention of ‘surveillance capitalism’ has remained limited.\nOver the two decades since passive data collection began commercializing the internet, survey research has shown the American public’s increasing concern about the dominance Big Tech has been allowed to exert. A 2019 study conducted by Pew Research Center found that 81% of Democrats and 70% of Republicans think there should be more government regulation of corporate data-use practices (Pew Research Center, 2019). It is very unusual to find majorities of both Republicans and Democrats agreeing on any policy position, since party affiliation is known to be a main predictor of any political stance, especially in the current polarized climate. The natural question that arises, then, is what other factors predict support for increased regulation of data-collection practices?\n\n\nHypothesis\nAlthough few studies have directly examined the mechanisms behind public support for regulation of passive data collection, a good amount of research has been done on factors influencing individual adoption of privacy protection measures (Barth et al., 2019; Boerman et al., 2021; Turow et al., 2015). It seems a reasonable extrapolation that these factors would similarly influence support for additional data privacy regulation, leading to these hypotheses:\n\nA higher level of awareness of data collection issues predicts support for increased ‘Big Tech’ regulation.\nGreater understanding of how companies use passively collected data predicts support for increased regulation.\nThe feeling of having no personal control over online tracking ‘digital resignation’ predicts support for increased regulation.\nCertain demographics (age group, education level, and political ideology) have an effect on attitudes toward ‘Big Tech’ regulation.\n\nSince there are currently dozens of data privacy bills pending in Congress, pinpointing the forces driving support for this type of legislation can help with both shaping the regulatory framework needed and appealing for broader support from voters.\n\n\nDescriptive Statistics\nPew Research Center’s American Trends Panel (Wave 49) data set can provide insight into which of these factors are predictive of support for greater regulation of technology company data practices. In June 2019, an online survey covering a wide variety of topics was conducted and 4,272 separate observations for 144 variables were collected from adults age 18 and over. The margin of error (at the 95% confidence level) is given as +/- 1.87 percentage points.\nThe data set was compiled in SPSS and all pertinent variables are categorical.\n\n\nCode\n#read in data from SPSS file\nwav49 <- read_sav(\"_data/ATPW49.sav\")\nwav49\n\n\n# A tibble: 4,272 × 144\n     QKEY DEVICE_TYPE_…¹ LANG_…² FORM_…³ SOCME…⁴ SOCME…⁵ SOCME…⁶ SOCME…⁷ SNSUS…⁸\n    <dbl> <dbl+lbl>      <dbl+l> <dbl+l> <dbl+l> <dbl+l> <dbl+l> <dbl+l> <dbl+l>\n 1 100260 2 [Tablet]     9 [Eng… 2 [For… 2 [No,… 2 [No,… 2 [No,… 2 [No,… 0 [Doe…\n 2 100588 1 [Mobile pho… 9 [Eng… 1 [For… 1 [Yes… 1 [Yes… 1 [Yes… 2 [No,… 1 [Soc…\n 3 100637 3 [Desktop]    9 [Eng… 1 [For… 1 [Yes… 2 [No,… 2 [No,… 2 [No,… 1 [Soc…\n 4 101224 1 [Mobile pho… 9 [Eng… 2 [For… 1 [Yes… 2 [No,… 2 [No,… 2 [No,… 1 [Soc…\n 5 101322 1 [Mobile pho… 9 [Eng… 1 [For… 1 [Yes… 2 [No,… 2 [No,… 2 [No,… 1 [Soc…\n 6 101437 3 [Desktop]    9 [Eng… 2 [For… 1 [Yes… 2 [No,… 2 [No,… 2 [No,… 1 [Soc…\n 7 101472 1 [Mobile pho… 9 [Eng… 1 [For… 1 [Yes… 2 [No,… 1 [Yes… 2 [No,… 1 [Soc…\n 8 101493 3 [Desktop]    9 [Eng… 1 [For… 1 [Yes… 2 [No,… 2 [No,… 1 [Yes… 1 [Soc…\n 9 102198 1 [Mobile pho… 9 [Eng… 1 [For… 1 [Yes… 1 [Yes… 2 [No,… 1 [Yes… 1 [Soc…\n10 103094 1 [Mobile pho… 9 [Eng… 1 [For… 1 [Yes… 1 [Yes… 1 [Yes… 1 [Yes… 1 [Soc…\n# … with 4,262 more rows, 135 more variables: ELECTFTGSNSINT_W49 <dbl+lbl>,\n#   TALKDISASNSINT_W49 <dbl+lbl>, TALKCMNSNSINT_W49 <dbl+lbl>,\n#   SECUR1_W49 <dbl+lbl>, PRIVACYNEWS1_W49 <dbl+lbl>,\n#   HOMEASSIST1_W49 <dbl+lbl>, HOMEASSIST2_W49 <dbl+lbl>,\n#   HOMEASSIST3_W49 <dbl+lbl>, HOMEASSIST4_W49 <dbl+lbl>,\n#   HOMEASSIST5a_W49 <dbl+lbl>, HOMEASSIST5b_W49 <dbl+lbl>,\n#   HOMEIOT_W49 <dbl+lbl>, FITTRACK_W49 <dbl+lbl>, LOYALTY_W49 <dbl+lbl>, …\n\n\nSince there are so many variables in the data set, selecting the variables of interest into a new data frame will make it easier to manage:\n\n\nCode\nsel_vars <- c('PRIVACYNEWS1_W49', 'TRACKCO1a_W49', 'CONTROLCO_W49', 'UNDERSTANDCO_W49', 'ANONYMOUS1CO_W49', 'PP4_W49', 'PRIVACYREG_W49', 'GOVREGV1_W49', 'PROFILE4_W49', 'F_AGECAT', 'F_EDUCCAT', 'F_PARTYSUM_FINAL', 'F_IDEO')\nwav49_selected <- wav49[sel_vars]\nwav49_selected\n\n\n# A tibble: 4,272 × 13\n   PRIVACYNEWS1_…¹ TRACKC…² CONTRO…³ UNDERS…⁴ ANONYM…⁵ PP4_W49  PRIVA…⁶ GOVREG…⁷\n   <dbl+lbl>       <dbl+lb> <dbl+lb> <dbl+lb> <dbl+lb> <dbl+lb> <dbl+l> <dbl+lb>\n 1 4 [Not at all … NA       NA       NA       NA       NA       3 [Ver… NA      \n 2 3 [Not too clo…  3 [Som…  2 [Som…  3 [Ver…  1 [Yes…  3 [Ver… 3 [Ver…  1 [Mor…\n 3 3 [Not too clo…  3 [Som…  3 [Ver…  3 [Ver…  1 [Yes…  2 [Som… 3 [Ver…  1 [Mor…\n 4 4 [Not at all … NA       NA       NA       NA        3 [Ver… 3 [Ver… NA      \n 5 4 [Not at all …  1 [All…  4 [No …  4 [Not…  2 [No,… NA       4 [Not…  1 [Mor…\n 6 2 [Somewhat cl… NA       NA       NA       NA        3 [Ver… 3 [Ver… NA      \n 7 2 [Somewhat cl…  2 [Mos…  3 [Ver…  3 [Ver…  2 [No,…  2 [Som… 2 [Som…  3 [Abo…\n 8 1 [Very closel…  1 [All…  4 [No …  4 [Not…  2 [No,… NA       3 [Ver…  3 [Abo…\n 9 3 [Not too clo…  1 [All…  3 [Ver…  2 [Som…  2 [No,…  3 [Ver… 3 [Ver…  1 [Mor…\n10 3 [Not too clo…  3 [Som…  2 [Som…  1 [A g…  1 [Yes…  2 [Som… 2 [Som…  2 [Les…\n# … with 4,262 more rows, 5 more variables: PROFILE4_W49 <dbl+lbl>,\n#   F_AGECAT <dbl+lbl>, F_EDUCCAT <dbl+lbl>, F_PARTYSUM_FINAL <dbl+lbl>,\n#   F_IDEO <dbl+lbl>, and abbreviated variable names ¹​PRIVACYNEWS1_W49,\n#   ²​TRACKCO1a_W49, ³​CONTROLCO_W49, ⁴​UNDERSTANDCO_W49, ⁵​ANONYMOUS1CO_W49,\n#   ⁶​PRIVACYREG_W49, ⁷​GOVREGV1_W49\n\n\nThe variable labels contain the survey questions asked:\n\n\nCode\n#summary of $variable names and their [labels]\nvar_label(wav49_selected)\n\n\nError in var_label(wav49_selected): could not find function \"var_label\"\n\n\nBecause the data set is made up of categorical variables, transformation is required before computing any statistics:\n\n\nCode\n#convert all variables to factors\nwav49_factored <- wav49_selected %>%\n  mutate_all(as_factor)\n#convert user-defined missing values to regular missing values\nzap_missing(wav49_factored)\n\n\n# A tibble: 4,272 × 13\n   PRIVACYNEWS…¹ TRACK…² CONTR…³ UNDER…⁴ ANONY…⁵ PP4_W49 PRIVA…⁶ GOVRE…⁷ PROFI…⁸\n   <fct>         <fct>   <fct>   <fct>   <fct>   <fct>   <fct>   <fct>   <fct>  \n 1 Not at all c… <NA>    <NA>    <NA>    <NA>    <NA>    Very l… <NA>    <NA>   \n 2 Not too clos… Some o… Some c… Very l… Yes, i… Very l… Very l… More r… <NA>   \n 3 Not too clos… Some o… Very l… Very l… Yes, i… Some    Very l… More r… Somewh…\n 4 Not at all c… <NA>    <NA>    <NA>    <NA>    Very l… Very l… <NA>    <NA>   \n 5 Not at all c… All or… No con… Nothing No, it… <NA>    Not at… More r… Not to…\n 6 Somewhat clo… <NA>    <NA>    <NA>    <NA>    Very l… Very l… <NA>    Not to…\n 7 Somewhat clo… Most o… Very l… Very l… No, it… Some    Some    About … Somewh…\n 8 Very closely  All or… No con… Nothing No, it… <NA>    Very l… About … Somewh…\n 9 Not too clos… All or… Very l… Some    No, it… Very l… Very l… More r… Somewh…\n10 Not too clos… Some o… Some c… A grea… Yes, i… Some    Some    Less r… Somewh…\n# … with 4,262 more rows, 4 more variables: F_AGECAT <fct>, F_EDUCCAT <fct>,\n#   F_PARTYSUM_FINAL <fct>, F_IDEO <fct>, and abbreviated variable names\n#   ¹​PRIVACYNEWS1_W49, ²​TRACKCO1a_W49, ³​CONTROLCO_W49, ⁴​UNDERSTANDCO_W49,\n#   ⁵​ANONYMOUS1CO_W49, ⁶​PRIVACYREG_W49, ⁷​GOVREGV1_W49, ⁸​PROFILE4_W49\n\n\nAfter the variables are converted to meaningful factors, a summary of response frequencies can be generated:\n\n\nCode\nsummary(wav49_factored)\n\n\n           PRIVACYNEWS1_W49                 TRACKCO1a_W49 \n Very closely      : 461    All or almost all of it: 881  \n Somewhat closely  :2046    Most of it             : 703  \n Not too closely   :1397    Some of it             : 381  \n Not at all closely: 359    Very little of it      :  88  \n Refused           :   9    None of it             :  76  \n                            Refused                :  11  \n                            NA's                   :2132  \n                 CONTROLCO_W49      UNDERSTANDCO_W49\n A great deal of control:  68   A great deal: 132   \n Some control           : 313   Some        : 716   \n Very little control    :1134   Very little :1040   \n No control             : 621   Nothing     : 242   \n Refused                :   4   Refused     :  10   \n NA's                   :2132   NA's        :2132   \n                                                    \n               ANONYMOUS1CO_W49         PP4_W49          PRIVACYREG_W49\n Yes, it is possible   : 772    A great deal: 328   A great deal: 136  \n No, it is not possible:1357    Some        :1405   Some        :1380  \n Refused               :  11    Very little : 751   Very little :2153  \n NA's                  :2132    Not at all  :  82   Not at all  : 593  \n                                Refused     :   5   Refused     :  10  \n                                NA's        :1701                      \n                                                                       \n                GOVREGV1_W49        PROFILE4_W49    F_AGECAT   \n More regulation      :1631   A great deal: 384   18-29 : 671  \n Less regulation      : 145   Somewhat    :1410   30-49 :1314  \n About the same amount: 331   Not too much: 900   50-64 :1308  \n Refused              :  33   Not at all  : 113   65+   : 977  \n NA's                 :2132   Refused     :   9   DK/REF:   2  \n                              NA's        :1456                \n                                                               \n                 F_EDUCCAT              F_PARTYSUM_FINAL\n College graduate+    :1600   Rep/Lean Rep      :1823   \n Some College         :1182   Dem/Lean Dem      :2296   \n H.S. graduate or less:1483   DK/Refused/No lean: 153   \n Don't know/Refused   :   7                             \n                                                        \n                                                        \n                                                        \n               F_IDEO    \n Very conservative: 353  \n Conservative     : 977  \n Moderate         :1615  \n Liberal          : 828  \n Very liberal     : 386  \n Refused          : 113  \n                         \n\n\n*High NA value indicates that the question was not presented to all respondents\nThe data set is now primed for examining correlations and testing hypotheses.\n\n\nReferences\nBarth, S., de Jong, M. D. T., Junger, M., Hartel, P. H. & Roppelt, J. C. (2019). Putting the privacy paradox to the test: Online privacy and security behaviors among users with technical knowledge, privacy awareness, and financial resources. Telematics and Informatics, 41, 55–69. doi:10.1016/j.tele.2019.03.003\nBoerman, S. C., Kruikemeier, S., & Zuiderveen Borgesius, F. J. (2021). Exploring Motivations for Online Privacy Protection Behavior: Insights From Panel Data. Communication Research, 48(7), 953–977. https://doi.org/10.1177/0093650218800915\nPew Research Center. (2019). Americans and privacy: Concerned, confused and feeling lack of control over their personal information. https://www.pewresearch.org/internet/2019/11/15/americans-and-privacy-concerned-confused-and- feeling-lack-of-control-over-their-personal-information/\nPew Research Center. (2020). Wave 49 American trends panel [Data set]. https://www.pewresearch.org/internet/dataset/american-trends-panel-wave-49/\nTurow, J., Hennessy, M. & Draper, N. (2015). The tradeoff fallacy – How marketers are misrepresenting American consumers and opening them up to exploitation. Annenberg School for Communication.\nZuboff, S. (2015). Big other: Surveillance capitalism and the prospects of an information civilization. Journal of Information Technology, 30(1), 75–89. doi:10.1057/jit.2015.5"
  },
  {
    "objectID": "posts/Homework1QH.html",
    "href": "posts/Homework1QH.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readxl)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/Homework1QH.html#a",
    "href": "posts/Homework1QH.html#a",
    "title": "Homework 1",
    "section": "1a",
    "text": "1a\n\n\nCode\nggplot(LungCapData, mapping = aes(LungCap)) +\n  geom_histogram(color = \"black\", fill = \"grey\")+\n  geom_density()+\n  labs(title = \"Distribution of Lung Capacity\", x = \"Lung Capacity\", y = \"Count\")\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nCode\nplot(x = LungCapData$LungCap, y = lungcap_prob_dense)\n\n\n\n\n\nWith these two functions I can see the distribution is normal with both a histogram and regular graph. The second graph more clearly depicts a normal distribution with the probability density points laid throughout. ## 1b\n\n\nCode\nggplot(LungCapData, mapping = aes(x = Gender, y = LungCap)) +\n  geom_boxplot() \n\n\n\n\n\nIt looks like men, on average, have a higher lung capacity than females, but only by a slim margin. Overall, lung capacity is relatively similar among genders. The real comparison will come with smokers and nonsmokers. ## 1c\n\n\nCode\nLungCapData %>% \n  group_by(Smoke) %>% \n  summarise(lung_cap_mean = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke lung_cap_mean\n  <chr>         <dbl>\n1 no             7.77\n2 yes            8.65\n\n\nAbove is the lung capacity mean for smokers and nonsmokers. I’m actually a little surprised the mean lung capacity for nonsmokers is slightly higher than that of nonsmokers. I would think the opposite to be true, but I suspect because there is a range of ages under 18 and the body is not fully developed yet, I imagine a 6 year old nonsmoker will not have the same lung capacity as a 17 year old smoker."
  },
  {
    "objectID": "posts/Homework1QH.html#d",
    "href": "posts/Homework1QH.html#d",
    "title": "Homework 1",
    "section": "1d",
    "text": "1d\nBelow I created a bunch of variables to separate people into certain age groups. I imagine there would be an easier way to separate them.\n\n\nCode\n#LungCapData %>% \n  #group_by(Age) %>% \n  #summarise(lungcap = mean(LungCap))\n  \nage13 <- LungCapData %>% \n  filter(Age <= 13) %>%\n  group_by(Smoke) %>% \n  summarise(lung_cap_mean = mean(LungCap))\n\nage1415 <- LungCapData %>% \n  filter(Age == 14 | Age == 15) %>%\n  group_by(Smoke) %>% \n  summarise(lung_cap_mean = mean(LungCap))\n\nage1617 <- LungCapData %>% \n  filter(Age == 16 | Age == 17) %>%\n  group_by(Smoke) %>% \n  summarise(lung_cap_mean = mean(LungCap))\n\nage18 <- LungCapData %>% \n  filter(Age >= 18) %>%\n  group_by(Smoke) %>% \n  summarise(lung_cap_mean = mean(LungCap))\n\nage13\n\n\n# A tibble: 2 × 2\n  Smoke lung_cap_mean\n  <chr>         <dbl>\n1 no             6.36\n2 yes            7.20\n\n\nCode\nage1415\n\n\n# A tibble: 2 × 2\n  Smoke lung_cap_mean\n  <chr>         <dbl>\n1 no             9.14\n2 yes            8.39\n\n\nCode\nage1617\n\n\n# A tibble: 2 × 2\n  Smoke lung_cap_mean\n  <chr>         <dbl>\n1 no            10.5 \n2 yes            9.38\n\n\nCode\nage18\n\n\n# A tibble: 2 × 2\n  Smoke lung_cap_mean\n  <chr>         <dbl>\n1 no             11.1\n2 yes            10.5"
  },
  {
    "objectID": "posts/Homework1QH.html#e",
    "href": "posts/Homework1QH.html#e",
    "title": "Homework 1",
    "section": "1e",
    "text": "1e\nBased on the variables I created above, it appears the lung capacity for people under 13, and that smoke, is higher than people who do not smoke. As the age brackets increase, so does lung capacity overall, but it begins to show that those who do smoke, generally have a lower lung capacity than those who choose not to smoke. This is what I would expect to happen since a 13 year old still has plenty of growing to do, therefore the lung capacity will be much lower than a grown teenager."
  },
  {
    "objectID": "posts/Homework1QH.html#f",
    "href": "posts/Homework1QH.html#f",
    "title": "Homework 1",
    "section": "1f",
    "text": "1f\n\n\nCode\ncor(LungCapData$LungCap, LungCapData$Age)\n\n\n[1] 0.8196749\n\n\nWith a correlation of 0.81, lung capacity and age have a fairly strong positive relationship. This is what I figured would be the case. As people age, their lung capacities grow larger. A 17 year old will be more developed and most likely have a larger lung capacity than, say, a child the age of 8.\nI created a table of the data frame in question 2\n\n\nCode\nxx <- c(0:4)\n\nfreq <- c(128, 434, 160, 64, 24)\n\ndf <- tibble(xx, freq)"
  },
  {
    "objectID": "posts/Homework1QH.html#a-1",
    "href": "posts/Homework1QH.html#a-1",
    "title": "Homework 1",
    "section": "2a",
    "text": "2a\n\n\nCode\n160/810\n\n\n[1] 0.1975309\n\n\nThe probability of selecting inmates with 2 prior convictions is 19.7%."
  },
  {
    "objectID": "posts/Homework1QH.html#b",
    "href": "posts/Homework1QH.html#b",
    "title": "Homework 1",
    "section": "2b",
    "text": "2b\n\n\nCode\n562/810\n\n\n[1] 0.6938272\n\n\nThe probability of selecting inmates with less than 2 prior convictions is 69%."
  },
  {
    "objectID": "posts/Homework1QH.html#c",
    "href": "posts/Homework1QH.html#c",
    "title": "Homework 1",
    "section": "2c",
    "text": "2c\n\n\nCode\n722/810\n\n\n[1] 0.891358\n\n\nThe probability of selecting inmates with 2 or less prior convictions is 89%."
  },
  {
    "objectID": "posts/Homework1QH.html#d-1",
    "href": "posts/Homework1QH.html#d-1",
    "title": "Homework 1",
    "section": "2d",
    "text": "2d\n\n\nCode\n88/810\n\n\n[1] 0.108642\n\n\nThe probability of selecting inmates with more than 2 prior convictions is 10.8%."
  },
  {
    "objectID": "posts/Homework1QH.html#e-1",
    "href": "posts/Homework1QH.html#e-1",
    "title": "Homework 1",
    "section": "2e",
    "text": "2e\nThe expected value for number of prior convictions is 291.4.\n\n\nCode\ntest <- c(128, 434, 160, 64, 24)\n\ntestprobs <- c(0.15, 0.54, 0.2, 0.08, 0.03)\n\nsum(test*testprobs)\n\n\n[1] 291.4"
  },
  {
    "objectID": "posts/Homework1QH.html#f-1",
    "href": "posts/Homework1QH.html#f-1",
    "title": "Homework 1",
    "section": "2f",
    "text": "2f\nuse rep()\n\n\nCode\nconvictions <- c(rep(0,128), rep(1, 434), rep(2,160), rep(3,64), rep(4,24))\n\nsd(convictions)\n\n\n[1] 0.9259016\n\n\nCode\nvar(convictions)\n\n\n[1] 0.8572937"
  },
  {
    "objectID": "posts/HW_1_QH.html",
    "href": "posts/HW_1_QH.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readxl)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/HW_1_QH.html#a",
    "href": "posts/HW_1_QH.html#a",
    "title": "Homework 1",
    "section": "1a",
    "text": "1a\n\n\nCode\nggplot(LungCapData, mapping = aes(LungCap)) +\n  geom_histogram(color = \"black\", fill = \"grey\")+\n  geom_density()+\n  labs(title = \"Distribution of Lung Capacity\", x = \"Lung Capacity\", y = \"Count\")\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nCode\nplot(x = LungCapData$LungCap, y = lungcap_prob_dense)\n\n\n\n\n\nWith these two functions I can see the distribution is normal with both a histogram and regular graph. The second graph more clearly depicts a normal distribution with the probability density points laid throughout. ## 1b\n\n\nCode\nggplot(LungCapData, mapping = aes(x = Gender, y = LungCap)) +\n  geom_boxplot() \n\n\n\n\n\nIt looks like men, on average, have a higher lung capacity than females, but only by a slim margin. Overall, lung capacity is relatively similar among genders. The real comparison will come with smokers and nonsmokers. ## 1c\n\n\nCode\nLungCapData %>% \n  group_by(Smoke) %>% \n  summarise(lung_cap_mean = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke lung_cap_mean\n  <chr>         <dbl>\n1 no             7.77\n2 yes            8.65\n\n\nAbove is the lung capacity mean for smokers and nonsmokers. I’m actually a little surprised the mean lung capacity for nonsmokers is slightly higher than that of nonsmokers. I would think the opposite to be true, but I suspect because there is a range of ages under 18 and the body is not fully developed yet, I imagine a 6 year old nonsmoker will not have the same lung capacity as a 17 year old smoker."
  },
  {
    "objectID": "posts/HW_1_QH.html#d",
    "href": "posts/HW_1_QH.html#d",
    "title": "Homework 1",
    "section": "1d",
    "text": "1d\nBelow I created a bunch of variables to separate people into certain age groups. I imagine there would be an easier way to separate them.\n\n\nCode\n#LungCapData %>% \n  #group_by(Age) %>% \n  #summarise(lungcap = mean(LungCap))\n  \nage13 <- LungCapData %>% \n  filter(Age <= 13) %>%\n  group_by(Smoke) %>% \n  summarise(lung_cap_mean = mean(LungCap))\n\nage1415 <- LungCapData %>% \n  filter(Age == 14 | Age == 15) %>%\n  group_by(Smoke) %>% \n  summarise(lung_cap_mean = mean(LungCap))\n\nage1617 <- LungCapData %>% \n  filter(Age == 16 | Age == 17) %>%\n  group_by(Smoke) %>% \n  summarise(lung_cap_mean = mean(LungCap))\n\nage18 <- LungCapData %>% \n  filter(Age >= 18) %>%\n  group_by(Smoke) %>% \n  summarise(lung_cap_mean = mean(LungCap))\n\nage13\n\n\n# A tibble: 2 × 2\n  Smoke lung_cap_mean\n  <chr>         <dbl>\n1 no             6.36\n2 yes            7.20\n\n\nCode\nage1415\n\n\n# A tibble: 2 × 2\n  Smoke lung_cap_mean\n  <chr>         <dbl>\n1 no             9.14\n2 yes            8.39\n\n\nCode\nage1617\n\n\n# A tibble: 2 × 2\n  Smoke lung_cap_mean\n  <chr>         <dbl>\n1 no            10.5 \n2 yes            9.38\n\n\nCode\nage18\n\n\n# A tibble: 2 × 2\n  Smoke lung_cap_mean\n  <chr>         <dbl>\n1 no             11.1\n2 yes            10.5"
  },
  {
    "objectID": "posts/HW_1_QH.html#e",
    "href": "posts/HW_1_QH.html#e",
    "title": "Homework 1",
    "section": "1e",
    "text": "1e\nBased on the variables I created above, it appears the lung capacity for people under 13, and that smoke, is higher than people who do not smoke. As the age brackets increase, so does lung capacity overall, but it begins to show that those who do smoke, generally have a lower lung capacity than those who choose not to smoke. This is what I would expect to happen since a 13 year old still has plenty of growing to do, therefore the lung capacity will be much lower than a grown teenager."
  },
  {
    "objectID": "posts/HW_1_QH.html#f",
    "href": "posts/HW_1_QH.html#f",
    "title": "Homework 1",
    "section": "1f",
    "text": "1f\n\n\nCode\ncor(LungCapData$LungCap, LungCapData$Age)\n\n\n[1] 0.8196749\n\n\nWith a correlation of 0.81, lung capacity and age have a fairly strong positive relationship. This is what I figured would be the case. As people age, their lung capacities grow larger. A 17 year old will be more developed and most likely have a larger lung capacity than, say, a child the age of 8.\nI created a table of the data frame in question 2\n\n\nCode\nxx <- c(0:4)\n\nfreq <- c(128, 434, 160, 64, 24)\n\ndf <- tibble(xx, freq)"
  },
  {
    "objectID": "posts/HW_1_QH.html#a-1",
    "href": "posts/HW_1_QH.html#a-1",
    "title": "Homework 1",
    "section": "2a",
    "text": "2a\n\n\nCode\n160/810\n\n\n[1] 0.1975309\n\n\nThe probability of selecting inmates with 2 prior convictions is 19.7%."
  },
  {
    "objectID": "posts/HW_1_QH.html#b",
    "href": "posts/HW_1_QH.html#b",
    "title": "Homework 1",
    "section": "2b",
    "text": "2b\n\n\nCode\n562/810\n\n\n[1] 0.6938272\n\n\nThe probability of selecting inmates with less than 2 prior convictions is 69%."
  },
  {
    "objectID": "posts/HW_1_QH.html#c",
    "href": "posts/HW_1_QH.html#c",
    "title": "Homework 1",
    "section": "2c",
    "text": "2c\n\n\nCode\n722/810\n\n\n[1] 0.891358\n\n\nThe probability of selecting inmates with 2 or less prior convictions is 89%."
  },
  {
    "objectID": "posts/HW_1_QH.html#d-1",
    "href": "posts/HW_1_QH.html#d-1",
    "title": "Homework 1",
    "section": "2d",
    "text": "2d\n\n\nCode\n88/810\n\n\n[1] 0.108642\n\n\nThe probability of selecting inmates with more than 2 prior convictions is 10.8%."
  },
  {
    "objectID": "posts/HW_1_QH.html#e-1",
    "href": "posts/HW_1_QH.html#e-1",
    "title": "Homework 1",
    "section": "2e",
    "text": "2e\nThe expected value for number of prior convictions is 291.4.\n\n\nCode\ntest <- c(128, 434, 160, 64, 24)\n\ntestprobs <- c(0.15, 0.54, 0.2, 0.08, 0.03)\n\nsum(test*testprobs)\n\n\n[1] 291.4"
  },
  {
    "objectID": "posts/HW_1_QH.html#f-1",
    "href": "posts/HW_1_QH.html#f-1",
    "title": "Homework 1",
    "section": "2f",
    "text": "2f\nuse rep()\n\n\nCode\nconvictions <- c(rep(0,128), rep(1, 434), rep(2,160), rep(3,64), rep(4,24))\n\nsd(convictions)\n\n\n[1] 0.9259016\n\n\nCode\nvar(convictions)\n\n\n[1] 0.8572937"
  },
  {
    "objectID": "posts/EmmaRasmussenFinalPart1.html",
    "href": "posts/EmmaRasmussenFinalPart1.html",
    "title": "Final Project Part 1",
    "section": "",
    "text": "Code\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)\n\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(dplyr)"
  },
  {
    "objectID": "posts/EmmaRasmussenFinalPart1.html#research-question",
    "href": "posts/EmmaRasmussenFinalPart1.html#research-question",
    "title": "Final Project Part 1",
    "section": "Research Question:",
    "text": "Research Question:\nDoes political partisanship correlate with COVID-19 death rates?\nThe COVID-19 pandemic became a political matter. Behaviors associated with COVID-19 prevention were adopted on partisan lines (masking, social distancing, and vaccine uptake). Early in the pandemic, mask mandates were protested in some communities. My research question is have these behaviors affected COVID-19 death rates along partisan lines? If so, public health interventions could target communities that may be higher risk for COVID-19 deaths based on political partisanship.\nI am thinking death toll would make the most sense to measure than infection rates as infection rates are constantly changing (other studies have looked at infection rates over waves of the pandemic, see this study from the Pew Research Center (Jones 2022)). I also think that one way to measure partisanship will be the 2020 county-level election results (% voting for Trump). In other words, my research is looking to see if (county-level) Trump support correlates with COVID-19 death rates. Both these variables can be found in county-level data sets so I can join multiple dataset with county name (or FIPS code) as the “key”.\nOther variables to consider at the county-level (confounding variables): vaccine (and booster) uptake, average age of population"
  },
  {
    "objectID": "posts/EmmaRasmussenFinalPart1.html#hypothesis",
    "href": "posts/EmmaRasmussenFinalPart1.html#hypothesis",
    "title": "Final Project Part 1",
    "section": "Hypothesis:",
    "text": "Hypothesis:\nWhile I came up with this research idea on my own, other organizations such as NPR (Wood and Brumfiel 2021) and the Pew Research Center ()have already tested this. For this project, I will use the most recent data I can find. I was hoping to consider the confounding variable of population density, for instance I am guessing more urban populations will tend to vote democratic but these more densely populated places may also have higher infection rates. However, I cannot find any county level population density data sets, so I may use the “Urban Rural Description” variable in one of my datasets.\nH0: B1 (and all beta values) is zero. There is no correlation Ha: B1 (or any beta value) is not zero. There is a correlation between partisanship and COVID-19 death rates."
  },
  {
    "objectID": "posts/EmmaRasmussenFinalPart1.html#descriptive-statistics",
    "href": "posts/EmmaRasmussenFinalPart1.html#descriptive-statistics",
    "title": "Final Project Part 1",
    "section": "Descriptive Statistics:",
    "text": "Descriptive Statistics:\n\n\nCode\n#set wd to change file path so I can access data on my computer without adding to posts folder\nsetwd(\"/Users/emmarasmussen/Documents\")\n\n\nError in setwd(\"/Users/emmarasmussen/Documents\"): cannot change working directory\n\n\nCode\nvotedf<- read_csv(\"countypres_2000-2020.csv\")\n\n\nError: 'countypres_2000-2020.csv' does not exist in current working directory ('/home/runner/work/603_Fall_2022/603_Fall_2022/posts').\n\n\nCode\nhead(votedf, 12)\n\n\nError in head(votedf, 12): object 'votedf' not found\n\n\nCode\ncoviddf<- read_csv(\"Provisional_COVID-19_Deaths_by_County__and_Race_and_Hispanic_Origin.csv\")\n\n\nError: 'Provisional_COVID-19_Deaths_by_County__and_Race_and_Hispanic_Origin.csv' does not exist in current working directory ('/home/runner/work/603_Fall_2022/603_Fall_2022/posts').\n\n\nCode\nhead(coviddf, 12)\n\n\nError in head(coviddf, 12): object 'coviddf' not found\n\n\nCode\n#counting the number of distinct counties in df\nn_distinct(votedf$county_name)\n\n\nError in list2(...): object 'votedf' not found\n\n\nCode\nn_distinct(coviddf$\"County Name\")\n\n\nError in list2(...): object 'coviddf' not found\n\n\n\n\nCode\nsummary(votedf)\n\n\nError in summary(votedf): object 'votedf' not found\n\n\nCode\nsummary(coviddf)\n\n\nError in summary(coviddf): object 'coviddf' not found\n\n\nThis data is going to require some tidying before merging. In the coviddf, each county is listed 3 times, (once per indicator) so I will likely filter out just the indicator “Distribution of COVID-19 deaths (%)” so each county is listed only once. Similarly, the votedf contains extra years. For my research, I am only concerned with 2016 data so I will filter out % voting for Trump in 2016 as a measure of political affiliation/partisanship. Then I will merge the two dfs based on county names (will also require some data tidying).\nThe votedf was compiled by the MIT Election Data and Science Lab. It was first published in 2018 and has been updated with the 2020 election. It contains county-level presidential election data beginning in 2000 and going up to the 2020 election. The data has 12 columns, and 72,617 rows (many of which I will filter out before conducting analysis.) There are 1,892 distinct county names in the data set.\nThe coviddf only has 857 unique county names in the data frame. This may be because not all counties reported COVID-19 death counts. When I join the data sets, I will join so as to only include observations that we have information from both data frames. The coviddf is provisional, meaning that it is consistently updated (I believe on a weekly basis) with current COVID-19 death toll data. It is likely compiled by counties/towns reporting these numbers to the CDC. This data has limitations, not all counties report this, and not all report it accurately/ attribute COVID-19 as the true cause of death in all circumstances. Using the summary function, we can see the “mean” COVID-19 deaths by county is 852.7, however this isn’t super meaningful given each county has this reported 3 times in the data and the median is significantly lower. Statistics provided by the summary function will be more meaningful once the data is tidied."
  },
  {
    "objectID": "posts/EmmaRasmussenFinalPart1.html#references",
    "href": "posts/EmmaRasmussenFinalPart1.html#references",
    "title": "Final Project Part 1",
    "section": "References",
    "text": "References\nJones, B. (2022). The Changing Political Geography of COVID-19 Over the Last Two Years. Pew Research Center. March 3, 2022. https://www.pewresearch.org/politics/2022/03/03/the-changing-political-geography-of-covid-19-over-the-last-two-years/\nMIT Election Data and Science Lab. (2021) County Presidential Election Returns 2000-2020. Accessed from the Harvard Dataverse [October 11, 2022]. https://doi.org/10.7910/DVN/VOQCHQ\nNational Center for Health Statistics. (2022). Provisional COVID-19 Deaths by County, and Race and Hispanic Origin. Accessed from the Centers for Disease Control [October 11, 2022]. https://data.cdc.gov/d/k8wy-p9cg\nWood, D. and Brumfiel, G. (2021). Pro-Trump counties now have far higher COVID death rates. Misinformation is to blame. NPR. December 5, 2021. https://www.npr.org/sections/health-shots/2021/12/05/1059828993/data-vaccine-misinformation-trump-counties-covid-death-rate\n[Need to add italics to references]"
  },
  {
    "objectID": "posts/MeghaJoseph_hw1.html",
    "href": "posts/MeghaJoseph_hw1.html",
    "title": "HOME WORK1 603",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(stats)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/MeghaJoseph_hw1.html#answer-1",
    "href": "posts/MeghaJoseph_hw1.html#answer-1",
    "title": "HOME WORK1 603",
    "section": "Answer 1",
    "text": "Answer 1\n\n\nCode\nreadD <- read_excel(\"_data/LungCapData.xls\")\nreadD\n\n\n# A tibble: 725 × 6\n   LungCap   Age Height Smoke Gender Caesarean\n     <dbl> <dbl>  <dbl> <chr> <chr>  <chr>    \n 1    6.48     6   62.1 no    male   no       \n 2   10.1     18   74.7 yes   female no       \n 3    9.55    16   69.7 no    female yes      \n 4   11.1     14   71   no    male   no       \n 5    4.8      5   56.9 no    male   no       \n 6    6.22    11   58.7 no    female no       \n 7    4.95     8   63.3 no    male   yes      \n 8    7.32    11   70.4 no    male   no       \n 9    8.88    15   70.5 no    male   no       \n10    6.8     11   59.2 no    male   no       \n# … with 715 more rows"
  },
  {
    "objectID": "posts/MeghaJoseph_hw1.html#answer-1-a",
    "href": "posts/MeghaJoseph_hw1.html#answer-1-a",
    "title": "HOME WORK1 603",
    "section": "Answer 1 (a)",
    "text": "Answer 1 (a)\nDistribution of LungCap:\n\n\nCode\nhist(readD$LungCap)\n\n\n\n\n\nThe distribution is a normal distribution. ## Answer 1 (b)\n\n\nCode\nboxplot(readD$LungCap ~ readD$Gender)\n\n\n\n\n\nThe mean of males appear higher than females."
  },
  {
    "objectID": "posts/MeghaJoseph_hw1.html#answer-1-c",
    "href": "posts/MeghaJoseph_hw1.html#answer-1-c",
    "title": "HOME WORK1 603",
    "section": "Answer 1 (c)",
    "text": "Answer 1 (c)\n\n\nCode\nreadD%>%\n  group_by(Smoke) %>% \n  summarize(Mean=mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke  Mean\n  <chr> <dbl>\n1 no     7.77\n2 yes    8.65\n\n\nCode\nreadD%>%\n  group_by(Smoke) %>% \n  summarize(stdev=sd(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke stdev\n  <chr> <dbl>\n1 no     2.73\n2 yes    1.88\n\n\nCode\nggplot(readD, aes(x=LungCap, y=Smoke))+geom_boxplot()\n\n\n\n\n\nThe mean of smokers is higher than the mean of non smokers and therefore it is not sensible."
  },
  {
    "objectID": "posts/MeghaJoseph_hw1.html#answer-1-d",
    "href": "posts/MeghaJoseph_hw1.html#answer-1-d",
    "title": "HOME WORK1 603",
    "section": "Answer 1 (d)",
    "text": "Answer 1 (d)\n\n\nCode\nclass(readD$Age)\n\n\n[1] \"numeric\"\n\n\nCode\nreadD <- mutate(readD, AgeGroup = case_when(Age <= 13 ~ \"13 and below\", \n                                            Age == 14 | Age == 15 ~ \"14 to 15\", \n                                            Age == 16 | Age == 17 ~ \"16 to 17\", \n                                            Age >= 18 ~ \"18 and above\"))\nggplot(readD, aes(x = LungCap)) +\n  geom_histogram() +\n  facet_grid(AgeGroup~Smoke)\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nCode\nreadD %>%\n  ggplot(aes(x = Age, y = LungCap, color = Smoke)) +\n  geom_line() +\n  facet_wrap(vars(Smoke)) +\n  labs(y = \"Lung Capacity\", x = \"Age\")\n\n\n\n\n\nFrom the above results we can say that people from age group 10 and above smoke."
  },
  {
    "objectID": "posts/MeghaJoseph_hw1.html#answer-1-f",
    "href": "posts/MeghaJoseph_hw1.html#answer-1-f",
    "title": "HOME WORK1 603",
    "section": "Answer 1 (f)",
    "text": "Answer 1 (f)\n\n\nCode\ncor(readD$LungCap,readD$Age)\n\n\n[1] 0.8196749\n\n\nCode\ncov(readD$LungCap,readD$Age)\n\n\n[1] 8.738289\n\n\nFrom the data we can see that the covariance is positive and it shows that there is a direct relationship between age and lung capacity. And the correlation is also positive, so they move in same direction. Therefore as the age increases, the lung capacity also increases that is they are directly proportional to each other."
  },
  {
    "objectID": "posts/MeghaJoseph_hw1.html#answer-2",
    "href": "posts/MeghaJoseph_hw1.html#answer-2",
    "title": "HOME WORK1 603",
    "section": "Answer 2",
    "text": "Answer 2\n\n\nCode\nX<-c(0, 1, 2, 3, 4)\nFrequency<-c(128, 434, 160, 64, 24)\nC<- data.frame(X, Frequency)\nC\n\n\n  X Frequency\n1 0       128\n2 1       434\n3 2       160\n4 3        64\n5 4        24\n\n\nCode\nC<-rename(C, PriorConvictions=X)\nC\n\n\n  PriorConvictions Frequency\n1                0       128\n2                1       434\n3                2       160\n4                3        64\n5                4        24\n\n\nCode\n#visualizing df using bar chart\nggplot(C, aes(x=PriorConvictions, y=Frequency))+geom_bar(stat=\"identity\")+geom_text(aes(label = Frequency), vjust = -.3)\n\n\n\n\n\nCode\n#There are 810 obs in df\nsum(Frequency)\n\n\n[1] 810\n\n\n\n\nCode\nPO<-Frequency/810\nPO\n\n\n[1] 0.15802469 0.53580247 0.19753086 0.07901235 0.02962963\n\n\nCode\n#A\n# P(x=2)=160/810\n160/810\n\n\n[1] 0.1975309\n\n\nCode\n#B\n#P(x<2)=P(0)+P(1)\n(128+434)/810\n\n\n[1] 0.6938272\n\n\nCode\n#C\n#P(x<=2)=P(0)+P(1)+P(2)\n(128+434+160)/810\n\n\n[1] 0.891358\n\n\nCode\n#D\n#1-P(above)\n1-((128+434+160)/810)\n\n\n[1] 0.108642\n\n\nCode\n#E\n#Expected value=sum of probabilities*each value (0, 1, 2, 3 or 4)\nweighted.mean(X, PO)\n\n\n[1] 1.28642\n\n\nCode\n#F\n#Calculating the Variance using the formula for variance\n(sum(Frequency*((X-1.28642)^2)))/(sum(Frequency)-1)\n\n\n[1] 0.8572937\n\n\nCode\n#Calculating the sample standard deviation from the variance\nsqrt(0.8572937)\n\n\n[1] 0.9259016\n\n\nAnswer\na: 19.75% b :9.38% c :89.14% d :10.86% e :1.28642 f: variance: 0.8572937 standard deviation: 0.9259016"
  },
  {
    "objectID": "posts/StephRobertsHW1.html",
    "href": "posts/StephRobertsHW1.html",
    "title": "Homework 1",
    "section": "",
    "text": "Homework 1\n##1. Use the LungCapData to answer the following questions. (Hint: Using dplyr, especiallygroup_by() and summarize() can help you answer the following questions relatively efficiently.)\n\n\nCode\ndf<- read_excel(\"LungCapData.xls\")\n\n\nError: `path` does not exist: 'LungCapData.xls'\n\n\nCode\nhead(df)\n\n\n                                              \n1 function (x, df1, df2, ncp, log = FALSE)    \n2 {                                           \n3     if (missing(ncp))                       \n4         .Call(C_df, x, df1, df2, log)       \n5     else .Call(C_dnf, x, df1, df2, ncp, log)\n6 }                                           \n\n\n#Summarize\n\n\nCode\nsummary(df)\n\n\nError in object[[i]]: object of type 'closure' is not subsettable\n\n\n\n\nCode\nmean(df$LungCap)\n\n\nError in df$LungCap: object of type 'closure' is not subsettable\n\n\n\n\nCode\nmedian(df$LungCap)\n\n\nError in df$LungCap: object of type 'closure' is not subsettable\n\n\n\n\nCode\nvar(df$LungCap)\n\n\nError in df$LungCap: object of type 'closure' is not subsettable\n\n\n\n\nCode\nsd(df$LungCap)\n\n\nError in df$LungCap: object of type 'closure' is not subsettable\n\n\n\n\nCode\nmin(df$LungCap)\n\n\nError in df$LungCap: object of type 'closure' is not subsettable\n\n\nCode\nmax(df$LungCap)\n\n\nError in df$LungCap: object of type 'closure' is not subsettable\n\n\n#a. What does the distribution of LungCap look like? (Hint: Plot a histogram with probability density on the y axis)\n\n\nCode\nggplot(df, aes(x=LungCap)) + \n  geom_histogram(binwidth=0.5,col='black',fill='gray')\n\n\nError in `ggplot()`:\n!   You're passing a function as global data.\n  Have you misspelled the `data` argument in `ggplot()`\n\n\nThe histogram follows a distribution close to normal distibution. In fact, if we change binwidth slightly, it appears even closer to normal distribution.\n\n\nCode\nggplot(df, aes(x=LungCap)) + \n  geom_histogram(binwidth=1,col='black',fill='gray')\n\n\nError in `ggplot()`:\n!   You're passing a function as global data.\n  Have you misspelled the `data` argument in `ggplot()`\n\n\nThis helps illustrate the importance of binwidth and what it can do to our visualization interpretations.\n#b. Compare the probability distribution of the LungCap with respect to Males and Females? (Hint: make boxplots separated by gender using the boxplot() function)\n\n\nCode\nggplot(df, aes(x = LungCap, y = Gender)) +        \n  geom_boxplot()\n\n\nError in `ggplot()`:\n!   You're passing a function as global data.\n  Have you misspelled the `data` argument in `ggplot()`\n\n\nThe distribution of male lung capacity is larger and longer than females’.\n#c. Compare the mean lung capacities for smokers and non-smokers. Does it make sense?\n\n\nCode\ndf %>%\n  filter(Smoke == 'yes') %>%\n  pull(LungCap) %>%\n  mean() \n\n\nError in UseMethod(\"filter\"): no applicable method for 'filter' applied to an object of class \"function\"\n\n\nCode\ndf %>%\n  filter(Smoke == 'no') %>%\n  pull(LungCap) %>%\n  mean()\n\n\nError in UseMethod(\"filter\"): no applicable method for 'filter' applied to an object of class \"function\"\n\n\nIt does not make sense at face value. In this sample, smokers have a higher mean lung capacity than non-smokers. Let’s check how big each subsample is.\n\n\nCode\nlength(which(df$Smoke == 'yes'))\n\n\nError in df$Smoke: object of type 'closure' is not subsettable\n\n\nCode\nlength(which(df$Smoke == 'no'))\n\n\nError in df$Smoke: object of type 'closure' is not subsettable\n\n\nAs suspected, there are far more, almost 10 times as many, non-smokers. If we could gather data from all the smokers, perhaps our means would look a lot different. Maybe our sample was taken from young people whose lungs have not been long affected by the smoking.\n\n\nCode\ndf %>%\n  filter(Smoke == 'yes') %>%\n  pull(Age) %>%\n  median() \n\n\nError in UseMethod(\"filter\"): no applicable method for 'filter' applied to an object of class \"function\"\n\n\nAgain, as suspected, our sample of smokers is a young age. Therefore, the lack of difference in lung capacity between smokers and non-smokers is not too surprising.\n#d. Examine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\n\nCode\n#Create age groups\ndf <- df %>% \n  mutate(agegroup = case_when(\n    Age <= 13  ~ \"less than or equal to 13\",\n    Age >= 14 & Age <= 15 ~ \"14 to 15\",\n    Age >= 16 & Age <= 17 ~ \"16 TO 17\",\n    Age >= 18 ~ \"greater than or equal to 18\"))\n\n\nError in UseMethod(\"mutate\"): no applicable method for 'mutate' applied to an object of class \"function\"\n\n\nCode\ntable(df$agegroup)\n\n\nError in df$agegroup: object of type 'closure' is not subsettable\n\n\nCode\ndf %>%\n  filter(Smoke == 'yes') %>%\n  ggplot(aes(x=LungCap)) + \n  geom_histogram(binwidth=1,col='black',fill='gray')+\n  facet_wrap(~agegroup)\n\n\nError in UseMethod(\"filter\"): no applicable method for 'filter' applied to an object of class \"function\"\n\n\nThese histograms suggest that participants 13 or younger have smaller lung capacity. The Lung capacity seems to generally increase with age as children grow.\n#e. Compare the lung capacities for smokers and non-smokers within each age group. Is your answer different from the one in part c. What could possibly be going on here?\n\n\nCode\nggplot(df, aes(x = LungCap, \n           fill = agegroup)) +\n  geom_density(alpha = 0.4)+\n  facet_wrap(~Smoke)\n\n\nError in `ggplot()`:\n!   You're passing a function as global data.\n  Have you misspelled the `data` argument in `ggplot()`\n\n\nThis visualization starts to explain furthermore why there is an unexpected result for lung capacity in smokers vs. non-smokers. As we have deducted, lung capacity generally improves with age (in growing years). However, teenagers approaching adulthood are also a group more likely to have access or influence to smoking cigarettes. It is likely that our smokers account for some of the older participants, who happen to be closer to normal smoking age.\n#f. Calculate the correlation and covariance between Lung Capacity and Age. (use the cov() and cor() functions in R). Interpret your results.\n\n\nCode\ncov(df$LungCap, df$Age) #calculate covariance\n\n\nError in df$Age: object of type 'closure' is not subsettable\n\n\nCode\ncor(df$LungCap, df$Age) #calculate correlation\n\n\nError in df$Age: object of type 'closure' is not subsettable\n\n\nA positive coraviance (8.74) indicates lung capacity and age tend to increase together. The positive correlation relatively close to 1 (0.82) indicates there is a fairly strong correlation between the variables.\n##2. Let X = number of prior convictions for prisoners at a state prison at which there are 810 prisoners.\n\n\nCode\n#create the sample\nx<-rep(c(0,1,2,3,4),times=c(128, 434, 160, 64, 24))\nsample(x, 10)\n\n\n [1] 1 1 2 0 1 0 1 1 2 1\n\n\nCode\n#Verify n of sample\nsum(128, 434, 160, 64, 24)\n\n\n[1] 810\n\n\n\n\nCode\n#Calculate the mean\nmean(x)\n\n\n[1] 1.28642\n\n\nCode\n#Verify the mean\nsample_mean <- (((128*0)+(434*1)+(160*2)+(64*3)+(24*4))/810)\nprint(sample_mean)\n\n\n[1] 1.28642\n\n\n\n\nCode\n#Calculate the sd\nsd(x)\n\n\n[1] 0.9259016\n\n\n#a. What is the probability that a randomly selected inmate has exactly 2 prior convictions?\n\n\nCode\n#probability of 2 convictions?\ndnorm.convict <- dnorm(2, mean(x), sd(x))\nprint(dnorm.convict)\n\n\n[1] 0.3201613\n\n\nThe probability of 2 convications in 0.32.\n#b. What is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\n\nCode\n#probability of <2 convictions\nless.than <- pnorm(2, mean(x), sd(x)) - dnorm.convict\nprint(less.than)\n\n\n[1] 0.4593924\n\n\nThe probability of <2 convictions is 0.46.\n#c. What is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\n\nCode\n#probability of =<2 convictions?\npnorm.convict <- pnorm(2, mean(x), sd(x))\nprint(pnorm.convict)\n\n\n[1] 0.7795537\n\n\nThe probability of less than or equal to 2 convictions is 0.78.\n#d. What is the probability that a randomly selected inmate has more than 2 prior convictions?\n\n\nCode\n#probability of >2 convictions?\ngreater.than <- 1 - pnorm.convict\nprint(greater.than)\n\n\n[1] 0.2204463\n\n\nThe probability of greater than 2 convictions is 0.22.\n\n\nCode\n#Verify all probabilities add to 1\nless.than + dnorm.convict + greater.than\n\n\n[1] 1\n\n\n#e. What is the expected value for the number of prior convictions?\n\n\nCode\n# Expected value of a probability distribution  can be found with μ = Σx * P(x), where x = data value and P(x) = probability of data. \n\n#Calculate probabilities of data\np0 <- dnorm(0, mean(x), sd(x))\np0\n\n\n[1] 0.1641252\n\n\nCode\np1 <- dnorm(1, mean(x), sd(x))\np1\n\n\n[1] 0.410739\n\n\nCode\np2 <- dnorm(2, mean(x), sd(x))\np2\n\n\n[1] 0.3201613\n\n\nCode\np3 <- dnorm(3, mean(x), sd(x))\np3\n\n\n[1] 0.07772916\n\n\nCode\np4 <- dnorm(4, mean(x), sd(x))\np4\n\n\n[1] 0.005877753\n\n\nCode\n#Calculate expected value\nev <- sum((0*p0), (1*p1), (2*p2), (3*p3), (4*p4))\nev\n\n\n[1] 1.30776\n\n\nCode\n#The expected value should be close to the mean in a normal distribution\nmean(x)\n\n\n[1] 1.28642\n\n\nThe expected value is 1.31.\n#f. Calculate the variance and the standard deviation for the Prior Convictions.\n\n\nCode\n#Calculate variance\nvar(x)\n\n\n[1] 0.8572937\n\n\n\n\nCode\n#Calculate the sd\nsd(x)\n\n\n[1] 0.9259016"
  },
  {
    "objectID": "posts/Final Project 1_Kaushika Potluri.html",
    "href": "posts/Final Project 1_Kaushika Potluri.html",
    "title": "Final Project Submission 1",
    "section": "",
    "text": "the research question that I have been interested in is the impact of education about sex and fertility for women and how that changes the fetility rate. Women’s education raises the value of time spent working in the market and, as a result, the opportunity cost of spending time to take care of their child seems less. Across time and places, there is a clear negative link between women’s education and fertility, although its meaning is ambiguous. Women’s level of education may impact fertility through its effects on children’s health, the number of children desired, and women’s ability to give birth and understanding of various birth control options. Each of these are influenced by local, institutional, and national circumstances. Their relative importance may fluctuate as a society develops economically. Since having children affects how much mothers must pay for childcare, women’s education may also be correlated with fertility. The data was acquired from various years of the National Opinion Resource Center’s General Social Survey. Compared to other women, mothers who stay at home with their kids are less likely to invest more money in their education. The correlation between women’s education and unobservable qualities that are jointly linked with fertility may be even more significant.\n###Hypothesis It can be thought of as the total number of unplanned and intended children. The number of kids a family can have, the number of kids the family desires, and the capability to regulate birth through the availability of modern contraceptives and the knowledge of how to use them are all impacted by advancements in women’s education. The number of children a woman has is halfway between the amount she wants and her level of natural fertility. Age and fertility control are the determining variables.If there was a variation by region in birth control availability, such information might be valuable. However, our data set does not contain geographical information (parameters). My assumption would be that if the level of education increases, the number of children would decrease.\n\n\nCode\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/Final Project 1_Kaushika Potluri.html#loading-in-packages",
    "href": "posts/Final Project 1_Kaushika Potluri.html#loading-in-packages",
    "title": "Final Project Submission 1",
    "section": "Loading in packages:",
    "text": "Loading in packages:\n\n\nCode\nlibrary(readr)\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ dplyr   1.0.10\n✔ tibble  3.1.8      ✔ stringr 1.4.1 \n✔ tidyr   1.2.1      ✔ forcats 0.5.2 \n✔ purrr   0.3.5      \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(readxl)"
  },
  {
    "objectID": "posts/Final Project 1_Kaushika Potluri.html#reading-in-data",
    "href": "posts/Final Project 1_Kaushika Potluri.html#reading-in-data",
    "title": "Final Project Submission 1",
    "section": "Reading in Data:",
    "text": "Reading in Data:\nThe data was acquired from Professor Sander’s article that he used.\n\n\nCode\nWomendata <-  read.csv(\"_data/data.csv\")"
  },
  {
    "objectID": "posts/Final Project 1_Kaushika Potluri.html#summary-of-the-data",
    "href": "posts/Final Project 1_Kaushika Potluri.html#summary-of-the-data",
    "title": "Final Project Submission 1",
    "section": "Summary of the data",
    "text": "Summary of the data\n\n\nCode\nsummary(Womendata)\n\n\n       X           mnthborn         yearborn          age       \n Min.   :   1   Min.   : 1.000   Min.   :38.00   Min.   :15.00  \n 1st Qu.:1091   1st Qu.: 3.000   1st Qu.:55.00   1st Qu.:20.00  \n Median :2181   Median : 6.000   Median :62.00   Median :26.00  \n Mean   :2181   Mean   : 6.331   Mean   :60.43   Mean   :27.41  \n 3rd Qu.:3271   3rd Qu.: 9.000   3rd Qu.:68.00   3rd Qu.:33.00  \n Max.   :4361   Max.   :12.000   Max.   :73.00   Max.   :49.00  \n                                                                \n    electric          radio              tv             bicycle      \n Min.   :0.0000   Min.   :0.0000   Min.   :0.00000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000  \n Median :0.0000   Median :1.0000   Median :0.00000   Median :0.0000  \n Mean   :0.1402   Mean   :0.7018   Mean   :0.09291   Mean   :0.2758  \n 3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.00000   Max.   :1.0000  \n NA's   :3        NA's   :2        NA's   :2         NA's   :3       \n      educ             ceb            agefbrth        children     \n Min.   : 0.000   Min.   : 0.000   Min.   :10.00   Min.   : 0.000  \n 1st Qu.: 3.000   1st Qu.: 1.000   1st Qu.:17.00   1st Qu.: 0.000  \n Median : 7.000   Median : 2.000   Median :19.00   Median : 2.000  \n Mean   : 5.856   Mean   : 2.442   Mean   :19.01   Mean   : 2.268  \n 3rd Qu.: 8.000   3rd Qu.: 4.000   3rd Qu.:20.00   3rd Qu.: 4.000  \n Max.   :20.000   Max.   :13.000   Max.   :38.00   Max.   :13.000  \n                                   NA's   :1088                    \n    knowmeth         usemeth          monthfm          yearfm     \n Min.   :0.0000   Min.   :0.0000   Min.   : 1.00   Min.   :50.00  \n 1st Qu.:1.0000   1st Qu.:0.0000   1st Qu.: 3.00   1st Qu.:72.00  \n Median :1.0000   Median :1.0000   Median : 6.00   Median :78.00  \n Mean   :0.9633   Mean   :0.5776   Mean   : 6.27   Mean   :76.91  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.: 9.00   3rd Qu.:83.00  \n Max.   :1.0000   Max.   :1.0000   Max.   :12.00   Max.   :88.00  \n NA's   :7        NA's   :71       NA's   :2282    NA's   :2282   \n     agefm          idlnchld          heduc            agesq       \n Min.   :10.00   Min.   : 0.000   Min.   : 0.000   Min.   : 225.0  \n 1st Qu.:17.00   1st Qu.: 3.000   1st Qu.: 0.000   1st Qu.: 400.0  \n Median :20.00   Median : 4.000   Median : 6.000   Median : 676.0  \n Mean   :20.69   Mean   : 4.616   Mean   : 5.145   Mean   : 826.5  \n 3rd Qu.:23.00   3rd Qu.: 6.000   3rd Qu.: 8.000   3rd Qu.:1089.0  \n Max.   :46.00   Max.   :20.000   Max.   :20.000   Max.   :2401.0  \n NA's   :2282    NA's   :120      NA's   :2405                     \n     urban           urb_educ          spirit          protest      \n Min.   :0.0000   Min.   : 0.000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.: 0.000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :1.0000   Median : 0.000   Median :0.0000   Median :0.0000  \n Mean   :0.5166   Mean   : 3.469   Mean   :0.4222   Mean   :0.2277  \n 3rd Qu.:1.0000   3rd Qu.: 7.000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n Max.   :1.0000   Max.   :20.000   Max.   :1.0000   Max.   :1.0000  \n                                                                    \n    catholic         frsthalf          educ0           evermarr     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :1.0000   Median :0.0000   Median :0.0000  \n Mean   :0.1025   Mean   :0.5405   Mean   :0.2078   Mean   :0.4767  \n 3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n                                                                    \n\n\n\n\nCode\nglimpse(Womendata)\n\n\nRows: 4,361\nColumns: 28\n$ X        <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18…\n$ mnthborn <int> 5, 1, 7, 11, 5, 8, 7, 9, 12, 9, 6, 10, 12, 2, 1, 6, 1, 8, 4, …\n$ yearborn <int> 64, 56, 58, 45, 45, 52, 51, 70, 53, 39, 46, 59, 42, 40, 53, 6…\n$ age      <int> 24, 32, 30, 42, 43, 36, 37, 18, 34, 49, 42, 29, 45, 48, 35, 2…\n$ electric <int> 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ radio    <int> 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ tv       <int> 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1…\n$ bicycle  <int> 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0…\n$ educ     <int> 12, 13, 5, 4, 11, 7, 16, 10, 5, 4, 15, 7, 0, 4, 12, 7, 7, 5, …\n$ ceb      <int> 0, 3, 1, 3, 2, 1, 4, 0, 1, 0, 3, 3, 4, 10, 3, 0, 4, 2, 0, 1, …\n$ agefbrth <int> NA, 25, 27, 17, 24, 26, 20, NA, 19, NA, 25, 23, 18, 19, 23, N…\n$ children <int> 0, 3, 1, 2, 2, 1, 4, 0, 1, 0, 3, 3, 2, 8, 3, 0, 4, 2, 0, 1, 0…\n$ knowmeth <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ usemeth  <int> 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1…\n$ monthfm  <int> NA, 11, 6, 1, 3, 11, 5, NA, 7, 11, 6, 1, 1, 10, 1, NA, NA, NA…\n$ yearfm   <int> NA, 80, 83, 61, 66, 76, 78, NA, 72, 61, 70, 84, 66, 66, 74, N…\n$ agefm    <int> NA, 24, 24, 15, 20, 24, 26, NA, 18, 22, 24, 24, 23, 26, 21, N…\n$ idlnchld <int> 2, 3, 5, 3, 2, 4, 4, 4, 4, 4, 3, 6, 6, 4, 3, 4, 5, 1, 2, 3, 2…\n$ heduc    <int> NA, 12, 7, 11, 14, 9, 17, NA, 3, 1, 16, 7, NA, 3, 16, NA, NA,…\n$ agesq    <int> 576, 1024, 900, 1764, 1849, 1296, 1369, 324, 1156, 2401, 1764…\n$ urban    <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ urb_educ <int> 12, 13, 5, 4, 11, 7, 16, 10, 5, 4, 15, 7, 0, 4, 12, 7, 7, 5, …\n$ spirit   <int> 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0…\n$ protest  <int> 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1…\n$ catholic <int> 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0…\n$ frsthalf <int> 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0…\n$ educ0    <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ evermarr <int> 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1…\n\n\nWe can see that we have 28 variables and 4361 observations in this dataset. The dependent variable of interest - number of living children Then I will perform data manipulation to tidy the data. The variables of interest are age, yearborn, month born, urban education and many more variables that seem intriguing. Variables like radio, bicycle, electric can be ignored in this.\n###References [1] The effect of women’s schooling on fertility by W Sander · 1992 [2] The Impact of Women’s Schooling on Fertility and Contraceptive Use by M Ainsworth · 1996"
  },
  {
    "objectID": "posts/HW1_PrahithaMovva.html",
    "href": "posts/HW1_PrahithaMovva.html",
    "title": "Homework 1 - Prahitha Movva",
    "section": "",
    "text": "First, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\ndf <- read_excel(\"_data/LungCapData.xls\")\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(df$LungCap)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\n\n\n\n\n\nCode\nboxplot(LungCap~Gender, data = df)\n\n\n\n\n\nFrom the boxplots for gender above, we can see that males seem to have (slightly) higher lung capacity than females.\n\n\n\n\n\nCode\naggregate(data = df, LungCap~Smoke, mean)\n\n\n  Smoke  LungCap\n1    no 7.770188\n2   yes 8.645455\n\n\nThe mean lung capacity for smokers and nonsmokers seems to be higher for smokers. This does not make sense as we generally expect smokers to have a reduced lung capacity due to the damage from smoking.\n\n\n\n\n\nCode\ndf_ageGroups <- mutate(df, AgeGroup = case_when(Age <= 13 ~ \"13 and below\", Age == 14 | Age == 15 ~ \"14 to 15\", Age == 16 | Age == 17 ~ \"16 to 17\", Age >= 18 ~ \"18 and above\"))\n\n\nError in mutate(df, AgeGroup = case_when(Age <= 13 ~ \"13 and below\", Age == : could not find function \"mutate\"\n\n\nCode\nggplot(df_ageGroups, aes(x = LungCap)) +\n  geom_histogram() +\n  facet_grid(AgeGroup~Smoke)\n\n\nError in ggplot(df_ageGroups, aes(x = LungCap)): could not find function \"ggplot\"\n\n\nWe see non-smokers to have a higher lung capacity than smokers, as expected.\n\n\n\nLung capacity seems to be directly proportional to age and after breaking down the data by age groups, we see that the lung capacities for non-smokers are higher than those of smokers in the same age group (except for less than or equal to 13). This could be because of the total number of observations in each age group. The age group less than or equal to 13 has the highest number of observations - thereby skewing the results (here, mean) for the entire distribution.\n\n\n\n\n\nCode\ncor(x= df$LungCap, y = df$Age)\n\n\n[1] 0.8196749\n\n\nCode\ncov(x= df$LungCap, y = df$Age)\n\n\n[1] 8.738289\n\n\nLung capacity seems to be positively correlated with age i.e., as age increases, lung capacity increases. Same is the case with covariance."
  },
  {
    "objectID": "posts/HW1_PrahithaMovva.html#a-1",
    "href": "posts/HW1_PrahithaMovva.html#a-1",
    "title": "Homework 1 - Prahitha Movva",
    "section": "a",
    "text": "a\n\n\nCode\na <- 160/810\n\n\nThe probability that a randomly selected inmate has exactly 2 prior convictions is 0.1975309."
  },
  {
    "objectID": "posts/HW1_PrahithaMovva.html#b-1",
    "href": "posts/HW1_PrahithaMovva.html#b-1",
    "title": "Homework 1 - Prahitha Movva",
    "section": "b",
    "text": "b\n\n\nCode\nb <- (128+434)/810\n\n\nThe probability that a randomly selected inmate has fewer than 2 prior convictions is 0.6938272."
  },
  {
    "objectID": "posts/HW1_PrahithaMovva.html#c-1",
    "href": "posts/HW1_PrahithaMovva.html#c-1",
    "title": "Homework 1 - Prahitha Movva",
    "section": "c",
    "text": "c\n\n\nCode\nc <- (128+434+160)/810\n\n\nThe probability that a randomly selected inmate has 2 or fewer prior convictions is 0.891358."
  },
  {
    "objectID": "posts/HW1_PrahithaMovva.html#d-1",
    "href": "posts/HW1_PrahithaMovva.html#d-1",
    "title": "Homework 1 - Prahitha Movva",
    "section": "d",
    "text": "d\n\n\nCode\nd <- (64+24)/810\n\n\nThe probability that a randomly selected inmate has more than 2 prior convictions is 0.108642."
  },
  {
    "objectID": "posts/HW1_PrahithaMovva.html#e-1",
    "href": "posts/HW1_PrahithaMovva.html#e-1",
    "title": "Homework 1 - Prahitha Movva",
    "section": "e",
    "text": "e\n\n\nCode\ne <- (0*(128/810)) + (1*(434/810)) + (2*(160/810)) + (3*(64/810)) + (4*(24/810))\n\n\nThe expected value for the number of prior convictions is 1.2864198 or 1, as the number of convictions cannot be a float."
  },
  {
    "objectID": "posts/HW1_PrahithaMovva.html#f-1",
    "href": "posts/HW1_PrahithaMovva.html#f-1",
    "title": "Homework 1 - Prahitha Movva",
    "section": "f",
    "text": "f\n\n\nCode\nvar_0 <- ((0-e)^2) * (128/810)\nvar_1 <- ((1-e)^2) * (434/810)\nvar_2 <- ((2-e)^2) * (160/810)\nvar_3 <- ((3-e)^2) * (64/810)\nvar_4 <- ((4-e)^2) * (24/810)\n\nvar <- var_0 + var_1 + var_2 + var_3 + var_4\n\nsd <- sqrt(var)\n\n\nFor prior convictions, the variance is 0.8562353 and the standard deviation is 0.9253298."
  },
  {
    "objectID": "posts/Final Project.html",
    "href": "posts/Final Project.html",
    "title": "Final Project",
    "section": "",
    "text": "Extensive research has been done on climate change and economic changes respectively but there is not a significant amount of research about their relation towards one another. There are research papers that touch on this but in different aspects and focus more on other factors like political aspects. I would like to look a little broader and look at the difference between each climate zone and their economic differences. This can be taken with a grain of salt as there are many factors that could effect the economic situation being left out. The data was pulled from NASA’s POWER data access viewer; here I pulled the data by region since pulling the whole country in one go was unavailable. Thus, I will conduct research on each region respectively and then compare the results.\n\n\n\n\n\n\nResearch Questions\n\n\n\nA. Is there a relation between climate zone and economic growth?\nB. Do Southern climates have the largest economic growth?"
  },
  {
    "objectID": "posts/Final Project.html#reading-in-the-data",
    "href": "posts/Final Project.html#reading-in-the-data",
    "title": "Final Project",
    "section": "Reading in the data",
    "text": "Reading in the data\n\n## problem 1 how to merge files that are this large together? do we reduce the file sizes or is there another work around\n# May just need to keep regions separated \n# Weather data\n# Reading in all the weather data \nAmherst <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/amherst.csv\", skip = 14)\n\nWarning in file(file, \"rt\"): cannot open file 'C:/Users/ethan/Documents/Github\nClass/603_Fall_2022_homework/amherst.csv': No such file or directory\n\n\nError in file(file, \"rt\"): cannot open the connection\n\nFlorida <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/flordia.csv\", skip = 14)\n\nWarning in file(file, \"rt\"): cannot open file 'C:/Users/ethan/Documents/Github\nClass/603_Fall_2022_homework/flordia.csv': No such file or directory\n\n\nError in file(file, \"rt\"): cannot open the connection\n\nIllinois <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/illinois.csv\", skip = 14)\n\nWarning in file(file, \"rt\"): cannot open file 'C:/Users/ethan/Documents/Github\nClass/603_Fall_2022_homework/illinois.csv': No such file or directory\n\n\nError in file(file, \"rt\"): cannot open the connection\n\nMiddle <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/middle.csv\", skip = 14)\n\nWarning in file(file, \"rt\"): cannot open file 'C:/Users/ethan/Documents/Github\nClass/603_Fall_2022_homework/middle.csv': No such file or directory\n\n\nError in file(file, \"rt\"): cannot open the connection\n\nNewmexico <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/Newmexico.csv\", skip = 14)\n\nWarning in file(file, \"rt\"): cannot open file 'C:/Users/ethan/Documents/Github\nClass/603_Fall_2022_homework/Newmexico.csv': No such file or directory\n\n\nError in file(file, \"rt\"): cannot open the connection\n\nNorth <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/North.csv\", skip = 14)\n\nWarning in file(file, \"rt\"): cannot open file 'C:/Users/ethan/Documents/Github\nClass/603_Fall_2022_homework/North.csv': No such file or directory\n\n\nError in file(file, \"rt\"): cannot open the connection\n\nSouth <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/south.csv\", skip = 14)\n\nWarning in file(file, \"rt\"): cannot open file 'C:/Users/ethan/Documents/Github\nClass/603_Fall_2022_homework/south.csv': No such file or directory\n\n\nError in file(file, \"rt\"): cannot open the connection\n\nSouthCali <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/SouthCali.csv\", skip = 14)\n\nWarning in file(file, \"rt\"): cannot open file 'C:/Users/ethan/Documents/Github\nClass/603_Fall_2022_homework/SouthCali.csv': No such file or directory\n\n\nError in file(file, \"rt\"): cannot open the connection\n\nTexas <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/Texas.csv\", skip = 14)\n\nWarning in file(file, \"rt\"): cannot open file 'C:/Users/ethan/Documents/Github\nClass/603_Fall_2022_homework/Texas.csv': No such file or directory\n\n\nError in file(file, \"rt\"): cannot open the connection\n\nWashington <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/washington.csv\", skip = 14)\n\nWarning in file(file, \"rt\"): cannot open file 'C:/Users/ethan/Documents/Github\nClass/603_Fall_2022_homework/washington.csv': No such file or directory\n\n\nError in file(file, \"rt\"): cannot open the connection\n\nWestV <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/WestV.csv\", skip = 14)\n\nWarning in file(file, \"rt\"): cannot open file 'C:/Users/ethan/Documents/Github\nClass/603_Fall_2022_homework/WestV.csv': No such file or directory\n\n\nError in file(file, \"rt\"): cannot open the connection\n\n\n\nAmherst\nHad trouble with pivot_wider since it would split the values up by each name but then would fill in the values with NA for the other sections. This added a ton of NA values that one looked bad and were hard to deal with. I had to go a more manual way and do it for each part of PARAMETER to get the exact number of rows I needed. This stopped the NA values and got them all lined up so it reduced the size of the document from 500k+ rows to 89290 rows. This is huge in terms of running the data and working with it. Finally, I just merged the data together and then I was able to rename all the columns and start regression analysis.\n\n# Bringing all the month columns into one column\nAmherst <- Amherst %>%\npivot_longer(\n  cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, DEC),\n  names_to = \"MONTH\",\n  values_to = \"Month_Average\",\n)\n\nError in pivot_longer(., cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, : object 'Amherst' not found\n\n## getting the parameter section broken up into different sections since the normal pivot_longer did not work\nTidy_amherst <- Amherst %>%\n  select(PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN) %>%\n  filter(PARAMETER == 'PS')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN): object 'Amherst' not found\n\nTidy_amherst <- Tidy_amherst %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'Tidy_amherst' not found\n\nTidy_amherst <- Tidy_amherst %>%\n  select(PS, YEAR, MONTH, LAT, LON, ANN)\n\nError in select(., PS, YEAR, MONTH, LAT, LON, ANN): object 'Tidy_amherst' not found\n\nt2m <- Amherst %>%\n  select(PARAMETER, Month_Average, YEAR) %>%\n  filter(PARAMETER == 'T2M')\n\nError in select(., PARAMETER, Month_Average, YEAR): object 'Amherst' not found\n\nt2m <- t2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 't2m' not found\n\nt2m <- t2m %>%\n  select(T2M, YEAR)\n\nError in select(., T2M, YEAR): object 't2m' not found\n\nTidy_amherst$T2M <- t2m$T2M\n\nError in eval(expr, envir, enclos): object 't2m' not found\n\nrh2m <- Amherst %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'RH2M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Amherst' not found\n\nrh2m <- rh2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'rh2m' not found\n\nrh2m <- rh2m %>%\n  select(RH2M, YEAR)\n\nError in select(., RH2M, YEAR): object 'rh2m' not found\n\nTidy_amherst$RH2M <- rh2m$RH2M\n\nError in eval(expr, envir, enclos): object 'rh2m' not found\n\nwh10m <- Amherst %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS10M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Amherst' not found\n\nwh10m <- wh10m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'wh10m' not found\n\nwh10m <- wh10m %>%\n  select(WS10M, YEAR)\n\nError in select(., WS10M, YEAR): object 'wh10m' not found\n\nTidy_amherst$WS10M <- wh10m$WS10M\n\nError in eval(expr, envir, enclos): object 'wh10m' not found\n\nwh50m <- Amherst %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS50M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Amherst' not found\n\nwh50m <- wh50m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'wh50m' not found\n\nwh50m <- wh50m %>%\n  select(WS50M, YEAR)\n\nError in select(., WS50M, YEAR): object 'wh50m' not found\n\nTidy_amherst$WS50M <- wh50m$WS50M\n\nError in eval(expr, envir, enclos): object 'wh50m' not found\n\nPRECTOTCORR <- Amherst %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'PRECTOTCORR')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Amherst' not found\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'PRECTOTCORR' not found\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  select(PRECTOTCORR, YEAR)\n\nError in select(., PRECTOTCORR, YEAR): object 'PRECTOTCORR' not found\n\nTidy_amherst$PRECTOTCORR <- PRECTOTCORR$PRECTOTCORR\n\nError in eval(expr, envir, enclos): object 'PRECTOTCORR' not found\n\n# renaming all the variables to easier to digest names\nTidy_amherst <- Tidy_amherst %>%\n  dplyr::rename(Temperature = T2M) %>%\n  dplyr::rename(Humidity = RH2M) %>%\n  dplyr::rename(Wind_10_meter = WS10M) %>%\n  dplyr::rename(Surface_Pressure = PS) %>%\n  dplyr::rename(Wind_50_meter = WS50M) %>%\n  dplyr::rename(Precipitation = PRECTOTCORR) %>%\n  dplyr::rename(Annual = ANN) %>%\n  dplyr::rename(Latitude = LAT) %>%\n  dplyr::rename(Longitude = LON) %>%\n  dplyr::rename(Month = MONTH) %>%\n  dplyr::rename(Year = YEAR)\n\nError in dplyr::rename(., Temperature = T2M): object 'Tidy_amherst' not found\n\n## Getting them in clean looking order\nTidy_amherst <- Tidy_amherst %>%\n  select(Year, Month, Latitude, Longitude, Temperature, Humidity, Precipitation, Surface_Pressure, Wind_10_meter, Wind_50_meter, Annual)\n\nError in select(., Year, Month, Latitude, Longitude, Temperature, Humidity, : object 'Tidy_amherst' not found\n\n## Summary and starting regression information \nsummary(Tidy_amherst)\n\nError in summary(Tidy_amherst): object 'Tidy_amherst' not found\n\nview_amherst <- Tidy_amherst %>%\n  slice(1:10)\n\nError in slice(., 1:10): object 'Tidy_amherst' not found\n\nkable(view_amherst, digits = 2, align = \"ccccccc\", col.names = c(\"Year\", \"Month\", \"Latitude\", \"Longitude\", \"Temperature\", \"Humidity\", \"Precipitation\", \"Surface Pressure\", \"Wind 10 Meters\", \"Wind 50 Meters\", \"Annual\"), caption = \"Amherst Data\") %>%\n  kable_styling(font_size = 16)\n\nError in kable_styling(., font_size = 16): could not find function \"kable_styling\"\n\n\n\n\nFlorida\n\nFlorida <- Florida %>%\npivot_longer(\n  cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, DEC),\n  names_to = \"MONTH\",\n  values_to = \"Month_Average\",\n)\n\nError in pivot_longer(., cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, : object 'Florida' not found\n\nTidy_Florida <- Florida %>%\n  select(PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN) %>%\n  filter(PARAMETER == 'PS')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN): object 'Florida' not found\n\nTidy_Florida <- Tidy_Florida %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'Tidy_Florida' not found\n\nTidy_Florida <- Tidy_Florida %>%\n  select(PS, YEAR, MONTH, LAT, LON, ANN)\n\nError in select(., PS, YEAR, MONTH, LAT, LON, ANN): object 'Tidy_Florida' not found\n\nt2m <- Florida %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'T2M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Florida' not found\n\nt2m <- t2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 't2m' not found\n\nt2m <- t2m %>%\n  select(T2M, YEAR)\n\nError in select(., T2M, YEAR): object 't2m' not found\n\nTidy_Florida$T2M <- t2m$T2M\n\nError in eval(expr, envir, enclos): object 't2m' not found\n\nrh2m <- Florida %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'RH2M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Florida' not found\n\nrh2m <- rh2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'rh2m' not found\n\nrh2m <- rh2m %>%\n  select(RH2M, YEAR)\n\nError in select(., RH2M, YEAR): object 'rh2m' not found\n\nTidy_Florida$RH2M <- rh2m$RH2M\n\nError in eval(expr, envir, enclos): object 'rh2m' not found\n\nwh10m <- Florida %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS10M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Florida' not found\n\nwh10m <- wh10m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'wh10m' not found\n\nwh10m <- wh10m %>%\n  select(WS10M, YEAR)\n\nError in select(., WS10M, YEAR): object 'wh10m' not found\n\nTidy_Florida$WS10M <- wh10m$WS10M\n\nError in eval(expr, envir, enclos): object 'wh10m' not found\n\nwh50m <- Florida %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS50M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Florida' not found\n\nwh50m <- wh50m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'wh50m' not found\n\nwh50m <- wh50m %>%\n  select(WS50M, YEAR)\n\nError in select(., WS50M, YEAR): object 'wh50m' not found\n\nTidy_Florida$WS50M <- wh50m$WS50M\n\nError in eval(expr, envir, enclos): object 'wh50m' not found\n\nPRECTOTCORR <- Florida %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'PRECTOTCORR')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Florida' not found\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'PRECTOTCORR' not found\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  select(PRECTOTCORR, YEAR)\n\nError in select(., PRECTOTCORR, YEAR): object 'PRECTOTCORR' not found\n\nTidy_Florida$PRECTOTCORR <- PRECTOTCORR$PRECTOTCORR\n\nError in eval(expr, envir, enclos): object 'PRECTOTCORR' not found\n\nTidy_Florida <- Tidy_Florida %>%\n  dplyr::rename(Temperature = T2M) %>%\n  dplyr::rename(Humidity = RH2M) %>%\n  dplyr::rename(Wind_10_meter = WS10M) %>%\n  dplyr::rename(Surface_Pressure = PS) %>%\n  dplyr::rename(Wind_50_meter = WS50M) %>%\n  dplyr::rename(Precipitation = PRECTOTCORR) %>%\n  dplyr::rename(Annual = ANN) %>%\n  dplyr::rename(Latitude = LAT) %>%\n  dplyr::rename(Longitude = LON) %>%\n  dplyr::rename(Month = MONTH) %>%\n  dplyr::rename(Year = YEAR)\n\nError in dplyr::rename(., Temperature = T2M): object 'Tidy_Florida' not found\n\nTidy_Florida <- Tidy_Florida %>%\n  select(Year, Month, Latitude, Longitude, Temperature, Humidity, Precipitation, Surface_Pressure, Wind_10_meter, Wind_50_meter, Annual)\n\nError in select(., Year, Month, Latitude, Longitude, Temperature, Humidity, : object 'Tidy_Florida' not found\n\nsummary(Tidy_Florida)\n\nError in summary(Tidy_Florida): object 'Tidy_Florida' not found\n\nTidy_Florida <- Tidy_Florida %>%\n  slice(1:10)\n\nError in slice(., 1:10): object 'Tidy_Florida' not found\n\nkable(Tidy_Florida, digits = 2, align = \"ccccccc\", col.names = c(\"Year\", \"Month\", \"Latitude\", \"Longitude\", \"Temperature\", \"Humidity\", \"Precipitation\", \"Surface Pressure\", \"Wind 10 Meters\", \"Wind 50 Meters\", \"Annual\"), caption = \"Florida Data\") %>%\n  kable_styling(font_size = 16)\n\nError in kable_styling(., font_size = 16): could not find function \"kable_styling\"\n\n\n\n\nIllinois\n\nIllinois <- Illinois %>%\npivot_longer(\n  cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, DEC),\n  names_to = \"MONTH\",\n  values_to = \"Month_Average\",\n)\n\nError in pivot_longer(., cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, : object 'Illinois' not found\n\nTidy_Illinois <- Illinois %>%\n  select(PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN) %>%\n  filter(PARAMETER == 'PS')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN): object 'Illinois' not found\n\nTidy_Illinois <- Tidy_Illinois %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'Tidy_Illinois' not found\n\nTidy_Illinois <- Tidy_Illinois %>%\n  select(PS, YEAR, MONTH, LAT, LON, ANN)\n\nError in select(., PS, YEAR, MONTH, LAT, LON, ANN): object 'Tidy_Illinois' not found\n\nt2m <- Illinois %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'T2M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Illinois' not found\n\nt2m <- t2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 't2m' not found\n\nt2m <- t2m %>%\n  select(T2M, YEAR)\n\nError in select(., T2M, YEAR): object 't2m' not found\n\nTidy_Illinois$T2M <- t2m$T2M\n\nError in eval(expr, envir, enclos): object 't2m' not found\n\nrh2m <- Illinois %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'RH2M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Illinois' not found\n\nrh2m <- rh2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'rh2m' not found\n\nrh2m <- rh2m %>%\n  select(RH2M, YEAR)\n\nError in select(., RH2M, YEAR): object 'rh2m' not found\n\nTidy_Illinois$RH2M <- rh2m$RH2M\n\nError in eval(expr, envir, enclos): object 'rh2m' not found\n\nwh10m <- Illinois %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS10M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Illinois' not found\n\nwh10m <- wh10m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'wh10m' not found\n\nwh10m <- wh10m %>%\n  select(WS10M, YEAR)\n\nError in select(., WS10M, YEAR): object 'wh10m' not found\n\nTidy_Illinois$WS10M <- wh10m$WS10M\n\nError in eval(expr, envir, enclos): object 'wh10m' not found\n\nwh50m <- Illinois %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS50M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Illinois' not found\n\nwh50m <- wh50m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'wh50m' not found\n\nwh50m <- wh50m %>%\n  select(WS50M, YEAR)\n\nError in select(., WS50M, YEAR): object 'wh50m' not found\n\nTidy_Illinois$WS50M <- wh50m$WS50M\n\nError in eval(expr, envir, enclos): object 'wh50m' not found\n\nPRECTOTCORR <- Illinois %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'PRECTOTCORR')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Illinois' not found\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'PRECTOTCORR' not found\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  select(PRECTOTCORR, YEAR)\n\nError in select(., PRECTOTCORR, YEAR): object 'PRECTOTCORR' not found\n\nTidy_Illinois$PRECTOTCORR <- PRECTOTCORR$PRECTOTCORR\n\nError in eval(expr, envir, enclos): object 'PRECTOTCORR' not found\n\nTidy_Illinois <- Tidy_Illinois %>%\n  dplyr::rename(Temperature = T2M) %>%\n  dplyr::rename(Humidity = RH2M) %>%\n  dplyr::rename(Wind_10_meter = WS10M) %>%\n  dplyr::rename(Surface_Pressure = PS) %>%\n  dplyr::rename(Wind_50_meter = WS50M) %>%\n  dplyr::rename(Precipitation = PRECTOTCORR) %>%\n  dplyr::rename(Annual = ANN) %>%\n  dplyr::rename(Latitude = LAT) %>%\n  dplyr::rename(Longitude = LON) %>%\n  dplyr::rename(Month = MONTH) %>%\n  dplyr::rename(Year = YEAR)\n\nError in dplyr::rename(., Temperature = T2M): object 'Tidy_Illinois' not found\n\nTidy_Illinois <- Tidy_Illinois %>%\n  select(Year, Month, Latitude, Longitude, Temperature, Humidity, Precipitation, Surface_Pressure, Wind_10_meter, Wind_50_meter, Annual)\n\nError in select(., Year, Month, Latitude, Longitude, Temperature, Humidity, : object 'Tidy_Illinois' not found\n\nsummary(Tidy_Illinois)\n\nError in summary(Tidy_Illinois): object 'Tidy_Illinois' not found\n\nTidy_Illinois <- Tidy_Illinois %>%\n  slice(1:10)\n\nError in slice(., 1:10): object 'Tidy_Illinois' not found\n\nkable(Tidy_Illinois, digits = 2, align = \"ccccccc\", col.names = c(\"Year\", \"Month\", \"Latitude\", \"Longitude\", \"Temperature\", \"Humidity\", \"Precipitation\", \"Surface Pressure\", \"Wind 10 Meters\", \"Wind 50 Meters\", \"Annual\"), caption = \"Amherst Data\") %>%\n  kable_styling(font_size = 16)\n\nError in kable_styling(., font_size = 16): could not find function \"kable_styling\"\n\n\n\n\nMiddle\n\nMiddle <- Middle %>%\npivot_longer(\n  cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, DEC),\n  names_to = \"MONTH\",\n  values_to = \"Month_Average\",\n)\n\nError in pivot_longer(., cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, : object 'Middle' not found\n\nTidy_Middle <- Middle %>%\n  select(PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN) %>%\n  filter(PARAMETER == 'PS')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN): object 'Middle' not found\n\nTidy_Middle <- Tidy_Middle %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'Tidy_Middle' not found\n\nTidy_Middle <- Tidy_Middle %>%\n  select(PS, YEAR, MONTH, LAT, LON, ANN)\n\nError in select(., PS, YEAR, MONTH, LAT, LON, ANN): object 'Tidy_Middle' not found\n\nt2m <- Middle %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'T2M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Middle' not found\n\nt2m <- t2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 't2m' not found\n\nt2m <- t2m %>%\n  select(T2M, YEAR)\n\nError in select(., T2M, YEAR): object 't2m' not found\n\nTidy_Middle$T2M <- t2m$T2M\n\nError in eval(expr, envir, enclos): object 't2m' not found\n\nrh2m <- Middle %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'RH2M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Middle' not found\n\nrh2m <- rh2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'rh2m' not found\n\nrh2m <- rh2m %>%\n  select(RH2M, YEAR)\n\nError in select(., RH2M, YEAR): object 'rh2m' not found\n\nTidy_Middle$RH2M <- rh2m$RH2M\n\nError in eval(expr, envir, enclos): object 'rh2m' not found\n\nwh10m <- Middle %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS10M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Middle' not found\n\nwh10m <- wh10m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'wh10m' not found\n\nwh10m <- wh10m %>%\n  select(WS10M, YEAR)\n\nError in select(., WS10M, YEAR): object 'wh10m' not found\n\nTidy_Middle$WS10M <- wh10m$WS10M\n\nError in eval(expr, envir, enclos): object 'wh10m' not found\n\nwh50m <- Middle %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS50M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Middle' not found\n\nwh50m <- wh50m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'wh50m' not found\n\nwh50m <- wh50m %>%\n  select(WS50M, YEAR)\n\nError in select(., WS50M, YEAR): object 'wh50m' not found\n\nTidy_Middle$WS50M <- wh50m$WS50M\n\nError in eval(expr, envir, enclos): object 'wh50m' not found\n\nPRECTOTCORR <- Middle %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'PRECTOTCORR')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Middle' not found\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'PRECTOTCORR' not found\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  select(PRECTOTCORR, YEAR)\n\nError in select(., PRECTOTCORR, YEAR): object 'PRECTOTCORR' not found\n\nTidy_Middle$PRECTOTCORR <- PRECTOTCORR$PRECTOTCORR\n\nError in eval(expr, envir, enclos): object 'PRECTOTCORR' not found\n\nTidy_Middle <- Tidy_Middle %>%\n  dplyr::rename(Temperature = T2M) %>%\n  dplyr::rename(Humidity = RH2M) %>%\n  dplyr::rename(Wind_10_meter = WS10M) %>%\n  dplyr::rename(Surface_Pressure = PS) %>%\n  dplyr::rename(Wind_50_meter = WS50M) %>%\n  dplyr::rename(Precipitation = PRECTOTCORR) %>%\n  dplyr::rename(Annual = ANN) %>%\n  dplyr::rename(Latitude = LAT) %>%\n  dplyr::rename(Longitude = LON) %>%\n  dplyr::rename(Month = MONTH) %>%\n  dplyr::rename(Year = YEAR)\n\nError in dplyr::rename(., Temperature = T2M): object 'Tidy_Middle' not found\n\nTidy_Middle <- Tidy_Middle %>%\n  select(Year, Month, Latitude, Longitude, Temperature, Humidity, Precipitation, Surface_Pressure, Wind_10_meter, Wind_50_meter, Annual)\n\nError in select(., Year, Month, Latitude, Longitude, Temperature, Humidity, : object 'Tidy_Middle' not found\n\nsummary(Tidy_Middle)\n\nError in summary(Tidy_Middle): object 'Tidy_Middle' not found\n\nTidy_Middle <- Tidy_Middle %>%\n  slice(1:10)\n\nError in slice(., 1:10): object 'Tidy_Middle' not found\n\nkable(Tidy_Middle, digits = 2, align = \"ccccccc\", col.names = c(\"Year\", \"Month\", \"Latitude\", \"Longitude\", \"Temperature\", \"Humidity\", \"Precipitation\", \"Surface Pressure\", \"Wind 10 Meters\", \"Wind 50 Meters\", \"Annual\"), caption = \"Amherst Data\") %>%\n  kable_styling(font_size = 16)\n\nError in kable_styling(., font_size = 16): could not find function \"kable_styling\"\n\n\n\n\nNew Mexico\n\nNewmexico <- Newmexico %>%\npivot_longer(\n  cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, DEC),\n  names_to = \"MONTH\",\n  values_to = \"Month_Average\",\n)\n\nError in pivot_longer(., cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, : object 'Newmexico' not found\n\nTidy_Newmexico <- Newmexico %>%\n  select(PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN) %>%\n  filter(PARAMETER == 'PS')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN): object 'Newmexico' not found\n\nTidy_Newmexico <- Tidy_Newmexico %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'Tidy_Newmexico' not found\n\nTidy_Newmexico <- Tidy_Newmexico %>%\n  select(PS, YEAR, MONTH, LAT, LON, ANN)\n\nError in select(., PS, YEAR, MONTH, LAT, LON, ANN): object 'Tidy_Newmexico' not found\n\nt2m <- Newmexico %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'T2M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Newmexico' not found\n\nt2m <- t2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 't2m' not found\n\nt2m <- t2m %>%\n  select(T2M, YEAR)\n\nError in select(., T2M, YEAR): object 't2m' not found\n\nTidy_Newmexico$T2M <- t2m$T2M\n\nError in eval(expr, envir, enclos): object 't2m' not found\n\nrh2m <- Newmexico %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'RH2M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Newmexico' not found\n\nrh2m <- rh2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'rh2m' not found\n\nrh2m <- rh2m %>%\n  select(RH2M, YEAR)\n\nError in select(., RH2M, YEAR): object 'rh2m' not found\n\nTidy_Newmexico$RH2M <- rh2m$RH2M\n\nError in eval(expr, envir, enclos): object 'rh2m' not found\n\nwh10m <- Newmexico %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS10M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Newmexico' not found\n\nwh10m <- wh10m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'wh10m' not found\n\nwh10m <- wh10m %>%\n  select(WS10M, YEAR)\n\nError in select(., WS10M, YEAR): object 'wh10m' not found\n\nTidy_Newmexico$WS10M <- wh10m$WS10M\n\nError in eval(expr, envir, enclos): object 'wh10m' not found\n\nwh50m <- Newmexico %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS50M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Newmexico' not found\n\nwh50m <- wh50m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'wh50m' not found\n\nwh50m <- wh50m %>%\n  select(WS50M, YEAR)\n\nError in select(., WS50M, YEAR): object 'wh50m' not found\n\nTidy_Newmexico$WS50M <- wh50m$WS50M\n\nError in eval(expr, envir, enclos): object 'wh50m' not found\n\nPRECTOTCORR <- Newmexico %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'PRECTOTCORR')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Newmexico' not found\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'PRECTOTCORR' not found\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  select(PRECTOTCORR, YEAR)\n\nError in select(., PRECTOTCORR, YEAR): object 'PRECTOTCORR' not found\n\nTidy_Newmexico$PRECTOTCORR <- PRECTOTCORR$PRECTOTCORR\n\nError in eval(expr, envir, enclos): object 'PRECTOTCORR' not found\n\nTidy_Newmexico <- Tidy_Newmexico %>%\n  dplyr::rename(Temperature = T2M) %>%\n  dplyr::rename(Humidity = RH2M) %>%\n  dplyr::rename(Wind_10_meter = WS10M) %>%\n  dplyr::rename(Surface_Pressure = PS) %>%\n  dplyr::rename(Wind_50_meter = WS50M) %>%\n  dplyr::rename(Precipitation = PRECTOTCORR) %>%\n  dplyr::rename(Annual = ANN) %>%\n  dplyr::rename(Latitude = LAT) %>%\n  dplyr::rename(Longitude = LON) %>%\n  dplyr::rename(Month = MONTH) %>%\n  dplyr::rename(Year = YEAR)\n\nError in dplyr::rename(., Temperature = T2M): object 'Tidy_Newmexico' not found\n\nTidy_Newmexico <- Tidy_Newmexico %>%\n  select(Year, Month, Latitude, Longitude, Temperature, Humidity, Precipitation, Surface_Pressure, Wind_10_meter, Wind_50_meter, Annual)\n\nError in select(., Year, Month, Latitude, Longitude, Temperature, Humidity, : object 'Tidy_Newmexico' not found\n\nsummary(Tidy_Newmexico)\n\nError in summary(Tidy_Newmexico): object 'Tidy_Newmexico' not found\n\nTidy_Newmexico <- Tidy_Newmexico %>%\n  slice(1:10)\n\nError in slice(., 1:10): object 'Tidy_Newmexico' not found\n\nkable(Tidy_Newmexico, digits = 2, align = \"ccccccc\", col.names = c(\"Year\", \"Month\", \"Latitude\", \"Longitude\", \"Temperature\", \"Humidity\", \"Precipitation\", \"Surface Pressure\", \"Wind 10 Meters\", \"Wind 50 Meters\", \"Annual\"), caption = \"Amherst Data\") %>%\n  kable_styling(font_size = 16)\n\nError in kable_styling(., font_size = 16): could not find function \"kable_styling\"\n\n\n\n\nNorth\n\nNorth <- North %>%\npivot_longer(\n  cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, DEC),\n  names_to = \"MONTH\",\n  values_to = \"Month_Average\",\n)\n\nError in pivot_longer(., cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, : object 'North' not found\n\nTidy_North <- North %>%\n  select(PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN) %>%\n  filter(PARAMETER == 'PS')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN): object 'North' not found\n\nTidy_North <- Tidy_North %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'Tidy_North' not found\n\nTidy_North <- Tidy_North %>%\n  select(PS, YEAR, MONTH, LAT, LON, ANN)\n\nError in select(., PS, YEAR, MONTH, LAT, LON, ANN): object 'Tidy_North' not found\n\nt2m <- North %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'T2M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'North' not found\n\nt2m <- t2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 't2m' not found\n\nt2m <- t2m %>%\n  select(T2M, YEAR)\n\nError in select(., T2M, YEAR): object 't2m' not found\n\nTidy_North$T2M <- t2m$T2M\n\nError in eval(expr, envir, enclos): object 't2m' not found\n\nrh2m <- North %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'RH2M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'North' not found\n\nrh2m <- rh2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'rh2m' not found\n\nrh2m <- rh2m %>%\n  select(RH2M, YEAR)\n\nError in select(., RH2M, YEAR): object 'rh2m' not found\n\nTidy_North$RH2M <- rh2m$RH2M\n\nError in eval(expr, envir, enclos): object 'rh2m' not found\n\nwh10m <- North %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS10M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'North' not found\n\nwh10m <- wh10m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'wh10m' not found\n\nwh10m <- wh10m %>%\n  select(WS10M, YEAR)\n\nError in select(., WS10M, YEAR): object 'wh10m' not found\n\nTidy_North$WS10M <- wh10m$WS10M\n\nError in eval(expr, envir, enclos): object 'wh10m' not found\n\nwh50m <- North %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS50M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'North' not found\n\nwh50m <- wh50m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'wh50m' not found\n\nwh50m <- wh50m %>%\n  select(WS50M, YEAR)\n\nError in select(., WS50M, YEAR): object 'wh50m' not found\n\nTidy_North$WS50M <- wh50m$WS50M\n\nError in eval(expr, envir, enclos): object 'wh50m' not found\n\nPRECTOTCORR <- North %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'PRECTOTCORR')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'North' not found\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'PRECTOTCORR' not found\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  select(PRECTOTCORR, YEAR)\n\nError in select(., PRECTOTCORR, YEAR): object 'PRECTOTCORR' not found\n\nTidy_North$PRECTOTCORR <- PRECTOTCORR$PRECTOTCORR\n\nError in eval(expr, envir, enclos): object 'PRECTOTCORR' not found\n\nTidy_North <- Tidy_North %>%\n  dplyr::rename(Temperature = T2M) %>%\n  dplyr::rename(Humidity = RH2M) %>%\n  dplyr::rename(Wind_10_meter = WS10M) %>%\n  dplyr::rename(Surface_Pressure = PS) %>%\n  dplyr::rename(Wind_50_meter = WS50M) %>%\n  dplyr::rename(Precipitation = PRECTOTCORR) %>%\n  dplyr::rename(Annual = ANN) %>%\n  dplyr::rename(Latitude = LAT) %>%\n  dplyr::rename(Longitude = LON) %>%\n  dplyr::rename(Month = MONTH) %>%\n  dplyr::rename(Year = YEAR)\n\nError in dplyr::rename(., Temperature = T2M): object 'Tidy_North' not found\n\nTidy_North <- Tidy_North %>%\n  select(Year, Month, Latitude, Longitude, Temperature, Humidity, Precipitation, Surface_Pressure, Wind_10_meter, Wind_50_meter, Annual)\n\nError in select(., Year, Month, Latitude, Longitude, Temperature, Humidity, : object 'Tidy_North' not found\n\nsummary(Tidy_North)\n\nError in summary(Tidy_North): object 'Tidy_North' not found\n\nTidy_North <- Tidy_North %>%\n  slice(1:10)\n\nError in slice(., 1:10): object 'Tidy_North' not found\n\nkable(Tidy_North, digits = 2, align = \"ccccccc\", col.names = c(\"Year\", \"Month\", \"Latitude\", \"Longitude\", \"Temperature\", \"Humidity\", \"Precipitation\", \"Surface Pressure\", \"Wind 10 Meters\", \"Wind 50 Meters\", \"Annual\"), caption = \"Amherst Data\") %>%\n  kable_styling(font_size = 16)\n\nError in kable_styling(., font_size = 16): could not find function \"kable_styling\"\n\n\n\n\nSouth\n\nSouth <- South %>%\npivot_longer(\n  cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, DEC),\n  names_to = \"MONTH\",\n  values_to = \"Month_Average\",\n)\n\nError in pivot_longer(., cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, : object 'South' not found\n\nTidy_South <- South %>%\n  select(PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN) %>%\n  filter(PARAMETER == 'PS')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN): object 'South' not found\n\nTidy_South <- Tidy_South %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'Tidy_South' not found\n\nTidy_South <- Tidy_South %>%\n  select(PS, YEAR, MONTH, LAT, LON, ANN)\n\nError in select(., PS, YEAR, MONTH, LAT, LON, ANN): object 'Tidy_South' not found\n\nt2m <- South %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'T2M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'South' not found\n\nt2m <- t2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 't2m' not found\n\nt2m <- t2m %>%\n  select(T2M, YEAR)\n\nError in select(., T2M, YEAR): object 't2m' not found\n\nTidy_South$T2M <- t2m$T2M\n\nError in eval(expr, envir, enclos): object 't2m' not found\n\nrh2m <- South %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'RH2M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'South' not found\n\nrh2m <- rh2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'rh2m' not found\n\nrh2m <- rh2m %>%\n  select(RH2M, YEAR)\n\nError in select(., RH2M, YEAR): object 'rh2m' not found\n\nTidy_South$RH2M <- rh2m$RH2M\n\nError in eval(expr, envir, enclos): object 'rh2m' not found\n\nwh10m <- South %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS10M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'South' not found\n\nwh10m <- wh10m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'wh10m' not found\n\nwh10m <- wh10m %>%\n  select(WS10M, YEAR)\n\nError in select(., WS10M, YEAR): object 'wh10m' not found\n\nTidy_South$WS10M <- wh10m$WS10M\n\nError in eval(expr, envir, enclos): object 'wh10m' not found\n\nwh50m <- South %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS50M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'South' not found\n\nwh50m <- wh50m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'wh50m' not found\n\nwh50m <- wh50m %>%\n  select(WS50M, YEAR)\n\nError in select(., WS50M, YEAR): object 'wh50m' not found\n\nTidy_South$WS50M <- wh50m$WS50M\n\nError in eval(expr, envir, enclos): object 'wh50m' not found\n\nPRECTOTCORR <- South %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'PRECTOTCORR')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'South' not found\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'PRECTOTCORR' not found\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  select(PRECTOTCORR, YEAR)\n\nError in select(., PRECTOTCORR, YEAR): object 'PRECTOTCORR' not found\n\nTidy_South$PRECTOTCORR <- PRECTOTCORR$PRECTOTCORR\n\nError in eval(expr, envir, enclos): object 'PRECTOTCORR' not found\n\nTidy_South <- Tidy_South %>%\n  dplyr::rename(Temperature = T2M) %>%\n  dplyr::rename(Humidity = RH2M) %>%\n  dplyr::rename(Wind_10_meter = WS10M) %>%\n  dplyr::rename(Surface_Pressure = PS) %>%\n  dplyr::rename(Wind_50_meter = WS50M) %>%\n  dplyr::rename(Precipitation = PRECTOTCORR) %>%\n  dplyr::rename(Annual = ANN) %>%\n  dplyr::rename(Latitude = LAT) %>%\n  dplyr::rename(Longitude = LON) %>%\n  dplyr::rename(Month = MONTH) %>%\n  dplyr::rename(Year = YEAR)\n\nError in dplyr::rename(., Temperature = T2M): object 'Tidy_South' not found\n\nTidy_South <- Tidy_South %>%\n  select(Year, Month, Latitude, Longitude, Temperature, Humidity, Precipitation, Surface_Pressure, Wind_10_meter, Wind_50_meter, Annual)\n\nError in select(., Year, Month, Latitude, Longitude, Temperature, Humidity, : object 'Tidy_South' not found\n\nsummary(Tidy_South)\n\nError in summary(Tidy_South): object 'Tidy_South' not found\n\nTidy_South <- Tidy_South %>%\n  slice(1:10)\n\nError in slice(., 1:10): object 'Tidy_South' not found\n\nkable(Tidy_South, digits = 2, align = \"ccccccc\", col.names = c(\"Year\", \"Month\", \"Latitude\", \"Longitude\", \"Temperature\", \"Humidity\", \"Precipitation\", \"Surface Pressure\", \"Wind 10 Meters\", \"Wind 50 Meters\", \"Annual\"), caption = \"Amherst Data\") %>%\n  kable_styling(font_size = 16)\n\nError in kable_styling(., font_size = 16): could not find function \"kable_styling\"\n\n\n\n\nSouth California\n\nSouthCali <- SouthCali %>%\npivot_longer(\n  cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, DEC),\n  names_to = \"MONTH\",\n  values_to = \"Month_Average\",\n)\n\nError in pivot_longer(., cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, : object 'SouthCali' not found\n\nTidy_SouthCali <- SouthCali %>%\n  select(PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN) %>%\n  filter(PARAMETER == 'PS')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN): object 'SouthCali' not found\n\nTidy_SouthCali <- Tidy_SouthCali %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'Tidy_SouthCali' not found\n\nTidy_SouthCali <- Tidy_SouthCali %>%\n  select(PS, YEAR, MONTH, LAT, LON, ANN)\n\nError in select(., PS, YEAR, MONTH, LAT, LON, ANN): object 'Tidy_SouthCali' not found\n\nt2m <- SouthCali %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'T2M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'SouthCali' not found\n\nt2m <- t2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 't2m' not found\n\nt2m <- t2m %>%\n  select(T2M, YEAR)\n\nError in select(., T2M, YEAR): object 't2m' not found\n\nTidy_SouthCali$T2M <- t2m$T2M\n\nError in eval(expr, envir, enclos): object 't2m' not found\n\nrh2m <- SouthCali %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'RH2M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'SouthCali' not found\n\nrh2m <- rh2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'rh2m' not found\n\nrh2m <- rh2m %>%\n  select(RH2M, YEAR)\n\nError in select(., RH2M, YEAR): object 'rh2m' not found\n\nTidy_SouthCali$RH2M <- rh2m$RH2M\n\nError in eval(expr, envir, enclos): object 'rh2m' not found\n\nwh10m <- SouthCali %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS10M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'SouthCali' not found\n\nwh10m <- wh10m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'wh10m' not found\n\nwh10m <- wh10m %>%\n  select(WS10M, YEAR)\n\nError in select(., WS10M, YEAR): object 'wh10m' not found\n\nTidy_SouthCali$WS10M <- wh10m$WS10M\n\nError in eval(expr, envir, enclos): object 'wh10m' not found\n\nwh50m <- SouthCali %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS50M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'SouthCali' not found\n\nwh50m <- wh50m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'wh50m' not found\n\nwh50m <- wh50m %>%\n  select(WS50M, YEAR)\n\nError in select(., WS50M, YEAR): object 'wh50m' not found\n\nTidy_SouthCali$WS50M <- wh50m$WS50M\n\nError in eval(expr, envir, enclos): object 'wh50m' not found\n\nPRECTOTCORR <- SouthCali %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'PRECTOTCORR')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'SouthCali' not found\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'PRECTOTCORR' not found\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  select(PRECTOTCORR, YEAR)\n\nError in select(., PRECTOTCORR, YEAR): object 'PRECTOTCORR' not found\n\nTidy_SouthCali$PRECTOTCORR <- PRECTOTCORR$PRECTOTCORR\n\nError in eval(expr, envir, enclos): object 'PRECTOTCORR' not found\n\nTidy_SouthCali <- Tidy_SouthCali %>%\n  dplyr::rename(Temperature = T2M) %>%\n  dplyr::rename(Humidity = RH2M) %>%\n  dplyr::rename(Wind_10_meter = WS10M) %>%\n  dplyr::rename(Surface_Pressure = PS) %>%\n  dplyr::rename(Wind_50_meter = WS50M) %>%\n  dplyr::rename(Precipitation = PRECTOTCORR) %>%\n  dplyr::rename(Annual = ANN) %>%\n  dplyr::rename(Latitude = LAT) %>%\n  dplyr::rename(Longitude = LON) %>%\n  dplyr::rename(Month = MONTH) %>%\n  dplyr::rename(Year = YEAR)\n\nError in dplyr::rename(., Temperature = T2M): object 'Tidy_SouthCali' not found\n\nTidy_SouthCali <- Tidy_SouthCali %>%\n  select(Year, Month, Latitude, Longitude, Temperature, Humidity, Precipitation, Surface_Pressure, Wind_10_meter, Wind_50_meter, Annual)\n\nError in select(., Year, Month, Latitude, Longitude, Temperature, Humidity, : object 'Tidy_SouthCali' not found\n\nsummary(Tidy_SouthCali)\n\nError in summary(Tidy_SouthCali): object 'Tidy_SouthCali' not found\n\nTidy_SouthCali <- Tidy_SouthCali %>%\n  slice(1:10)\n\nError in slice(., 1:10): object 'Tidy_SouthCali' not found\n\nkable(Tidy_SouthCali, digits = 2, align = \"ccccccc\", col.names = c(\"Year\", \"Month\", \"Latitude\", \"Longitude\", \"Temperature\", \"Humidity\", \"Precipitation\", \"Surface Pressure\", \"Wind 10 Meters\", \"Wind 50 Meters\", \"Annual\"), caption = \"Amherst Data\") %>%\n  kable_styling(font_size = 16)\n\nError in kable_styling(., font_size = 16): could not find function \"kable_styling\"\n\n\n\n\nTexas\n\nTexas <- Texas %>%\npivot_longer(\n  cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, DEC),\n  names_to = \"MONTH\",\n  values_to = \"Month_Average\",\n)\n\nError in pivot_longer(., cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, : object 'Texas' not found\n\nTidy_Texas <- Texas %>%\n  select(PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN) %>%\n  filter(PARAMETER == 'PS')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN): object 'Texas' not found\n\nTidy_Texas <- Tidy_Texas %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'Tidy_Texas' not found\n\nTidy_Texas <- Tidy_Texas %>%\n  select(PS, YEAR, MONTH, LAT, LON, ANN)\n\nError in select(., PS, YEAR, MONTH, LAT, LON, ANN): object 'Tidy_Texas' not found\n\nt2m <- Texas %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'T2M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Texas' not found\n\nt2m <- t2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 't2m' not found\n\nt2m <- t2m %>%\n  select(T2M, YEAR)\n\nError in select(., T2M, YEAR): object 't2m' not found\n\nTidy_Texas$T2M <- t2m$T2M\n\nError in eval(expr, envir, enclos): object 't2m' not found\n\nrh2m <- Texas %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'RH2M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Texas' not found\n\nrh2m <- rh2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'rh2m' not found\n\nrh2m <- rh2m %>%\n  select(RH2M, YEAR)\n\nError in select(., RH2M, YEAR): object 'rh2m' not found\n\nTidy_Texas$RH2M <- rh2m$RH2M\n\nError in eval(expr, envir, enclos): object 'rh2m' not found\n\nwh10m <- Texas %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS10M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Texas' not found\n\nwh10m <- wh10m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'wh10m' not found\n\nwh10m <- wh10m %>%\n  select(WS10M, YEAR)\n\nError in select(., WS10M, YEAR): object 'wh10m' not found\n\nTidy_Texas$WS10M <- wh10m$WS10M\n\nError in eval(expr, envir, enclos): object 'wh10m' not found\n\nwh50m <- Texas %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS50M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Texas' not found\n\nwh50m <- wh50m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'wh50m' not found\n\nwh50m <- wh50m %>%\n  select(WS50M, YEAR)\n\nError in select(., WS50M, YEAR): object 'wh50m' not found\n\nTidy_Texas$WS50M <- wh50m$WS50M\n\nError in eval(expr, envir, enclos): object 'wh50m' not found\n\nPRECTOTCORR <- Texas %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'PRECTOTCORR')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Texas' not found\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'PRECTOTCORR' not found\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  select(PRECTOTCORR, YEAR)\n\nError in select(., PRECTOTCORR, YEAR): object 'PRECTOTCORR' not found\n\nTidy_Texas$PRECTOTCORR <- PRECTOTCORR$PRECTOTCORR\n\nError in eval(expr, envir, enclos): object 'PRECTOTCORR' not found\n\nTidy_Texas <- Tidy_Texas %>%\n  dplyr::rename(Temperature = T2M) %>%\n  dplyr::rename(Humidity = RH2M) %>%\n  dplyr::rename(Wind_10_meter = WS10M) %>%\n  dplyr::rename(Surface_Pressure = PS) %>%\n  dplyr::rename(Wind_50_meter = WS50M) %>%\n  dplyr::rename(Precipitation = PRECTOTCORR) %>%\n  dplyr::rename(Annual = ANN) %>%\n  dplyr::rename(Latitude = LAT) %>%\n  dplyr::rename(Longitude = LON) %>%\n  dplyr::rename(Month = MONTH) %>%\n  dplyr::rename(Year = YEAR)\n\nError in dplyr::rename(., Temperature = T2M): object 'Tidy_Texas' not found\n\nTidy_Texas <- Tidy_Texas %>%\n  select(Year, Month, Latitude, Longitude, Temperature, Humidity, Precipitation, Surface_Pressure, Wind_10_meter, Wind_50_meter, Annual)\n\nError in select(., Year, Month, Latitude, Longitude, Temperature, Humidity, : object 'Tidy_Texas' not found\n\nsummary(Tidy_Texas)\n\nError in summary(Tidy_Texas): object 'Tidy_Texas' not found\n\nTidy_Texas <- Tidy_Texas %>%\n  slice(1:10)\n\nError in slice(., 1:10): object 'Tidy_Texas' not found\n\nkable(Tidy_Texas, digits = 2, align = \"ccccccc\", col.names = c(\"Year\", \"Month\", \"Latitude\", \"Longitude\", \"Temperature\", \"Humidity\", \"Precipitation\", \"Surface Pressure\", \"Wind 10 Meters\", \"Wind 50 Meters\", \"Annual\"), caption = \"Amherst Data\") %>%\n  kable_styling(font_size = 16)\n\nError in kable_styling(., font_size = 16): could not find function \"kable_styling\"\n\n\n\n\nWashington\n\nWashington <- Washington %>%\npivot_longer(\n  cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, DEC),\n  names_to = \"MONTH\",\n  values_to = \"Month_Average\",\n)\n\nError in pivot_longer(., cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, : object 'Washington' not found\n\nTidy_Washington <- Washington %>%\n  select(PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN) %>%\n  filter(PARAMETER == 'PS')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN): object 'Washington' not found\n\nTidy_Washington <- Tidy_Washington %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'Tidy_Washington' not found\n\nTidy_Washington <- Tidy_Washington %>%\n  select(PS, YEAR, MONTH, LAT, LON, ANN)\n\nError in select(., PS, YEAR, MONTH, LAT, LON, ANN): object 'Tidy_Washington' not found\n\nt2m <- Washington %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'T2M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Washington' not found\n\nt2m <- t2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 't2m' not found\n\nt2m <- t2m %>%\n  select(T2M, YEAR)\n\nError in select(., T2M, YEAR): object 't2m' not found\n\nTidy_Washington$T2M <- t2m$T2M\n\nError in eval(expr, envir, enclos): object 't2m' not found\n\nrh2m <- Washington %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'RH2M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Washington' not found\n\nrh2m <- rh2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'rh2m' not found\n\nrh2m <- rh2m %>%\n  select(RH2M, YEAR)\n\nError in select(., RH2M, YEAR): object 'rh2m' not found\n\nTidy_Washington$RH2M <- rh2m$RH2M\n\nError in eval(expr, envir, enclos): object 'rh2m' not found\n\nwh10m <- Washington %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS10M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Washington' not found\n\nwh10m <- wh10m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'wh10m' not found\n\nwh10m <- wh10m %>%\n  select(WS10M, YEAR)\n\nError in select(., WS10M, YEAR): object 'wh10m' not found\n\nTidy_Washington$WS10M <- wh10m$WS10M\n\nError in eval(expr, envir, enclos): object 'wh10m' not found\n\nwh50m <- Washington %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS50M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Washington' not found\n\nwh50m <- wh50m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'wh50m' not found\n\nwh50m <- wh50m %>%\n  select(WS50M, YEAR)\n\nError in select(., WS50M, YEAR): object 'wh50m' not found\n\nTidy_Washington$WS50M <- wh50m$WS50M\n\nError in eval(expr, envir, enclos): object 'wh50m' not found\n\nPRECTOTCORR <- Washington %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'PRECTOTCORR')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'Washington' not found\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'PRECTOTCORR' not found\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  select(PRECTOTCORR, YEAR)\n\nError in select(., PRECTOTCORR, YEAR): object 'PRECTOTCORR' not found\n\nTidy_Washington$PRECTOTCORR <- PRECTOTCORR$PRECTOTCORR\n\nError in eval(expr, envir, enclos): object 'PRECTOTCORR' not found\n\nTidy_Washington <- Tidy_Washington %>%\n  dplyr::rename(Temperature = T2M) %>%\n  dplyr::rename(Humidity = RH2M) %>%\n  dplyr::rename(Wind_10_meter = WS10M) %>%\n  dplyr::rename(Surface_Pressure = PS) %>%\n  dplyr::rename(Wind_50_meter = WS50M) %>%\n  dplyr::rename(Precipitation = PRECTOTCORR) %>%\n  dplyr::rename(Annual = ANN) %>%\n  dplyr::rename(Latitude = LAT) %>%\n  dplyr::rename(Longitude = LON) %>%\n  dplyr::rename(Month = MONTH) %>%\n  dplyr::rename(Year = YEAR)\n\nError in dplyr::rename(., Temperature = T2M): object 'Tidy_Washington' not found\n\nTidy_Washington <- Tidy_Washington %>%\n  select(Year, Month, Latitude, Longitude, Temperature, Humidity, Precipitation, Surface_Pressure, Wind_10_meter, Wind_50_meter, Annual)\n\nError in select(., Year, Month, Latitude, Longitude, Temperature, Humidity, : object 'Tidy_Washington' not found\n\nsummary(Tidy_Washington)\n\nError in summary(Tidy_Washington): object 'Tidy_Washington' not found\n\nTidy_Washington <- Tidy_Washington %>%\n  slice(1:10)\n\nError in slice(., 1:10): object 'Tidy_Washington' not found\n\nkable(Tidy_Washington, digits = 2, align = \"ccccccc\", col.names = c(\"Year\", \"Month\", \"Latitude\", \"Longitude\", \"Temperature\", \"Humidity\", \"Precipitation\", \"Surface Pressure\", \"Wind 10 Meters\", \"Wind 50 Meters\", \"Annual\"), caption = \"Amherst Data\") %>%\n  kable_styling(font_size = 16)\n\nError in kable_styling(., font_size = 16): could not find function \"kable_styling\"\n\n\n\n\nWest Virgina\n\nWestV <- WestV %>%\npivot_longer(\n  cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, DEC),\n  names_to = \"MONTH\",\n  values_to = \"Month_Average\",\n)\n\nError in pivot_longer(., cols = c(NOV, JAN, FEB, MAR, APR, MAY, JUN, JUL, : object 'WestV' not found\n\nTidy_WestV <- WestV %>%\n  select(PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN) %>%\n  filter(PARAMETER == 'PS')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT, LON, MONTH, ANN): object 'WestV' not found\n\nTidy_WestV <- Tidy_WestV %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'Tidy_WestV' not found\n\nTidy_WestV <- Tidy_WestV %>%\n  select(PS, YEAR, MONTH, LAT, LON, ANN)\n\nError in select(., PS, YEAR, MONTH, LAT, LON, ANN): object 'Tidy_WestV' not found\n\nt2m <- WestV %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'T2M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'WestV' not found\n\nt2m <- t2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 't2m' not found\n\nt2m <- t2m %>%\n  select(T2M, YEAR)\n\nError in select(., T2M, YEAR): object 't2m' not found\n\nTidy_WestV$T2M <- t2m$T2M\n\nError in eval(expr, envir, enclos): object 't2m' not found\n\nrh2m <- WestV %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'RH2M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'WestV' not found\n\nrh2m <- rh2m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'rh2m' not found\n\nrh2m <- rh2m %>%\n  select(RH2M, YEAR)\n\nError in select(., RH2M, YEAR): object 'rh2m' not found\n\nTidy_WestV$RH2M <- rh2m$RH2M\n\nError in eval(expr, envir, enclos): object 'rh2m' not found\n\nwh10m <- WestV %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS10M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'WestV' not found\n\nwh10m <- wh10m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'wh10m' not found\n\nwh10m <- wh10m %>%\n  select(WS10M, YEAR)\n\nError in select(., WS10M, YEAR): object 'wh10m' not found\n\nTidy_WestV$WS10M <- wh10m$WS10M\n\nError in eval(expr, envir, enclos): object 'wh10m' not found\n\nwh50m <- WestV %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'WS50M')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'WestV' not found\n\nwh50m <- wh50m %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'wh50m' not found\n\nwh50m <- wh50m %>%\n  select(WS50M, YEAR)\n\nError in select(., WS50M, YEAR): object 'wh50m' not found\n\nTidy_WestV$WS50M <- wh50m$WS50M\n\nError in eval(expr, envir, enclos): object 'wh50m' not found\n\nPRECTOTCORR <- WestV %>%\n  select(PARAMETER, Month_Average, YEAR, LAT) %>%\n  filter(PARAMETER == 'PRECTOTCORR')\n\nError in select(., PARAMETER, Month_Average, YEAR, LAT): object 'WestV' not found\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  group_by(PARAMETER) %>%\n  mutate(row = row_number()) %>%\n  tidyr::pivot_wider(names_from = PARAMETER, values_from = Month_Average) %>%\n  select(-row)\n\nError in group_by(., PARAMETER): object 'PRECTOTCORR' not found\n\nPRECTOTCORR <- PRECTOTCORR %>%\n  select(PRECTOTCORR, YEAR)\n\nError in select(., PRECTOTCORR, YEAR): object 'PRECTOTCORR' not found\n\nTidy_WestV$PRECTOTCORR <- PRECTOTCORR$PRECTOTCORR\n\nError in eval(expr, envir, enclos): object 'PRECTOTCORR' not found\n\nTidy_WestV <- Tidy_WestV %>%\n  dplyr::rename(Temperature = T2M) %>%\n  dplyr::rename(Humidity = RH2M) %>%\n  dplyr::rename(Wind_10_meter = WS10M) %>%\n  dplyr::rename(Surface_Pressure = PS) %>%\n  dplyr::rename(Wind_50_meter = WS50M) %>%\n  dplyr::rename(Precipitation = PRECTOTCORR) %>%\n  dplyr::rename(Annual = ANN) %>%\n  dplyr::rename(Latitude = LAT) %>%\n  dplyr::rename(Longitude = LON) %>%\n  dplyr::rename(Month = MONTH) %>%\n  dplyr::rename(Year = YEAR)\n\nError in dplyr::rename(., Temperature = T2M): object 'Tidy_WestV' not found\n\nTidy_WestV <- Tidy_WestV %>%\n  select(Year, Month, Latitude, Longitude, Temperature, Humidity, Precipitation, Surface_Pressure, Wind_10_meter, Wind_50_meter, Annual)\n\nError in select(., Year, Month, Latitude, Longitude, Temperature, Humidity, : object 'Tidy_WestV' not found\n\nsummary(Tidy_WestV)\n\nError in summary(Tidy_WestV): object 'Tidy_WestV' not found\n\nTidy_WestV <- Tidy_WestV %>%\n  slice(1:10)\n\nError in slice(., 1:10): object 'Tidy_WestV' not found\n\nkable(Tidy_WestV, digits = 2, align = \"ccccccc\", col.names = c(\"Year\", \"Month\", \"Latitude\", \"Longitude\", \"Temperature\", \"Humidity\", \"Precipitation\", \"Surface Pressure\", \"Wind 10 Meters\", \"Wind 50 Meters\", \"Annual\"), caption = \"Amherst Data\") %>%\n  kable_styling(font_size = 16)\n\nError in kable_styling(., font_size = 16): could not find function \"kable_styling\"\n\n\n\n\nState Economy data\nThe economic data is pulled from the Bureau of Economic Analysis (Analysis, n.d.). This data is the ins, outs, and the difference between the former two in income by state. The data ranges from 1990 to 2020 and covers every state in the US.\n\n# Reading in economic data\n\nEconomy <- read.csv(\"C:/Users/ethan/Documents/Github Class/603_Fall_2022_homework/Economy.csv\")\n\nWarning in file(file, \"rt\"): cannot open file 'C:/Users/ethan/Documents/Github\nClass/603_Fall_2022_homework/Economy.csv': No such file or directory\n\n\nError in file(file, \"rt\"): cannot open the connection\n\n# Renaming the columns to remove the X\nEconomy <- Economy %>%\n  dplyr::rename('1990' = X1990) %>%\n  dplyr::rename('1991' = X1991) %>%\n  dplyr::rename('1992' = X1992) %>%\n  dplyr::rename('1993' = X1993) %>%\n  dplyr::rename('1994' = X1994) %>%\n  dplyr::rename('1995' = X1995) %>%\n  dplyr::rename('1996' = X1996) %>%\n  dplyr::rename('1997' = X1997) %>%\n  dplyr::rename('1998' = X1998) %>%\n  dplyr::rename('1999' = X1999) %>%\n  dplyr::rename('2000' = X2000) %>%\n  dplyr::rename('2001' = X2001) %>%\n  dplyr::rename('2002' = X2002) %>%\n  dplyr::rename('2003' = X2003) %>%\n  dplyr::rename('2004' = X2004) %>%\n  dplyr::rename('2005' = X2005) %>%\n  dplyr::rename('2006' = X2006) %>%\n  dplyr::rename('2007' = X2007) %>%\n  dplyr::rename('2008' = X2008) %>%\n  dplyr::rename('2009' = X2009) %>%\n  dplyr::rename('2010' = X2010) %>%\n  dplyr::rename('2011' = X2011) %>%\n  dplyr::rename('2012' = X2012) %>%\n  dplyr::rename('2013' = X2013) %>%\n  dplyr::rename('2014' = X2014) %>%\n  dplyr::rename('2015' = X2015) %>%\n  dplyr::rename('2016' = X2016) %>%\n  dplyr::rename('2017' = X2017) %>%\n  dplyr::rename('2018' = X2018) %>%\n  dplyr::rename('2019' = X2019) %>%\n  dplyr::rename('2020' = X2020) \n\nError in dplyr::rename(., `1990` = X1990): object 'Economy' not found\n\n# Pivoting to combine all the years into one column\nEconomy <- Economy %>%\npivot_longer(\n  cols = c('1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020'),\n  names_to = \"Year\",\n  values_to = \"Yearly_Fianace\",\n)\n\nError in pivot_longer(., cols = c(\"1990\", \"1991\", \"1992\", \"1993\", \"1994\", : object 'Economy' not found\n\n## Change from char to numeric\nEconomy$Year <- as.numeric(Economy$Year)\n\nError in eval(expr, envir, enclos): object 'Economy' not found\n\n# Changing the finance column to be in millions\nEconomy <- Economy %>%\n  mutate(Year_Money_Millions = Yearly_Fianace/1000)\n\nError in mutate(., Year_Money_Millions = Yearly_Fianace/1000): object 'Economy' not found\n\nsummary(Economy)\n\nError in summary(Economy): object 'Economy' not found"
  },
  {
    "objectID": "posts/HW1answers_DonnySnyder.html",
    "href": "posts/HW1answers_DonnySnyder.html",
    "title": "Homework 1 - Donny Snyder",
    "section": "",
    "text": "First, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\ndf <- read_excel(\"_data/LungCapData.xls\")\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(df$LungCap)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\n##b\n\n\nCode\nlibrary(ggplot2)\nggplot(df, aes(x = Gender, y = LungCap)) + geom_boxplot()\n\n\n\n\n\nThe probability distribution suggests that the lung capacity of males tends to be higher.\n##c\n\n\nCode\naggregate(data = df, LungCap~Smoke, mean)\n\n\n  Smoke  LungCap\n1    no 7.770188\n2   yes 8.645455\n\n\nThe mean lung capacity of smokers vs nonsmokers appears to be higher for smokers. This doesn’t really make sense because I’ve been taught to think smokers tend to have reduced lung capacity.\n##d and e\n\n\nCode\nx=1\ndf$AgeGroup <- rep(c(\"NA\"),times=725)\nwhile(x <= 725){\n  if(df$Age[x] <= 13){\n    df$AgeGroup[x] = \"less than or equal to 13\"\n  }\n  else if((df$Age[x] >= 14)&&(df$Age[x] <= 15)){\n    df$AgeGroup[x] = \"14 to 15\"\n  }\n  else if((df$Age[x] >= 16)&&(df$Age[x] <= 17)){\n    df$AgeGroup[x] = \"16 to 17\"\n  }\n  else if(df$Age[x] >= 18){\n    df$AgeGroup[x] = \"greater than 18\"\n  }\nx = x + 1\n}\naggregate(data = df, LungCap~AgeGroup+Smoke, mean)\n\n\n                  AgeGroup Smoke   LungCap\n1                 14 to 15    no  9.138810\n2                 16 to 17    no 10.469805\n3          greater than 18    no 11.068846\n4 less than or equal to 13    no  6.358746\n5                 14 to 15   yes  8.391667\n6                 16 to 17   yes  9.383750\n7          greater than 18   yes 10.513333\n8 less than or equal to 13   yes  7.201852\n\n\nCode\naggregate(data = df,LungCap~AgeGroup+Smoke,length)\n\n\n                  AgeGroup Smoke LungCap\n1                 14 to 15    no     105\n2                 16 to 17    no      77\n3          greater than 18    no      65\n4 less than or equal to 13    no     401\n5                 14 to 15   yes      15\n6                 16 to 17   yes      20\n7          greater than 18   yes      15\n8 less than or equal to 13   yes      27\n\n\nCode\naggregate(data = df,Age~Smoke,mean)\n\n\n  Smoke      Age\n1    no 12.03549\n2   yes 14.77922\n\n\nIt seems like people tend to have a lung capacity that increases with age. However, nonsmokers have a higher lung capacity for each age break down besides less than or equal to 13. It seems like smokers just might tend to be older. I confirmed this by looking at the length and mean ages per group, where you can see a majority of smokers are older, whereas non smokers tend to be younger. The mean age for smokers also tends to be older.\n##f\n\n\nCode\ncor(x= df$LungCap, y = df$Age)\n\n\n[1] 0.8196749\n\n\nCode\ncov(x= df$LungCap, y = df$Age)\n\n\n[1] 8.738289\n\n\nLung capacity appears to be quite correlated with age. This means that Lung capacity tends to go up as age goes up, and vice versa. This is confirmed also by the covariance.\n#Question 2\n##a\n\n\nCode\nprint((160/810) * 100)\n\n\n[1] 19.75309\n\n\nThe probability is 19.75309% that a randomly selected inmate has exactly 2 prior convictions.\n##b\n\n\nCode\nprint(((434+128)/810) * 100)\n\n\n[1] 69.38272\n\n\nThe probability is 69.38272% that a randomly selected inmate has fewer than 2 prior convictions.\n##c\n\n\nCode\nprint(((160+434+128)/810) * 100)\n\n\n[1] 89.1358\n\n\nThe probability is 89.1358% that a randomly selected inmate has 2 or fewer prior convictions.\n##d\n\n\nCode\nprint(((64+24)/810) * 100)\n\n\n[1] 10.8642\n\n\nThe probability is 10.8642% that a randomly selected inmate has more than 2 prior convictions.\n##e\n\n\nCode\nnewDf <- NA\nnewDf[1:128] <- 0\nnewDf[129:562] <- 1\nnewDf[563:722] <- 2\nnewDf[723:786] <- 3\nnewDf[787:810] <- 4\nnewDf <- as.data.frame(newDf)\nmean(newDf$newDf)\n\n\n[1] 1.28642\n\n\nThe expected value, known as the “mean” when it deals in data that are not probability distributions, is 1.28642. Because I created a vector here, I took the mean, though I also could have calculated the expected value by multiplying the probabilities by the numbers. They are both the same value in this case.\n##f\n\n\nCode\nsd(newDf$newDf)\n\n\n[1] 0.9259016\n\n\nCode\nvar(newDf$newDf)\n\n\n[1] 0.8572937\n\n\nThe variance of prior convictions is 0.8572937, the standard deviation of prior convictions is 0.9259016."
  },
  {
    "objectID": "posts/Final_Project_1.html",
    "href": "posts/Final_Project_1.html",
    "title": "Final_Project_1",
    "section": "",
    "text": "Research Question : examining the relationship between the maximum heart rate one can achieve during exercise and the likelihood of developing heart disease. Using multiple logistic regression, examining handle the confounding effects of age and gender.\nHypothesis Testing : Is there any statistical difference between the gender and age in terms of heart attack prediction.\n#Loading Dataset\n\n\nCode\nlibrary(readr)\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ dplyr   1.0.10\n✔ tibble  3.1.8      ✔ stringr 1.4.1 \n✔ tidyr   1.2.1      ✔ forcats 0.5.2 \n✔ purrr   0.3.5      \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nheart_cleveland_upload <- read_csv(\"heart_cleveland_upload.csv\")\n\n\nRows: 297 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (14): age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpea...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nhead(heart_cleveland_upload)\n\n\n\n\n  \n\n\n\n\n\nCode\ndim(heart_cleveland_upload)\n\n\n[1] 297  14\n\n\nData set contains 297 Columns and 14 columns\n\n\nCode\ncolnames(heart_cleveland_upload)\n\n\n [1] \"age\"       \"sex\"       \"cp\"        \"trestbps\"  \"chol\"      \"fbs\"      \n [7] \"restecg\"   \"thalach\"   \"exang\"     \"oldpeak\"   \"slope\"     \"ca\"       \n[13] \"thal\"      \"condition\"\n\n\nhere are 13 attributes\nage: age in years sex: sex (1 = male; 0 = female) cp: chest pain type – Value 0: typical angina – Value 1: atypical angina – Value 2: non-anginal pain – Value 3: asymptomatic trestbps: resting blood pressure (in mm Hg on admission to the hospital) chol: serum cholestoral in mg/dl fbs: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false) restecg: resting electrocardiographic results – Value 0: normal – Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV) – Value 2: showing probable or definite left ventricular hypertrophy by Estes’ criteria thalach: maximum heart rate achieved exang: exercise induced angina (1 = yes; 0 = no) oldpeak = ST depression induced by exercise relative to rest slope: the slope of the peak exercise ST segment – Value 0: upsloping – Value 1: flat – Value 2: downsloping ca: number of major vessels (0-3) colored by flourosopy thal: 0 = normal; 1 = fixed defect; 2 = reversable defect and the label condition: 0 = no disease, 1 = disease\n\nDescriptive statistics\n\n\nCode\nsummary(heart_cleveland_upload)\n\n\n      age             sex               cp           trestbps    \n Min.   :29.00   Min.   :0.0000   Min.   :0.000   Min.   : 94.0  \n 1st Qu.:48.00   1st Qu.:0.0000   1st Qu.:2.000   1st Qu.:120.0  \n Median :56.00   Median :1.0000   Median :2.000   Median :130.0  \n Mean   :54.54   Mean   :0.6768   Mean   :2.158   Mean   :131.7  \n 3rd Qu.:61.00   3rd Qu.:1.0000   3rd Qu.:3.000   3rd Qu.:140.0  \n Max.   :77.00   Max.   :1.0000   Max.   :3.000   Max.   :200.0  \n      chol            fbs            restecg          thalach     \n Min.   :126.0   Min.   :0.0000   Min.   :0.0000   Min.   : 71.0  \n 1st Qu.:211.0   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:133.0  \n Median :243.0   Median :0.0000   Median :1.0000   Median :153.0  \n Mean   :247.4   Mean   :0.1448   Mean   :0.9966   Mean   :149.6  \n 3rd Qu.:276.0   3rd Qu.:0.0000   3rd Qu.:2.0000   3rd Qu.:166.0  \n Max.   :564.0   Max.   :1.0000   Max.   :2.0000   Max.   :202.0  \n     exang           oldpeak          slope              ca        \n Min.   :0.0000   Min.   :0.000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.800   Median :1.0000   Median :0.0000  \n Mean   :0.3266   Mean   :1.056   Mean   :0.6027   Mean   :0.6768  \n 3rd Qu.:1.0000   3rd Qu.:1.600   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :6.200   Max.   :2.0000   Max.   :3.0000  \n      thal         condition     \n Min.   :0.000   Min.   :0.0000  \n 1st Qu.:0.000   1st Qu.:0.0000  \n Median :0.000   Median :0.0000  \n Mean   :0.835   Mean   :0.4613  \n 3rd Qu.:2.000   3rd Qu.:1.0000  \n Max.   :2.000   Max.   :1.0000  \n\n\n\n\nCode\nglimpse(heart_cleveland_upload)\n\n\nRows: 297\nColumns: 14\n$ age       <dbl> 69, 69, 66, 65, 64, 64, 63, 61, 60, 59, 59, 59, 59, 58, 56, …\n$ sex       <dbl> 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, …\n$ cp        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ trestbps  <dbl> 160, 140, 150, 138, 110, 170, 145, 134, 150, 178, 170, 160, …\n$ chol      <dbl> 234, 239, 226, 282, 211, 227, 233, 234, 240, 270, 288, 273, …\n$ fbs       <dbl> 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, …\n$ restecg   <dbl> 2, 0, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 0, 2, …\n$ thalach   <dbl> 131, 151, 114, 174, 144, 155, 150, 145, 171, 145, 159, 125, …\n$ exang     <dbl> 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ oldpeak   <dbl> 0.1, 1.8, 2.6, 1.4, 1.8, 0.6, 2.3, 2.6, 0.9, 4.2, 0.2, 0.0, …\n$ slope     <dbl> 1, 0, 2, 1, 1, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, …\n$ ca        <dbl> 1, 2, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 2, …\n$ thal      <dbl> 0, 0, 0, 0, 0, 2, 1, 0, 0, 2, 2, 0, 0, 0, 2, 1, 2, 0, 2, 0, …\n$ condition <dbl> 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, …"
  },
  {
    "objectID": "posts/Final Project Proposal.html",
    "href": "posts/Final Project Proposal.html",
    "title": "Final Project Proposal",
    "section": "",
    "text": "The research questions that I am looking to investigate involve the factors that increase university students’ GPA. These include the following:\n1) Does classroom engagement (i.e., taking notes, attending class, listening) result in a higher GPA in university students?\n2) Does reported studying (i.e., weekly study hours) result in a higher GPA in university students?\n3) Does collaboration between students (i.e., studying together, positive class discussions) result in a higher GPA in university students?\n\n\n\n\n\nFor the first research question, it is reasonable to hypothesize that classroom engagement will have a positive effect on students’ academic achievement. Previous research supports this hypothesis. For example, one study found that classroom engagement, as well as other related factors such as time management and autonomous motivation, are predictors of academic achievement (Fokkens-Bruinsma, et al., 2021). Another study found that attendance in higher education is a small, but still statistically significant, predictor of academic performance (Büchele, 2021). In this study, classroom engagement will be defined as “taking notes, attendance, and frequency of listening.” These measures will be reported by university students via survey.\n\n\n\nIn regards to the second research question, it is hypothesized that students who study more will have a higher GPA. There are many previous studies that support this claim. For instance, one study found that university freshmen who studied more than eight hours a week saw an average increase in GPA of 0.580 (Nelson, 2003). Research has also found that increasing study time leads to an increased GPA (Thibodeaux, et al., 2017). In this study, hours spent studying will be measured through students’ estimated range of hours studied, reported via survey.\n\n\n\nIn response to the third research question, it is hypothesized that student collaboration will have a positive effect on student GPA. There is some research literature that supports this statement. One study found that students who study with their peers achieve significantly higher homework scores (Vargas, et al., 2018). Another study found that university students who had a strong social network and exhibited collaborative behaviors tended to achieve higher grades (Ellis & Han, 2021). Effective student collaboration can also occur during class time, such as through small group discussions. Research has found that students who participate in small group discussions demonstrate an increase in resilience, which has shown to improve academic performance (Torrento-estimo, et al, 2012). In this study, student collaboration will be measured through students’ reported time spent studying with peers, and impact that their class discussions have.\n\n\n\n\nThe dataset used is one retrieved from Kaggle using the link here. The dataset is named, “Higher Education Student Performance Evaluation.” This dataset was used in a self-report survey study conducted by Yılmaz and Sekeroglu (2019).\n\n\nCode\nstudentsurvey <- read.csv(\"student_prediction.csv\")\n\n\nWarning in file(file, \"rt\"): cannot open file 'student_prediction.csv': No such\nfile or directory\n\n\nError in file(file, \"rt\"): cannot open the connection\n\n\nCode\nsummary(studentsurvey)\n\n\nError in summary(studentsurvey): object 'studentsurvey' not found\n\n\nCode\nlibrary(ggplot2)\n\n\nTo begin, it is important to examine the demographic variables through descriptive statistics to observe the sample.\n\n\nTo start, students’ reported gender (1 = female and 2 = male) is plotted in the bar graph below.\n\n\nCode\nggplot(studentsurvey, aes(x = GENDER)) + geom_bar()\n\n\nError in ggplot(studentsurvey, aes(x = GENDER)): object 'studentsurvey' not found\n\n\nIn this sample, there are more males than females.\n\n\n\nThe bar graph below plots the students’ reported ages at the time of the survey (1 = 18-21, 2 = 22-25, 3 = 26 or above).\n\n\nCode\nggplot(studentsurvey, aes(x = AGE)) + geom_bar()\n\n\nError in ggplot(studentsurvey, aes(x = AGE)): object 'studentsurvey' not found\n\n\nThe majority of students are between the ages 18-25, with very few above the age of 26.\n\n\n\nThe bar graph below depicts what type of high school the university students graduated from (1= private, 2 = state, 3 = other).\n\n\nCode\nggplot(studentsurvey, aes(x = HS_TYPE)) + geom_bar()\n\n\nError in ggplot(studentsurvey, aes(x = HS_TYPE)): object 'studentsurvey' not found\n\n\nAccording to the graph, most students attended a state (public) high school.\n\n\n\nThe bar graph below demonstrates what percentage of their tuition was paid for by scholarship (1 = None, 2 = 25%, 3 = 50%, 4 = 75%, 5 = Full)\n\n\nCode\nggplot(studentsurvey, aes(x = SCHOLARSHIP)) + geom_bar()\n\n\nError in ggplot(studentsurvey, aes(x = SCHOLARSHIP)): object 'studentsurvey' not found\n\n\nMost students have received at least 50% scholarship at this university.\n\n\n\nThe bar graph below depicts how many students work a job outside of their classes (1 = Yes, 2 = No)\n\n\nCode\nggplot(studentsurvey, aes(x = WORK)) + geom_bar()\n\n\nError in ggplot(studentsurvey, aes(x = WORK)): object 'studentsurvey' not found\n\n\nMost students do not have a job while they are studying at university in this sample.\n\n\n\nThis sample may not be representative of the U.S. student population. There are more male than female students, which is not the case at most schools: there is about a 1:2 male to female ratio at U.S. colleges (Leukhina & Smaldone, 2022). The ages of students, however, do align with the ages of current university students: about a third of students in university are ages 24 and under (Hanson, 2022). Additionally, like in the sample, the vast majority of students attended public schools (Riser-Kositsky, 2022). In regards to scholarships, the students at this particular university receive scholarships at significantly higher rates than the rest of the U.S. Only about one in eight students receive a scholarship, and only 5% receive a full scholarship (Scholarship Statistics, 2021). While the enrollment statuses of the students were not given, if all students were full-time students, it would align with research that shows that less than half of full-time students (40%) in U.S. universities work while in school. While this sample may not be entirely representative of the U.S. college student population, analyses of this dataset conducted may provide some insight on factors that improve university students GPA.\n\n\n\n\nBüchele, S. (2021). Evaluating the link between attendance and performance in higher education: the role of classroom engagement dimensions. Assessment & Evaluation in Higher Education, 46(1), 132-150.\nEllis, R., & Han, F. (2021). Assessing university student collaboration in new ways. Assessment & Evaluation in Higher Education, 46(4), 509-524.\nFokkens-Bruinsma, M., Vermue, C., Deinumdataset, J. F., & van Rooij, E. (2021). First-year academic achievement: the role of academic self-efficacy, self-regulated learning and beyond classroom engagement. Assessment & Evaluation in Higher Education, 46(7), 1115-1126.\nHanson, M. (2022, July 26). College Enrollment & Student Demographic Statistics. EducationData.org. Retrieved from https://educationdata.org/college-enrollment-statistics.\nLeukhina, O., & Smaldone, A. (2022, March 14). Why do women outnumber men in college enrollment? Saint Louis Fed Eagle. Retrieved from https://www.stlouisfed.org/on-the-economy/2022/mar/why-women-outnumber-men-college-enrollment#:~:text=When%20the%20fall%20college%20enrollment,seen%20in%20U.S.%20college%20enrollment.\nNational Center for Education Statistics. (2022, May). College Student Employment. Coe - college student employment. Retrieved from https://nces.ed.gov/programs/coe/indicator/ssa/college-student-employment\nNelson, R. (2003). Student Efficiency: A study on the behavior and productive efficiency of college students and the determinants of GPA. Issues in Political Economy, 12, 32-43.\nRiser-Kositsky, M. (2022, August 2). Education statistics: Facts about American Schools. Education Week. Retrieved from https://www.edweek.org/leadership/education-statistics-facts-about-american-schools/2019/01.\nScholarship statistics. ThinkImpact.com. (2021, November 10). Retrieved from https://www.thinkimpact.com/scholarship-statistics/.\nThibodeaux, J., Deutsch, A., Kitsantas, A., & Winsler, A. (2017). First-year college students' time use: Relations with self-regulation and GPA. Journal of Advanced Academics, 28(1), 5-27.\nTorrento-estimo, E., Lourdes, C., & Evidente, L. G. (2012). Collaborative Learning in Small Group Discussions and Its Impact on Resilience Quotient and Academic Performance. JPAIR Multidisciplinary Research Journal, 7(1), 1-1.\nVargas, D. L., Bridgeman, A. M., Schmidt, D. R., Kohl, P. B., Wilcox, B. R., & Carr, L. D. (2018). Correlation between student collaboration network centrality and academic performance. Physical Review Physics Education Research, 14(2), 020112.\nYılmaz, N., & Sekeroglu, B. (2019, August). Student Performance Classification Using Artificial Intelligence Techniques. In International Conference on Theory and Application of Soft Computing, Computing with Words and Perceptions (pp. 596-603). Springer, Cham."
  },
  {
    "objectID": "posts/KenDocekal_HW1.html",
    "href": "posts/KenDocekal_HW1.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#a",
    "href": "posts/KenDocekal_HW1.html#a",
    "title": "Homework 1",
    "section": "a",
    "text": "a\nRead in the data from the Excel file:\n\n\nCode\nlibrary(readr)\nlibrary(readxl)\n\nLungCapData <- read_excel(\"_data/LungCapData.xls\")\nView(LungCapData)\n\n\nWarning in View(LungCapData): unable to open display\n\n\nError in .External2(C_dataviewer, x, title): unable to start data viewer\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(LungCapData$LungCap)"
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#b",
    "href": "posts/KenDocekal_HW1.html#b",
    "title": "Homework 1",
    "section": "b",
    "text": "b\nProbability distribution of the LungCap, Males and Females, in a box plot:\n\n\nCode\nboxplot(LungCapData$LungCap ~ LungCapData$Gender)"
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#c",
    "href": "posts/KenDocekal_HW1.html#c",
    "title": "Homework 1",
    "section": "c",
    "text": "c\nLung capacities for smokers and non-smokers, mean and standard deviation:\n\n\nCode\nLungCapData %>% \n  group_by(Smoke) %>% \n  summarise(mean = mean(LungCap, na.rm = TRUE), sd = sd(LungCap, na.rm = TRUE))\n\n\n# A tibble: 2 × 3\n  Smoke  mean    sd\n  <chr> <dbl> <dbl>\n1 no     7.77  2.73\n2 yes    8.65  1.88\n\n\nResults seem to point to smokers having greater lung capacity which is odd and could indicate factors other than age are influencing lung capacity"
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#d",
    "href": "posts/KenDocekal_HW1.html#d",
    "title": "Homework 1",
    "section": "d",
    "text": "d\nThe relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”:\nage 13 and lower:\n\n\nCode\nLungCapData %>% \n  group_by(Smoke) %>% \n dplyr::filter(Age <=13)%>% \n  summarise(mean = mean(LungCap, na.rm = TRUE),sd = sd(LungCap, na.rm = TRUE))\n\n\n# A tibble: 2 × 3\n  Smoke  mean    sd\n  <chr> <dbl> <dbl>\n1 no     6.36  2.21\n2 yes    7.20  1.58\n\n\nage 14 to 15:\n\n\nCode\nLungCapData %>% \n  group_by(Smoke) %>% \n dplyr::filter(Age == 14:15)%>% \n  summarise(mean = mean(LungCap, na.rm = TRUE),sd = sd(LungCap, na.rm = TRUE))\n\n\nWarning in Age == 14:15: longer object length is not a multiple of shorter\nobject length\n\n\n# A tibble: 2 × 3\n  Smoke  mean    sd\n  <chr> <dbl> <dbl>\n1 no     8.84 1.36 \n2 yes    8.91 0.865\n\n\nage 16 to 17:\n\n\nCode\nLungCapData %>% \n  group_by(Smoke) %>% \n dplyr::filter(Age == 16:17)%>% \n  summarise(mean = mean(LungCap, na.rm = TRUE),sd = sd(LungCap, na.rm = TRUE))\n\n\nWarning in Age == 16:17: longer object length is not a multiple of shorter\nobject length\n\n\n# A tibble: 2 × 3\n  Smoke  mean    sd\n  <chr> <dbl> <dbl>\n1 no    10.4   1.73\n2 yes    9.60  1.41\n\n\nage 18 and over:\n\n\nCode\nLungCapData %>% \n  group_by(Smoke) %>% \n dplyr::filter(Age >=18)%>% \n  summarise(mean = mean(LungCap, na.rm = TRUE),sd = sd(LungCap, na.rm = TRUE))\n\n\n# A tibble: 2 × 3\n  Smoke  mean    sd\n  <chr> <dbl> <dbl>\n1 no     11.1  1.56\n2 yes    10.5  1.25"
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#e",
    "href": "posts/KenDocekal_HW1.html#e",
    "title": "Homework 1",
    "section": "e",
    "text": "e\nWhen looking at mean lung capacity of smokers versus non-smokers by age groups we can see lung capacity increasing consistently as age increases. For the two lowest age groups mean capacity is lower for non-smokers although the difference decreases as age increases; this trend is reversed from age 16 onwards as non-smokers overtake smokers in lung capacity. Across all age groups non-smokers also have a greater standard deviation in lung capacity compared to smokers with the age 13 and under non-smoker group having the greatest standard deviation. It is likely that the greater number of age 13 and under respondents is the reason why overall results mirror the distribution seen in the youngest age group."
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#f",
    "href": "posts/KenDocekal_HW1.html#f",
    "title": "Homework 1",
    "section": "f",
    "text": "f\nCovariance between lung capacity and age:\n\n\nCode\ncov(LungCapData$Age,LungCapData$LungCap)\n\n\n[1] 8.738289\n\n\nA positive covariance is shown which lets us know that as age increases lung capacity also increases.\nCorrelation between lung capacity and age:\n\n\nCode\ncor(LungCapData$Age,LungCapData$LungCap)\n\n\n[1] 0.8196749\n\n\nThe correlation coefficient is also positive; similar to the covariance this lets us know that there is a positive relationship between age and lung capacity. Additionally, since .819 is a relatively high score, as a score of 1 would indicate a perfect positive relationship, we know there is a strong relationship where a older respondent would be highly likely to have higher lung capacity and a younger respondent would likely have lower lung capacity."
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#a-1",
    "href": "posts/KenDocekal_HW1.html#a-1",
    "title": "Homework 1",
    "section": "a",
    "text": "a\nThe probability that a randomly selected inmate has exactly 2 prior convictions:\nCreate data frame:\n\n\nCode\nconvictions<- c(0,1,2,3,4)\nprisoners<- c(128, 434, 160, 64, 24)\n\ndf <- data.frame(convictions, prisoners)\n\ntibble(df)\n\n\n# A tibble: 5 × 2\n  convictions prisoners\n        <dbl>     <dbl>\n1           0       128\n2           1       434\n3           2       160\n4           3        64\n5           4        24\n\n\nProbability of exactly 2 prior convictions:\n\n\nCode\n160/sum(prisoners)\n\n\n[1] 0.1975309"
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#b-1",
    "href": "posts/KenDocekal_HW1.html#b-1",
    "title": "Homework 1",
    "section": "b",
    "text": "b\nProbability of fewer than 2 prior convictions (total # of prisoners with less than 2 prior convictions = 562):\n\n\nCode\n562/sum(prisoners)\n\n\n[1] 0.6938272"
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#c-1",
    "href": "posts/KenDocekal_HW1.html#c-1",
    "title": "Homework 1",
    "section": "c",
    "text": "c\nProbability of 2 or fewer prior convictions (total # of prisoners with 2 or fewer prior convictions = 722):\n\n\nCode\n722/sum(prisoners)\n\n\n[1] 0.891358"
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#d-1",
    "href": "posts/KenDocekal_HW1.html#d-1",
    "title": "Homework 1",
    "section": "d",
    "text": "d\nProbability of more than 2 prior convictions (total # of prisoners with more than 2 prior convictions = 88):\n\n\nCode\n88/sum(prisoners)\n\n\n[1] 0.108642"
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#e-1",
    "href": "posts/KenDocekal_HW1.html#e-1",
    "title": "Homework 1",
    "section": "e",
    "text": "e\nThe expected value for the number of prior convictions (using the probability of observing each prisoner prior conviction group):\n\n\nCode\ncon1<- c(0,1,2,3,4)\npprob<- c(.158,.536,.198,.079,.028)\n\n\nsum(con1*pprob)\n\n\n[1] 1.281"
  },
  {
    "objectID": "posts/KenDocekal_HW1.html#f-1",
    "href": "posts/KenDocekal_HW1.html#f-1",
    "title": "Homework 1",
    "section": "f",
    "text": "f\nVariance and standard deviation for prior convictions:\n\n\nCode\nvar(prisoners)\n\n\n[1] 25948\n\n\nCode\nsd(prisoners)\n\n\n[1] 161.0838"
  },
  {
    "objectID": "posts/HW2_EthanCampbell.html",
    "href": "posts/HW2_EthanCampbell.html",
    "title": "Homework 2",
    "section": "",
    "text": "First, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(dplyr)"
  },
  {
    "objectID": "posts/HW2_EthanCampbell.html#a",
    "href": "posts/HW2_EthanCampbell.html#a",
    "title": "Homework 2",
    "section": "A",
    "text": "A\nTest whether the mean income of female employees differs from $500 per week. Include assumptions, hypotheses, test statistic, and P-value. Interpret the result.\nHere we can get the t statistic since it will show us the difference in two means\nNull hypothesis mean = 500\n\n\nCode\n# Calculating the t statistic\nT_statistic = (410-500)/(90/(sqrt(9)))\nT_statistic\n\n\n[1] -3\n\n\nCode\n# calculating the p value\n\npvalue = 2* pt(T_statistic, df=8)\n\npvalue\n\n\n[1] 0.01707168\n\n\nCode\n# the p value is showing evidence that we would reject the null hypothesis here since it is < .05."
  },
  {
    "objectID": "posts/HW2_EthanCampbell.html#b",
    "href": "posts/HW2_EthanCampbell.html#b",
    "title": "Homework 2",
    "section": "B",
    "text": "B\nTesting to see p value of it being less than 500\n\n\nCode\npvalue_left <- pt(T_statistic, df = 8, lower.tail = TRUE)\npvalue_left\n\n\n[1] 0.008535841\n\n\nCode\n# this is also showing a value smaller than the 5% given which means it is more evidence to reject the null hypothesis"
  },
  {
    "objectID": "posts/HW2_EthanCampbell.html#c",
    "href": "posts/HW2_EthanCampbell.html#c",
    "title": "Homework 2",
    "section": "C",
    "text": "C\nTesting to see the p value greater than 500\n\n\nCode\npvalue_right <- pt(T_statistic, df = 8, lower.tail = FALSE)\n\npvalue_right\n\n\n[1] 0.9914642\n\n\nCode\n# Making sure the two values equal 1\nsum(pvalue_left, pvalue_right)\n\n\n[1] 1\n\n\nthis is showing a 99.14% chance of observing if the population mean was less than that 500 mark. This is interesting and we would fail to reject the null hypothesis here since it exceeds the amount specified. This would indicate that they are not getting paid the same amount."
  },
  {
    "objectID": "posts/HW2_EthanCampbell.html#a-1",
    "href": "posts/HW2_EthanCampbell.html#a-1",
    "title": "Homework 2",
    "section": "A",
    "text": "A\nShow that t = 1.95 and P-value = 0.051 for Jones. Show that t = 1.97 and P-value = 0.049 for Smith.\n\n\nCode\n# Lets run the test and see whats going on\n\nJones <- (519.5-500)/(10)\nSmith= (519.7-500)/(10)\n\n# Here we can see the t stat they are both getting so looking good so far\nJones\n\n\n[1] 1.95\n\n\nCode\nSmith\n\n\n[1] 1.97\n\n\nCode\n# Now to get the P-value\n\nJones_p <- 2*pt(Jones, df= 999, lower.tail = FALSE)\nSmith_p <- 2*pt(Smith, df= 999, lower.tail = FALSE)\n\n# Observing the p values\n\nJones_p\n\n\n[1] 0.05145555\n\n\nCode\nSmith_p\n\n\n[1] 0.04911426"
  },
  {
    "objectID": "posts/HW2_EthanCampbell.html#b-1",
    "href": "posts/HW2_EthanCampbell.html#b-1",
    "title": "Homework 2",
    "section": "B",
    "text": "B\nUsing this example, explain the misleading aspects of reporting the result of a test as “P ≤ 0.05” versus “P > 0.05,” or as “reject H0” versus “Do not reject H0 ,” without reporting the actual P-value.\nBased on the basic test of this with a CI of 95% we could say that Jones would be unable to reject the null hypothesis since his exceeds .05. Smith on the other hand would barley be able to reject the null hypothesis with his equalling .049."
  },
  {
    "objectID": "posts/HW2_EthanCampbell.html#c.",
    "href": "posts/HW2_EthanCampbell.html#c.",
    "title": "Homework 2",
    "section": "C.",
    "text": "C.\nUsing this example, explain the misleading aspects of reporting the result of a test as “P ≤ 0.05” versus “P > 0.05,” or as “reject H0” versus “Do not reject H0 ,” without reporting the actual P-value.\nBoth of these p values were extremely close to the actual cut off point which shows including them is important. If I would have saw these p scores I would have had doubts or questions regarding the data and would have ran my own test to validate the claims. I think that is reason it would be important to include them to allow other people to see how close the study was."
  },
  {
    "objectID": "posts/Buck_Yoon_finalpart1.html",
    "href": "posts/Buck_Yoon_finalpart1.html",
    "title": "finalpart1",
    "section": "",
    "text": "we are going to be using the National Longitudinal Study of Adolescent to Adult Health, 1994-2018 we are interested in exploring the relation between education levels and health.\n#Some of our research questions are:\nWhat is the correlation and relationship between someone’s education and health? Does the type and duration of education matter? Are there fields that may be “more healthy”? How does the relationship between education and health differ among the education levels/ is there a difference?\nWhat does this data set have to say to a possible causal link between education and health? Does the data set provide apt data to establish a causal link?"
  },
  {
    "objectID": "posts/Buck_Yoon_finalpart1.html#hypothesis",
    "href": "posts/Buck_Yoon_finalpart1.html#hypothesis",
    "title": "finalpart1",
    "section": "Hypothesis",
    "text": "Hypothesis\nWe are going to be using the hypothesis from researchers Eric R. Ride and Mark H. Showalter, but using the data from the National Longitudinal Study\nThere hypothesis was: ’The empirical link between education and health is firmly established. Numerous studies document that higher levels of education are positively associated with longer life and better health throughout the lifespan…But measuring the causal links between education and health is a more challenging task.” Estimating the relation between health and education: what do we know and what do we need to know?\nWe are hypothesizing that a positive correlation exists between education and health; the more education an individual receives, the better health the individual may have.\nWe want to look at the National Longitudinal Study of Adolescent to Adult Health 1992-2018 and observe what other factors beyond education there is that can affect the correlation to health. What are the potential moderating or mediating variables?"
  },
  {
    "objectID": "posts/Buck_Yoon_finalpart1.html#descriptive-statistics",
    "href": "posts/Buck_Yoon_finalpart1.html#descriptive-statistics",
    "title": "finalpart1",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\nThis is an overview of the entire data set we are still determining which specific sections we want to analyze for our final project.\nAccording to ICPSR:\nStudy Purpose: Add Health was developed in response to a mandate from the U.S. Congress to fund a study of adolescent health. Waves I and II focused on the forces that may influence adolescents’ health and risk behaviors, including personal traits, families, friendships, romantic relationships, peer groups, schools, neighborhoods, and communities. As participants aged into adulthood, the scientific goals of the study expanded and evolved. Wave III explored adolescent experiences and behaviors related to decisions, behavior, and health outcomes in the transition to adulthood. Wave IV expanded to examine developmental and health trajectories across the life course of adolescence into young adulthood, using an integrative study design which combined social, behavioral, and biomedical measures data collection. Wave V aimed to track the emergence of chronic disease as the cohort aged into their 30s and early 40s.\nStudy Design: Add health is a school-based longitudinal study of a nationally-representative sample of adolescents in grates 7-12 in the United States in 1945-45. Over more than 20 years of data collection, data have been collected from adolescents, their fellow students, school administrators, parents, siblings, friends, and romantic partners through multiple data collection components. In addition, existing databases with information about respondents’ neighborhoods and communities have been merged with Add Health data, including variables on income poverty, unemployment, availability and utilization of health services, crime, church membership, and social programs and policies.\nSample:\n\nWave I: The Stage 1 in-school sample was a stratified, random sample of all high schools in the United States. A school was eligible for the sample if it included an 11th grade and had a minimum enrollment of 30 students. A feeder school – a school that sent graduates to the high school and that included a 7th grade – was also recruited from the community. The in-school questionnaire was administered to more than 90,000 students in grades 7 through 12. The Stage 2 in-home sample of 27,000 adolescents consisted of a core sample from each community, plus selected special over samples. Eligibility for over samples was determined by an adolescent’s responses on the in-school questionnaire. Adolescents could qualify for more than one sample.\nWave II: The Wave II in-home interview surveyed almost 15,000 of the same students one year after Wave I.\nWave III: The in-home Wave III sample consists of over 15,000 Wave I respondents who could be located and re-interviewed six years later.\nWave IV: All original Wave I in-home respondents were eligible for in-home interviews at Wave IV. At Wave IV, the Add Health sample was dispersed across the nation with respondents living in all 50 states. Administrators were able to locate 92.5% of the Wave IV sample and interviewed 80.3% of eligible sample members.\nWave V: All Wave I respondents who were still living were eligible at Wave V, yielding a pool of 19,828 persons. This pool was split into three stratified random samples for the purposes of survey design testing.\nTime Method: Longitudinal:Panel\nUniverse: Adolescents in grades 7 through 12 during the 1994-1995 school year. Respondents were geographically located in the United States.\nUnits of Observation: Individual\nData Types: Survey Data\nTime periods: 1994 - 2018\nDate of Collections: Wave 1(1994-01 - 1995-12), Wave II(1996-04 - 1996-09), Wave III(2001-04 - 2002 -04), Wave IV(2007-04 - 2009-01), Wave V(2016-03 - 2018-11)\nResponse Rates: Wave 1(79%), Wave 2(88.6%), Wave III(77.4%), Wave IV(80.3%), Wave V(71.8%)."
  },
  {
    "objectID": "posts/shelton_HW1.html",
    "href": "posts/shelton_HW1.html",
    "title": "Homework 1 Solution",
    "section": "",
    "text": "1.) Using LungCapData, answer descriptive questions about the data and its distributions.\n2.) Use the given distribution to answer questions about the probability of discrete events.\n\n\n\n\n\n\nCode\n#| include: false\n#| label: Loading in LungCap\n\n og_lungcap <- readxl::read_xls(\"_data/LungCapData.xls\")\n\n# Quick look at dataset\n# glimpse(og_lungcap)\n\n# Variables - 3<dbl> ratio 3<char> (can coerce to logical if needed), \n\n# length(which(is.na(og_lungcap)))\n\n# No missing values to consider\n\n# Descriptive\n# summarytools::dfSummary(og_lungcap)\n\n\nLungCapData: Describes the lung capacity of a population of 725 children aged 3 - 19. It further categorizes the subjects by height, sex, smoking habits, and whether they were birthed using the Caesarean section technique.\nIn the following sections, we’ll use select(), group_by(), filter(), and summarize() to further explore the data and find important relations between variables.\n\n\n\n\n\n\n\n\nLungCap looks to be approximately normally distributed (unimodal, symmetric) with most observations centered around the mean (7.86).\n\n\n\n\n\nCode\nhist_gender <- ggplot(og_lungcap, aes(x=LungCap, y=..density.., fill=Gender)) +\n  geom_histogram(alpha=.5, position=\"identity\", bins=20)+\n  geom_vline(aes(xintercept=mean(LungCap)))\nhist_gender\n\n\n\n\n\nPackage ggplot2 functions ggplot() and geom_histogram() are used to display the LungCap distribution filled by the Gender variable. Both density plots center on the mean, indicating both male and female lung capacity observations are highly concentrated around the mean. The male distribution is shifted slightly to the right of the female distribution, meaning male observations had a higher upper range value than female observations. Males had more observations concentrated to the right of the mean, and the female distribution reciprocated this effect to the left of the mean.\n\n\n\n\n\nCode\nsmokers <- group_by(og_lungcap, Smoke)\nsmokers %>%\n  summarize(mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke `mean(LungCap)`\n  <chr>           <dbl>\n1 no               7.77\n2 yes              8.65\n\n\nAfter creating a new dataset smokers by using group_by() on our original data, smokers is piped into a summarize() call. The results surprisingly show that the smoking group had a higher mean lung capacity than the nonsmoking group. This is likely due to a mean age difference within the groups.\n\n\n\n\n\nCode\n# Creating Age Groups Using Case When\n\nsmokers_age <- smokers %>%\n  mutate(AgeGroup = case_when(Age >= 18 ~ \"18+\", \n            Age == 16 | Age == 17 ~ \"16-17\",\n            Age == 14 | Age == 15 ~ \"14-15\",\n            Age <= 13~ \"Under 13\"))\n\n# Mean LungCap by Age and Smoke\n# Must regroup by Smoke again\nsmokers_age %>%\n  group_by(AgeGroup, Smoke) %>%\n    summarize(mean(LungCap))\n\n\n# A tibble: 8 × 3\n# Groups:   AgeGroup [4]\n  AgeGroup Smoke `mean(LungCap)`\n  <chr>    <chr>           <dbl>\n1 14-15    no               9.14\n2 14-15    yes              8.39\n3 16-17    no              10.5 \n4 16-17    yes              9.38\n5 18+      no              11.1 \n6 18+      yes             10.5 \n7 Under 13 no               6.36\n8 Under 13 yes              7.20\n\n\nAfter using mutate() to add a column AgeGroup to a copy of smokers, group_by() groups the new dataset by AgeGroup and Smoke before piping it into a summarize() command to find the grouped means of LungCap by AgeGroup and Smoke.\nThe results show that for children above the age of 13, smokers had a lower mean lung capacity than non-smokers. However, for the 13 and under group, we again see results that imply smokers have greater lung capacity than nonsmokers. Let’s investigate further into the relationship between age and lung capacity to explain this quizzical result.\n\n\n\n\n\nCode\ncov(og_lungcap$Age, og_lungcap$LungCap)\n\n\n[1] 8.738289\n\n\nCode\ncor(og_lungcap$Age, og_lungcap$LungCap)\n\n\n[1] 0.8196749\n\n\nCode\n#GGPlot of Age vs Lung\nggplot(og_lungcap, aes(x=Age, y=LungCap)) + geom_point()\n\n\n\n\n\nAge and LungCap have a high covariance which leads to a high correlation (p=0.82). This strong positive value (-1<p<1) indicates these variables “vary greatly” together: when Age is high in the data, so is LungCap. We cannot say that an increase in Age causes an increase Lung capacity without first showing this through regression; however, our results show the variables are highly correlated.\nWe can use knowledge of the human body to infer that as our body ages, our lungs mature. The ages of smokers of the Under 13 group are likely highly left skewed, as I don’t expect many children under 10 to be smoking. This underlying age distribution explains our puzzling results from the previous section.\n\n\nCode\nsmokers_age%>%\n  group_by(AgeGroup, Smoke) %>%\n    summarize(mean(Age))\n\n\n`summarise()` has grouped output by 'AgeGroup'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 3\n# Groups:   AgeGroup [4]\n  AgeGroup Smoke `mean(Age)`\n  <chr>    <chr>       <dbl>\n1 14-15    no          14.5 \n2 14-15    yes         14.6 \n3 16-17    no          16.4 \n4 16-17    yes         16.6 \n5 18+      no          18.5 \n6 18+      yes         18.1 \n7 Under 13 no           9.49\n8 Under 13 yes         11.7 \n\n\n\n\n\n\nFirst, let’s create two vectors: x_val and freq. Then, we’ll use rbind() to create a table.\n\n\nCode\nx_val <-c(0,1,2,3,4)\nfreq <- c(128,434,160,64,24)\nprob <- freq/sum(freq)\n\nxdist <- rbind(x_val,prob)\n\nxdist\n\n\n           [,1]      [,2]      [,3]       [,4]       [,5]\nx_val 0.0000000 1.0000000 2.0000000 3.00000000 4.00000000\nprob  0.1580247 0.5358025 0.1975309 0.07901235 0.02962963\n\n\n\n\n\n\nCode\n# Finding probability of inmate having exactly 2 prior convictions\n\n#Column Index is 3 as the first column is 0\n\n#Surely there is a cleaner way to do this using tidyverse functions rather than base?\n\n# a\na <- xdist['prob',3] \na\n\n\n     prob \n0.1975309 \n\n\n\n\n\n\n\nCode\n#b\nb <- sum(xdist['prob',1:2])\nb\n\n\n[1] 0.6938272\n\n\n\n\n\n\n\nCode\n# c\nc <- a + b\nc\n\n\n    prob \n0.891358 \n\n\n\n\n\n\n\nCode\n#d\nd <- 1 - c\nd\n\n\n    prob \n0.108642 \n\n\n\n\n\n\n\n[1] 1.28642\n\n\n\n\n\n\n\n\n\nCode\n# Var= E(X^2) - E(X)^2\n# Again using brute force because cannot use var() function on the object xdist correctly\nvar_x <-sum((x_val^2)*prob) - ex^2\nvar_x\n\n\n[1] 0.8562353\n\n\n\n\n\n\n\n[1] 0.9253298"
  },
  {
    "objectID": "posts/HW1_EmmaRasmussen.html",
    "href": "posts/HW1_EmmaRasmussen.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlungcap<-read_excel(\"_data/LungCapData.xls\")\nhead(lungcap)\n\n\n# A tibble: 6 × 6\n  LungCap   Age Height Smoke Gender Caesarean\n    <dbl> <dbl>  <dbl> <chr> <chr>  <chr>    \n1    6.48     6   62.1 no    male   no       \n2   10.1     18   74.7 yes   female no       \n3    9.55    16   69.7 no    female yes      \n4   11.1     14   71   no    male   no       \n5    4.8      5   56.9 no    male   no       \n6    6.22    11   58.7 no    female no       \n\n\nCode\n#saving a copy of original dataset\nlungcap_orig<-lungcap\n\n#checking for missing values in LungCap\nwhich(is.na(lungcap$LungCap))\n\n\ninteger(0)\n\n\n\n1a.\nThe distribution of LungCapData is plotted as a histogram below.\n\n\nCode\nggplot(lungcap, aes(x=LungCap))+geom_histogram()\n\n\n\n\n\nThe histogram looks approximately normally distributed\n\n\n1b.\nThe probability distribution of LungCap data for males and females is compared using the boxplots below:\n\n\nCode\nggplot(lungcap, aes(x=LungCap, y=Gender))+geom_boxplot()\n\n\n\n\n\nThe mean lung capacity of males appears slightly higher than that of females. The IQR and range for males and females appears similarly spread with a higher average for males.\n\n\n1c.\nBelow the mean and standard deviation of smokers and non-smokers is compared. They are also plotted as a boxplot to help visualize the distribution.\n\n\nCode\nlungcap%>%\n  group_by(Smoke) %>% \n  summarize(Mean=mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke  Mean\n  <chr> <dbl>\n1 no     7.77\n2 yes    8.65\n\n\nCode\nlungcap%>%\n  group_by(Smoke) %>% \n  summarize(stdev=sd(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke stdev\n  <chr> <dbl>\n1 no     2.73\n2 yes    1.88\n\n\nCode\nggplot(lungcap, aes(x=LungCap, y=Smoke))+geom_boxplot()\n\n\n\n\n\nThe mean lung capacity for smokers (8.645) in this sample is higher than that of non-smokers (7.770). This does not make sense. However, the standard deviation of non-smokers (2.726) is much higher than smokers (1.883) so there might be something else going on (see boxplot).\n\n\n1d.\nBelow, means are taken by age groups of smokers/non-smokers. I also created a new age category variable (“AgeCat”) to plot the data by smoking status and age category.\n\n\nCode\n#Mean under 13 and nonsmoker\nlungcap %>% \n  filter(Age<=13 & Smoke==\"no\") %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 6.358746\n\n\nCode\n#Mean under 13 and smoker\nlungcap %>% \n  filter(Age<=13 & Smoke==\"yes\") %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 7.201852\n\n\nCode\n#Mean 14-15 and nonsmoker\nlungcap %>% \n  filter(Age==14 | Age==15 & Smoke==\"no\") %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 9.068018\n\n\nCode\n#Mean 14-15 and smoker\nlungcap %>% \n  filter(Age==14 | Age==15 & Smoke==\"yes\") %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 8.689231\n\n\nCode\n#Mean 16-17 and nonsmoker\nlungcap %>% \n  filter(Age==16 | Age==17 & Smoke==\"no\") %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 10.30523\n\n\nCode\n#Mean 16-17 and smoker\nlungcap %>% \n  filter(Age==16 | Age==17 & Smoke==\"yes\") %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 9.850385\n\n\nCode\n#Mean over 18 and nonsmoker\nlungcap %>% \n  filter(Age>=18 & Smoke==\"no\") %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 11.06885\n\n\nCode\n#Mean over 18 and smoker\nlungcap %>% \n  filter(Age>=18 & Smoke==\"yes\") %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 10.51333\n\n\nCode\n#creating new variable AgeCat to create boxplots\nlungcap<-lungcap %>% \n  mutate(AgeCat= as.factor(case_when(Age <= 13 ~ \"13 and under\", \n                           Age == 14 |Age ==15 ~ \"14-15\", \n                           Age == 16 | Age==17 ~ \"16-17\",\n                           Age >= 18 ~ \"18 or over\"\n                           )))\n\n#new Category AgeCat is the last column\nlungcap\n\n\n# A tibble: 725 × 7\n   LungCap   Age Height Smoke Gender Caesarean AgeCat      \n     <dbl> <dbl>  <dbl> <chr> <chr>  <chr>     <fct>       \n 1    6.48     6   62.1 no    male   no        13 and under\n 2   10.1     18   74.7 yes   female no        18 or over  \n 3    9.55    16   69.7 no    female yes       16-17       \n 4   11.1     14   71   no    male   no        14-15       \n 5    4.8      5   56.9 no    male   no        13 and under\n 6    6.22    11   58.7 no    female no        13 and under\n 7    4.95     8   63.3 no    male   yes       13 and under\n 8    7.32    11   70.4 no    male   no        13 and under\n 9    8.88    15   70.5 no    male   no        14-15       \n10    6.8     11   59.2 no    male   no        13 and under\n# … with 715 more rows\n\n\nCode\nggplot(lungcap, aes(x=LungCap))+geom_boxplot()+facet_grid(Smoke ~ AgeCat)\n\n\n\n\n\n\n\n1e.\nComparing the lung capacities for smokers and non-smokers in different age categories:\nNow we can see that the mean lung capacity for smokers by age group is generally lower than that of nonsmokers. This is true in all categories except for Under 13, which is likely because smokers in that category are going to be older than nonsmokers in that category (i.e. it is more likely that a 12 year old smokes than a 6 year old, and a 12 year old has a larger lung capacity than a 6 year old regardless of smoking status)\nThis explains the first calculation of mean by smoking status (before finding the mean by age categories). Smokers are generally going to be older than non-smokers for this sample (the oldest participant in the sample is 19- see code below), which explains why the mean for smokers versus non-smokers (not separated by age categories) makes it look like smokers have a higher average lung capacity.\n\n\nCode\n#checking how old participants in the sample are\nlungcap %>% \n  summarize(range(Age))\n\n\n# A tibble: 2 × 1\n  `range(Age)`\n         <dbl>\n1            3\n2           19\n\n\n\n\n1f.\nCalculating the correlation and covariance between Lung Capacity and Age:\n\n\nCode\n#Creating vectors of Age and Lung Capacity from df (lungcap) to apply cov() and cor() functions to\nx<-c(lungcap$Age)\ny<-c(lungcap$LungCap)\n\n\n#Calculating covariance\ncov(x, y)\n\n\n[1] 8.738289\n\n\nCode\n#calculating correlation\ncor(x, y)\n\n\n[1] 0.8196749\n\n\nThe covariance, 8.738 is fairly high and positive, meaning as age increases, so does lung capacity (i.e. age and lung capacity co-vary). The correlation (0.82) is fairly close to one and positive, indicating they correlate fairly closely.\n\n\n2a-f.\nPrior Conviction Data\n\n\nCode\n#creating a data frame\nX<-c(0, 1, 2, 3, 4)\nFrequency<-c(128, 434, 160, 64, 24)\nprison<- data.frame(X, Frequency)\nprison\n\n\n  X Frequency\n1 0       128\n2 1       434\n3 2       160\n4 3        64\n5 4        24\n\n\nCode\nprison<-rename(prison, PriorConvictions=X)\nprison\n\n\n  PriorConvictions Frequency\n1                0       128\n2                1       434\n3                2       160\n4                3        64\n5                4        24\n\n\nCode\n#visualizing df using bar chart\nggplot(prison, aes(x=PriorConvictions, y=Frequency))+geom_bar(stat=\"identity\")+geom_text(aes(label = Frequency), vjust = -.3)\n\n\n\n\n\nCode\n#There are 810 obs in df\nsum(Frequency)\n\n\n[1] 810\n\n\nAnswering the Questions\n\n\nCode\n#creating a vector of probabilities\nprobs<-Frequency/810\nprobs\n\n\n[1] 0.15802469 0.53580247 0.19753086 0.07901235 0.02962963\n\n\nCode\n#A\n# P(x=2)=160/810\n160/810\n\n\n[1] 0.1975309\n\n\nCode\n#B\n#P(x<2)=P(0)+P(1)\n(128+434)/810\n\n\n[1] 0.6938272\n\n\nCode\n#C\n#P(x<=2)=P(0)+P(1)+P(2)\n(128+434+160)/810\n\n\n[1] 0.891358\n\n\nCode\n#D\n#1-P(above)\n1-((128+434+160)/810)\n\n\n[1] 0.108642\n\n\nCode\n#E\n#Expected value=sum of probabilities*each value (0, 1, 2, 3 or 4)\nweighted.mean(X, probs)\n\n\n[1] 1.28642\n\n\nCode\n#F\n#Calculating the Variance using the formula for variance\n(sum(Frequency*((X-1.28642)^2)))/(sum(Frequency)-1)\n\n\n[1] 0.8572937\n\n\nCode\n#Calculating the sample standard deviation from the variance\nsqrt(0.8572937)\n\n\n[1] 0.9259016\n\n\n\nWhat is the probability that a randomly selected inmate has exactly 2 prior convictions? 19.75% probability (or 0.1975)\nWhat is the probability that a randomly selected inmate has fewer than 2 prior convictions? 69.38% probability\nWhat is the probability that a randomly selected inmate has 2 or fewer prior convictions? 89.14% probability\nWhat is the probability that a randomly selected inmate has more than 2 prior convictions? 10.86% probability\nWhat is the expected value for the number of prior convictions? 1.28642 prior convictions\nCalculate the variance and the standard deviation for the Prior Convictions. variance: 0.8572937 standard deviation: 0.9259016 prior convictions"
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html",
    "href": "posts/RahulGundeti_DACSS603_HW1.html",
    "title": "DACSS603_HW1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(stats)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#question-1",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#question-1",
    "title": "DACSS603_HW1",
    "section": "Question 1",
    "text": "Question 1"
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#reading-data",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#reading-data",
    "title": "DACSS603_HW1",
    "section": "Reading data",
    "text": "Reading data\n\n\nCode\nlung <- read_excel(\"C:/Users/gunde/Downloads/LungCapData.xls\")\n\n\nError: `path` does not exist: 'C:/Users/gunde/Downloads/LungCapData.xls'\n\n\nCode\nlung\n\n\nError in eval(expr, envir, enclos): object 'lung' not found\n\n\nThe Lung Capacity data contains 725 rows and 6 columns that determine age, height etc., The key classification parameter is based on smoker vs non-smoker."
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#a",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#a",
    "title": "DACSS603_HW1",
    "section": "1_A",
    "text": "1_A\nThe distribution of LungCap looks as follows:\n\n\nCode\nlung %>%\n  ggplot(aes(LungCap, ..density..)) +\n  geom_histogram(bins= 40, color = \"red\") +\n  geom_density(color = \"green\") +\n  theme_classic() + \n  labs(title = \"LungCap Probability Distribution\", x = \"Lung Capcity\", y = \"Probability Density\")\n\n\nError in ggplot(., aes(LungCap, ..density..)): object 'lung' not found\n\n\nThe observations plotted by histogram are closer to mean which suggests that it is a normal distribution."
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#b",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#b",
    "title": "DACSS603_HW1",
    "section": "1_B",
    "text": "1_B\nThe distribution of LungCap on basis of gender looks as follows:\n\n\nCode\nlung %>%\n  ggplot(aes(y = dnorm(LungCap), color = Gender)) +\n  geom_boxplot() +\n  theme_classic() + \n  labs(title = \"LungCap Probability Distribution based on gender\", y = \"Probability Density\")\n\n\nError in ggplot(., aes(y = dnorm(LungCap), color = Gender)): object 'lung' not found\n\n\nThe box plot shows that the probability density of the male < female."
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#c",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#c",
    "title": "DACSS603_HW1",
    "section": "1_C",
    "text": "1_C\nComparison of mean lung capacities between smokers and non-smokers:\n\n\nCode\nMean_smoke <- lung %>%\n  group_by(Smoke) %>%\n  summarise(mean = mean(LungCap))\n\n\nError in group_by(., Smoke): object 'lung' not found\n\n\nCode\nMean_smoke\n\n\nError in eval(expr, envir, enclos): object 'Mean_smoke' not found\n\n\nThe table contains the mean lung capacity. The observations suggest that the mean value is higher for smokers than non-smokers. This isn’t entirely correct as the individual biological factors plays a main role. So the data is inadequate to form an opinion."
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#d",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#d",
    "title": "DACSS603_HW1",
    "section": "1_D",
    "text": "1_D\nRelationship between Smoke and Lung capacity on basis of given age categories:\n\n\nCode\nlung <- mutate(lung, AgeGrp = case_when(Age <= 13 ~ \"less than or equal to 13\",\n                                    Age == 14 | Age == 15 ~ \"14 to 15\",\n                                    Age == 16 | Age == 17 ~ \"16 to 17\",\n                                    Age >= 18 ~ \"greater than or equal to 18\"))\n\n\nError in mutate(lung, AgeGrp = case_when(Age <= 13 ~ \"less than or equal to 13\", : object 'lung' not found\n\n\nCode\nlung %>%\n  ggplot(aes(y = LungCap, color = Smoke)) +\n  geom_histogram(bins = 40) +\n  facet_wrap(vars(AgeGrp)) +\n  theme_classic() + \n  labs(title = \"Relationship of LungCap and Smoke based on age categories\", y = \"Lung Capacity\", x = \"Frequency\")\n\n\nError in ggplot(., aes(y = LungCap, color = Smoke)): object 'lung' not found\n\n\nFrom the above plot, we can derive two important observations: 1. The lung capacity of non-smokers is more than smokers. 2. The people who smoke are less in age group of “less than or equal to 13”. So as the result as age increases the lung capacity decreases."
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#e",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#e",
    "title": "DACSS603_HW1",
    "section": "1_E",
    "text": "1_E\nRelationship between Smoke and Lung capacity on basis of age:\n\n\nCode\nlung %>%\n  ggplot(aes(x = Age, y = LungCap, color = Smoke)) +\n  geom_line() +\n  theme_classic() + \n  facet_wrap(vars(Smoke)) +\n  labs(title = \"Relationship of LungCap and Smoke based on age\", y = \"Lung Capacity\", x = \"Age\")\n\n\nError in ggplot(., aes(x = Age, y = LungCap, color = Smoke)): object 'lung' not found\n\n\nComparing 1_D and 1_E we can find similarity which points that only 10 and above age group smoke."
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#f",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#f",
    "title": "DACSS603_HW1",
    "section": "1_F",
    "text": "1_F\nCalculating the correlation and covariance between Lung Capacity and Age:\n\n\nCode\nCovariance <- cov(lung$LungCap, lung$Age)\n\n\nError in is.data.frame(y): object 'lung' not found\n\n\nCode\nCorrelation <- cor(lung$LungCap, lung$Age)\n\n\nError in is.data.frame(y): object 'lung' not found\n\n\nCode\nCovariance\n\n\nError in eval(expr, envir, enclos): object 'Covariance' not found\n\n\nCode\nCorrelation\n\n\nError in eval(expr, envir, enclos): object 'Correlation' not found\n\n\nThe comparison shows that the covariance is positive, indicating that lung capacity and age have a direct relationship. As a result, they are moving in the same direction due to the positive correlation as well. This means that as age increases, lung capacity increases as well, which means they are directly proportional."
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#question-2",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#question-2",
    "title": "DACSS603_HW1",
    "section": "Question 2",
    "text": "Question 2"
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#reading-the-table",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#reading-the-table",
    "title": "DACSS603_HW1",
    "section": "Reading the table",
    "text": "Reading the table\n\n\nCode\nPrior_convitions <- c(0:4)\nInmate_count <- c(128, 434, 160, 64, 24)\nprior <- data_frame(Prior_convitions, Inmate_count)\n\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nℹ Please use `tibble()` instead.\n\n\nCode\nprior\n\n\n\n\n  \n\n\n\n\n\nCode\nprior <- mutate(prior, Probability = Inmate_count/sum(Inmate_count))\nprior"
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#a-1",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#a-1",
    "title": "DACSS603_HW1",
    "section": "2_A",
    "text": "2_A\nProbability that a randomly selected inmate has exactly 2 prior convictions:\n\n\nCode\nprior %>%\n  filter(Prior_convitions == 2) %>%\n  select(Probability)"
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#b-1",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#b-1",
    "title": "DACSS603_HW1",
    "section": "2_B",
    "text": "2_B\nProbability that a randomly selected inmate has fewer than 2 convictions:\n\n\nCode\nrandom <- prior %>%\n  filter(Prior_convitions < 2)\nsum(random$Probability)\n\n\n[1] 0.6938272"
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#c-1",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#c-1",
    "title": "DACSS603_HW1",
    "section": "2_C",
    "text": "2_C\nProbability that a randomly selected inmate has 2 or fewer prior convictions:\n\n\nCode\nrandom <- prior %>%\n  filter(Prior_convitions <= 2)\nsum(random$Probability)\n\n\n[1] 0.891358"
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#d-1",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#d-1",
    "title": "DACSS603_HW1",
    "section": "2_D",
    "text": "2_D\nProbability that a randomly selected inmate has more than 2 prior convictions:\n\n\nCode\nrandom <- prior %>%\n  filter(Prior_convitions > 2)\nsum(random$Probability)\n\n\n[1] 0.108642"
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#e-1",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#e-1",
    "title": "DACSS603_HW1",
    "section": "2_E",
    "text": "2_E\nExpected value for the number of prior convictions:\n\n\nCode\nprior <- mutate(prior, Wm = Prior_convitions*Probability)\nev <- sum(prior$Wm)\nev\n\n\n[1] 1.28642"
  },
  {
    "objectID": "posts/RahulGundeti_DACSS603_HW1.html#f-1",
    "href": "posts/RahulGundeti_DACSS603_HW1.html#f-1",
    "title": "DACSS603_HW1",
    "section": "2_F",
    "text": "2_F\nVariance for the Prior Convictions:\n\n\nCode\nvariance <-sum(((prior$Prior_convitions-ev)^2)*prior$Probability)\nvariance\n\n\n[1] 0.8562353\n\n\nstandard deviation for the Prior Convictions:\n\n\nCode\nsqrt(variance)\n\n\n[1] 0.9253298"
  },
  {
    "objectID": "posts/FinalProjectPart1_DonnySnyder.html",
    "href": "posts/FinalProjectPart1_DonnySnyder.html",
    "title": "Final Project Part 1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(dplyr)"
  },
  {
    "objectID": "posts/FinalProjectPart1_DonnySnyder.html#research-question",
    "href": "posts/FinalProjectPart1_DonnySnyder.html#research-question",
    "title": "Final Project Part 1",
    "section": "Research Question",
    "text": "Research Question\nAffective polarization describes a heightened state of animosity between partisans that has steadily grown from the 1970s to today (Iyengar et al., 2019). Identifying antecedents of affective polarization is essential to creating intervention strategies into this negative state of politics. Levendusky (2009) proposes a social model where individuals making sense of simplified elite cues enables people to understand the relevant identities of the political landscape, which may lead to downstream affective polarization. I intend to expand on this model, testing a construct of construal level, or the level of abstraction to concreteness (Trope & Liberman, 2010) with which partisans perceive partisan groups and group cues. Prior studies suggest that lower construal may serve as an antecedent to affective polarization when partisans view issues in more concrete, group terms (Snyder, Unpublished). This study will expand these models into extant, large scale, political science datasets. Additionally, this project will employ supervised machine learning models to qualitatively code a large-n sample of free response questions."
  },
  {
    "objectID": "posts/FinalProjectPart1_DonnySnyder.html#hypotheses",
    "href": "posts/FinalProjectPart1_DonnySnyder.html#hypotheses",
    "title": "Final Project Part 1",
    "section": "Hypotheses",
    "text": "Hypotheses\nI hypothesize that partisans who are qualitatively coded as having a lower construal level will demonstrate higher levels of group/affective polarization, as measured on a feeling thermometer or measures of feelings about political groups - whichever is available in the datasets.\nI hypothesize that using a sentiment analysis, these tendencies may be moderated by valence of their free response, with stronger valence enhancing the effect of construal level on affective polarization."
  },
  {
    "objectID": "posts/FinalProjectPart1_DonnySnyder.html#datasets",
    "href": "posts/FinalProjectPart1_DonnySnyder.html#datasets",
    "title": "Final Project Part 1",
    "section": "Datasets",
    "text": "Datasets\nI intend to use ANES and/or NAES free response data to provide an initial exploratory analysis. I will qualitatively code these data using a novel construal level paradigm (Snyder, unpublished). i will then use this qualitative coding process to train a supervised machine learning algorithm."
  },
  {
    "objectID": "posts/FinalProjectPart1_DonnySnyder.html#references",
    "href": "posts/FinalProjectPart1_DonnySnyder.html#references",
    "title": "Final Project Part 1",
    "section": "References",
    "text": "References\nIyengar, S., Lelkes, Y., Levendusky, M., Malhotra, N., & Westwood, S. J. (2019). The origins and consequences of affective polarization in the United States. Annual Review of Political Science, 22(1), 129-146. Levendusky, M. (2009). The partisan sort: How liberals became Democrats and conservatives became Republicans. University of Chicago Press. Snyder, D. (2022). Keep It Simple Stupid: How Individual Differences in Cue Construal Explain Variations in Affective Polarization. Unpublished Manuscript Trope, Y., & Liberman, N. (2010). Construal-level theory of psychological distance. Psychological review, 117(2), 440."
  },
  {
    "objectID": "posts/FinalProject_ManiShankerKamarapu.html",
    "href": "posts/FinalProject_ManiShankerKamarapu.html",
    "title": "Final project part 1",
    "section": "",
    "text": "Churning refers to a customer who leaves one company to go to another company. Customer churn introduces not only some loss in income but also other negative effects on the operation of companies. Churn management is the concept of identifying those customers who are intending to move their custom to a competing service provider.\nRisselada et al. (2010) stated that churn management is becoming part of customer relationship management. It is important for companies to consider it as they try to establish long-term relationships with customers and maximize the value of their customer base.\n\n\n\n\n\n\nResearch Questions\n\n\n\nA. Does churn-rate depend on the geographical factors of the customer?\nB. Do non-active members are probable to churn or not?\n\n\nThis project will be useful to better understand more about the customer difficulties and factors and also give us a pretty good idea on the factors effecting the customers to exit and also about the dormant state of the customers."
  },
  {
    "objectID": "posts/FinalProject_ManiShankerKamarapu.html#hypothesis",
    "href": "posts/FinalProject_ManiShankerKamarapu.html#hypothesis",
    "title": "Final project part 1",
    "section": "Hypothesis",
    "text": "Hypothesis\nCustomer churn analysis has become a major concern in almost every industry that offers products and services. The model developed will help banks identify clients who are likely to be churners and develop appropriate marketing actions to retain their valuable clients. And this model also supports information about similar customer group to consider which marketing reactions are to be provided. Thus, due to existing customers are retained, it will provide banks with increased profits and revenues.\nGiven the above, we can frame our hypotheses as follows:\n\n\n\n\n\n\nH0A\n\n\n\nGeographical factors will not be statistically predict the churn-rate.\n\n\n\n\n\n\n\n\nH1A\n\n\n\nGeographical factors will be statistically predict the churn-rate.\n\n\n\n\n\n\n\n\nH0B\n\n\n\nActive members will not churn.\n\n\n\n\n\n\n\n\nH1B\n\n\n\nActive members will churn."
  },
  {
    "objectID": "posts/FinalProject_ManiShankerKamarapu.html#loading-libraries",
    "href": "posts/FinalProject_ManiShankerKamarapu.html#loading-libraries",
    "title": "Final project part 1",
    "section": "Loading libraries",
    "text": "Loading libraries\n\n\nCode\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(stats)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/FinalProject_ManiShankerKamarapu.html#reading-the-data-set",
    "href": "posts/FinalProject_ManiShankerKamarapu.html#reading-the-data-set",
    "title": "Final project part 1",
    "section": "Reading the data set",
    "text": "Reading the data set\n\n\nCode\nChurn <- read_csv(\"_data/Churn_Modelling.csv\")\n\n\nRows: 10000 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): Surname, Geography, Gender\ndbl (11): RowNumber, CustomerId, CreditScore, Age, Tenure, Balance, NumOfPro...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nChurn\n\n\n\n\n  \n\n\n\nThis data set includes 10k bank customer data records with 14 attributes including socio-demographic attributes, account level and behavioural attributes.\nAttribute Description 1. Row Number- Number of customers 2. Customer ID- ID of customer 3. Surname- Customer name 4. Credit Score- Score of credit card usage 5. Geography- Location of customer 6. Gender- Customer gender 7. Age- Age of Customer 8. Tenure- The period of having the account in months 9. Balance- Customer main balance 10. NumOfProducts- No of products used by customer 11. HasCrCard- If the customer has a credit card or not 12. IsActiveMember- Customer account is active or not 13. Estimated Salary- Estimated salary of the customer. 14. Exited- Indicate churned or not\n\n\nCode\nstr(Churn)\n\n\nspec_tbl_df [10,000 × 14] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ RowNumber      : num [1:10000] 1 2 3 4 5 6 7 8 9 10 ...\n $ CustomerId     : num [1:10000] 15634602 15647311 15619304 15701354 15737888 ...\n $ Surname        : chr [1:10000] \"Hargrave\" \"Hill\" \"Onio\" \"Boni\" ...\n $ CreditScore    : num [1:10000] 619 608 502 699 850 645 822 376 501 684 ...\n $ Geography      : chr [1:10000] \"France\" \"Spain\" \"France\" \"France\" ...\n $ Gender         : chr [1:10000] \"Female\" \"Female\" \"Female\" \"Female\" ...\n $ Age            : num [1:10000] 42 41 42 39 43 44 50 29 44 27 ...\n $ Tenure         : num [1:10000] 2 1 8 1 2 8 7 4 4 2 ...\n $ Balance        : num [1:10000] 0 83808 159661 0 125511 ...\n $ NumOfProducts  : num [1:10000] 1 1 3 2 1 2 2 4 2 1 ...\n $ HasCrCard      : num [1:10000] 1 0 1 0 1 1 1 1 0 1 ...\n $ IsActiveMember : num [1:10000] 1 1 0 0 1 0 1 0 1 1 ...\n $ EstimatedSalary: num [1:10000] 101349 112543 113932 93827 79084 ...\n $ Exited         : num [1:10000] 1 0 1 0 0 1 0 1 0 0 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   RowNumber = col_double(),\n  ..   CustomerId = col_double(),\n  ..   Surname = col_character(),\n  ..   CreditScore = col_double(),\n  ..   Geography = col_character(),\n  ..   Gender = col_character(),\n  ..   Age = col_double(),\n  ..   Tenure = col_double(),\n  ..   Balance = col_double(),\n  ..   NumOfProducts = col_double(),\n  ..   HasCrCard = col_double(),\n  ..   IsActiveMember = col_double(),\n  ..   EstimatedSalary = col_double(),\n  ..   Exited = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr>"
  },
  {
    "objectID": "posts/FinalProject_ManiShankerKamarapu.html#descriptive-statistics",
    "href": "posts/FinalProject_ManiShankerKamarapu.html#descriptive-statistics",
    "title": "Final project part 1",
    "section": "Descriptive statistics",
    "text": "Descriptive statistics\n\n\nCode\nsummary(Churn)\n\n\n   RowNumber       CustomerId         Surname           CreditScore   \n Min.   :    1   Min.   :15565701   Length:10000       Min.   :350.0  \n 1st Qu.: 2501   1st Qu.:15628528   Class :character   1st Qu.:584.0  \n Median : 5000   Median :15690738   Mode  :character   Median :652.0  \n Mean   : 5000   Mean   :15690941                      Mean   :650.5  \n 3rd Qu.: 7500   3rd Qu.:15753234                      3rd Qu.:718.0  \n Max.   :10000   Max.   :15815690                      Max.   :850.0  \n  Geography            Gender               Age            Tenure      \n Length:10000       Length:10000       Min.   :18.00   Min.   : 0.000  \n Class :character   Class :character   1st Qu.:32.00   1st Qu.: 3.000  \n Mode  :character   Mode  :character   Median :37.00   Median : 5.000  \n                                       Mean   :38.92   Mean   : 5.013  \n                                       3rd Qu.:44.00   3rd Qu.: 7.000  \n                                       Max.   :92.00   Max.   :10.000  \n    Balance       NumOfProducts    HasCrCard      IsActiveMember  \n Min.   :     0   Min.   :1.00   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:     0   1st Qu.:1.00   1st Qu.:0.0000   1st Qu.:0.0000  \n Median : 97199   Median :1.00   Median :1.0000   Median :1.0000  \n Mean   : 76486   Mean   :1.53   Mean   :0.7055   Mean   :0.5151  \n 3rd Qu.:127644   3rd Qu.:2.00   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :250898   Max.   :4.00   Max.   :1.0000   Max.   :1.0000  \n EstimatedSalary         Exited      \n Min.   :    11.58   Min.   :0.0000  \n 1st Qu.: 51002.11   1st Qu.:0.0000  \n Median :100193.91   Median :0.0000  \n Mean   :100090.24   Mean   :0.2037  \n 3rd Qu.:149388.25   3rd Qu.:0.0000  \n Max.   :199992.48   Max.   :1.0000  \n\n\n\n\nCode\nglimpse(Churn)\n\n\nRows: 10,000\nColumns: 14\n$ RowNumber       <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ CustomerId      <dbl> 15634602, 15647311, 15619304, 15701354, 15737888, 1557…\n$ Surname         <chr> \"Hargrave\", \"Hill\", \"Onio\", \"Boni\", \"Mitchell\", \"Chu\",…\n$ CreditScore     <dbl> 619, 608, 502, 699, 850, 645, 822, 376, 501, 684, 528,…\n$ Geography       <chr> \"France\", \"Spain\", \"France\", \"France\", \"Spain\", \"Spain…\n$ Gender          <chr> \"Female\", \"Female\", \"Female\", \"Female\", \"Female\", \"Mal…\n$ Age             <dbl> 42, 41, 42, 39, 43, 44, 50, 29, 44, 27, 31, 24, 34, 25…\n$ Tenure          <dbl> 2, 1, 8, 1, 2, 8, 7, 4, 4, 2, 6, 3, 10, 5, 7, 3, 1, 9,…\n$ Balance         <dbl> 0.00, 83807.86, 159660.80, 0.00, 125510.82, 113755.78,…\n$ NumOfProducts   <dbl> 1, 1, 3, 2, 1, 2, 2, 4, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, …\n$ HasCrCard       <dbl> 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, …\n$ IsActiveMember  <dbl> 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, …\n$ EstimatedSalary <dbl> 101348.88, 112542.58, 113931.57, 93826.63, 79084.10, 1…\n$ Exited          <dbl> 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, …"
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html",
    "href": "posts/HW1_ManiShankerKamarapu.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(stats)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#question-1",
    "href": "posts/HW1_ManiShankerKamarapu.html#question-1",
    "title": "Homework 1",
    "section": "Question 1",
    "text": "Question 1"
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#reading-data",
    "href": "posts/HW1_ManiShankerKamarapu.html#reading-data",
    "title": "Homework 1",
    "section": "Reading data",
    "text": "Reading data\n\n\nCode\nLc <- read_excel(\"_data/LungCapData.xls\")\nLc\n\n\n\n\n  \n\n\n\nThe data consists of 725 rows and 6 columns. It determines the lung capacity of the based on their age, height and different characteristics. The main key classification that I can see is if they smoke or not."
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#a",
    "href": "posts/HW1_ManiShankerKamarapu.html#a",
    "title": "Homework 1",
    "section": "1a",
    "text": "1a\nThe distribution of LungCap looks as follows:\n\n\nCode\nLc %>%\n  ggplot(aes(LungCap, ..density..)) +\n  geom_histogram(bins= 25, color = \"orange\") +\n  geom_density(color = \"darkblue\") +\n  theme_classic() + \n  labs(title = \"Probability distribution of LungCap\", x = \"Lung Capcity\", y = \"Probability density\")\n\n\n\n\n\nThe histogram and density plots show that it is pretty close to a normal distribution. Most of the observations are close to the mean."
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#b",
    "href": "posts/HW1_ManiShankerKamarapu.html#b",
    "title": "Homework 1",
    "section": "1b",
    "text": "1b\nThe distribution of LungCap on basis of gender looks as follows:\n\n\nCode\nLc %>%\n  ggplot(aes(y = dnorm(LungCap), color = Gender)) +\n  geom_boxplot() +\n  theme_classic() + \n  labs(title = \"Probability distribution of LungCap based on gender\", y = \"Probability density\")\n\n\n\n\n\nThe box plot shows that the probability density of the male is lesser than the female."
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#c",
    "href": "posts/HW1_ManiShankerKamarapu.html#c",
    "title": "Homework 1",
    "section": "1c",
    "text": "1c\nComparison of mean lung capacities between smokers and non-smokers:\n\n\nCode\nMean_smoke <- Lc %>%\n  group_by(Smoke) %>%\n  summarise(mean = mean(LungCap))\nMean_smoke\n\n\n\n\n  \n\n\n\nFrom the above table, we see that the mean lung capacity of those who smoke is greater than those who don’t smoke, but it doesn’t make sense. It also depends on the biological factors of the person who smoke, so we can’t conclude it."
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#d",
    "href": "posts/HW1_ManiShankerKamarapu.html#d",
    "title": "Homework 1",
    "section": "1d",
    "text": "1d\nRelationship between Smoke and Lung capacity on basis of given age categories:\n\n\nCode\nLc <- mutate(Lc, AgeGrp = case_when(Age <= 13 ~ \"less than or equal to 13\",\n                                    Age == 14 | Age == 15 ~ \"14 to 15\",\n                                    Age == 16 | Age == 17 ~ \"16 to 17\",\n                                    Age >= 18 ~ \"greater than or equal to 18\"))\n\nLc %>%\n  ggplot(aes(y = LungCap, color = Smoke)) +\n  geom_histogram(bins = 25) +\n  facet_wrap(vars(AgeGrp)) +\n  theme_classic() + \n  labs(title = \"Relationship of LungCap and Smoke based on age categories\", y = \"Lung Capacity\", x = \"Frequency\")\n\n\n\n\n\nFrom the above plot, we can derive two important observations: 1. The lung capacity of non smokers is more than smokers. 2. The people who smoke are less in age group of “less than or equal to 13”. So as the result as age increases the lung capacity decreases."
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#e",
    "href": "posts/HW1_ManiShankerKamarapu.html#e",
    "title": "Homework 1",
    "section": "1e",
    "text": "1e\nRelationship between Smoke and Lung capacity on basis of age:\n\n\nCode\nLc %>%\n  ggplot(aes(x = Age, y = LungCap, color = Smoke)) +\n  geom_line() +\n  theme_classic() + \n  facet_wrap(vars(Smoke)) +\n  labs(title = \"Relationship of LungCap and Smoke based on age\", y = \"Lung Capacity\", x = \"Age\")\n\n\n\n\n\nForm the above data we can compare 1d and 1e and can say the results are pretty similar. Only 10 and above age group smoke."
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#f",
    "href": "posts/HW1_ManiShankerKamarapu.html#f",
    "title": "Homework 1",
    "section": "1f",
    "text": "1f\nCalculating the correlation and covariance between Lung Capacity and Age:\n\n\nCode\nCovariance <- cov(Lc$LungCap, Lc$Age)\nCorrelation <- cor(Lc$LungCap, Lc$Age)\nCovariance\n\n\n[1] 8.738289\n\n\nCode\nCorrelation\n\n\n[1] 0.8196749\n\n\nWe can observe from the comparison that the covariance is positive and it indicates that there is a direct relationship between age and lung capacity. And the correlation is also positive, so they move in same direction. We can say from these results that as the age increases, the lung capacity also increases that is they are directly proportional to each other."
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#question-2",
    "href": "posts/HW1_ManiShankerKamarapu.html#question-2",
    "title": "Homework 1",
    "section": "Question 2",
    "text": "Question 2"
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#reading-the-table",
    "href": "posts/HW1_ManiShankerKamarapu.html#reading-the-table",
    "title": "Homework 1",
    "section": "Reading the table",
    "text": "Reading the table\n\n\nCode\nPrior_convitions <- c(0:4)\nInmate_count <- c(128, 434, 160, 64, 24)\nPc <- data_frame(Prior_convitions, Inmate_count)\n\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nPlease use `tibble()` instead.\n\n\nCode\nPc\n\n\n\n\n  \n\n\n\n\n\nCode\nPc <- mutate(Pc, Probability = Inmate_count/sum(Inmate_count))\nPc"
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#a-1",
    "href": "posts/HW1_ManiShankerKamarapu.html#a-1",
    "title": "Homework 1",
    "section": "2a",
    "text": "2a\nProbability that a randomly selected inmate has exactly 2 prior convictions:\n\n\nCode\nPc %>%\n  filter(Prior_convitions == 2) %>%\n  select(Probability)"
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#b-1",
    "href": "posts/HW1_ManiShankerKamarapu.html#b-1",
    "title": "Homework 1",
    "section": "2b",
    "text": "2b\nProbability that a randomly selected inmate has fewer than 2 convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions < 2)\nsum(temp$Probability)\n\n\n[1] 0.6938272"
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#c-1",
    "href": "posts/HW1_ManiShankerKamarapu.html#c-1",
    "title": "Homework 1",
    "section": "2c",
    "text": "2c\nProbability that a randomly selected inmate has 2 or fewer prior convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions <= 2)\nsum(temp$Probability)\n\n\n[1] 0.891358"
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#d-1",
    "href": "posts/HW1_ManiShankerKamarapu.html#d-1",
    "title": "Homework 1",
    "section": "2d",
    "text": "2d\nProbability that a randomly selected inmate has more than 2 prior convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions > 2)\nsum(temp$Probability)\n\n\n[1] 0.108642"
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#e-1",
    "href": "posts/HW1_ManiShankerKamarapu.html#e-1",
    "title": "Homework 1",
    "section": "2e",
    "text": "2e\nExpected value for the number of prior convictions:\n\n\nCode\nPc <- mutate(Pc, Wm = Prior_convitions*Probability)\ne <- sum(Pc$Wm)\ne\n\n\n[1] 1.28642"
  },
  {
    "objectID": "posts/HW1_ManiShankerKamarapu.html#f-1",
    "href": "posts/HW1_ManiShankerKamarapu.html#f-1",
    "title": "Homework 1",
    "section": "2f",
    "text": "2f\nVariance for the Prior Convictions:\n\n\nCode\nv <-sum(((Pc$Prior_convitions-e)^2)*Pc$Probability)\nv\n\n\n[1] 0.8562353\n\n\nstandard deviation for the Prior Convictions:\n\n\nCode\nsqrt(v)\n\n\n[1] 0.9253298"
  },
  {
    "objectID": "posts/MEGHA JOSEPH_BLOG1.html",
    "href": "posts/MEGHA JOSEPH_BLOG1.html",
    "title": "Project Proposal",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(dplyr)"
  },
  {
    "objectID": "posts/MEGHA JOSEPH_BLOG1.html#research-question",
    "href": "posts/MEGHA JOSEPH_BLOG1.html#research-question",
    "title": "Project Proposal",
    "section": "Research Question",
    "text": "Research Question\nAccording to statistics,Cardiovascular diseases (CVDs) kill approximately 17 million people globally every year.Most cardiovascular diseases can be prevented by addressing behavioural risk factors such as tobacco use, unhealthy diet and obesity, physical inactivity and harmful use of alcohol using population-wide strategies. People with cardiovascular disease or who are at high cardiovascular risk (due to the presence of one or more risk factors such as hypertension, diabetes, hyperlipidaemia or already established disease) need early detection and management. Research question is: Which clinical feature will lead to high cardiovascular risk?"
  },
  {
    "objectID": "posts/MEGHA JOSEPH_BLOG1.html#hypothesis",
    "href": "posts/MEGHA JOSEPH_BLOG1.html#hypothesis",
    "title": "Project Proposal",
    "section": "Hypothesis",
    "text": "Hypothesis\n1:Behavioral risk factors will not underline significant predictors of predicting Heart Failure.\n2:Behavioral risk factors will underline significant predictors of predicting Heart Failure ."
  },
  {
    "objectID": "posts/MEGHA JOSEPH_BLOG1.html#descriptive-statistics",
    "href": "posts/MEGHA JOSEPH_BLOG1.html#descriptive-statistics",
    "title": "Project Proposal",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\nI am going to analyze a dataset of 299 patients with heart failure collected in 2015.This dataset is comprised of self-reported survey, with 13 clinical features. data.https://www.kaggle.com/datasets/whenamancodes/heart-failure-clinical-records. The important variables of research are ejection fraction, serum creatinine, and smoking.\n.\n\n\nCode\nlibrary(readr)\nmf <- read_csv(\"C:/Users/user/Downloads/Heart Failure Clinical Records.csv\")\nsummary(mf)\n``\n\n\nError: attempt to use zero-length variable name"
  },
  {
    "objectID": "posts/MEGHA JOSEPH_BLOG1.html#references",
    "href": "posts/MEGHA JOSEPH_BLOG1.html#references",
    "title": "Project Proposal",
    "section": "References",
    "text": "References\n\nSurvival prediction of heart failure patients using machine learning techniques *. (n.d.). Retrieved October 11, 2022, from https://www.sciencedirect.com/science/article/pii/S2352914821002458\n\nMachine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone. https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-020-1023-5"
  },
  {
    "objectID": "posts/HW2_EmmaRasmussen.html",
    "href": "posts/HW2_EmmaRasmussen.html",
    "title": "Homework 2",
    "section": "",
    "text": "Code\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)\n\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(dplyr)"
  },
  {
    "objectID": "posts/HW2_EmmaRasmussen.html#section",
    "href": "posts/HW2_EmmaRasmussen.html#section",
    "title": "Homework 2",
    "section": "1.",
    "text": "1.\n\n\nCode\n#Bypass\n#calculating t-score for 90% confidence interval\ntscoreb<- qt(p=1-.05, df=539-1)\n\n#calculating standard error\nseb<- 10/sqrt(539)\n\nmeanb<- 19\n\nCIb<- c(meanb- (tscoreb*seb), meanb+ (tscoreb*seb))\nCIb\n\n\n[1] 18.29029 19.70971\n\n\nCode\n#Angiography\n#calculating t-score for 90% confidence interval\ntscorea<- qt(p=1-.05, df=847-1)\n\n#calculating standard error\nsea<- 9/sqrt(847)\n\nmeana<- 18\n\nCIa<- c(meana- (tscorea*sea), meana+ (tscorea*sea))\nCIa\n\n\n[1] 17.49078 18.50922\n\n\nThe 90% confidence interval for bypass is [18.29, 19.71] days. The 90% confidence interval for angiography is [17.49, 18.51] days. The confidence interval for angiography is narrower, which makes sense given it has a (slightly) smaller standard deviation and a larger sample size (larger sample size reduces margin of error)."
  },
  {
    "objectID": "posts/HW2_EmmaRasmussen.html#section-1",
    "href": "posts/HW2_EmmaRasmussen.html#section-1",
    "title": "Homework 2",
    "section": "2.",
    "text": "2.\n\n\nCode\n#assigning n= number of trials\nn<- 1031\n#assigning k= number agree\nk<- 567\n\n#calculating point estimate\np<- 567/1031\np\n\n\n[1] 0.5499515\n\n\nCode\n#calculating margin of error for 95% CI. I have no idea how to calculate a confidence interval without a sd. I found this formula online.\nmargin<- qnorm(0.975)*sqrt(p*(1-p)/n)\nmargin\n\n\n[1] 0.03036761\n\n\nCode\nCI<- c(p-margin, p+ margin)\nCI\n\n\n[1] 0.5195839 0.5803191\n\n\nThe 95% confidence interval for American’s agreeing that college education is essential for success is [51.96, 58.03]%. The point estimate for this value based on the survey is 55%."
  },
  {
    "objectID": "posts/HW2_EmmaRasmussen.html#section-2",
    "href": "posts/HW2_EmmaRasmussen.html#section-2",
    "title": "Homework 2",
    "section": "3.",
    "text": "3.\n\n\nCode\n#estimating population standard deviation\n(200-30)/4\n\n\n[1] 42.5\n\n\nCode\n#solving for n in the equation for confidence intervals 5=1.96*(42.5/sqrt(n))\n#n= 277.56 or 278\n\n\nBy plugging in 5 to the formula for confidence intervals (the t-value for 95%, and the standard deviation estimate of 42.5) we get a value of n=277.56 or 278 need to be in the sample to retrieve a confidence interval of width 10."
  },
  {
    "objectID": "posts/HW2_EmmaRasmussen.html#section-3",
    "href": "posts/HW2_EmmaRasmussen.html#section-3",
    "title": "Homework 2",
    "section": "4.",
    "text": "4.\n\na.\n\nAssume data is normally distributed\nHo: μ =500\nHa: μ not equal to 500 μ < 500 μ > 500\nalpha level =0.05\n\n\n\nCode\n#calculating the standard error\nsef<- 90/sqrt(9)\nsef\n\n\n[1] 30\n\n\nCode\n#calculating t-score\ntf<-(410-500)/(sef)\ntf \n\n\n[1] -3\n\n\nCode\n#calculating the p-value from the test statistic (multiply times two because we are doing a two-sided test)\n(pt(q=-3, df=8))*2\n\n\n[1] 0.01707168\n\n\nCode\n#this represents the probability of getting a random sample from the population with a mean of 410 or lower, as the default calculates the lower tail)\npt(-3, 8)\n\n\n[1] 0.008535841\n\n\nCode\n#this represents the probability of getting a random sample from the population with a mean of 410 or higher, as we included lower.tail=FALSE)\npt(-3, 8, lower.tail=FALSE)\n\n\n[1] 0.9914642\n\n\nCode\n# since our p-value is 0.99 we do not have evidence that the mean income of female employees is greater than 500 a week\n\n\nTwo-sided: Since our p-value is 0.017 we can reject the null hypothesis at alpha level=0.05. We have evidence that the mean weekly earnings for women at this company is different from $500. ### b. Lower tail: Since our p-value (0.0085) is less than the alpha level of 0.05, we can reject the null. We have evidence that the mean weekly earnings at this company for women is less than $500. ### c.  Upper tail: Since our p-value is 0.99 we do not have evidence that the mean income of female employees is greater than $500 a week"
  },
  {
    "objectID": "posts/HW2_EmmaRasmussen.html#section-4",
    "href": "posts/HW2_EmmaRasmussen.html#section-4",
    "title": "Homework 2",
    "section": "5.",
    "text": "5.\n\na.\n\n\nCode\n#Jones\n#calculating t-score\n(519.5-500)/(10)\n\n\n[1] 1.95\n\n\nCode\n#Calculating from p value from t-score. Because it is a two sided test, we multiply the result times two.\n(pt(q=1.95, df=999, lower.tail=FALSE))*2\n\n\n[1] 0.05145555\n\n\nCode\n#Smith\n##calculating t-score\n(519.7-500)/(10)\n\n\n[1] 1.97\n\n\nCode\n#Calculating from p value from t-score. Because it is a two sided test, we multiply the result times two.\n(pt(q=1.97, df=999, lower.tail=FALSE))*2\n\n\n[1] 0.04911426\n\n\n\n\nb.\nAt the .05 significance level, Jones’ findings are not significant but Smith’s findings are.\n\n\nc.\nThis example shows that there is a very find line between rejecting and not rejecting the null hypothesis. Their findings were extremely similar, the means are different by only 0.2. In this way, reporting the p-value retrieved is actually really important to make this distinction. Similarly, Jones’ findings would have been significant at the 0.1 significance level, so rejecting or not rejecting the null hypothesis based on a p-value can be fairly arbitrary."
  },
  {
    "objectID": "posts/HW2_EmmaRasmussen.html#section-5",
    "href": "posts/HW2_EmmaRasmussen.html#section-5",
    "title": "Homework 2",
    "section": "6.",
    "text": "6.\n\n\nCode\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\nt.test(gas_taxes, mu=45.0, alternative=\"less\")\n\n\n\n    One Sample t-test\n\ndata:  gas_taxes\nt = -1.8857, df = 17, p-value = 0.03827\nalternative hypothesis: true mean is less than 45\n95 percent confidence interval:\n     -Inf 44.67946\nsample estimates:\nmean of x \n 40.86278 \n\n\nUsing a 95% confidence level we get a p-value of 0.038. We reject the null hypothesis. We have evidence that the average tax per gallon of gas in the U.S. is less than 45 cents."
  },
  {
    "objectID": "posts/Niharika_HW1.html#question-1",
    "href": "posts/Niharika_HW1.html#question-1",
    "title": "Homework 1",
    "section": "Question 1",
    "text": "Question 1"
  },
  {
    "objectID": "posts/Niharika_HW1.html#reading-data",
    "href": "posts/Niharika_HW1.html#reading-data",
    "title": "Homework 1",
    "section": "Reading data",
    "text": "Reading data\n\n\nCode\nLc <- read_excel(\"LungCapData.xls\")\n\n\nError: `path` does not exist: 'LungCapData.xls'\n\n\nCode\nLc\n\n\nError in eval(expr, envir, enclos): object 'Lc' not found\n\n\nThe data consists of 725 rows and 6 columns. It determines the lung capacity of the based on their age, height and different characteristics. The main key classification that I can see is if they smoke or not."
  },
  {
    "objectID": "posts/Niharika_HW1.html#a",
    "href": "posts/Niharika_HW1.html#a",
    "title": "Homework 1",
    "section": "1a",
    "text": "1a\nThe distribution of LungCap looks as follows:\n\n\nCode\nLc %>%\n  ggplot(aes(LungCap, ..density..)) +\n  geom_histogram(bins= 25, color = \"orange\") +\n  geom_density(color = \"darkblue\") +\n  theme_classic() + \n  labs(title = \"Probability distribution of LungCap\", x = \"Lung Capcity\", y = \"Probability density\")\n\n\nError in ggplot(., aes(LungCap, ..density..)): object 'Lc' not found\n\n\nThe histogram and density plots show that it is pretty close to a normal distribution. Most of the observations are close to the mean."
  },
  {
    "objectID": "posts/Niharika_HW1.html#b",
    "href": "posts/Niharika_HW1.html#b",
    "title": "Homework 1",
    "section": "1b",
    "text": "1b\nThe distribution of LungCap on basis of gender looks as follows:\n\n\nCode\nLc %>%\n  ggplot(aes(y = dnorm(LungCap), color = Gender)) +\n  geom_boxplot() +\n  theme_classic() + \n  labs(title = \"Probability distribution of LungCap based on gender\", y = \"Probability density\")\n\n\nError in ggplot(., aes(y = dnorm(LungCap), color = Gender)): object 'Lc' not found\n\n\nThe box plot shows that the probability density of the male is lesser than the female."
  },
  {
    "objectID": "posts/Niharika_HW1.html#c",
    "href": "posts/Niharika_HW1.html#c",
    "title": "Homework 1",
    "section": "1c",
    "text": "1c\nComparison of mean lung capacities between smokers and non-smokers:\n\n\nCode\nMean_smoke <- Lc %>%\n  group_by(Smoke) %>%\n  summarise(mean = mean(LungCap))\n\n\nError in group_by(., Smoke): object 'Lc' not found\n\n\nCode\nMean_smoke\n\n\nError in eval(expr, envir, enclos): object 'Mean_smoke' not found\n\n\nFrom the above table, we see that the mean lung capacity of those who smoke is greater than those who don’t smoke, but it doesn’t make sense. It also depends on the biological factors of the person who smoke, so we can’t conclude it."
  },
  {
    "objectID": "posts/Niharika_HW1.html#d",
    "href": "posts/Niharika_HW1.html#d",
    "title": "Homework 1",
    "section": "1d",
    "text": "1d\nRelationship between Smoke and Lung capacity on basis of given age categories:\n\n\nCode\nLc <- mutate(Lc, AgeGrp = case_when(Age <= 13 ~ \"less than or equal to 13\",\n                                    Age == 14 | Age == 15 ~ \"14 to 15\",\n                                    Age == 16 | Age == 17 ~ \"16 to 17\",\n                                    Age >= 18 ~ \"greater than or equal to 18\"))\n\n\nError in mutate(Lc, AgeGrp = case_when(Age <= 13 ~ \"less than or equal to 13\", : object 'Lc' not found\n\n\nCode\nLc %>%\n  ggplot(aes(y = LungCap, color = Smoke)) +\n  geom_histogram(bins = 25) +\n  facet_wrap(vars(AgeGrp)) +\n  theme_classic() + \n  labs(title = \"Relationship of LungCap and Smoke based on age categories\", y = \"Lung Capacity\", x = \"Frequency\")\n\n\nError in ggplot(., aes(y = LungCap, color = Smoke)): object 'Lc' not found\n\n\nFrom the above plot, we can derive two important observations: 1. The lung capacity of non smokers is more than smokers. 2. The people who smoke are less in age group of “less than or equal to 13”. So as the result as age increases the lung capacity decreases."
  },
  {
    "objectID": "posts/Niharika_HW1.html#e",
    "href": "posts/Niharika_HW1.html#e",
    "title": "Homework 1",
    "section": "1e",
    "text": "1e\nRelationship between Smoke and Lung capacity on basis of age:\n\n\nCode\nLc %>%\n  ggplot(aes(x = Age, y = LungCap, color = Smoke)) +\n  geom_line() +\n  theme_classic() + \n  facet_wrap(vars(Smoke)) +\n  labs(title = \"Relationship of LungCap and Smoke based on age\", y = \"Lung Capacity\", x = \"Age\")\n\n\nError in ggplot(., aes(x = Age, y = LungCap, color = Smoke)): object 'Lc' not found\n\n\nForm the above data we can compare 1d and 1e and can say the results are pretty similar. Only 10 and above age group smoke."
  },
  {
    "objectID": "posts/Niharika_HW1.html#f",
    "href": "posts/Niharika_HW1.html#f",
    "title": "Homework 1",
    "section": "1f",
    "text": "1f\nCalculating the correlation and covariance between Lung Capacity and Age:\n\n\nCode\nCovariance <- cov(Lc$LungCap, Lc$Age)\n\n\nError in is.data.frame(y): object 'Lc' not found\n\n\nCode\nCorrelation <- cor(Lc$LungCap, Lc$Age)\n\n\nError in is.data.frame(y): object 'Lc' not found\n\n\nCode\nCovariance\n\n\nError in eval(expr, envir, enclos): object 'Covariance' not found\n\n\nCode\nCorrelation\n\n\nError in eval(expr, envir, enclos): object 'Correlation' not found\n\n\nWe can observe from the comparison that the covariance is positive and it indicates that there is a direct relationship between age and lung capacity. And the correlation is also positive, so they move in same direction. We can say from these results that as the age increases, the lung capacity also increases that is they are directly proportional to each other."
  },
  {
    "objectID": "posts/Niharika_HW1.html#question-2",
    "href": "posts/Niharika_HW1.html#question-2",
    "title": "Homework 1",
    "section": "Question 2",
    "text": "Question 2"
  },
  {
    "objectID": "posts/Niharika_HW1.html#reading-the-table",
    "href": "posts/Niharika_HW1.html#reading-the-table",
    "title": "Homework 1",
    "section": "Reading the table",
    "text": "Reading the table\n\n\nCode\nPrior_convitions <- c(0:4)\nInmate_count <- c(128, 434, 160, 64, 24)\nPc <- data_frame(Prior_convitions, Inmate_count)\n\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nℹ Please use `tibble()` instead.\n\n\nCode\nPc\n\n\n\n\n  \n\n\n\n\n\nCode\nPc <- mutate(Pc, Probability = Inmate_count/sum(Inmate_count))\nPc"
  },
  {
    "objectID": "posts/Niharika_HW1.html#a-1",
    "href": "posts/Niharika_HW1.html#a-1",
    "title": "Homework 1",
    "section": "2a",
    "text": "2a\nProbability that a randomly selected inmate has exactly 2 prior convictions:\n\n\nCode\nPc %>%\n  filter(Prior_convitions == 2) %>%\n  select(Probability)"
  },
  {
    "objectID": "posts/Niharika_HW1.html#b-1",
    "href": "posts/Niharika_HW1.html#b-1",
    "title": "Homework 1",
    "section": "2b",
    "text": "2b\nProbability that a randomly selected inmate has fewer than 2 convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions < 2)\nsum(temp$Probability)\n\n\n[1] 0.6938272"
  },
  {
    "objectID": "posts/Niharika_HW1.html#c-1",
    "href": "posts/Niharika_HW1.html#c-1",
    "title": "Homework 1",
    "section": "2c",
    "text": "2c\nProbability that a randomly selected inmate has 2 or fewer prior convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions <= 2)\nsum(temp$Probability)\n\n\n[1] 0.891358"
  },
  {
    "objectID": "posts/Niharika_HW1.html#d-1",
    "href": "posts/Niharika_HW1.html#d-1",
    "title": "Homework 1",
    "section": "2d",
    "text": "2d\nProbability that a randomly selected inmate has more than 2 prior convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions > 2)\nsum(temp$Probability)\n\n\n[1] 0.108642"
  },
  {
    "objectID": "posts/Niharika_HW1.html#e-1",
    "href": "posts/Niharika_HW1.html#e-1",
    "title": "Homework 1",
    "section": "2e",
    "text": "2e\nExpected value for the number of prior convictions:\n\n\nCode\nPc <- mutate(Pc, Wm = Prior_convitions*Probability)\ne <- sum(Pc$Wm)\ne\n\n\n[1] 1.28642"
  },
  {
    "objectID": "posts/Niharika_HW1.html#f-1",
    "href": "posts/Niharika_HW1.html#f-1",
    "title": "Homework 1",
    "section": "2f",
    "text": "2f\nVariance for the Prior Convictions:\n\n\nCode\nv <-sum(((Pc$Prior_convitions-e)^2)*Pc$Probability)\nv\n\n\n[1] 0.8562353\n\n\nstandard deviation for the Prior Convictions:\n\n\nCode\nsqrt(v)\n\n\n[1] 0.9253298"
  },
  {
    "objectID": "posts/Homework 1 LJones.html",
    "href": "posts/Homework 1 LJones.html",
    "title": "Homework 1",
    "section": "",
    "text": "First I’ll load the libraries and read in the data.\n\n\nCode\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(readxl)\nlc <- read_excel(\"_data/LungCapData.xls\")\n\n\n\n\n\n\n\nThe distribution of lung capacity is as follows:\n\n\nCode\nhist(lc$LungCap)\n\n\n\n\n\nThe histogram appears close to the normal distribution.\n\n\n\n\n\nCode\nboxplot(LungCap~Gender, data=lc)\n\n\n\n\n\n\n\n\n\n\nCode\nlc %>%\n  group_by(Smoke) %>%\n  summarize(Mean = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke  Mean\n  <chr> <dbl>\n1 no     7.77\n2 yes    8.65\n\n\nInterestingly, the mean lung capacity is higher for smokers than it is for non-smokers.\n\n\n\n\n\nCode\nlcbyagegrp <- lc %>% \n  mutate(age_group = case_when(\n    Age <=13 ~ \"13 and Under\",\n    Age >=14 & Age <=15 ~\"14-15\",\n    Age >=16 & Age <=17 ~\"16 - 17\",\n    Age >=18 ~\"18+\")) %>% \n  arrange(age_group, Age)\n\nggplot(lcbyagegrp, aes(x = LungCap)) +\n  geom_histogram() +\n  facet_grid(age_group ~ Smoke)\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nCode\nlcbyagegrp %>%\n  group_by(age_group, Smoke) %>%\n  summarize(Mean = mean(LungCap))\n\n\n`summarise()` has grouped output by 'age_group'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 3\n# Groups:   age_group [4]\n  age_group    Smoke  Mean\n  <chr>        <chr> <dbl>\n1 13 and Under no     6.36\n2 13 and Under yes    7.20\n3 14-15        no     9.14\n4 14-15        yes    8.39\n5 16 - 17      no    10.5 \n6 16 - 17      yes    9.38\n7 18+          no    11.1 \n8 18+          yes   10.5 \n\n\n\n\nThe mean lung capacity for smokers aged 13 and under is higher than that of non-smokers in the same age group, which defies expectation. The rest of the age groups meet that expectation. There may be an error or extreme outlier in the data for smokers aged 13 and under.\n\n\n\n\n\n\nCode\nlc %>% cov(Age, LungCap)\n\n\nError in pmatch(use, c(\"all.obs\", \"complete.obs\", \"pairwise.complete.obs\", : object 'LungCap' not found\n\n\n\n\nCode\n#correlation\ncor(lc$LungCap,lc$Age)\n\n\n[1] 0.8196749\n\n\nCode\n#covariance\ncov(lc$LungCap, lc$Age)\n\n\n[1] 8.738289\n\n\nThe correlation is very close to positive 1, indicating a strong positive correlation between between lung capacity and age. The covariance being a positive number indicates a positive relationship.\n\n\n\n\n\n\nCode\nX <- c(0:4)\nFrequency <- c(128, 434, 160, 64, 24)\n\ndf <- data.frame(X, Frequency)\n\ndf\n\n\n  X Frequency\n1 0       128\n2 1       434\n3 2       160\n4 3        64\n5 4        24\n\n\n\n\n\n\nCode\ndf2 <- mutate(df, Probability = Frequency/sum(Frequency))\ndf2\n\n\n  X Frequency Probability\n1 0       128  0.15802469\n2 1       434  0.53580247\n3 2       160  0.19753086\n4 3        64  0.07901235\n5 4        24  0.02962963\n\n\nThe probability is about 19.75%.\n\n\n\n\n\nCode\nb2 <- df2 %>% \n  filter(X < 2)\n\nsum(b2$Probability)\n\n\n[1] 0.6938272\n\n\nThe probability is about 69%.\n\n\n\n\n\nCode\nc2 <- df2 %>% \n  filter(X <= 2)\n\nsum(c2$Probability)\n\n\n[1] 0.891358\n\n\nThe probability is about 89%.\n\n\n\n\n\nCode\nd2 <- df2 %>% \n  filter(X > 2)\n\nsum(d2$Probability)\n\n\n[1] 0.108642\n\n\nThe probability is about 10.9%.\n\n\n\n\n\nCode\ne <- weighted.mean(df2$X, df2$Probability)\ne\n\n\n[1] 1.28642\n\n\nThe expected number of prior convictions is about 1.286.\n\n\n\n\n\nCode\n#variance\nvariance <- (sum(Frequency*((X-e)^2)))/(sum(Frequency)-1)\nvariance\n\n\n[1] 0.8572937\n\n\nCode\n#standard deviation\nsd <- sqrt(variance)\nsd\n\n\n[1] 0.9259016\n\n\nThe variance of prior convictions is about 0.857, and the standard deviation (simply, the square root of the variance) is about 0.926."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html",
    "href": "posts/HW1_Saaradhaa.html",
    "title": "Homework 1",
    "section": "",
    "text": "knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)"
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#a",
    "href": "posts/HW1_Saaradhaa.html#a",
    "title": "Homework 1",
    "section": "1 (a)",
    "text": "1 (a)\nReading in the data:\n\n# load packages.\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(lsr)\n\n# read in data.\ndf <- read_excel(\"_data/LungCapData.xls\")\n\nDistribution of LungCap:\n\nhist(df$LungCap)\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15)."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#b",
    "href": "posts/HW1_Saaradhaa.html#b",
    "title": "Homework 1",
    "section": "1 (b)",
    "text": "1 (b)\nThe boxplots below show the probability distributions grouped by gender.\n\nboxplot(LungCap~Gender, data = df)\n\n\n\n\nMales appear to have a slightly greater lung capacity than females."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#c",
    "href": "posts/HW1_Saaradhaa.html#c",
    "title": "Homework 1",
    "section": "1 (c)",
    "text": "1 (c)\n\n# check class of Smoke.\nclass(df$Smoke)\n\n[1] \"character\"\n\n# convert Smoke to factor type.\ndf$Smoke <- as.factor(df$Smoke)\n\n# mean lung capacity for smokers.\ndf %>% select(Smoke, LungCap) %>% group_by(Smoke) %>% summarise(mean(LungCap))\n\n\n\n  \n\n\n\nIt does not make sense, as I did not expect smokers to have greater mean lung capacities than non-smokers."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#d",
    "href": "posts/HW1_Saaradhaa.html#d",
    "title": "Homework 1",
    "section": "1 (d)",
    "text": "1 (d)\n\n# check class of Age.\nclass(df$Age)\n\n[1] \"numeric\"\n\n# convert Age to categorical variable.\ndf <- mutate(df, AgeGroup = case_when(Age <= 13 ~ \"13 and below\", Age == 14 | Age == 15 ~ \"14 to 15\", Age == 16 | Age == 17 ~ \"16 to 17\", Age >= 18 ~ \"18 and above\"))\n\n# construct histogram.\nggplot(df, aes(x = LungCap)) +\n  geom_histogram() +\n  facet_grid(AgeGroup~Smoke)\n\n\n\n\nMost people seem to be non-smokers, and non-smokers seem to have greater lung capacity."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#e",
    "href": "posts/HW1_Saaradhaa.html#e",
    "title": "Homework 1",
    "section": "1 (e)",
    "text": "1 (e)\n\n# check class of AgeGroup.\nclass(df$AgeGroup)\n\n[1] \"character\"\n\n# convert AgeGroup to factor.\ndf$AgeGroup <- as.factor(df$AgeGroup)\n\n# construct table.\ndf %>% select(Smoke, LungCap, AgeGroup) %>% group_by(AgeGroup, Smoke) %>% summarise(mean(LungCap))\n\n\n\n  \n\n\n\nNon-smokers have greater mean lung capacity for ages 14-15, 16-17 and 18 and above. Smokers have greater mean lung capacity for age 13 and below, which is different from 1(d). There might be some extreme outliers affecting the results for those age 13 and below."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#f",
    "href": "posts/HW1_Saaradhaa.html#f",
    "title": "Homework 1",
    "section": "1 (f)",
    "text": "1 (f)\n\n# correlation.\ncor(df$LungCap,df$Age)\n\n[1] 0.8196749\n\n# covariance.\ncov(df$LungCap,df$Age)\n\n[1] 8.738289\n\n\nThe value of 0.82 for correlation indicates a strong positive relationship between lung capacity and age - as age increases, lung capacity increases. The covariance is a little harder to interpret - the positive value reflects a positive relationship between lung capacity and age, but it is hard to assess the strength of the relationship, given that covariance ranges from negative infinity to infinity. I would prefer to use correlation in most cases."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#a-1",
    "href": "posts/HW1_Saaradhaa.html#a-1",
    "title": "Homework 1",
    "section": "2 (a)",
    "text": "2 (a)\n\na <- 160/810\n\nThe probability that a randomly selected inmate has exactly 2 prior convictions is 0.1975309."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#b-1",
    "href": "posts/HW1_Saaradhaa.html#b-1",
    "title": "Homework 1",
    "section": "2 (b)",
    "text": "2 (b)\n\nb <- (128+434)/810\n\nThe probability that a randomly selected inmate has fewer than 2 prior convictions is 0.6938272."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#c-1",
    "href": "posts/HW1_Saaradhaa.html#c-1",
    "title": "Homework 1",
    "section": "2 (c)",
    "text": "2 (c)\n\nc <- (128+434+160)/810\n\nThe probability that a randomly selected inmate has 2 or fewer prior convictions is 0.891358."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#d-1",
    "href": "posts/HW1_Saaradhaa.html#d-1",
    "title": "Homework 1",
    "section": "2 (d)",
    "text": "2 (d)\n\nd <- (64+24)/810\n\nThe probability that a randomly selected inmate has more than 2 prior convictions is 0.108642."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#e-1",
    "href": "posts/HW1_Saaradhaa.html#e-1",
    "title": "Homework 1",
    "section": "2 (e)",
    "text": "2 (e)\n\n# multiply each value of X by its probability and add the products.\ne <- (0*(128/810)) + (1*(434/810)) + (2*(160/810)) + (3*(64/810)) + (4*(24/810))\n\nThe expected value for the number of prior convictions is 1.2864198. To be more precise, since number of prior convictions should not have decimal places, we can round this down to 1, which is what the line graph showed us as well."
  },
  {
    "objectID": "posts/HW1_Saaradhaa.html#f-1",
    "href": "posts/HW1_Saaradhaa.html#f-1",
    "title": "Homework 1",
    "section": "2 (f)",
    "text": "2 (f)\n\n# calculate required formula for each value of X.\nf1_0 <- ((0-e)^2) * (128/810)\nf1_1 <- ((1-e)^2) * (434/810)\nf1_2 <- ((2-e)^2) * (160/810)\nf1_3 <- ((3-e)^2) * (64/810)\nf1_4 <- ((4-e)^2) * (24/810)\n\n# sum up the above for variance.\nf1 <- f1_0 + f1_1 + f1_2 + f1_3 + f1_4\n\n# square root for SD.\nf2 <- sqrt(f1)\n\nFor prior convictions, the variance is 0.8562353 and the standard deviation is 0.9253298. In general, I think it might be more meaningful to calculate mode and proportions when generating descriptive statistics for number of prior convictions."
  },
  {
    "objectID": "posts/finalpart1.html",
    "href": "posts/finalpart1.html",
    "title": "finalpart1",
    "section": "",
    "text": "Are Women and Racial minorities underrepresented in STEM fields (Study & Career)? A predictive analysis of the likelihood of STEM careers.\n\n\nWomen are significantly underrepresented in STEM (science, technology, engineering, and mathematics) fields in the USA, making up less than a quarter of those working in STEM occupations (Noonan, [2017](https://stemeducationjournal.springeropen.com/articles/10.1186/s40594-020-00219-2#ref-CR13 “Noonan, R. Women in STEM: 2017 update (ESA Issue Brief #06-17). Office of the Chief Economist, Economics and Statistics Administration, U.S. Department of Commerce (November 13, 2017). Retrieved from https://www.commerce.gov/news/fact-sheets/2017/11/women-stem-2017-update\n“); Ong, Smith, & Ko, [2018](https://stemeducationjournal.springeropen.com/articles/10.1186/s40594-020-00219-2#ref-CR15”Ong, M., Smith, J. M., & Ko, L. T. (2018). Counterspaces for women of color in STEM higher education: marginal and central spaces for persistence and success. Journal of Research in Science Teaching, 55(2), 206–245. https://doi.org/10.1002/tea.21417\n.”)).\nRepresentation of women of color is even lower, with Hispanic, Asian, and African American women each receiving less than 5% of STEM bachelor's degrees in the USA (Ong et al., [2018](https://stemeducationjournal.springeropen.com/articles/10.1186/s40594-020-00219-2#ref-CR15 “Ong, M., Smith, J. M., & Ko, L. T. (2018). Counterspaces for women of color in STEM higher education: marginal and central spaces for persistence and success. Journal of Research in Science Teaching, 55(2), 206–245. https://doi.org/10.1002/tea.21417\n.”);\nBy the time students reach college, women are significantly underrepresented in STEM majors — for instance, only around 21% of engineering majors are women and only around 19% of computer and information science majors are women.https://www.aauw.org/resources/research/the-stem-gap/\nThe fact that women and racial minorities are still discriminated and underrepresented in the STEM in the 21st century while mankind is stepping foot on other planets is a topic to be given a serious thought.\nThe above mentioned articles are my motivation to perform this analysis in addition to the 2011 survey by US Department of Commerce showing that women and racial minorities are underrpresented in stem fields in two ways: They represent a disproportionatly small percentage of STEM degree holders, as well as STEM workers. These reports are linked below:\n\n“Women in STEM: A Gender Gap to Innovation”\n“Education Supports Racial and Ethnic Equality in STEM”\n\nThe goal of this project is to build a model to predict likelihood of working in a STEM (Science, Technology, Engineering, and Math) career based on basic demographics: Age, sex, race, state of origin."
  },
  {
    "objectID": "posts/finalpart1.html#hypothesis",
    "href": "posts/finalpart1.html#hypothesis",
    "title": "finalpart1",
    "section": "Hypothesis:",
    "text": "Hypothesis:\nMy hypothesis: Women and Racial minorities are underrepresented in STEM fields.\nThe above mentioned hypothesis has been tested and proved by many researchers and government survey analysis already. Bus i wish to perform this study again by modifying it by developing regression models to resume the likelihood of STEM careers.\n---\n\nLoading the libraries\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(stats)\n\nknitr::opts_chunk$set(echo = TRUE)\n\n\n\n\nReading the raw data\n\n\nCode\npop <- read.csv(\"C:/Users/91955/Desktop/603_Fall_2022/ss13pusa.csv\")\n\n\nWarning in file(file, \"rt\"): cannot open file 'C:/Users/91955/Desktop/\n603_Fall_2022/ss13pusa.csv': No such file or directory\n\n\nError in file(file, \"rt\"): cannot open the connection\n\n\nCode\nhead(pop)\n\n\nError in head(pop): object 'pop' not found"
  },
  {
    "objectID": "posts/finalpart1.html#descriptive-statistics",
    "href": "posts/finalpart1.html#descriptive-statistics",
    "title": "finalpart1",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\n\n\nCode\nsummary(pop)\n\n\nError in summary(pop): object 'pop' not found\n\n\nCode\nnrow(pop)\n\n\nError in nrow(pop): object 'pop' not found\n\n\nCode\nncol(pop)\n\n\nError in ncol(pop): object 'pop' not found\n\n\nCode\nglimpse(pop)\n\n\nError in glimpse(pop): object 'pop' not found\n\n\n\n\nThe data has 1613672 rows and 238 columns. The variables I am interested in are AGEP, SEX, HISP, POBP, RAC1P, SCIENGP, SOCP.\nThe data needs cleaning and rearranging the columns and rows."
  },
  {
    "objectID": "posts/FinalProjectProposal_Saaradhaa.html",
    "href": "posts/FinalProjectProposal_Saaradhaa.html",
    "title": "Final Project Proposal",
    "section": "",
    "text": "Code\n# load libraries.\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(summarytools)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/FinalProjectProposal_Saaradhaa.html#introduction",
    "href": "posts/FinalProjectProposal_Saaradhaa.html#introduction",
    "title": "Final Project Proposal",
    "section": "Introduction",
    "text": "Introduction\nPrior research literature in the social sciences has continually stressed the need for more research on the Global South. However, few papers actually focus on it. Hence, I am interested to learn more about this region. A data source that lends itself useful for this is the World Values Survey, a global survey with an easily accessible database.\nI am specifically interested in understanding what drives subjective well-being, which can be interpreted via happiness and life satisfaction (Addai et al., 2013).\n\n\n\n\n\n\nResearch Questions\n\n\n\nA. What predicts happiness and life satisfaction in the Global South?\nB. Do predictors of happiness and life satisfaction differ between the Global North and South?\n\n\nThis project will be useful to better understand motivations and desires in the Global South, reduce inter-cultural tensions and enhance cross-cultural cohesion. Governments can also benefit from this research in terms of policy prioritization to maximize citizens’ well-being."
  },
  {
    "objectID": "posts/FinalProjectProposal_Saaradhaa.html#hypothesis",
    "href": "posts/FinalProjectProposal_Saaradhaa.html#hypothesis",
    "title": "Final Project Proposal",
    "section": "Hypothesis",
    "text": "Hypothesis\nPast researchers have studied happiness and life satisfaction in the Global South via the World Values Survey (Addai et al., 2013; Ngamaba, 2016). The studies focused on Ghana and Rwanda respectively. The common predictors of happiness and life satisfaction across both countries were satisfaction with health and income.\nTo the best of my knowledge, few studies comparing well-being in the Global North and South exist. Alba (2019) found that happiness was generally greater in the Global North than the Global South, and indicated that future research should attempt to cover the factors behind this. I think happiness and well-being in the Global North may depend on more subjective measures, given that health and income-related issues should be relatively more accounted for.\nGiven the above, we can frame our hypotheses as follows:\n\n\n\n\n\n\nH0A\n\n\n\nHealth and financial satisfaction will not be statistically significant predictors of happiness and life satisfaction in the Global South.\n\n\n\n\n\n\n\n\nH1A\n\n\n\nHealth and financial satisfaction will be statistically significant predictors of happiness and life satisfaction in the Global South.\n\n\n\n\n\n\n\n\nH0B\n\n\n\nPredictors of happiness and life satisfaction will not differ between the Global North and South.\n\n\n\n\n\n\n\n\nH1B\n\n\n\nPredictors of happiness and life satisfaction will differ between the Global North and South."
  },
  {
    "objectID": "posts/Emily Duryea Homework 1.html",
    "href": "posts/Emily Duryea Homework 1.html",
    "title": "Duryea Homework 1",
    "section": "",
    "text": "Code\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(readxl)\ndf <- read_excel(\"_data/LungCapData.xls\")  \n\nhist(df$LungCap)\n\n\n\n\n\nPart A: Plotting probability density histogram\n\n\nCode\nhist(df$LungCap, \n     col=\"yellow\",\n     border=\"black\",\n     prob = TRUE,\n     xlab = \"LungCap\",\n     main = \"Density Plot\")\n\nlines(density(df$LungCap),\n      lwd = 2,\n      col = \"chocolate3\")\n\n\n\n\n\nPart B: Compare the probability distribution of the LungCap with respect to Males and Females\n\n\nCode\nggplot(df, aes(y = dnorm(LungCap), color = Gender)) +\n  geom_boxplot() +\n  labs(title = \"LungCap Probability Distribution for Males and Females\", y = \"Probability density\")\n\n\n\n\n\nPart C: Compare the mean lung capacities for smokers and non-smokers\n\n\nCode\nmean_smoking <- df %>%\n  group_by(Smoke) %>%\n  summarise(mean = mean(LungCap))\nmean_smoking\n\n\n# A tibble: 2 × 2\n  Smoke  mean\n  <chr> <dbl>\n1 no     7.77\n2 yes    8.65\n\n\nThe means of smokers vs non smokers does not make sense since non smokers have a lower mean lung cap, when one would think it would be the other way around. However, limited data is provided on the sample, so there could be other factors in play.\nPart D: Examine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”\n\n\nCode\ndf <- mutate(df, AgeGroup = case_when(Age <= 13 ~ \"less than or equal to 13\",\n                                    Age == 14 | Age == 15 ~ \"14 to 15\",\n                                    Age == 16 | Age == 17 ~ \"16 to 17\",\n                                    Age >= 18 ~ \"greater than or equal to 18\"))\n\ndf %>%\n  ggplot(aes(y = LungCap, color = Smoke)) +\n  geom_histogram(bins = 25) +\n  facet_wrap(vars(AgeGroup)) +\n  theme_classic() + \n  labs(title = \"LungCap and Smoke based on age groups\", y = \"Lung Capacity\", x = \"Frequency\")\n\n\n\n\n\nBased on the histograms, Part D seems to contrast with Part C, since the plots seem to demonstrate non-smokers having higher lung capacity than smokers in all age groups. Additionally, lung capacity appears to decrease with age based on the graph.\nPart E: Compare the lung capacities for smokers and non-smokers within each age group\n\n\nCode\ndf %>%\n  ggplot(aes(x = Age, y = LungCap, color = Smoke)) +\n  geom_line() +\n  facet_wrap(vars(Smoke)) +\n  labs(title = \"LungCap and Smoke based on age and smoker vs nonsmoker\", y = \"Lung Capacity\", x = \"Age\")\n\n\n\n\n\nBased on information gained in Part D and Part E, it appears that lung capacity decreases with age, and, despite the means in Part C, lung capacity is higher for non-smokers.\nPart F: Calculate the correlation and covariance between Lung Capacity and Age\n\n\nCode\nCov_lungcapage <- cov(df$LungCap, df$Age)\nCor_lungcapeage <- cor(df$LungCap, df$Age)\nCov_lungcapage\n\n\n[1] 8.738289\n\n\nCode\nCor_lungcapeage\n\n\n[1] 0.8196749\n\n\nBecause both the covariance and correlation are positive numbers, the relationship between lung capacity and age are positively related, meaning as one increases, the other also increases in a proportional manner.\nQuestion 2\n\n\nCode\nPrior_Convictions <- c(0:4)\nInmate_Number <- c(128, 434, 160, 64, 24)\nip <- tibble(Prior_Convictions, Inmate_Number)\n\nip <- mutate(ip, Probability = Inmate_Number/sum(Inmate_Number))\nip\n\n\n# A tibble: 5 × 3\n  Prior_Convictions Inmate_Number Probability\n              <int>         <dbl>       <dbl>\n1                 0           128      0.158 \n2                 1           434      0.536 \n3                 2           160      0.198 \n4                 3            64      0.0790\n5                 4            24      0.0296\n\n\nPart A: What is the probability that a randomly selected inmate has exactly 2 prior convictions?\n\n\nCode\nip %>%\n  filter(Prior_Convictions == 2) %>%\n  select(Probability)\n\n\n# A tibble: 1 × 1\n  Probability\n        <dbl>\n1       0.198\n\n\nThe probability that a randomly selected inmate has exactly two prior convictions is 0.1975309.\nPart B: What is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\n\nCode\npartb <- ip %>%\n  filter(Prior_Convictions < 2)\nsum(partb$Probability)\n\n\n[1] 0.6938272\n\n\nThe probability that a randomly selected inmate has fewer than two prior convictions is 0.6938272.\nPart C: What is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\n\nCode\npartc <- ip %>%\n  filter(Prior_Convictions <= 2)\nsum(partc$Probability)\n\n\n[1] 0.891358\n\n\nThe probability that a randomly selected inmate has two or fewer prior convictions is 0.891358.\nPart D: What is the probability that a randomly selected inmate has more than 2 prior convictions?\n\n\nCode\npartd <- ip %>%\n  filter(Prior_Convictions > 2)\nsum(partd$Probability)\n\n\n[1] 0.108642\n\n\nThe probability that a randomly selected inmate has more than two prior convictions is 0.108642.\nPart E: What is the expected value for the number of prior convictions?\n\n\nCode\nip <- mutate(ip, vl = Prior_Convictions*Probability)\nparte <- sum(ip$vl)\nparte\n\n\n[1] 1.28642\n\n\nThe expected value for the number of prior convictions is 1.28642.\nPart F: Calculate the variance and the standard deviation for the Prior Convictions\n\n\nCode\nip_var <-sum(((ip$Prior_Convictions-parte)^2)*ip$Probability)\nip_var\n\n\n[1] 0.8562353\n\n\nCode\nsqrt(ip_var)\n\n\n[1] 0.9253298\n\n\nThe variance for prior convictions is 0.8562353 and the standard deviation is 0.9253298."
  },
  {
    "objectID": "posts/HW1_Yakub Rabiutheen.html",
    "href": "posts/HW1_Yakub Rabiutheen.html",
    "title": "Homework 1",
    "section": "",
    "text": "First, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\ndf <- read_excel(\"_data/LungCapData.xls\")\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(df$LungCap,freq = FALSE)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\n\n\n\nComparison of the Genders for both Men and Women using a Boxplot.\n\n\nCode\nboxplot(df$LungCap ~ df$Gender)\n\n\n\n\n\n\n\n\nHere is the capacity of Smokers vs Non-Smokers\n\n\nCode\nboxplot(df$LungCap~df$Smoke,\n        ylab = \"Capacity\", \n        main = \"Lung Capacity of Smokers Vs Non-Smokers\",\n        las = 1)\n\n\n\n\n\n\n\n\nLet’s break it down even further, this is the Lung Capacity by Age Group\n\n\nCode\ndf$Agegroups<-cut(df$Age,breaks=c(-Inf, 13, 15, 17, 20), labels=c(\"0-13 years\", \"14-15 years\", \"16-17 years\", \"18+ years\"))\n\n\nBelow is the overall Lung Capacity of Age Groups without including Smokers.\n\n\nCode\nlibrary(ggplot2)\nggplot(df, aes(x = LungCap, y = Agegroups, fill = Gender)) +\n          geom_bar(stat = \"identity\") +\n          coord_flip() +\n          theme_classic()\n\n\n\n\n\n#e\nHere is a comparision of AgeGroup Lung Capacity in comparison with Smoker vs Non-Smoker.\n\n\nCode\nggplot(df, aes(x = LungCap, y = Agegroups, fill = Smoke)) +\n    geom_bar(stat = \"identity\") +\n    coord_flip() +\n    theme_classic()\n\n\n\n\n\n\n\n\nBased on the comparison of lung capacities between Smoker and Non-Smoker the results are pretty similar.\n\n\nCode\ncov(df$LungCap, df$Age)\n\n\n[1] 8.738289\n\n\nCode\ncor(df$LungCap, df$Age)\n\n\n[1] 0.8196749\n\n\nQuestion 2\n\n\nCode\nX <- c(0:4)\nFrequency <- c(128, 434, 160, 64, 24)\ndf <- data.frame(X, Frequency)\ndf\n\n\n  X Frequency\n1 0       128\n2 1       434\n3 2       160\n4 3        64\n5 4        24\n\n\nAs shown below, the most common Prior Convictions is 1.\n\n\nCode\ndf\n\n\n  X Frequency\n1 0       128\n2 1       434\n3 2       160\n4 3        64\n5 4        24\n\n\nDividing by the total among 810 we can determine the probability for each. 810 is the Sum of the Frequency which I checked manually.\n\n\nCode\ndf2 <- mutate(df, Probability = Frequency/sum(Frequency))\n\n\nError in mutate(df, Probability = Frequency/sum(Frequency)): could not find function \"mutate\"\n\n\nCode\ndf2\n\n\nError in eval(expr, envir, enclos): object 'df2' not found\n\n\n\nFilter for Probability of 2 Convictions\n\n\n\nCode\nb2 <- df2 %>% \n  filter(X < 2)\n\n\nError in df2 %>% filter(X < 2): could not find function \"%>%\"\n\n\nCode\nsum(b2$Probability)\n\n\nError in eval(expr, envir, enclos): object 'b2' not found\n\n\n\nFilter for Probability of Less than 2 Convictions\n\n\n\nCode\nc2 <- df2 %>% \n  filter(X <= 2)\n\n\nError in df2 %>% filter(X <= 2): could not find function \"%>%\"\n\n\nCode\nsum(c2$Probability)\n\n\nError in eval(expr, envir, enclos): object 'c2' not found\n\n\n\n\n\nFilter for Probability of greater than 2 convictions.\n\n\nCode\nd2 <- df2 %>% \n  filter(X > 2)\n\n\nError in df2 %>% filter(X > 2): could not find function \"%>%\"\n\n\nCode\nsum(d2$Probability)\n\n\nError in eval(expr, envir, enclos): object 'd2' not found\n\n\nWhat is the expected value of the number of prior convictions?\n\n\nCode\ne <- weighted.mean(df2$X, df2$Probability)\n\n\nError in weighted.mean(df2$X, df2$Probability): object 'df2' not found\n\n\nCode\ne\n\n\nError in eval(expr, envir, enclos): object 'e' not found\n\n\n\n\n\nVariance and Standard Deviation for Question.\n\n\nCode\nvar(df$X)\n\n\n[1] 2.5\n\n\n\n\nCode\nsd(df$X)\n\n\n[1] 1.581139"
  },
  {
    "objectID": "posts/HW_1_603.html",
    "href": "posts/HW_1_603.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(stats)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/HW_1_603.html#question-1",
    "href": "posts/HW_1_603.html#question-1",
    "title": "Homework 1",
    "section": "Question 1",
    "text": "Question 1\n\n\nCode\nLung_data<- read_excel(\"C:/Users/manik/Desktop/LungCapData.xls\")\n\n\nError: `path` does not exist: 'C:/Users/manik/Desktop/LungCapData.xls'\n\n\nCode\nLung_data\n\n\nError in eval(expr, envir, enclos): object 'Lung_data' not found\n\n\nGiven data consists of 725 rows and 6 columns\n\nWhat does the distribution of LungCap look like?\n\n\n\nCode\nLung_data %>%\n  ggplot(aes(LungCap, ..density..)) +\n  geom_histogram() +\n  geom_density(color = \"Red\") +\n  theme_classic() + \n  labs(title = \"Probability distribution of LungCap\", x = \"Lung Capcity\", y = \"Probability density\")\n\n\nError in ggplot(., aes(LungCap, ..density..)): object 'Lung_data' not found\n\n\nBased on above histogram , we can say the distribution is very close to the normal distribution\nCompare the probability distribution of the LungCap with respect to Males and Females?\n\n\nCode\nLung_data %>%\n  ggplot(aes(y = dnorm(LungCap), color = Gender)) +\n  geom_boxplot() +\n  labs(title = \"Probability distribution of LungCap based on gender\", y = \"Probability density\")\n\n\nError in ggplot(., aes(y = dnorm(LungCap), color = Gender)): object 'Lung_data' not found\n\n\nCompare the mean lung capacities for smokers and non-smokers. Does it make sense?\n\n\nCode\nMean_smokers <- Lung_data %>%\n  group_by(Smoke) %>%\n  summarise(mean = mean(LungCap))\n\n\nError in group_by(., Smoke): object 'Lung_data' not found\n\n\nCode\nMean_smokers\n\n\nError in eval(expr, envir, enclos): object 'Mean_smokers' not found\n\n\nThe mean of the lung capacity who smokes is greater than the people who doesnt smoke which doesnt make any sense in practical\nExamine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\n\nCode\nLung_data <- mutate(Lung_data, AgeGrp = case_when(Age <= 13 ~ \"less than or equal to 13\",\n                                    Age == 14 | Age == 15 ~ \"14 to 15\",\n                                    Age == 16 | Age == 17 ~ \"16 to 17\",\n                                    Age >= 18 ~ \"greater than or equal to 18\"))\n\n\nError in mutate(Lung_data, AgeGrp = case_when(Age <= 13 ~ \"less than or equal to 13\", : object 'Lung_data' not found\n\n\nCode\nLung_data %>%\n  ggplot(aes(y = LungCap, color = Smoke)) +\n  geom_histogram(bins = 25) +\n  facet_wrap(vars(AgeGrp)) +\n  theme_classic() + coord_flip()\n\n\nError in ggplot(., aes(y = LungCap, color = Smoke)): object 'Lung_data' not found\n\n\nCode\n  labs(title = \"Relationship of LungCap and Smoke based on age categories\", y = \"Lung Capacity\", x = \"Frequency\")\n\n\n$y\n[1] \"Lung Capacity\"\n\n$x\n[1] \"Frequency\"\n\n$title\n[1] \"Relationship of LungCap and Smoke based on age categories\"\n\nattr(,\"class\")\n[1] \"labels\"\n\n\nCompare the lung capacities for smokers and non-smokers within each age group. Is your answer different from the one in part d. What could possibly be going on here?\n\n\nCode\nLung_data %>%\n  ggplot(aes(x = Age, y = LungCap, color = Smoke)) +\n  geom_line() +\n  theme_classic() + \n  facet_wrap(vars(Smoke)) +\n  labs(title = \"Relationship of LungCap and Smoke based on age\", y = \"Lung Capacity\", x = \"Age\")\n\n\nError in ggplot(., aes(x = Age, y = LungCap, color = Smoke)): object 'Lung_data' not found\n\n\nForm the above data we can compare 1d and 1e and can say the results are pretty similar. Only 10 and above age group smoke.\nCalculate the correlation and covariance between Lung Capacity and Age. (use the cov() and cor() functions in R). Interpret your results.\n\n\nCode\nCovariance_LA <- cov(Lung_data$LungCap, Lung_data$Age)\n\n\nError in is.data.frame(y): object 'Lung_data' not found\n\n\nCode\nCorrelation_LA <- cor(Lung_data$LungCap, Lung_data$Age)\n\n\nError in is.data.frame(y): object 'Lung_data' not found\n\n\nCode\nCovariance_LA\n\n\nError in eval(expr, envir, enclos): object 'Covariance_LA' not found\n\n\nCode\nCorrelation_LA\n\n\nError in eval(expr, envir, enclos): object 'Correlation_LA' not found\n\n\nFrom the above result we can say that both covariance and correlation is positive and which indicates direct relationship that means Lungcapacity increases as age increases"
  },
  {
    "objectID": "posts/HW_1_603.html#question-2",
    "href": "posts/HW_1_603.html#question-2",
    "title": "Homework 1",
    "section": "Question 2",
    "text": "Question 2\n\n\nCode\nPrior_convitions <- c(0:4)\nInmate_count <- c(128, 434, 160, 64, 24)\nIP<- data_frame(Prior_convitions, Inmate_count)\n\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nℹ Please use `tibble()` instead.\n\n\nCode\nIP\n\n\n\n\n  \n\n\n\n\n\nCode\nIP <- mutate(IP, Probability = Inmate_count/sum(Inmate_count))\nIP\n\n\n\n\n  \n\n\n\nWhat is the probability that a randomly selected inmate has exactly 2 prior convictions?\n\n\nCode\nIP %>%\n  filter(Prior_convitions == 2) %>%\n  select(Probability)\n\n\n\n\n  \n\n\n\nWhat is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\n\nCode\np_2 <- IP %>%\n  filter(Prior_convitions < 2)\nsum(p_2$Probability)\n\n\n[1] 0.6938272\n\n\nWhat is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\n\nCode\np <- IP %>%\n  filter(Prior_convitions <= 2)\nsum(p$Probability)\n\n\n[1] 0.891358\n\n\nWhat is the probability that a randomly selected inmate has more than 2 prior convictions?\n\n\nCode\nP_3 <- IP %>%\n  filter(Prior_convitions > 2)\nsum(P_3$Probability)\n\n\n[1] 0.108642\n\n\nWhat is the expected value for the number of prior convictions?\n\n\nCode\nIP <- mutate(IP, Wm = Prior_convitions*Probability)\nexpe<- sum(IP$Wm)\nexpe\n\n\n[1] 1.28642\n\n\nCalculate the variance and the standard deviation for the Prior Convictions.\n\n\nCode\nvar_ <-sum(((IP$Prior_convitions-expe)^2)*IP$Probability)\nvar_\n\n\n[1] 0.8562353\n\n\nstandard deviation:\n\n\nCode\nsqrt(var_)\n\n\n[1] 0.9253298"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html",
    "href": "posts/HW1_KarenDetter.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#plot-histogram-with-probability-density-on-the-y-axis",
    "href": "posts/HW1_KarenDetter.html#plot-histogram-with-probability-density-on-the-y-axis",
    "title": "Homework 1",
    "section": "Plot histogram with probability density on the y axis",
    "text": "Plot histogram with probability density on the y axis\n\n\nCode\nhist(LungCapData$LungCap, freq = FALSE)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution - most of the observations are close to the mean, with very few close to the margins (0 and 15)."
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#create-boxplots-separated-by-gender",
    "href": "posts/HW1_KarenDetter.html#create-boxplots-separated-by-gender",
    "title": "Homework 1",
    "section": "Create boxplots separated by gender",
    "text": "Create boxplots separated by gender\n\n\nCode\nboxplot(LungCap ~ Gender, data = LungCapData, horizontal = TRUE)\n\n\n\n\n\nThe boxplots show that male lung capacity has a wider range than that of females; however, the minimum, median, and maximum values are all higher than those of females. This implies that, as a group, men are likely to have higher lung capacity than women."
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#group-by-smoking-status-and-summarize-mean-lung-capacities",
    "href": "posts/HW1_KarenDetter.html#group-by-smoking-status-and-summarize-mean-lung-capacities",
    "title": "Homework 1",
    "section": "Group by smoking status and summarize mean lung capacities",
    "text": "Group by smoking status and summarize mean lung capacities\n\n\nCode\nlibrary(dplyr)\nLungCapData %>%\ngroup_by(Smoke) %>%\nsummarize(mean = mean(LungCap), n = n())\n\n\n# A tibble: 2 × 3\n  Smoke  mean     n\n  <chr> <dbl> <int>\n1 no     7.77   648\n2 yes    8.65    77\n\n\nIn this dataset, the mean lung capacity of smokers is actually higher than that of non-smokers. Since this is counter to what would be expected, there is likely another variable exerting a confounding effect on lung capacity."
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#create-new-data-frame-with-age-group-category-variables",
    "href": "posts/HW1_KarenDetter.html#create-new-data-frame-with-age-group-category-variables",
    "title": "Homework 1",
    "section": "Create new data frame with age group category variables",
    "text": "Create new data frame with age group category variables\n\n\nCode\nLungCapData_AgeGroups <- LungCapData %>%\nmutate(AgeGroup = case_when(Age <= 13 ~ \"less than or equal to 13\", \n            Age == 14 | Age == 15 ~ \"14 to 15\",\n            Age == 16 | Age == 17 ~ \"16 to 17\",\n            Age >= 18 ~ \"greater than or equal to 18\"))"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#summarize-mean-lung-capacities-by-age-group-and-smoking-status",
    "href": "posts/HW1_KarenDetter.html#summarize-mean-lung-capacities-by-age-group-and-smoking-status",
    "title": "Homework 1",
    "section": "Summarize mean lung capacities by age group and smoking status",
    "text": "Summarize mean lung capacities by age group and smoking status\n\n\nCode\nLungCapData_AgeGroups %>%\ngroup_by(AgeGroup, Smoke) %>%\nsummarize(MeanLungCap = mean(LungCap), n = n())\n\n\n`summarise()` has grouped output by 'AgeGroup'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 4\n# Groups:   AgeGroup [4]\n  AgeGroup                    Smoke MeanLungCap     n\n  <chr>                       <chr>       <dbl> <int>\n1 14 to 15                    no           9.14   105\n2 14 to 15                    yes          8.39    15\n3 16 to 17                    no          10.5     77\n4 16 to 17                    yes          9.38    20\n5 greater than or equal to 18 no          11.1     65\n6 greater than or equal to 18 yes         10.5     15\n7 less than or equal to 13    no           6.36   401\n8 less than or equal to 13    yes          7.20    27"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#calculate-correlation-and-covariance-between-lung-capacity-and-age",
    "href": "posts/HW1_KarenDetter.html#calculate-correlation-and-covariance-between-lung-capacity-and-age",
    "title": "Homework 1",
    "section": "Calculate correlation and covariance between lung capacity and age",
    "text": "Calculate correlation and covariance between lung capacity and age\n\n\nCode\ncor(LungCapData$LungCap, LungCapData$Age)\n\n\n[1] 0.8196749\n\n\nCode\ncov(LungCapData$LungCap, LungCapData$Age)\n\n\n[1] 8.738289\n\n\nSince the correlation coefficient is close to 1, there is a high degree of correlation between lung capacity and age. The covariance of 8.7, being a positive number, indicates that as age increases, lung capacity increases."
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#create-data-frame",
    "href": "posts/HW1_KarenDetter.html#create-data-frame",
    "title": "Homework 1",
    "section": "Create data frame",
    "text": "Create data frame\n\n\nCode\nPriorConv <- c(0,1,2,3,4)\nFreq <- c(128,434,160,64,24)\nPrisonerData <- data.frame (PriorConv, Freq)\nPrisonerData\n\n\n  PriorConv Freq\n1         0  128\n2         1  434\n3         2  160\n4         3   64\n5         4   24"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#calculate-probability-that-an-inmate-has-2-prior-convictions",
    "href": "posts/HW1_KarenDetter.html#calculate-probability-that-an-inmate-has-2-prior-convictions",
    "title": "Homework 1",
    "section": "Calculate probability that an inmate has == 2 prior convictions",
    "text": "Calculate probability that an inmate has == 2 prior convictions\nprobability = frequency/n\n\n\nCode\n160/810\n\n\n[1] 0.1975309"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#calculate-probability-that-an-inmate-has-2-prior-convictions-1",
    "href": "posts/HW1_KarenDetter.html#calculate-probability-that-an-inmate-has-2-prior-convictions-1",
    "title": "Homework 1",
    "section": "Calculate probability that an inmate has < 2 prior convictions",
    "text": "Calculate probability that an inmate has < 2 prior convictions\nprobability = frequency(0)/n + frequency(1)/n\n\n\nCode\n(128/810) + (434/810)\n\n\n[1] 0.6938272"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#calculate-probability-that-an-inmate-has-2-prior-convictions-2",
    "href": "posts/HW1_KarenDetter.html#calculate-probability-that-an-inmate-has-2-prior-convictions-2",
    "title": "Homework 1",
    "section": "Calculate probability that an inmate has <= 2 prior convictions",
    "text": "Calculate probability that an inmate has <= 2 prior convictions\nprobability = frequency(0)/n + frequency(1)/n + frequency(2)/n\n\n\nCode\n(128/810) + (434/810) + (160/810)\n\n\n[1] 0.891358"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#calculate-probability-that-an-inmate-has-2-prior-convictions-3",
    "href": "posts/HW1_KarenDetter.html#calculate-probability-that-an-inmate-has-2-prior-convictions-3",
    "title": "Homework 1",
    "section": "Calculate probability that an inmate has > 2 prior convictions",
    "text": "Calculate probability that an inmate has > 2 prior convictions\nprobability = frequency(3)/n + frequency(4)/n\n\n\nCode\n(64/810) + (24/810)\n\n\n[1] 0.108642"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#calculate-expected-value-for-number-of-prior-convictions",
    "href": "posts/HW1_KarenDetter.html#calculate-expected-value-for-number-of-prior-convictions",
    "title": "Homework 1",
    "section": "Calculate expected value for number of prior convictions",
    "text": "Calculate expected value for number of prior convictions"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#create-a-matrix-of-prior-conviction-values-and-their-probabilities",
    "href": "posts/HW1_KarenDetter.html#create-a-matrix-of-prior-conviction-values-and-their-probabilities",
    "title": "Homework 1",
    "section": "Create a matrix of prior conviction values and their probabilities",
    "text": "Create a matrix of prior conviction values and their probabilities\n\n\nCode\nPriorConv <- c(0,1,2,3,4)\nProbs <- c(0.1580247, 0.5358025, 0.1975309, 0.07901235, 0.02962963)"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#calculate-expected-value",
    "href": "posts/HW1_KarenDetter.html#calculate-expected-value",
    "title": "Homework 1",
    "section": "Calculate expected value",
    "text": "Calculate expected value\n\n\nCode\nc(PriorConv %*% Probs)\n\n\n[1] 1.28642"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#calculate-variance-and-standard-deviation-for-prior-convictions",
    "href": "posts/HW1_KarenDetter.html#calculate-variance-and-standard-deviation-for-prior-convictions",
    "title": "Homework 1",
    "section": "Calculate variance and standard deviation for prior convictions",
    "text": "Calculate variance and standard deviation for prior convictions\n\n\nCode\nvar(PriorConv)\n\n\n[1] 2.5\n\n\nCode\nsd(PriorConv)\n\n\n[1] 1.581139"
  },
  {
    "objectID": "posts/HW1_KarenDetter.html#double-check-values",
    "href": "posts/HW1_KarenDetter.html#double-check-values",
    "title": "Homework 1",
    "section": "Double-check values",
    "text": "Double-check values\n\n\nCode\nsqrt(var(PriorConv)) == sd(PriorConv)\n\n\n[1] TRUE"
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#question-1",
    "href": "posts/HW1_603_Niharikapola.html#question-1",
    "title": "Homework 1",
    "section": "Question 1",
    "text": "Question 1"
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#reading-data",
    "href": "posts/HW1_603_Niharikapola.html#reading-data",
    "title": "Homework 1",
    "section": "Reading data",
    "text": "Reading data\n\n\nCode\nLc <- read_excel(\"LungCapData.xls\")\n\n\nError: `path` does not exist: 'LungCapData.xls'\n\n\nCode\nLc\n\n\nError in eval(expr, envir, enclos): object 'Lc' not found\n\n\nThe data consists of 725 rows and 6 columns. It determines the lung capacity of the based on their age, height and different characteristics. The main key classification that I can see is if they smoke or not."
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#a",
    "href": "posts/HW1_603_Niharikapola.html#a",
    "title": "Homework 1",
    "section": "1a",
    "text": "1a\nThe distribution of LungCap looks as follows:\n\n\nCode\nLc %>%\n  ggplot(aes(LungCap, ..density..)) +\n  geom_histogram(bins= 25, color = \"orange\") +\n  geom_density(color = \"darkblue\") +\n  theme_classic() + \n  labs(title = \"Probability distribution of LungCap\", x = \"Lung Capcity\", y = \"Probability density\")\n\n\nError in ggplot(., aes(LungCap, ..density..)): object 'Lc' not found\n\n\nThe histogram and density plots show that it is pretty close to a normal distribution. Most of the observations are close to the mean."
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#b",
    "href": "posts/HW1_603_Niharikapola.html#b",
    "title": "Homework 1",
    "section": "1b",
    "text": "1b\nThe distribution of LungCap on basis of gender looks as follows:\n\n\nCode\nLc %>%\n  ggplot(aes(y = dnorm(LungCap), color = Gender)) +\n  geom_boxplot() +\n  theme_classic() + \n  labs(title = \"Probability distribution of LungCap based on gender\", y = \"Probability density\")\n\n\nError in ggplot(., aes(y = dnorm(LungCap), color = Gender)): object 'Lc' not found\n\n\nThe box plot shows that the probability density of the male is lesser than the female."
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#c",
    "href": "posts/HW1_603_Niharikapola.html#c",
    "title": "Homework 1",
    "section": "1c",
    "text": "1c\nComparison of mean lung capacities between smokers and non-smokers:\n\n\nCode\nMean_smoke <- Lc %>%\n  group_by(Smoke) %>%\n  summarise(mean = mean(LungCap))\n\n\nError in group_by(., Smoke): object 'Lc' not found\n\n\nCode\nMean_smoke\n\n\nError in eval(expr, envir, enclos): object 'Mean_smoke' not found\n\n\nFrom the above table, we see that the mean lung capacity of those who smoke is greater than those who don’t smoke, but it doesn’t make sense. It also depends on the biological factors of the person who smoke, so we can’t conclude it."
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#d",
    "href": "posts/HW1_603_Niharikapola.html#d",
    "title": "Homework 1",
    "section": "1d",
    "text": "1d\nRelationship between Smoke and Lung capacity on basis of given age categories:\n\n\nCode\nLc <- mutate(Lc, AgeGrp = case_when(Age <= 13 ~ \"less than or equal to 13\",\n                                    Age == 14 | Age == 15 ~ \"14 to 15\",\n                                    Age == 16 | Age == 17 ~ \"16 to 17\",\n                                    Age >= 18 ~ \"greater than or equal to 18\"))\n\n\nError in mutate(Lc, AgeGrp = case_when(Age <= 13 ~ \"less than or equal to 13\", : object 'Lc' not found\n\n\nCode\nLc %>%\n  ggplot(aes(y = LungCap, color = Smoke)) +\n  geom_histogram(bins = 25) +\n  facet_wrap(vars(AgeGrp)) +\n  theme_classic() + \n  labs(title = \"Relationship of LungCap and Smoke based on age categories\", y = \"Lung Capacity\", x = \"Frequency\")\n\n\nError in ggplot(., aes(y = LungCap, color = Smoke)): object 'Lc' not found\n\n\nFrom the above plot, we can derive two important observations: 1. The lung capacity of non smokers is more than smokers. 2. The people who smoke are less in age group of “less than or equal to 13”. So as the result as age increases the lung capacity decreases."
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#e",
    "href": "posts/HW1_603_Niharikapola.html#e",
    "title": "Homework 1",
    "section": "1e",
    "text": "1e\nRelationship between Smoke and Lung capacity on basis of age:\n\n\nCode\nLc %>%\n  ggplot(aes(x = Age, y = LungCap, color = Smoke)) +\n  geom_line() +\n  theme_classic() + \n  facet_wrap(vars(Smoke)) +\n  labs(title = \"Relationship of LungCap and Smoke based on age\", y = \"Lung Capacity\", x = \"Age\")\n\n\nError in ggplot(., aes(x = Age, y = LungCap, color = Smoke)): object 'Lc' not found\n\n\nForm the above data we can compare 1d and 1e and can say the results are pretty similar. Only 10 and above age group smoke."
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#f",
    "href": "posts/HW1_603_Niharikapola.html#f",
    "title": "Homework 1",
    "section": "1f",
    "text": "1f\nCalculating the correlation and covariance between Lung Capacity and Age:\n\n\nCode\nCovariance <- cov(Lc$LungCap, Lc$Age)\n\n\nError in is.data.frame(y): object 'Lc' not found\n\n\nCode\nCorrelation <- cor(Lc$LungCap, Lc$Age)\n\n\nError in is.data.frame(y): object 'Lc' not found\n\n\nCode\nCovariance\n\n\nError in eval(expr, envir, enclos): object 'Covariance' not found\n\n\nCode\nCorrelation\n\n\nError in eval(expr, envir, enclos): object 'Correlation' not found\n\n\nWe can observe from the comparison that the covariance is positive and it indicates that there is a direct relationship between age and lung capacity. And the correlation is also positive, so they move in same direction. We can say from these results that as the age increases, the lung capacity also increases that is they are directly proportional to each other."
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#question-2",
    "href": "posts/HW1_603_Niharikapola.html#question-2",
    "title": "Homework 1",
    "section": "Question 2",
    "text": "Question 2"
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#reading-the-table",
    "href": "posts/HW1_603_Niharikapola.html#reading-the-table",
    "title": "Homework 1",
    "section": "Reading the table",
    "text": "Reading the table\n\n\nCode\nPrior_convitions <- c(0:4)\nInmate_count <- c(128, 434, 160, 64, 24)\nPc <- data_frame(Prior_convitions, Inmate_count)\n\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nℹ Please use `tibble()` instead.\n\n\nCode\nPc\n\n\n\n\n  \n\n\n\n\n\nCode\nPc <- mutate(Pc, Probability = Inmate_count/sum(Inmate_count))\nPc"
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#a-1",
    "href": "posts/HW1_603_Niharikapola.html#a-1",
    "title": "Homework 1",
    "section": "2a",
    "text": "2a\nProbability that a randomly selected inmate has exactly 2 prior convictions:\n\n\nCode\nPc %>%\n  filter(Prior_convitions == 2) %>%\n  select(Probability)"
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#b-1",
    "href": "posts/HW1_603_Niharikapola.html#b-1",
    "title": "Homework 1",
    "section": "2b",
    "text": "2b\nProbability that a randomly selected inmate has fewer than 2 convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions < 2)\nsum(temp$Probability)\n\n\n[1] 0.6938272"
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#c-1",
    "href": "posts/HW1_603_Niharikapola.html#c-1",
    "title": "Homework 1",
    "section": "2c",
    "text": "2c\nProbability that a randomly selected inmate has 2 or fewer prior convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions <= 2)\nsum(temp$Probability)\n\n\n[1] 0.891358"
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#d-1",
    "href": "posts/HW1_603_Niharikapola.html#d-1",
    "title": "Homework 1",
    "section": "2d",
    "text": "2d\nProbability that a randomly selected inmate has more than 2 prior convictions:\n\n\nCode\ntemp <- Pc %>%\n  filter(Prior_convitions > 2)\nsum(temp$Probability)\n\n\n[1] 0.108642"
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#e-1",
    "href": "posts/HW1_603_Niharikapola.html#e-1",
    "title": "Homework 1",
    "section": "2e",
    "text": "2e\nExpected value for the number of prior convictions:\n\n\nCode\nPc <- mutate(Pc, Wm = Prior_convitions*Probability)\ne <- sum(Pc$Wm)\ne\n\n\n[1] 1.28642"
  },
  {
    "objectID": "posts/HW1_603_Niharikapola.html#f-1",
    "href": "posts/HW1_603_Niharikapola.html#f-1",
    "title": "Homework 1",
    "section": "2f",
    "text": "2f\nVariance for the Prior Convictions:\n\n\nCode\nv <-sum(((Pc$Prior_convitions-e)^2)*Pc$Probability)\nv\n\n\n[1] 0.8562353\n\n\nstandard deviation for the Prior Convictions:\n\n\nCode\nsqrt(v)\n\n\n[1] 0.9253298"
  },
  {
    "objectID": "posts/hw1.html",
    "href": "posts/hw1.html",
    "title": "Homework #1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(readxl)\nlibrary (ggplot)\n\n\nError in library(ggplot): there is no package called 'ggplot'\n\n\nCode\nlungcap<- read_excel(\"LungCapData.xls\") \n\n\nError: `path` does not exist: 'LungCapData.xls'\n\n\nCode\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/hw1.html#lungcapdata",
    "href": "posts/hw1.html#lungcapdata",
    "title": "Homework #1",
    "section": "LungCapData",
    "text": "LungCapData\n\n1a. What does the distribution of LungCap look like?\n\n\nCode\nggplot(lungcap, aes(x=LungCap))+ geom_histogram()\n``\nThis is not normally distributed as there are far more observations of lower lung capacity than higher suggesting the distribution is negatively skewed.\n \n### 1b. Compare the probability distribution of the LungCap with respect to Males and Females? \n\n\nError: attempt to use zero-length variable name\n\n\n\n\nCode\nlungcap %>%\ngroup_by(Gender)%>%\nsummarise(mean(LungCap))\n\n\nError in group_by(., Gender): object 'lungcap' not found\n\n\nThe average lung capacity for females is 7.41, lower than the average for males at 8.31.\n\n\n1c. Compare the mean lung capacities for smokers and non-smokers. Does it make sense?\n\n\nCode\nlungcap %>%\ngroup_by(Smoke)%>%\nsummarise(mean(LungCap))\n\n\nError in group_by(., Smoke): object 'lungcap' not found\n\n\nThe mean lung capacity for non-smokers is 7.77, lower than the mean for smokers at 8.65. At first glance, this seems contradictory as one would guess smokers to have a lower lung capacity than non-smokers.The following grid displays non-smokers as having overall higher lung capacity, conflicting with the mean above.\n\n\nCode\nggplot(lungcap, aes(x = LungCap)) +\nfacet_grid(Gender ~ Smoke)+\n  geom_histogram()\n\n\nError in ggplot(lungcap, aes(x = LungCap)): object 'lungcap' not found\n\n\n\n\n1d. Examine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\n\n1e. Compare the lung capacities for smokers and non-smokers within each age group.\nLung capacity for those under age 13 is 6.36 for non-smokers and 7.20 for smokers.\n\n\nCode\nlungcap %>%\n+ filter(Age <= 13)%>%\n+ group_by(Smoke)%>%\n+ summarise(mean(LungCap))\n\nLung capacity for those between the age of 14 to 15\nlungcap%>%\n+ filter(Age=<15 & Age >=14)%>%\n+ group_by(Smoke)%>%\n+ summarise(mean(LungCap))\n\nLung capacity for those between the age of 16 to 17\nlungcap%>%\n+     filter(Age=<17>=16)%>%\n+ group_by(Smoke)%>%\n+ summarise(mean(LungCap))\n\nLung capacity for those 18 and older\nlungcap%>%\n+ filter(Age>=18)%>%\n+ group_by(Smoke)%>%\n+ summarise(mean(LungCap))\n\n\nError: <text>:6:6: unexpected symbol\n5: \n6: Lung capacity\n        ^\n\n\n\n\nIs your answer different from the one in part c? What could possibly be going on here?\n\n\n1f. Calculate the correlation and covariance between Lung Capacity and Age. (use the cov() and cor() functions in R). Interpret results.\n\n\nCode\ncov(lungcap$LungCap, lungcap$Age)\n\n\nError in is.data.frame(y): object 'lungcap' not found\n\n\nCode\ncor(lungcap$LungCap, lungcap$Age)\n\n\nError in is.data.frame(y): object 'lungcap' not found\n\n\nThe covariance between lung capacity and age is 8.74 suggesting a positive relationship in which both variables move in the same direction (i.e. for this data set an increase in lung capacity would suggest an increase in age as well).\nThe correlation between lung capacity and age is 0.82 suggesting a strong positive correlation (0.82 of a potential -1 to +1)."
  },
  {
    "objectID": "posts/hw1.html#inmate-data",
    "href": "posts/hw1.html#inmate-data",
    "title": "Homework #1",
    "section": "Inmate Data",
    "text": "Inmate Data\n\n\nCode\nx<- c(0, 1, 2, 3, 4)\ny<- c(128, 434, 160, 64, 24)\nprison <-data.frame(x,y)\nView(prison)\n\n\nWarning in View(prison): unable to open display\n\n\nError in .External2(C_dataviewer, x, title): unable to start data viewer\n\n\n2a. What is the probability that a randomly selected inmate has exactly 2 prior convictions? 20% 2b. What is the probability that a randomly selected inmate has fewer than 2 prior convictions? 69% 2c. What is the probability that a randomly selected inmate has 2 or fewer prior convictions? 89% 2d. What is the probability that a randomly selected inmate has more than 2 prior convictions? 11% 2e. What is the expected value for the number of prior convictions? 84% 2f. Calculate the variance and the standard deviation for the Prior Convictions.\n\n\nCode\nvar(prison, y= NULL)\nsd(rnorm(810))\nThe standard deviation is 1.02.\n\n\nError: <text>:3:5: unexpected symbol\n2: sd(rnorm(810))\n3: The standard\n       ^"
  },
  {
    "objectID": "posts/Quarkume HW1.html#lungcapdate",
    "href": "posts/Quarkume HW1.html#lungcapdate",
    "title": "HW1 Quat",
    "section": "LungCapDate",
    "text": "LungCapDate\n\nUse the LungCapData to answer the following questions. (Hint: Using dplyr, especially group_by() and summarize() can help you answer the following questions relatively efficiently.)\n\nInstall Libraries\n\n#install.packages(\"dplyr\")\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n#install.packages(\"ggplot2\")\nlibrary(ggplot2)\n#install.packages(\"readxl\")\nlibrary(readxl)\n#install.packages(\"magrittr\")\nlibrary(magrittr)\n\n\nWhat does the distribution of LungCap look like?\nThe distribution of Lung Capacity in the data set looks normally distributed.\n\n\n#histogram of LungCap\nhist(LungCapData$LungCap, xlab = 'LungCap', main = '', freq = F)\n\nError in hist(LungCapData$LungCap, xlab = \"LungCap\", main = \"\", freq = F): object 'LungCapData' not found\n\n\n\nCompare the probability distribution of the LungCap with respect to Males and Females?\nLooking at the comparative boxplot males have a higher lung capacity than females.\n\n\nboxplot(LungCapData$LungCap ~ LungCapData$Gender,\n        col = c(\"#FFE0B2\", \"#FFA726\"))\n\nError in eval(predvars, data, env): object 'LungCapData' not found\n\n\nc. Compare the mean lung capacities for smokers and non-smokers. Does it make sense? In comparing the means, the lung capacity for smokers is higher than for nonsmokers.\n\n#Mean Lung capacities of smokers\nLungCapData %>%\n  filter(Smoke == 'yes') %>%\n  pull(LungCap) %>%\n  mean()\n\nError in filter(., Smoke == \"yes\"): object 'LungCapData' not found\n\n#Mean Lung capacities of non-smokers\nLungCapData %>%\n  filter(Smoke == 'no') %>%\n  pull(LungCap) %>%\n  mean()\n\nError in filter(., Smoke == \"no\"): object 'LungCapData' not found\n\n\nd. Examine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\n#new var for Age Groups\nLungCapData$Age_Cat <- cut(LungCapData$Age,\n                           breaks = c(0,13,15,17,25),\n                           labels = c('less than or equal to 13','14 to 15','16 to 17','greater than or equal to 18'))\n\nError in cut(LungCapData$Age, breaks = c(0, 13, 15, 17, 25), labels = c(\"less than or equal to 13\", : object 'LungCapData' not found\n\nggplot(LungCapData, aes(x=Smoke, y=LungCap)) + \n    geom_boxplot() +\n  facet_wrap(~Age_Cat, scale=\"free\")\n\nError in ggplot(LungCapData, aes(x = Smoke, y = LungCap)): object 'LungCapData' not found\n\n\ne. Compare the lung capacities for smokers and non-smokers within each age group. Is your answer different from the one in part c. What could possibly be going on here? We see an intervening relationship with age. Where most young children either don’t smoke ar all and have smaller lung capacities because of their size.\n\nggplot(LungCapData, aes(x=Smoke, y=LungCap)) + \n    geom_boxplot() +\n  facet_wrap(~Age, scale=\"free\")\n\n--\n  \n\nError: <text>:7:0: unexpected end of input\n5: --\n6:   \n  ^\n\n\nf.Calculate the correlation and correlation between Lung Capacity and Age. (use the cov() and cor() functions in R).\n\n#correlation\nLungCapData %>% \n  summarize(correlation = cor(LungCap, Age))\n\nError in summarize(., correlation = cor(LungCap, Age)): object 'LungCapData' not found\n\n#correlation\nLungCapData %>% \n  summarize(covariance = cov(LungCap, Age))\n\nError in summarize(., covariance = cov(LungCap, Age)): object 'LungCapData' not found"
  },
  {
    "objectID": "posts/Quarkume HW1.html#examination-of-prison-convictions",
    "href": "posts/Quarkume HW1.html#examination-of-prison-convictions",
    "title": "HW1 Quat",
    "section": "1. Examination of Prison Convictions",
    "text": "1. Examination of Prison Convictions"
  },
  {
    "objectID": "posts/Quarkume HW1.html#prisondata",
    "href": "posts/Quarkume HW1.html#prisondata",
    "title": "HW1 Quat",
    "section": "PrisonData",
    "text": "PrisonData\nData\n\nPrisonData <- tibble(\n  prior_convictions = c(0,1,2,3,4),\n  freq = c(128,434,160,64,24))\n\nPrisonData\n\n# A tibble: 5 × 2\n  prior_convictions  freq\n              <dbl> <dbl>\n1                 0   128\n2                 1   434\n3                 2   160\n4                 3    64\n5                 4    24\n\nnum <- sum (PrisonData$freq)\nnum\n\n[1] 810\n\n\n\nWhat is the probability that a randomly selected inmate has exactly 2 prior convictions?\n\n\nPrisonData %>% \n  filter(prior_convictions == 2) %>% \n  pull (freq) %>% \n  divide_by (num)\n\n[1] 0.1975309\n\n\nb. What is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\nPrisonData %>% \n  filter(prior_convictions < 2) %>% \n  pull (freq) %>% \n  sum() %>%\n  divide_by (num)\n\n[1] 0.6938272\n\n\nc. What is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\nPrisonData %>% \n  filter(prior_convictions <= 2) %>% \n  pull (freq) %>% \n  sum() %>%\n  divide_by (num)\n\n[1] 0.891358\n\n\nd.What is the probability that a randomly selected inmate has more than 2 prior convictions?\n\nPrisonData %>% \n  filter(prior_convictions > 2) %>% \n  pull (freq) %>% \n  sum() %>%\n  divide_by (num)\n\n[1] 0.108642\n\n\ne. What is the expected value for the number of prior convictions?\n\nsum(prior_convictions*freq)\n\nError in eval(expr, envir, enclos): object 'prior_convictions' not found\n\n\nf. Calculate the variance and the standard deviation for the Prior Convictions.\n\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "posts/Final_SteveONeill.html",
    "href": "posts/Final_SteveONeill.html",
    "title": "Final Part 1",
    "section": "",
    "text": "── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()"
  },
  {
    "objectID": "posts/Final_SteveONeill.html#introduction",
    "href": "posts/Final_SteveONeill.html#introduction",
    "title": "Final Part 1",
    "section": "Introduction",
    "text": "Introduction\nBy analyzing public Paycheck Protection Program data, I have the ability to examine correlations between PPP loan size, forgiveness status, business status, geographical location, and - most optimistically - political affiliation. In the United States, the PPP was introduced as an emergency economic measure in 2020 during the Covid-19 pandemic. As a massive direct-loan program, some have criticized it for lax oversight.\nPPP fraud is an important issue, but finding lawbreakers is probably better left to the Feds. Instead, I think there is room in the academic body of work to study political affiliation for loan recipients.\n\nExisting Work\nThere have already been many studies about the PPP focusing on overall economic impact and the emergence of non-traditional, non-bank lenders.\nSeparately, two interesting studies have been done about racial disparities re: access to PPP loans, with one finding that Black-owned businesses in Florida were 25% less likely to receive PPP funds (Chernenko & Scharfstein, 2022), and another finding even higher of a disparity (50%) but taking note of mitigating factors (e.g. access to “fintech” lending instead of traditional banks) (Atkins, Cook & Seamans)\nI am not so much interested in the efficacy of the PPP or the racial make-up of PPP borrowers. But I am interested in their political affiliation, i.e. if they registered are Democrat or Republican. So, similarly to Chernenko & Scharfstein, I intend to use public-access data to cross-reference federal PPP data with state-level voter registration and corporation search data.\nA relevant paper I found after I started looking at this data - “Buying the Vote? The Economics of Electoral Politics and Small-Business Loans” - does look at data from SBA and PPP loans and pit them against the hypothesis that “electoral considerations may have tilted the allocation of PPP funds toward firms in areas or industries that could have a significant impact on the results of the 2020 election”.(Duchin & Hackney, 2021)\nThat particular study measured political ad spending and FEC filings as indicators of electoral considerations and used the Partisan Voting Index (PVI) from the Cook Political National Report to find which states were “battleground” or solid-R states. PPP lending outcomes were compared with electoral considerations to find if the SBA (under Trump) preferred to give PPP loans to swing voters or members of the party “base” in anticipation of an upcoming general election.\nRather than aggregate-level state data, my analysis will compare individuals’ personal voter affiliation - if they are registered, and to which party - with their loan amount, forgiveness status, and other metrics."
  },
  {
    "objectID": "posts/Final_SteveONeill.html#research-question",
    "href": "posts/Final_SteveONeill.html#research-question",
    "title": "Final Part 1",
    "section": "Research Question",
    "text": "Research Question\nI am still developing my research question, but a simple one could be:\nHow does political affiliation affect PPP loan forgiveness status?\nThe data for PPP loans is current available on ProPublica, but not in a queryable way.\nFortunately, the underlying data has been made public at https://data.sba.gov/dataset/ppp-foia.\nMy hypotheses could be that:\nHypothesis 1 (H1): PPP loan forgiveness was given to registered Republicans more often than registered Democrats\nNull Hypothesis (H0): There is no difference in loan forgiveness given to registered Democrats vs registered Republicans.\nIn some ways this is similar to Duchin & Hackney, but this benefits from a narrower look at who actually received PPP stimulus rather than eventual outcomes on the state level.\nClearly a few effects that would need to be controlled for. For example, Republicans could be more likely to be in any kind of business in the first place, confounding my results.\nIdeally, I would have focused on my home state of Massachusetts. However, although voter registration data is personally available in MA, you can’t download it all in one .csv, and scraping the Commonwealth’s website is not allowed. The National Conference of State Legislatures keeps track of which states have full voter registration data for download. For now, I will use Ohio as an example (although later on I will explain why I could have chosen better):\n\nPPP Data Dictionary\nTo help understand which fields mean what, the PPP data comes with a “Data Dictionary” with an explanation of columns [scroll right to see explanation]:\n\n\nCode\nppp_data_dictionary <- read_excel(\"_data/ppp-data-dictionary.xlsx\")\n\n\nError: `path` does not exist: '_data/ppp-data-dictionary.xlsx'\n\n\nCode\nppp_data_dictionary\n\n\nError in eval(expr, envir, enclos): object 'ppp_data_dictionary' not found\n\n\n\n\nPPP Data (Ohio)\nImporting the data of the actual PPP loans is pretty easy, although it gets clipped at 900k rows. This .csv contains just the PPP loans below $150k - others are contained in a smaller spreadsheet that covers all 50 states, and will be part of my final project.\n\n\nCode\nppp_all <- read_csv(\"_data/public_up_to_150k_9_220930.csv\")\n\n\nError: '_data/public_up_to_150k_9_220930.csv' does not exist in current working directory ('/home/runner/work/603_Fall_2022/603_Fall_2022/posts').\n\n\nCode\nppp_all\n\n\nError in eval(expr, envir, enclos): object 'ppp_all' not found\n\n\nIt still seems to capture all of Ohio, because Ohio doesn’t come last alphabetically:\n\n\nCode\nppp_ohio <- ppp_all %>% filter(BorrowerState == \"OH\")\n\n\nError in filter(., BorrowerState == \"OH\"): object 'ppp_all' not found\n\n\nCode\nppp_ohio\n\n\nError in eval(expr, envir, enclos): object 'ppp_ohio' not found\n\n\n\n\nLLCs, Corporations\nVisually, you may notice that businesses and LLCs make up a majority of the loan recipients.\nWhen I was preparing to do this project for Massachusetts - before I knew about the limitation of voter registration data in that state - I contacted the Secretary of the Commonwealth and they sent me a document with the entire “Corporation Search” data in tabular format, with the name of the founder, every board member, business type, year established, etc. I anticipated I would be able to match those individuals with the voter registration data, but that data was unfortunately available.\nThe Corporation Search data would be essential to the successful completion of the project.\nI have not inquired yet, but assume Ohio will provide the same Corporation Search data. And if they do not, I will just pick another state that 1.) has public voter registration information, and 2.) can supply the Corporation Search data in .csv or .xlsx (as Massachusetts did).\n\n\nDeeper Looks\n\n\nCode\nglimpse(ppp_ohio)\n\n\nError in glimpse(ppp_ohio): object 'ppp_ohio' not found\n\n\nForgivenessAmount, ForgivenessDate, and BorrowerName promise to be the most useful variables.\n\n\nCode\nprint(summarytools::dfSummary(ppp_ohio,\n                        varnumbers = FALSE,\n                        plain.ascii  = FALSE, \n                        style        = \"grid\", \n                        graph.magnif = 0.70, \n                        valid.col    = FALSE),\n      method = 'render',\n      table.classes = 'table-condensed')\n\n\nWarning: no DISPLAY variable so Tk is not available\n\n\nError in summarytools::dfSummary(ppp_ohio, varnumbers = FALSE, plain.ascii = FALSE, : object 'ppp_ohio' not found\n\n\nFrom a first look, most applicants reported only one employee needing coverage under the PPP. In fact, “Sole Proprietorship” was the highest category of BusinessType, above even LLCs, with 33.3%.\n19% of applicants were white, leading the race category, and 68% were unreported.\nMedian ForgivenessAmount was $20,438.7, and most loans were forgiven in 2021."
  },
  {
    "objectID": "posts/Final_SteveONeill.html#voter-registration",
    "href": "posts/Final_SteveONeill.html#voter-registration",
    "title": "Final Part 1",
    "section": "Voter Registration",
    "text": "Voter Registration\nThe Ohio voter registration data is easily read-in:\n\n\nCode\nohio_voters <- read_csv(\"_data/SWVF_1_22.txt\")\n\n\nError: '_data/SWVF_1_22.txt' does not exist in current working directory ('/home/runner/work/603_Fall_2022/603_Fall_2022/posts').\n\n\nCode\nohio_voters\n\n\nError in eval(expr, envir, enclos): object 'ohio_voters' not found\n\n\nZip codes will let us know with high confidence that we are dealing with the same business owner even if names are duplicated.\nThe historical information tells us if they have changed their party affiliation from year-to-year, which can be useful in determining if political rent-seeking was successful - we can even see ‘D’ or ‘R’ going back 22 years:\n\n\nCode\nglimpse(ohio_voters)\n\n\nError in glimpse(ohio_voters): object 'ohio_voters' not found\n\n\n\n\nCode\nprint(summarytools::dfSummary(ohio_voters,\n                        varnumbers = FALSE,\n                        plain.ascii  = FALSE, \n                        style        = \"grid\", \n                        graph.magnif = 0.70, \n                        valid.col    = FALSE),\n      method = 'render',\n      table.classes = 'table-condensed')\n\n\nError in summarytools::dfSummary(ohio_voters, varnumbers = FALSE, plain.ascii = FALSE, : object 'ohio_voters' not found\n\n\nSo - it seems like registered voters in our example of Ohio are slightly more Republican (by 2.8%), but a majority are undeclared.\nOhio actually has open primaries which is a good reason to consider another state for this dataset. I’ll be looking for others. But maybe, on the other hand, we can take PARTY_AFFILIATION to mean emphatic support for one party over another."
  },
  {
    "objectID": "posts/Final_SteveONeill.html#next-steps",
    "href": "posts/Final_SteveONeill.html#next-steps",
    "title": "Final Part 1",
    "section": "Next Steps",
    "text": "Next Steps\nNext, I will find the most advantageous state with a closed primary. Ideally, it will be a battleground or solid-Republican state with freely available voter registration data and a downloadable Corporation Search database (or available upon request).\nI look forward to any feedback or refinements to the hypotheses above."
  },
  {
    "objectID": "posts/KPopiela_FinalProposal.html",
    "href": "posts/KPopiela_FinalProposal.html",
    "title": "KPopiela_final p1",
    "section": "",
    "text": "#I will need to do some more thorough testing to make sure I can actually do this, but I'd like to focus my final project on ethnic violence since I know a lot about it (I wrote my undergrad thesis on ethno-religious violence in the Polish-Ukrainian borderlands). I found some data sets for my DACSS-601 intensive final that were pretty useful - I found a lot of information but now that I will have the statistical background I'd like to see if I can go further with it. Specifically in the sense of finding out statistics related to the likelihood of an eruption of ethnic violence in countries that fit specific criteria on paper. I can come up with a different research question for this topic area if my initial idea isn't feasible though.  \n\n#These criteria are as follows:  \n# - The population doesn't have an overwhelming ethnic majority; there are 2+ groups, each with substantial numbers.  \n# - History of socio-political repression by one group against the other(s) when said group has political power/alternating episodes of targeted political repression depending on what group holds a political majority.  \n# - The country/population is in a state of severe socio-political instability (war, territorial conquest, political power vacuum, etc.)  \n\n#To make this a little less challenging, I'm going to simplify things for myself. First, I will narrow the data down geographically and temporally - I'm going to focus on former Yugoslav states and the former USSR (I might change the location though). Second, since the data sets I'll be using are pretty big, I'm also going to look at certain columns based on the criteria I presented above (ethnic groups involved, group(s) being oppressed and by whom, and presence/absence of political instability). \n\n# Research Question: Based on what the data show, (1) is there actually a higher probability of ethnic armed conflict/war when these conditions, and (2) does one particular condition have a greater effect on political stability than the others?\n\n\nlibrary(readr)\nlibrary(poliscidata)\n\nError in library(poliscidata): there is no package called 'poliscidata'\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\nlibrary(foreign)\n\n##Summary Stats/Visuals\n\n#All data sets I will be using are from the Harvard Dataverse and they are as follows:  \n\n#     Lars-Erik Cederman; Brian Min; Andreas Wimmer, 2010, \"Ethnic Power Relations dataset\", https://doi.org/10.7910/DVN/NDJUJM, Harvard Dataverse, V1, UNF:5:k4xxXC2ASI204QZ4jqvUrQ== [fileUNF]  \n#     Lars-Erik Cederman; Brian Min; Andreas Wimmer, 2010, \"Ethnic Armed Conflict dataset\", https://doi.org/10.7910/DVN/K3OIJQ, Harvard Dataverse, V1  \n#    UCDP/PRIO Armed Conflict Dataset version 22.1. Gleditsch, Nils Petter, Peter Wallensteen, Mikael Eriksson, Margareta Sollenberg, and Håvard Strand (2002) Armed Conflict 1946-2001: A New Dataset. Journal of Peace Research 39(5).\n\n#I don't need to look at these in any particular order, so I'm just going to present them in the order they are in above. \n\n\n# Data set 1: \"Ethnic Power Relations dataset\"\n\nethnic_power_relations <- MASTER_EPR_v1_IrgFiR\n\nError in eval(expr, envir, enclos): object 'MASTER_EPR_v1_IrgFiR' not found\n\nethnic_power_relations <- ethnic_power_relations %>%\n  select(statename,from,to,group,status,size) %>%\n  filter(statename == c(\"Albania\",\"Croatia\",\"Bosnia and Herzegovina\",\"Yugoslavia\",\"Macedonia\",\"Poland\",\"Ukraine\",\"Russia\",\"Hungary\",\"Romania\",\"Bulgaria\"), from >= 1980) \n\nError in select(., statename, from, to, group, status, size): object 'ethnic_power_relations' not found\n\nethnic_power_relations\n\nError in eval(expr, envir, enclos): object 'ethnic_power_relations' not found\n\n\n\n#Data set 2: \"Ethnic Armed Conflict dataset\"\n#I'm going to use select() to look at \"country\", \"startyr\", \"endyr\", and \"ETHNOWAR\". Then I will use filter() to meet my geographic requirements.\n\nethnic_armed_conflict <- EAC_edPcfy\n\nError in eval(expr, envir, enclos): object 'EAC_edPcfy' not found\n\nethnic_armed_conflict <- ethnic_armed_conflict %>%\n  select(country, startyr, endyr, ETHNOAIMS, ETHNOWAR) %>%\n  filter(country == c(\"Croatia\",\"Yugoslavia\",\"Bosnia and Herzegovina\",\"USSR\",\"Russia\"),startyr >= 1980)\n\nError in select(., country, startyr, endyr, ETHNOAIMS, ETHNOWAR): object 'ethnic_armed_conflict' not found\n\nethnic_armed_conflict\n\nError in eval(expr, envir, enclos): object 'ethnic_armed_conflict' not found\n\n#This data set is based off of another one (Gleditsch, Nils Petter, Peter Wallensteen, Mikael Eriksson, Margareta Sollenberg, and Håvard Strand (2002) Armed Conflict 1946-2001: A New Dataset. Journal of Peace Research 39(5).) so I will include that as well\n\n#NOTE: I don't know why only 2 of the 5 countries I listed are showing up\n\n\n#Data set 3: \"UCDP/PRIO Armed Conflict Dataset\" version 22.1\n\nUCDP_Prio_AC <- ucdp_prio_acd_221_wKBkVs\n\nError in eval(expr, envir, enclos): object 'ucdp_prio_acd_221_wKBkVs' not found\n\nUCDP_Prio_AC <- UCDP_Prio_AC %>%\n  select(location, side_a, side_b, start_date) %>%\n  filter(location == c(\"Yugoslavia\",\"Croatia\",\"Serbia\",\"Russia\"))\n\nError in select(., location, side_a, side_b, start_date): object 'UCDP_Prio_AC' not found\n\nUCDP_Prio_AC\n\nError in eval(expr, envir, enclos): object 'UCDP_Prio_AC' not found\n\n#NOTE: I don't know why this one is doing the same thing as the previous one.\n\n\n#I'm obviously going to do more in-depth work with all three data sets, these (below) are just kind of a sample of what I will be doing.\n\n\nethnic_power_relations %>%\n  ggplot(mapping=aes(x=group,y=size,col=status)) + geom_point() + coord_flip()\n\nError in ggplot(., mapping = aes(x = group, y = size, col = status)): object 'ethnic_power_relations' not found\n\n\n\nethnic_power_relations %>%\n  summarise(mean(size))\n\nError in summarise(., mean(size)): object 'ethnic_power_relations' not found\n\n\n\nethnic_power_relations %>%\n  count(status)\n\nError in count(., status): object 'ethnic_power_relations' not found"
  },
  {
    "objectID": "posts/NiyatiSharma_blog1.html",
    "href": "posts/NiyatiSharma_blog1.html",
    "title": "Final Project Proposal",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(dplyr)\n\nlibrary(ggplot2)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/NiyatiSharma_blog1.html#introduction",
    "href": "posts/NiyatiSharma_blog1.html#introduction",
    "title": "Final Project Proposal",
    "section": "Introduction",
    "text": "Introduction\nCredit risk is defined as the risk of loss resulting from the failure by a borrower to repay the principal and interest owed to the leader.So the purpose of credit analysis is to determine the creditworthiness of borrowers by measuring the risk of loss that the lender is exposed to.When calculating the credit risk of a particular borrower, lenders consider various factors like analyze different documents, such as the borrower’s income statement, balance sheet, credit reports, and other documents that reveal the financial situation of the borrower. to evaluate the characteristics of the borrower and conditions of the loan to estimate the probability of default and the subsequent risk of financial loss."
  },
  {
    "objectID": "posts/NiyatiSharma_blog1.html#research-question",
    "href": "posts/NiyatiSharma_blog1.html#research-question",
    "title": "Final Project Proposal",
    "section": "Research Question",
    "text": "Research Question\nQ1. How credit risk depends on the age of the person. Q2. Dominating factor on which credit risk depends. Q3. Is credit risk depends on loan_intent?"
  },
  {
    "objectID": "posts/NiyatiSharma_blog1.html#hypothesis",
    "href": "posts/NiyatiSharma_blog1.html#hypothesis",
    "title": "Final Project Proposal",
    "section": "Hypothesis",
    "text": "Hypothesis\nAccording to research credit risk of a particular borrower, lenders consider various factors include the borrower’s capacity to repay are income, character, house ownership, and credit history. Check the relationship between the age, income with credit risk with new dataset."
  },
  {
    "objectID": "posts/NiyatiSharma_blog1.html#dataset",
    "href": "posts/NiyatiSharma_blog1.html#dataset",
    "title": "Final Project Proposal",
    "section": "Dataset",
    "text": "Dataset\nThis dataset contains columns simulating credit bureau data, factors on which credit risk depends. The variables of interest for me are income, age, employment length and home ownership.\n\n\nCode\nlibrary(readr)\ndf <- read_csv(\"C:/Users/Lenovo/Downloads/credit_risk_dataset_1.csv\")\n\n\nError: 'C:/Users/Lenovo/Downloads/credit_risk_dataset_1.csv' does not exist.\n\n\nCode\nsummary(df)\n\n\nError in object[[i]]: object of type 'closure' is not subsettable"
  },
  {
    "objectID": "posts/HW1_SteveONeill.html",
    "href": "posts/HW1_SteveONeill.html",
    "title": "Homework 1",
    "section": "",
    "text": "Question 2\nI will make a dataframe from the values provided:\n\n\nCode\nprior_convictions=c(0,1,2,3,4)\nfreq=c(128, 434, 160, 64, 24)\nprisondata <- data.frame(prior_convictions, freq)\nprisondata\n\n\n  prior_convictions freq\n1                 0  128\n2                 1  434\n3                 2  160\n4                 3   64\n5                 4   24\n\n\nAnd add a probability column:\n\n\nCode\nprison_prob <- prisondata %>% mutate(prob = freq/sum(freq))\nprison_prob\n\n\n  prior_convictions freq       prob\n1                 0  128 0.15802469\n2                 1  434 0.53580247\n3                 2  160 0.19753086\n4                 3   64 0.07901235\n5                 4   24 0.02962963\n\n\n\n2a.\nWhat is the probability that a randomly selected inmate has exactly 2 prior convictions?\nFrom the table above, the probability is 0.19753086, nearly 20 percent.\n\n\n2b.\nWhat is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\n\nCode\nhead(prison_prob,2) %>% summarise(sum(prob))\n\n\n  sum(prob)\n1 0.6938272\n\n\nThe probability a randomly selected inmate has has fewer than 2 prior convictions is ~69%.\n\n\n2c.\nWhat is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\n\nCode\nhead(prison_prob,3) %>% summarise(sum(prob))\n\n\n  sum(prob)\n1  0.891358\n\n\nThe probability a randomly selected inmate has 2 or fewer convictions is ~89%\n\n\n2d.\nWhat is the probability that a randomly selected inmate has more than 2 prior convictions?\n\n\nCode\ntail(prison_prob,3) %>% summarise(sum(prob))\n\n\n  sum(prob)\n1 0.3061728\n\n\nThe probability a randomly selected inmate has more than 2 prior convictions is ~30.6%\n\n\n2e.\nWhat is the expected value of the number of prior convictions?\n\n\nCode\nsum(prison_prob$prior_convictions*prison_prob$prob)\n\n\n[1] 1.28642\n\n\nCode\n#Or another way,\n\nweighted.mean(prison_prob$prior_convictions,prison_prob$prob)\n\n\n[1] 1.28642\n\n\nThe expected value of prior convictions is 1.28642\n\n\n2f\n\n\nCode\nprison_prob\n\n\n  prior_convictions freq       prob\n1                 0  128 0.15802469\n2                 1  434 0.53580247\n3                 2  160 0.19753086\n4                 3   64 0.07901235\n5                 4   24 0.02962963\n\n\nCode\nvar(prison_prob$freq)\n\n\n[1] 25948\n\n\nCode\nsd(prison_prob$freq)\n\n\n[1] 161.0838\n\n\nThe variance among all prior convictions is 25948. The standard deviation among all prior convictions is 161.0838."
  },
  {
    "objectID": "posts/Project_Yakub Rabiutheen.html",
    "href": "posts/Project_Yakub Rabiutheen.html",
    "title": "Project Rough Draft Proposal",
    "section": "",
    "text": "Hypopthesis\nThis research project will be testing two hypothesis regarding Britain and France.\n#Colonial Powers Hypopthesis. 1. The Years that France and Britain had more Exports is when the rate of colonization increased. 2. The Years that France and Britain had more Iron Production correlates to the years France and Britain increased levels of colonization.\n\n\nCode\nlibrary(readxl)\nlibrary(readr)\nColonial_Years <- read_excel(\"C:/Users/yakub/Documents/GitHub/603_Fall_2022/posts/_data/Colonial_transformation_data.xls\")\n\n\nError: `path` does not exist: 'C:/Users/yakub/Documents/GitHub/603_Fall_2022/posts/_data/Colonial_transformation_data.xls'\n\n\nCode\nImports_Exports<-read_csv(\"C:/Users/yakub/Documents/GitHub/603_Fall_2022/posts/_data/Countries_Imports_Exports.csv\")\n\n\nError: 'C:/Users/yakub/Documents/GitHub/603_Fall_2022/posts/_data/Countries_Imports_Exports.csv' does not exist.\n\n\nCode\nmilitary_raw_metals<-read_csv(\"C:/Users/yakub/Documents/GitHub/603_Fall_2022/posts/_data/NMC_v4_0.csv\")\n\n\nError: 'C:/Users/yakub/Documents/GitHub/603_Fall_2022/posts/_data/NMC_v4_0.csv' does not exist.\n\n\n#Descriptive Statistics.\nAs shown below, I tried finding Data regarding when colonialism began by France and Uk and seeing whether France and UK had more Trade Surpluses as they expanded their colonial empire. However, I was proven wrong as it appears that the UK has been running a Trade Deficit and has never had a Trade Surplus during their Colonial era pre-1960s. As such, I will have to change the approach of this research study. It appears the Balance of Trade has no relationship to Colonialism.\n\n\nCode\ncolnames(Colonial_Years)[3] <- \"Colonizing Country\"\n\n\nError in colnames(Colonial_Years)[3] <- \"Colonizing Country\": object 'Colonial_Years' not found\n\n\nCode\ncolnames(Colonial_Years)[4]<- \"Year_Colonization_Began\"\n\n\nError in colnames(Colonial_Years)[4] <- \"Year_Colonization_Began\": object 'Colonial_Years' not found\n\n\n\n\nCode\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nColonial_Years<-select(Colonial_Years,\"Colonizing Country\",\"Year_Colonization_Began\")\n\n\nError in select(Colonial_Years, \"Colonizing Country\", \"Year_Colonization_Began\"): object 'Colonial_Years' not found\n\n\nCode\nColonial_Years<-filter(Colonial_Years,`Colonizing Country` %in% c(\"F\",\"UK\"))\n\n\nError in filter(Colonial_Years, `Colonizing Country` %in% c(\"F\", \"UK\")): object 'Colonial_Years' not found\n\n\nCode\ntable(Colonial_Years)\n\n\nError in table(Colonial_Years): object 'Colonial_Years' not found\n\n\n\n\nCode\nImports_Exports%>% filter(year < '1960') \n\n\nError in filter(., year < \"1960\"): object 'Imports_Exports' not found\n\n\n\n\nCode\ncolonial_trade<-filter(Imports_Exports,`stateabb` %in% c(\"FRN\",\"UKG\"))\n\n\nError in filter(Imports_Exports, stateabb %in% c(\"FRN\", \"UKG\")): object 'Imports_Exports' not found\n\n\n\n\nCode\noptions(scipen = 999)    \n\n\nCreated a Forumula to calculate Trade Surplus and Deficits.\n\n\nCode\ncolonial_trade$trade_balance<-(colonial_trade$exports-colonial_trade$imports)\n\n\nError in eval(expr, envir, enclos): object 'colonial_trade' not found\n\n\nFound a better way to find years that France and Britain were running Trade Deficits.\n\n\nCode\nprint(colonial_trade[colonial_trade$exports < colonial_trade$imports,] )\n\n\nError in print(colonial_trade[colonial_trade$exports < colonial_trade$imports, : object 'colonial_trade' not found\n\n\nI did the inverse to find that the UK has always had a Trade Deficit\n\n\nCode\nprint(colonial_trade[colonial_trade$exports > colonial_trade$imports,] )\n\n\nError in print(colonial_trade[colonial_trade$exports > colonial_trade$imports, : object 'colonial_trade' not found\n\n\nMy finding has found that there is no relationship between Trade Deficits and Colonialism as the UK has never had a positive trade balance.\n##Conclusion\nI think that the approach of my research has to be changed as my initial theory about trade deficits and Colonialism has been disapprove. As such, I think I will shift this project towards a different approach. I will try exploring the historical prices of commodity goods when France and U.K. were colonial powers.\n\n\nReferences\nMcWhinney, E. (1960, December 14). Declaration on the granting of Independence to colonial countries and Peoples. United Nations. Retrieved October 10, 2022, from https://legal.un.org/avl/ha/dicc/dicc.html\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::{#quarto-navigation-envelope .hidden}\n[Project Rough Draft Proposal]{.hidden render-id=\"quarto-int-sidebar-title\"}\n[Project Rough Draft Proposal]{.hidden render-id=\"quarto-int-navbar-title\"}\n[Fall 2022 Posts]{.hidden render-id=\"quarto-int-navbar:Fall 2022 Posts\"}\n[Contributors]{.hidden render-id=\"quarto-int-navbar:Contributors\"}\n[DACSS]{.hidden render-id=\"quarto-int-navbar:DACSS\"}\n:::\n\n\n\n:::{#quarto-meta-markdown .hidden}\n[ - Project Rough Draft Proposal]{.hidden render-id=\"quarto-metatitle\"}\n[ - Project Rough Draft Proposal]{.hidden render-id=\"quarto-twittercardtitle\"}\n[ - Project Rough Draft Proposal]{.hidden render-id=\"quarto-ogcardtitle\"}\n[International Trade's influence on War]{.hidden render-id=\"quarto-metadesc\"}\n:::\n\n\n\n\n<!-- -->\n\n::: {.quarto-embedded-source-code}\n```````````````````{.markdown shortcodes=\"false\"}\n---\ntitle: \"Project Rough Draft Proposal\"\nauthor: \"Yakub Rabiutheen\"\ndescription: \"International Trade's influence on War\"\ndate: \"10/11/2022\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - finalproject1\n  - desriptive statistics \n  - probability\n---\n\n# Research Question\n\nHow has international trade influenced how countries interact with each other? This research project looks specifically at  France and Britain which  are grouped together as Colonial Powers to explore the relationship of Colonialism and international trade. This research project will be looking at data from the Correlates Of War Project, which has international trade data from 1870 to 2015. The cut-off year for this research project will be 1960, as  on December 14,1960, the UN declared Colonialism was a human's right's violation and legally declared Colonialism was over(McWhinney,1960).   \n\n\n# Hypopthesis\n\nThis research project will be testing two hypothesis regarding Britain and France.\n\n#Colonial Powers Hypopthesis.\n1. The Years that France and Britain had more Exports is when the rate of colonization increased.\n2. The Years that France and Britain had more Iron Production correlates to the years France and Britain increased levels of colonization.\n\n\n\nquarto-executable-code-5450563D\n\n```r\nlibrary(readxl)\nlibrary(readr)\nColonial_Years <- read_excel(\"C:/Users/yakub/Documents/GitHub/603_Fall_2022/posts/_data/Colonial_transformation_data.xls\")\nImports_Exports<-read_csv(\"C:/Users/yakub/Documents/GitHub/603_Fall_2022/posts/_data/Countries_Imports_Exports.csv\")\nmilitary_raw_metals<-read_csv(\"C:/Users/yakub/Documents/GitHub/603_Fall_2022/posts/_data/NMC_v4_0.csv\")\n#Descriptive Statistics.\nAs shown below, I tried finding Data regarding when colonialism began by France and Uk and seeing whether France and UK had more Trade Surpluses as they expanded their colonial empire. However, I was proven wrong as it appears that the UK has been running a Trade Deficit and has never had a Trade Surplus during their Colonial era pre-1960s. As such, I will have to change the approach of this research study. It appears the Balance of Trade has no relationship to Colonialism.\nquarto-executable-code-5450563D\ncolnames(Colonial_Years)[3] <- \"Colonizing Country\"\ncolnames(Colonial_Years)[4]<- \"Year_Colonization_Began\"\nquarto-executable-code-5450563D\nlibrary(dplyr)\nColonial_Years<-select(Colonial_Years,\"Colonizing Country\",\"Year_Colonization_Began\")\nColonial_Years<-filter(Colonial_Years,`Colonizing Country` %in% c(\"F\",\"UK\"))\ntable(Colonial_Years)\nquarto-executable-code-5450563D\nImports_Exports%>% filter(year < '1960') \nquarto-executable-code-5450563D\ncolonial_trade<-filter(Imports_Exports,`stateabb` %in% c(\"FRN\",\"UKG\"))\nquarto-executable-code-5450563D\noptions(scipen = 999)    \nCreated a Forumula to calculate Trade Surplus and Deficits.\nquarto-executable-code-5450563D\ncolonial_trade$trade_balance<-(colonial_trade$exports-colonial_trade$imports)\nFound a better way to find years that France and Britain were running Trade Deficits. quarto-executable-code-5450563D\nprint(colonial_trade[colonial_trade$exports < colonial_trade$imports,] )\nI did the inverse to find that the UK has always had a Trade Deficit quarto-executable-code-5450563D\nprint(colonial_trade[colonial_trade$exports > colonial_trade$imports,] )\nMy finding has found that there is no relationship between Trade Deficits and Colonialism as the UK has never had a positive trade balance.\n##Conclusion\nI think that the approach of my research has to be changed as my initial theory about trade deficits and Colonialism has been disapprove. As such, I think I will shift this project towards a different approach. I will try exploring the historical prices of commodity goods when France and U.K. were colonial powers.\n\n\nReferences\nMcWhinney, E. (1960, December 14). Declaration on the granting of Independence to colonial countries and Peoples. United Nations. Retrieved October 10, 2022, from https://legal.un.org/avl/ha/dicc/dicc.html\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "posts/DACSS 603 Final Part 1.html",
    "href": "posts/DACSS 603 Final Part 1.html",
    "title": "DACSS 603 Final Project - Proposal",
    "section": "",
    "text": "Code\n# Setup\n\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(readr)\nlibrary(scales)\n\n\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\n\nCode\n# Importing datasets\n\nNYC_2019 <- read_csv(\"/Users/karenkimble/Documents/UMass/SPP/Fall 2022/DACSS 603/DACSS Final Project/NYC School Data/2018-2019_School_Demographic_Snapshot.csv\", col_types = cols(`Grade PK (Half Day & Full Day)` = col_skip(), `# Multiple Race Categories Not Represented` = col_skip(), `% Multiple Race Categories Not Represented` = col_skip()))\n\n\nError: '/Users/karenkimble/Documents/UMass/SPP/Fall 2022/DACSS 603/DACSS Final Project/NYC School Data/2018-2019_School_Demographic_Snapshot.csv' does not exist.\n\n\nCode\nNYC_2019$`% Poverty` <- percent(NYC_2019$`% Poverty`, accuracy=0.1)\n\n\nError in number(x = x, accuracy = accuracy, scale = scale, prefix = prefix, : object 'NYC_2019' not found\n\n\nCode\nNYC_2021 <- read_csv(\"/Users/karenkimble/Documents/UMass/SPP/Fall 2022/DACSS 603/DACSS Final Project/NYC School Data/2020-2021_Demographic_Snapshot_School.csv\", col_types = cols(`Grade 3K+PK (Half Day & Full Day)` = col_skip(), `# Multi-Racial` = col_skip(), `% Multi-Racial` = col_skip(), `# Native American` = col_skip(), `% Native American` = col_skip(), `# Missing Race/Ethnicity Data` = col_skip(), `% Missing Race/Ethnicity Data` = col_skip()))\n\n\nError: '/Users/karenkimble/Documents/UMass/SPP/Fall 2022/DACSS 603/DACSS Final Project/NYC School Data/2020-2021_Demographic_Snapshot_School.csv' does not exist.\n\n\nCode\n# In order to bind the data, I had to remove columns that were not present in the other spreadsheet: Grade PK or 3K, Native American, the different multi-racial categories, and Missing Data\n\nschool_data <- rbind(NYC_2019, NYC_2021)\n\n\nError in rbind(NYC_2019, NYC_2021): object 'NYC_2019' not found\n\n\nCode\n# Making values coded as \"above 95%\" to equal 95% and \"below 5%\" to equal 5% for the purposes of this analysis\n\nschool_data$`% Poverty` <- recode(school_data$`% Poverty`, \"Above 95%\" = \"95%\", \"Below 5%\" = \"5%\")\n\n\nError in recode(school_data$`% Poverty`, `Above 95%` = \"95%\", `Below 5%` = \"5%\"): object 'school_data' not found\n\n\nCode\n# Re-coding variables as numeric\n\nschool_data$`% Poverty` <- sapply(school_data$`% Poverty`, function(x) gsub(\"%\", \"\", x))\n\n\nError in lapply(X = X, FUN = FUN, ...): object 'school_data' not found\n\n\nCode\nschool_data$`% Poverty` <- as.numeric(school_data$`% Poverty`)\n\n\nError in eval(expr, envir, enclos): object 'school_data' not found\n\n\nCode\nschool_data$`Economic Need Index` <- as.numeric(school_data$`Economic Need Index`)\n\n\nError in eval(expr, envir, enclos): object 'school_data' not found"
  },
  {
    "objectID": "posts/DACSS 603 Final Part 1.html#research-question",
    "href": "posts/DACSS 603 Final Part 1.html#research-question",
    "title": "DACSS 603 Final Project - Proposal",
    "section": "Research Question",
    "text": "Research Question\nThe research question I want to explore is whether child poverty has increased in schools that are predominantly made up of non-white students from the 2014-2015 school year to the 2020-2021 school year. I think this is extremely important to look at because of the pandemic’s impact on not only child learning but also families’ economic resources. According to the Columbia University Center on Poverty and Social Policy, “nearly a quarter of children ages 0-3 live in poverty and nearly half of the city’s young children live in lower-opportunity neighborhoods where the poverty rate is at least 20 percent” (“Poverty”). Unfortunately, research shows that poverty is disproportionately felt according to one’s race or ethnicity. In New York State, as of 2021, child poverty among children of color is almost 30%, with Black or African American children more than twice as likely to live in poverty than White, Non-Hispanic children (“New York State”, 2021). With this disproportionate level of economic need in children of color, it seems important to investigate if the poverty level within New York City schools that are predominately non-White has increased significantly compared to schools that are predominantly White. When searching the UMass Libraries databases and other sources, it was hard to find studies that used this data in this way. It is important to understand if there is increasing poverty levels within an already vulnerable group."
  },
  {
    "objectID": "posts/DACSS 603 Final Part 1.html#hypothesis",
    "href": "posts/DACSS 603 Final Part 1.html#hypothesis",
    "title": "DACSS 603 Final Project - Proposal",
    "section": "Hypothesis",
    "text": "Hypothesis\nI hypothesize that the poverty rate in NYC schools that are predominantly children of color will have increased more between the 2014-2015 and the 2020-2021 school years than the poverty rate in schools that are predominantly White. Since I have not found many previous studies on this, it is hard to know if this hypothesis was tested before. However, this data is fairly recent and also relates to the pandemic’s effects on economics, so I think it is still a significant contribution to test this hypothesis."
  },
  {
    "objectID": "posts/DACSS 603 Final Part 1.html#descriptive-statistics",
    "href": "posts/DACSS 603 Final Part 1.html#descriptive-statistics",
    "title": "DACSS 603 Final Project - Proposal",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\nA description and summary of your data. How was your data collected by its original collectors? What are the important variables of interest for your research question? Use functions like glimpse() and summary() to present your data.\nThe data was collected by New York City and put on its Open Data source. The data covers NYC schools in the academic years 2014-2015 to 2020-2021. The important variables of interest included in the data are:\n\nAcademic year\nNumber and percentage of Asisan, Black, Hispanic, and White students\nNumber and percentage of students in poverty\nEconomic need index, which is the average of students’ “Economic Need Values”\n\nThe Economic Need Index (ENI) estimates the percentage of students facing economic hardship\n\n\nThe other variables included are: DBN (district, borough, school number), school name, total enrollment, enrollment numbers for K-12, number and percentage of female and male students, number and percentage of students with disabilities, and number and percentage of English-Language Learner (ELL) students.\n\n\nCode\nglimpse(school_data)\n\n\nError in glimpse(school_data): object 'school_data' not found\n\n\n\n\nCode\nsummary(school_data)\n\n\nError in summary(school_data): object 'school_data' not found\n\n\nCode\n# Note: the summary data for the enrollment numbers split by grade is somewhat off (especially minimums) because there is no variable listed for type of school (i.e., middle versus high school). So, for example, an elementary school would have an enrollment total of 0 for grade 12, which would show up as the minimum.\n\n\nAs we can see from this summary, the median percent of poverty in NYC schools (81.4%) is higher than the mean percent (75.89%), indicating that there may be low outliers with very low percentages of poverty. The same holds true for the Economic Need Index, with the mean (0.691) lower than the median (0.743). It is troubling, however, that both the mean and median percentages of poverty in NYC schools overall is more than three-fourths of the population."
  },
  {
    "objectID": "posts/DACSS 603 Final Part 1.html#references",
    "href": "posts/DACSS 603 Final Part 1.html#references",
    "title": "DACSS 603 Final Project - Proposal",
    "section": "References",
    "text": "References\nNew York State Child Poverty Facts. Schuyler Center for Analysis and Advocacy. (2021, February 18). Retrieved from https://scaany.org/wp-content/uploads/2021/02/NYS-Child-Poverty-Facts_Feb2021.pdf\nPoverty in New York City. Columbia University Center on Poverty and Social Policy. (n.d.). Retrieved from https://www.povertycenter.columbia.edu/poverty-in-new-york-city#:~:text=Children%20and%20Families%20in%20New%20York%20City&text=Through%20surveys%2C%20we%20find%20that,is%20at%20least%2020%20percent."
  },
  {
    "objectID": "posts/HW1_EthanCampbell.html",
    "href": "posts/HW1_EthanCampbell.html",
    "title": "Homework 1",
    "section": "",
    "text": "First, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(dplyr)\ndf <- read_excel(\"_data/LungCapData.xls\")\n\n\n\n\n(The distribution of LungCap looks as follows:)\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\n\n\nCode\nhead(df)\n\n\n# A tibble: 6 × 6\n  LungCap   Age Height Smoke Gender Caesarean\n    <dbl> <dbl>  <dbl> <chr> <chr>  <chr>    \n1    6.48     6   62.1 no    male   no       \n2   10.1     18   74.7 yes   female no       \n3    9.55    16   69.7 no    female yes      \n4   11.1     14   71   no    male   no       \n5    4.8      5   56.9 no    male   no       \n6    6.22    11   58.7 no    female no       \n\n\nCode\nhist(df$LungCap)\n\n\n\n\n\n\n\n\n(Comparing lung cap by gender)\nHere we notice that males tend to have a higher lung cap compared to females. Females average tends to sit around 8 while males seems to sit closer to 9\n\n\nCode\nboxplot(df$LungCap~df$Gender)\n\n\n\n\n\n\n\n\n(smoker vs non-smoker lung cap)\nInterestingly, none smokers tend to have a lower lung capacity however, I believe this might be due to age. No this does not make sense at first glance and does betray my expectation.\n\n\nCode\ndf %>%\n  group_by(Smoke) %>%\n  summarize_at(vars(LungCap), list(mean = mean))\n\n\n# A tibble: 2 × 2\n  Smoke  mean\n  <chr> <dbl>\n1 no     7.77\n2 yes    8.65\n\n\n\n\n\n(relation between smoking and lung cap at different age groups)\nThe lung cap starts off higher but takes and dip then rises as the age continues to grow. I believe the trend is the higher age grows the higher the lung cap until it reaches a certain point.\n\n\nCode\n# lung cap is 9.62\ndf %>%\n  select(Age, LungCap) %>%\n  filter(Age >= 13) %>%\n  colMeans()\n\n\n      Age   LungCap \n15.609290  9.628757 \n\n\nCode\n# lung cap is 9.04\ndf %>%\n  select(Age, LungCap) %>%\n  filter(Age >= 14 & Age <= 15) %>%\n  colMeans()\n\n\n      Age   LungCap \n14.533333  9.045417 \n\n\nCode\n# lung cap is 10.24\ndf %>%\n  select(Age, LungCap) %>%\n  filter(Age >= 16 & Age <= 17) %>%\n  colMeans()\n\n\n     Age  LungCap \n16.44330 10.24588 \n\n\nCode\n# lung cap is 11.26\ndf %>%\n  select(Age, LungCap) %>%\n  filter(Age > 18) %>%\n  colMeans()\n\n\n     Age  LungCap \n19.00000 11.26149 \n\n\n\n\n\n(lung cap for smokers and non smokers broken into age groups)\nWe notice a clear trend that smokers have a lower lung capacity compared to non-smokers\n\n\nCode\ndf %>%\n  select(Age, LungCap, Smoke) %>%\n  group_by(Smoke) %>%\n  filter(Age >= 13) %>%\n  summarize_at(vars(LungCap), list(mean = mean))\n\n\n# A tibble: 2 × 2\n  Smoke  mean\n  <chr> <dbl>\n1 no     9.71\n2 yes    9.21\n\n\nCode\ndf %>%\n  select(Age, LungCap, Smoke) %>%\n  group_by(Smoke) %>%\n  filter(Age >= 14 & Age <= 15) %>%\n  summarize_at(vars(LungCap), list(mean = mean))\n\n\n# A tibble: 2 × 2\n  Smoke  mean\n  <chr> <dbl>\n1 no     9.14\n2 yes    8.39\n\n\nCode\ndf %>%\n  select(Age, LungCap, Smoke) %>%\n  group_by(Smoke) %>%\n  filter(Age >= 16 & Age <= 17) %>%\n  summarize_at(vars(LungCap), list(mean = mean))\n\n\n# A tibble: 2 × 2\n  Smoke  mean\n  <chr> <dbl>\n1 no    10.5 \n2 yes    9.38\n\n\nCode\ndf %>%\n  select(Age, LungCap, Smoke) %>%\n  group_by(Smoke) %>%\n  filter(Age > 18) %>%\n  summarize_at(vars(LungCap), list(mean = mean))\n\n\n# A tibble: 2 × 2\n  Smoke  mean\n  <chr> <dbl>\n1 no     11.3\n2 yes    11.3\n\n\n\n\n\n(correlation and covariance between lung capacity and age)\ncorrelation is at .819 meaning they have a positive correlation of about 82%. This means that there is a connection between the two and when one goes up so does the other.\n\n\nCode\ncov(df$LungCap, df$Age)\n\n\n[1] 8.738289\n\n\nCode\ncor(df$LungCap, df$Age)\n\n\n[1] 0.8196749"
  },
  {
    "objectID": "posts/HW1_EthanCampbell.html#a-1",
    "href": "posts/HW1_EthanCampbell.html#a-1",
    "title": "Homework 1",
    "section": "2.a",
    "text": "2.a\nprobability of exactly 2 convictions probability = 19.7%\n\n\nCode\ndf1 %>%\n  select(X, Freq, Probability) %>%\n  filter(X == 2)\n\n\n# A tibble: 1 × 3\n      X  Freq Probability\n  <dbl> <dbl>       <dbl>\n1     2   160       0.197"
  },
  {
    "objectID": "posts/HW1_EthanCampbell.html#b-1",
    "href": "posts/HW1_EthanCampbell.html#b-1",
    "title": "Homework 1",
    "section": "2.b",
    "text": "2.b\nprobability of fewer than 2 convictions probability = 69.2%\n\n\nCode\nsum(df1$Probability[1:2])\n\n\n[1] 0.6921182"
  },
  {
    "objectID": "posts/HW1_EthanCampbell.html#c-1",
    "href": "posts/HW1_EthanCampbell.html#c-1",
    "title": "Homework 1",
    "section": "2.c",
    "text": "2.c\nProbability of having 2 or fewer convictions probability = 88.9%\n\n\nCode\nsum(df1$Probability[1:3])\n\n\n[1] 0.8891626"
  },
  {
    "objectID": "posts/HW1_EthanCampbell.html#d-1",
    "href": "posts/HW1_EthanCampbell.html#d-1",
    "title": "Homework 1",
    "section": "2.d",
    "text": "2.d\nprobability of having more than 2 convictions probability = 11.08%\n\n\nCode\nsum(df1$Probability[4:5])\n\n\n[1] 0.1108374"
  },
  {
    "objectID": "posts/HW1_EthanCampbell.html#e-1",
    "href": "posts/HW1_EthanCampbell.html#e-1",
    "title": "Homework 1",
    "section": "2.e",
    "text": "2.e\nWhat is the expected value expected value is 1.29 convictions\n\n\nCode\ndf1 %>%\n  select(X, Freq, Probability) %>%\n  mutate(expected_value = (0*0.15763547)+(1*0.53448276)+(2*0.19704433)+(3*0.07881773)+(4*0.03201970))\n\n\n# A tibble: 5 × 4\n      X  Freq Probability expected_value\n  <dbl> <dbl>       <dbl>          <dbl>\n1     0   128      0.158            1.29\n2     1   434      0.534            1.29\n3     2   160      0.197            1.29\n4     3    64      0.0788           1.29\n5     4    26      0.0320           1.29"
  },
  {
    "objectID": "posts/HW1_EthanCampbell.html#f-1",
    "href": "posts/HW1_EthanCampbell.html#f-1",
    "title": "Homework 1",
    "section": "2.f",
    "text": "2.f\nWhat is the variance and standard deviation of the prior convictions Variance = 25810.8 standard deviation = 160.6574\n\n\nCode\nvar(df$Freq)\n\n\n[1] 25810.8\n\n\nCode\nsd(df$Freq)\n\n\n[1] 160.6574"
  },
  {
    "objectID": "posts/Untitled.html",
    "href": "posts/Untitled.html",
    "title": "Blog Post Template",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/Untitled.html#instructions",
    "href": "posts/Untitled.html#instructions",
    "title": "Blog Post Template",
    "section": "Instructions",
    "text": "Instructions\nThis document provides yaml header inforamtion you will need to replicate each week to submit your homework or other blog posts. Please observe the following conventions:\n\nSave your own copy of this template as a blog post in the posts folder, naming it FirstLast_hwX.qmd\nEdit the yaml header to change your author name - use the same name each week\ninclude a description that is reader friendly\nupdate the category list to indicate the type of submission, the data used, the main packages or techniques, your name, or any thing else to make your document easy to find\nedit as a normal qmd/rmd file\n\n\n\nCode\nx <- c(2,3,4,5)\nmean(x)\n\n\n[1] 3.5"
  },
  {
    "objectID": "posts/Untitled.html#rendering-your-post",
    "href": "posts/Untitled.html#rendering-your-post",
    "title": "Blog Post Template",
    "section": "Rendering your post",
    "text": "Rendering your post\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code.\n\n\n\n\n\n\nWarning\n\n\n\nBe sure that you have moved your *.qmd file into the posts folder BEFORE you render it, so that all files are stored in the correct location.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nOnly render a single file - don’t try to render the whole website!\n\n\n\n\n\n\n\n\nPilot Student Blogs\n\n\n\nWe are piloting a workflow including individual student websites with direted and limited pull requests back to course blogs. Please let us know if you would like to participate."
  },
  {
    "objectID": "posts/Untitled.html#reading-in-data-files",
    "href": "posts/Untitled.html#reading-in-data-files",
    "title": "Blog Post Template",
    "section": "Reading in data files",
    "text": "Reading in data files\nThe easiest data source to use - at least initially - is to choose something easily accessible, either from our _data folder provided, or from an online source that is publicly available.\n\n\n\n\n\n\nUsing Other Data\n\n\n\nIf you would like to use a source that you have access to and it is small enough and you don’t mind making it public, you can copy it into the _data file and include in your commit and pull request.\n\n\n:::{.callout-tip} ## Using Private Data\nIf you would like to use a proprietary source of data, that should be possible using the same process outlined above. There may initially be a few issues. We hope to have this feature working smoothly soon!"
  },
  {
    "objectID": "posts/KPopiela_HW1.html",
    "href": "posts/KPopiela_HW1.html",
    "title": "HW1",
    "section": "",
    "text": "library(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(lsr)\n\nError in library(lsr): there is no package called 'lsr'\n#Question 1"
  },
  {
    "objectID": "posts/KPopiela_HW1.html#a1b.-what-does-the-distribution-of-lungcap-look-like",
    "href": "posts/KPopiela_HW1.html#a1b.-what-does-the-distribution-of-lungcap-look-like",
    "title": "HW1",
    "section": "1a/1b. What does the distribution of LungCap look like?",
    "text": "1a/1b. What does the distribution of LungCap look like?\n\nHint: Plot a histogram with probability density on the y axis\n\n\nHint: make boxplots separated by gender using the boxplot() function\n\nLungCap <- read_xls(\"_data/LungCapData.xls\")\nhead(LungCap)\n\n# A tibble: 6 × 6\n  LungCap   Age Height Smoke Gender Caesarean\n    <dbl> <dbl>  <dbl> <chr> <chr>  <chr>    \n1    6.48     6   62.1 no    male   no       \n2   10.1     18   74.7 yes   female no       \n3    9.55    16   69.7 no    female yes      \n4   11.1     14   71   no    male   no       \n5    4.8      5   56.9 no    male   no       \n6    6.22    11   58.7 no    female no       \n\n\n\nhist(LungCap$LungCap)\n\n\n\n\n\nLungCap_MF <- LungCap %>%\n  arrange(LungCap, Gender) %>%\n  group_by(Gender)\nboxplot(LungCap_MF$LungCap ~ LungCap_MF$Gender)\n\n\n\n#I wanted to change the axis labels to \"Gender\" (x) and \"Lung Capacity\" (y), but after an hour and a half of trying to no avail, I had to call it for my own sanity.\n\n\ncolnames(LungCap)\n\n[1] \"LungCap\"   \"Age\"       \"Height\"    \"Smoke\"     \"Gender\"    \"Caesarean\""
  },
  {
    "objectID": "posts/KPopiela_HW1.html#c.-compare-the-mean-lung-capacities-for-smokers-and-non-smokers.-does-it-make-sense",
    "href": "posts/KPopiela_HW1.html#c.-compare-the-mean-lung-capacities-for-smokers-and-non-smokers.-does-it-make-sense",
    "title": "HW1",
    "section": "1c. Compare the mean lung capacities for smokers and non-smokers. Does it make sense?",
    "text": "1c. Compare the mean lung capacities for smokers and non-smokers. Does it make sense?\n\nLungCap_smoke <- LungCapData %>%\n  select(LungCap, Smoke) %>%\n  group_by(Smoke)\n\nError in select(., LungCap, Smoke): object 'LungCapData' not found\n\nhead(LungCap_smoke)\n\nError in head(LungCap_smoke): object 'LungCap_smoke' not found\n\n\n\nsummarise(LungCap_smoke, mean(LungCap))\n\nError in summarise(LungCap_smoke, mean(LungCap)): object 'LungCap_smoke' not found\n\n#The mean lung capacities for non-smokers and smokers is 7.77 and 8.65 respectively. Does this make sense? No. One would expect that the mean lung capacity for non-smokers would be higher, but that is not the case here. Let's do some digging to see what the range of values for smokers' and non-smokers' lung capacity. I also want to look at how many people voted \"yes\" or \"no\"; it could be that fewer people (with higher lung capacity) voted \"yes,\" contributing to the higher mean.\n\n\nLCS2 <- LungCap_smoke %>%\n  filter(Smoke == \"yes\")\n\nError in filter(., Smoke == \"yes\"): object 'LungCap_smoke' not found\n\nrange(LCS2$LungCap)\n\nError in eval(expr, envir, enclos): object 'LCS2' not found\n\nLCS2 <- LungCap_smoke %>%\n  filter(Smoke == \"no\")\n\nError in filter(., Smoke == \"no\"): object 'LungCap_smoke' not found\n\nrange(LCS2$LungCap)\n\nError in eval(expr, envir, enclos): object 'LCS2' not found\n\n##Lung capacity for smokers ranges from 3.850 to 13.325, while the range for non-smokers is 0.507 to 14.675. Right off the bat, smokers have a higher minimum value, which prevents the mean from being dragged down during calculation. Non-smokers' minimum value is 0.507, an outlier which does seem to have an effect on this category's mean. \n\n\nLungCap_smoke %>%\n  count(Smoke)\n\nError in count(., Smoke): object 'LungCap_smoke' not found\n\n#Out of 725 respondents only 77 voted yes and 648 voted no, so I was right with my guess as to what caused the difference in mean lung capacity between smokers and non-smokers."
  },
  {
    "objectID": "posts/KPopiela_HW1.html#d.-examine-the-relationship-between-smoking-and-lung-capacity-within-age-groups-less-than-or-equal-to-13-14-to-15-16-to-17-and-greater-than-or-equal-to-18.",
    "href": "posts/KPopiela_HW1.html#d.-examine-the-relationship-between-smoking-and-lung-capacity-within-age-groups-less-than-or-equal-to-13-14-to-15-16-to-17-and-greater-than-or-equal-to-18.",
    "title": "HW1",
    "section": "1d. Examine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.",
    "text": "1d. Examine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\n#To start, I'm going to calculate the range and mean of each of the above age groups, as well as a tally of how many are and aren't smokers.\n\n#a) Less than or equal to 13\nLC_Age13 <- LungCap %>%\n  select(LungCap, Age, Smoke) %>%\n  filter(Age <= 13)\nrange(LC_Age13$LungCap)\n\n[1]  0.507 12.050\n\n#The range of lung capacity values for children under the age of 13 is 0.507 to 12.050. The mean is 6.412.\n\n\nsummarise(LC_Age13, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            6.41\n\n\n\nLC_Age13 %>%\n  count(Smoke)\n\n# A tibble: 2 × 2\n  Smoke     n\n  <chr> <int>\n1 no      401\n2 yes      27\n\n#401 individuals 13 and under responded that they don't smoke, while 27 said they do. Compared to the initial calculations for the whole survey, the mean value is slightly lower, which is likely indicative of the fact that children have smaller lungs than adults and therefore have less lung capacity. Something important to note, however, is that this age group accounts for 428 of the total 725 responses (about 59%).\n\n\n#b) 14 to 15 \nLC_Age145 <- LungCap %>%\n  select(LungCap, Age, Smoke) %>%\n  filter(Age == 14:15)\n\nWarning in Age == 14:15: longer object length is not a multiple of shorter\nobject length\n\nrange(LC_Age145$LungCap)\n\n[1]  5.625 12.900\n\n#The minimum and maximum lung capacity values for individuals aged 14-15 are 5.625 and 12.900. The mean is 8.842.\n\n\nsummarise(LC_Age145, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            8.84\n\n\n\nLC_Age145 %>%\n  count(Smoke)\n\n# A tibble: 2 × 2\n  Smoke     n\n  <chr> <int>\n1 no       44\n2 yes       8\n\n#Out of the 52 respondents in this age group, 44 stated that they don't smoke and 8 said that they do. The 14-15y/o age group is MUCH smaller than the \"13 and under\" one (it makes up only 12% of total responses). The percentage of smokers to non-smokers in each of the above age groups,is 7% and 18% respectively. If you were to take these percentages at face value without taking sample size into account, it would look as if the 14-15 y/o age group makes up 18% of the total 725 responses. In reality, this sample accounts for 6% of the total, making its impact relatively low.\n\n\n#c) 16 to 17\nLC_Age167 <- LungCap %>%\n  select(LungCap, Age, Smoke) %>%\n  filter(Age == 16:17)\n\nWarning in Age == 16:17: longer object length is not a multiple of shorter\nobject length\n\nrange(LC_Age167$LungCap)\n\n[1]  5.675 13.375\n\n#The minimum and maximum lung capacity values for individuals ages 16 to 17 are 5.675 and 13.375. The mean is 10.058.\n\n\nsummarise(LC_Age167, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            10.1\n\n\n\nLC_Age167 %>%\n  count(Smoke)\n\n# A tibble: 2 × 2\n  Smoke     n\n  <chr> <int>\n1 no       40\n2 yes       8\n\n#This sample is similar in size to the previous (14-15 year olds) with only 48 responses, and smokers make up 20% of the responses. Now lets discuss the other figures.  \n\n#The mean lung capacity for 16-17 year olds is 10.058, 1.216 units higher than the previous age group, and 3.646 units higher than the \"13 and under\" age group. As of this point in my calculations, the only relationship seems to be between age and lung capacity rather than smoking and lung capacity; this is due to the facts that: 1) not that many people ages 0-17 smoke, and 2) the sample sizes for the 14-17 age group is 100 compared to the 428 responses in the \"13 and under\" group.\n\n\nLC_Age18p <- LungCap %>%\n  select(LungCap, Age, Smoke) %>%\n  filter(Age >= 18)\nrange(LC_Age18p$LungCap)\n\n[1]  7.750 14.675\n\n#The minimum and maximum range values for the 18+ age group are 7.750 and 14.675. The mean is 10.965.\n\n\nsummarise(LC_Age18p, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            11.0\n\n\n\nLC_Age18p %>%\n  count(Smoke)\n\n# A tibble: 2 × 2\n  Smoke     n\n  <chr> <int>\n1 no       65\n2 yes      15\n\n#Ok so what we've learned here is that this survey was HEAVILY focused on kids 13 and younger; although the sample for this age group is larger than the previous 2, it's still only 80 out of 725 responses (about 11% of total respondents). The mean lung capacity for this group is the highest of all of them at 10.965, but this still doesn't seem to show a relationship between smoking and lung capacity. Rather, at least to me, it shows a relationship between age and lung capacity (i.e. stage of lung development and lung capacity).\n\n##1e. Compare the lung capacities for smokers and non-smokers within each age group. Is your answer different from the one in part d. What could possibly be going on here?\n\n#I will place a comparison of all values produced by the following calculations at the bottom. (I will go through the smoker and non-smoker calculations first)\n\nLCu13 <- LC_Age13 %>%\n  filter(Smoke == \"yes\")\nrange(LCu13$LungCap)\n\n[1]  3.850 10.275\n\n\n\nsummarise(LCu13, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            7.20\n\n\n\nLCu145 <- LC_Age145 %>%\n  filter(Smoke == \"yes\")\nrange(LCu145$LungCap)\n\n[1]  6.225 11.025\n\n\n\nsummarise(LCu145, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            8.36\n\n\n\nLCu167 <- LC_Age167 %>%\n  filter(Smoke == \"yes\")\nrange(LCu167$LungCap)\n\n[1]  7.550 11.775\n\n\n\nsummarise(LCu167, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            9.06\n\n\n\nLCu18p <- LC_Age18p %>%\n  filter(Smoke == \"yes\")\nrange(LCu18p$LungCap)\n\n[1]  8.200 13.325\n\n\n\nsummarise(LCu18p, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            10.5\n\n\n\n#Now for the non-smoker calculations.\n\nLCu13 <- LC_Age13 %>%\n  filter(Smoke == \"no\")\nrange(LCu13$LungCap)\n\n[1]  0.507 12.050\n\n\n\nsummarise(LCu13, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            6.36\n\n\n\nLCu145 <- LC_Age145 %>%\n  filter(Smoke == \"no\")\nrange(LCu145$LungCap)\n\n[1]  5.625 12.900\n\n\n\nsummarise(LCu145, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            8.93\n\n\n\nLCu167 <- LC_Age167 %>%\n  filter(Smoke == \"no\")\nrange(LCu167$LungCap)\n\n[1]  5.675 13.375\n\n\n\nsummarise(LCu167, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            10.3\n\n\n\nLCu18p <- LC_Age18p %>%\n  filter(Smoke == \"no\")\nrange(LCu18p$LungCap)\n\n[1]  7.750 14.675\n\n\n\nsummarise(LC_Age18p, mean(LungCap))\n\n# A tibble: 1 × 1\n  `mean(LungCap)`\n            <dbl>\n1            11.0\n\n\n\n#Comparison!!  \n  # 13 and under smokers: range = 3.850 to 10.275, mean = 7.202\n  # 13 and under non-smokers: range = 0.507 and 12.050, mean = 6.359 \n    \n  # 14-15 smokers: range = 6.225 and 11.025, mean = 8.359\n  # 14-15 non-smokers: range = 5.625 and 12.900, mean = 8.930  \n  \n  # 16-17 smokers: range = 7.550 and 11.775, mean = 9.063\n  # 16-17 non-smokers: range = 5.675 and 13.375, mean = 10.257  \n    \n  # 18+ smokers: range = 8.200 and 13.325,mean = 10.513 \n  # 18+ non-smokers: range = 7.750 and 14.675, mean = 10.965\n\n\n#The answers I got for smokers vs. non-smokers are obviously different, but I wouldn't say they necessarily convey something different to what I interpreted from 1d. I don't see a relationship between smoking and lung capacity, and I certainly don't see a massive difference in the values comparing the lung capacity of smokers and non-smokers."
  },
  {
    "objectID": "posts/KPopiela_HW1.html#f.-calculate-the-correlation-and-covariance-between-lung-capacity-and-age.-use-the-cov-and-cor-functions-in-r.-interpret-your-results.",
    "href": "posts/KPopiela_HW1.html#f.-calculate-the-correlation-and-covariance-between-lung-capacity-and-age.-use-the-cov-and-cor-functions-in-r.-interpret-your-results.",
    "title": "HW1",
    "section": "1f. Calculate the correlation and covariance between Lung Capacity and Age. (use the cov() and cor() functions in R). Interpret your results.",
    "text": "1f. Calculate the correlation and covariance between Lung Capacity and Age. (use the cov() and cor() functions in R). Interpret your results.\n\ncov(LungCap$LungCap, LungCap$Age)\n\n[1] 8.738289\n\n\n\ncor(LungCap$LungCap, LungCap$Age)\n\n[1] 0.8196749\n\n\n\n#Covariance between lung capacity and age: 8.738.  \n#Correlation between lung capacity and age: 0.820  \n\n#I'm not totally confident in my understanding of covariance yet, but from what I know, it's the positive or negative relationship between two variables and the further the value is from 0, the stronger the relationship is. And the covariance between lung capacity and age is 8.738. Correlation gets stronger the closer the value gets to 1 or -1; the correlation between lung capacity and age for 'LungCap' dataset is 0.820, a figure relatively close to 1, so I would say there is a moderate to strong correlation between the two variables in question here.\n\n#Question 2\n###Let X=number of prior convictions for prisoners at a state prison at which there are 810 inmates."
  },
  {
    "objectID": "posts/KPopiela_HW1.html#a.-what-is-the-probability-that-a-randomly-selected-inmate-has-fewer-than-2-prior-convictions",
    "href": "posts/KPopiela_HW1.html#a.-what-is-the-probability-that-a-randomly-selected-inmate-has-fewer-than-2-prior-convictions",
    "title": "HW1",
    "section": "2a. What is the probability that a randomly selected inmate has fewer than 2 prior convictions?",
    "text": "2a. What is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\nconrange <- rep(c(0,1,2,3,4),times=c(128,434,160,64,24))\nconrange\n\n  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n [38] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n [75] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[112] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[556] 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[593] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[630] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[667] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[704] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n[741] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n[778] 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n\n#To start I just wanted to present a visualization of the frequency of each categorical variable.  \n  # 0 prior convictions = 128  \n  # 1 prior conviction = 434  \n  # 2 prior convictions = 160  \n  # 3 prior convictions = 64  \n  # 4 prior convictions = 24\n\n\nprop.table(table(conrange))[0:2]\n\nconrange\n        0         1 \n0.1580247 0.5358025 \n\n#By combining the probability values for 0 and 1, we can see that the probability of a randomly selected inmate having fewer than 2 prior convictions is 0.694."
  },
  {
    "objectID": "posts/KPopiela_HW1.html#b.-what-is-the-probability-that-a-randomly-selected-inmate-has-2-or-fewer-prior-convictions",
    "href": "posts/KPopiela_HW1.html#b.-what-is-the-probability-that-a-randomly-selected-inmate-has-2-or-fewer-prior-convictions",
    "title": "HW1",
    "section": "2b. What is the probability that a randomly selected inmate has 2 or fewer prior convictions?",
    "text": "2b. What is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\nprop.table(table(conrange))[0:3]\n\nconrange\n        0         1         2 \n0.1580247 0.5358025 0.1975309 \n\n#By using the same math above, the probability that a randomly selected inmate has 2 or fewer prior convictions is 0.891."
  },
  {
    "objectID": "posts/KPopiela_HW1.html#c.-what-is-the-probability-that-a-randomly-selected-inmate-has-more-than-2-prior-convictions",
    "href": "posts/KPopiela_HW1.html#c.-what-is-the-probability-that-a-randomly-selected-inmate-has-more-than-2-prior-convictions",
    "title": "HW1",
    "section": "2c. What is the probability that a randomly selected inmate has more than 2 prior convictions?",
    "text": "2c. What is the probability that a randomly selected inmate has more than 2 prior convictions?\n\nprop.table(table(conrange))[4:5]\n\nconrange\n         3          4 \n0.07901235 0.02962963 \n\n#The probability that a randomly selected inmate has more than 2 prior convictions is 0.108."
  },
  {
    "objectID": "posts/KPopiela_HW1.html#d.-what-is-the-expected-value-for-the-number-of-prior-convictions",
    "href": "posts/KPopiela_HW1.html#d.-what-is-the-expected-value-for-the-number-of-prior-convictions",
    "title": "HW1",
    "section": "2d. What is the expected value for the number of prior convictions?",
    "text": "2d. What is the expected value for the number of prior convictions?\n\nprior_con_range <- c(0,1,2,3,4)\nprobs <- c(0.158,0.535,0.197,0.079,0.029)\nc(prior_con_range %*% probs)\n\n[1] 1.282\n\n#The expected value for the number of prior convictions is 1.282"
  },
  {
    "objectID": "posts/KPopiela_HW1.html#e.-calculate-the-variance-and-the-standard-deviation-for-the-prior-convictions.",
    "href": "posts/KPopiela_HW1.html#e.-calculate-the-variance-and-the-standard-deviation-for-the-prior-convictions.",
    "title": "HW1",
    "section": "2e. Calculate the variance and the standard deviation for the Prior Convictions.",
    "text": "2e. Calculate the variance and the standard deviation for the Prior Convictions.\n\nvar(conrange)\n\n[1] 0.8572937\n\nsd(conrange)\n\n[1] 0.9259016\n\n#The variance and standard deviation for prior convictions are 0.857 and 0.925 respectively."
  },
  {
    "objectID": "posts/FinalPart1_CalebHill.html",
    "href": "posts/FinalPart1_CalebHill.html",
    "title": "Final Part 1",
    "section": "",
    "text": "Multiple research reports state that there is a relationship between re-hospitalization rates and social characteristics, such as demographic and economic identifiers, (Barnett, Hsu & McWilliams, 2015; Murray, Allen, Clark, Daly & Jacobs, 2021). Specifically, racial characteristics play a large role in predicting re-hospitalization in a population (Li, Cai & Glance, 2015). While some articles examine economic and health factors contributing to these disparities, very few dig deep into environmental factors that influence this phenomenon, (Spatz, Bernheim, Horwitz & Herrin, 2020). With your zipcode affecting up to 60% of your health outcomes, this research is relevant to better improving one of our most costly health expenditures: hospitalization.\nThis paper aims to explore how different environmental variables impact re-hospitalization rates on a county-by-county level, controlling for racial, ethnic, and sex variables (maybe). These environmental factors will include both common environmental concerns, such as heat index, average temperature, precipitation, and natural disasters, along with the built environment, population density.\nThe data-set chosen for this analysis is taken from the Agency for Healthcare Research and Quality, Social Determinants of Health (SDOH) Database. This data-set has over 300 variables to explore each SDOH domain: social context, economic context, education, healthcare, and the environment. We shall pull data from three of these five domains: social, economic, and environmental.\nTo further reduce data bloat, we shall limit the geographic review to Texas counties – my home state! That should provide us with 200+ observations.\nThe hypothesis for this research report is: *Environmental factors increase rates of re-hospitalization in Texas counties.\nTherefore, the null hypothesis is: *Environmental factors do not increase rates of re-hospitalization in Texas counties.\nMultiple regression analyses shall be employed to determine the relationship – or lack thereof – between these variables.\nFirst I’ll import the relevant libraries.\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(corrplot)\n\n\nError in library(corrplot): there is no package called 'corrplot'\n\n\nCode\nknitr::opts_chunk$set(echo = TRUE)\n\n\nThen I’ll import the dataset and view the first six rows.\n\n\nCode\ndf <- SDOH_2020_COUNTY_1_0 <- read_excel(\"_data/SDOH_2020_COUNTY_1_0.xlsx\", sheet = \"Data\")\n\n\nWarning: Expecting logical in OA1673 / R1673C391: got '46123'\n\n\nWarning: Expecting logical in OA1765 / R1765C391: got '32510'\n\n\nWarning: Expecting logical in OB1765 / R1765C392: got '41025'\n\n\nWarning: Expecting logical in OC1765 / R1765C393: got '41037'\n\n\nWarning: Expecting logical in OA2799 / R2799C391: got '49017'\n\n\nWarning: Expecting logical in OB2799 / R2799C392: got '49019'\n\n\nWarning: Expecting logical in OC2799 / R2799C393: got '49025'\n\n\nWarning: Expecting logical in OD2799 / R2799C394: got '49055'\n\n\nWarning: Expecting logical in OA2844 / R2844C391: got '51760'\n\n\nCode\nhead(df)\n\n\n# A tibble: 6 × 685\n   YEAR COUNTYFIPS STATEFIPS STATE COUNTY REGION TERRI…¹ ACS_T…² ACS_T…³ ACS_T…⁴\n  <dbl> <chr>      <chr>     <chr> <chr>  <chr>    <dbl>   <dbl>   <dbl>   <dbl>\n1  2020 01001      01        Alab… Autau… South        0   55639   54929   52404\n2  2020 01003      01        Alab… Baldw… South        0  218289  216518  206329\n3  2020 01005      01        Alab… Barbo… South        0   25026   24792   23694\n4  2020 01007      01        Alab… Bibb … South        0   22374   22073   21121\n5  2020 01009      01        Alab… Bloun… South        0   57755   57164   54250\n6  2020 01011      01        Alab… Bullo… South        0   10173   10143    9579\n# … with 675 more variables: ACS_TOT_POP_ABOVE15 <dbl>,\n#   ACS_TOT_POP_ABOVE16 <dbl>, ACS_TOT_POP_16_19 <dbl>,\n#   ACS_TOT_POP_ABOVE25 <dbl>, ACS_TOT_CIVIL_POP_ABOVE18 <dbl>,\n#   ACS_TOT_CIVIL_VET_POP_ABOVE25 <dbl>, ACS_TOT_OWN_CHILD_BELOW17 <dbl>,\n#   ACS_TOT_WORKER_NWFH <dbl>, ACS_TOT_WORKER_HH <dbl>,\n#   ACS_TOT_CIVILIAN_LABOR <dbl>, ACS_TOT_CIVIL_EMPLOY_POP <dbl>,\n#   ACS_TOT_POP_POV <dbl>, ACS_TOT_CIVIL_NONINST_POP_POV <dbl>, …\n\n\nNext I want to verify the class is a dataframe. Otherwise, I’ll need to transform the data to make it easier to work with.\n\n\nCode\nclass(df)\n\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nAll good here.\nNow on to data transformation. We will need to select only the relevant columns for this analysis and filter by Texas, bringing the observations (rows) down to 254.\n\n\nCode\ndf_new <- df %>%\n  select(COUNTYFIPS,\n         STATE,\n         COUNTY,\n         ACS_TOT_POP_WT,\n         ACS_PCT_MALE,\n         ACS_PCT_FEMALE,\n         ACS_PCT_AIAN,\n         ACS_PCT_ASIAN,\n         ACS_PCT_BLACK,\n         ACS_PCT_HISPANIC,\n         ACS_PCT_MULT_RACE,\n         ACS_PCT_NHPI,\n         ACS_PCT_OTHER_RACE,\n         ACS_PCT_WHITE,\n         CEN_POPDENSITY_COUNTY,\n         NEPHTN_HEATIND_105,\n         NOAAC_AVG_TEMP_YEARLY,\n         NOAAC_PRECIPITATION_AVG_YEARLY,\n         NOAAS_TOT_NATURAL_DISASTERS,\n         SAIPE_MEDIAN_HH_INCOME,\n         SAIPE_PCT_POV,\n         LTC_AVG_OBS_REHOSP_RATE) %>%\n  filter(STATE == \"Texas\")\nhead(df_new)\n\n\n# A tibble: 6 × 22\n  COUNTYF…¹ STATE COUNTY ACS_T…² ACS_P…³ ACS_P…⁴ ACS_P…⁵ ACS_P…⁶ ACS_P…⁷ ACS_P…⁸\n  <chr>     <chr> <chr>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 48001     Texas Ander…   57917    61.2    38.8    0.41    0.6    20.9    17.9 \n2 48003     Texas Andre…   18227    49.6    50.4    0       0.31    2.29   56.9 \n3 48005     Texas Angel…   87119    48.9    51.1    0.31    1.11   15.1    22.3 \n4 48007     Texas Arans…   24220    49.5    50.5    0.9     1.14    0.33   28.0 \n5 48009     Texas Arche…    8754    50.2    49.8    1.46    0.17    1.1     8.21\n6 48011     Texas Armst…    1950    45.7    54.3    0.77    0       0.72    8.46\n# … with 12 more variables: ACS_PCT_MULT_RACE <dbl>, ACS_PCT_NHPI <dbl>,\n#   ACS_PCT_OTHER_RACE <dbl>, ACS_PCT_WHITE <dbl>, CEN_POPDENSITY_COUNTY <dbl>,\n#   NEPHTN_HEATIND_105 <dbl>, NOAAC_AVG_TEMP_YEARLY <dbl>,\n#   NOAAC_PRECIPITATION_AVG_YEARLY <dbl>, NOAAS_TOT_NATURAL_DISASTERS <dbl>,\n#   SAIPE_MEDIAN_HH_INCOME <dbl>, SAIPE_PCT_POV <dbl>,\n#   LTC_AVG_OBS_REHOSP_RATE <dbl>, and abbreviated variable names ¹​COUNTYFIPS,\n#   ²​ACS_TOT_POP_WT, ³​ACS_PCT_MALE, ⁴​ACS_PCT_FEMALE, ⁵​ACS_PCT_AIAN, …\n\n\nOut of 300+ variables, we’ve whittled them down to 22. Of those 22, we have three (3) that are unique identifiers (FIPS, State, and County), 11 that are potential control variables (population, gender, and race / ethnicity), and eight (8) that we can explore (Population Density to Re-hospitalization Rate).\nBefore we launch into exploring these eight variables via descriptive statistics, first we need to determine where the NAs are and see if any of the variables will have a substantial amount of missing data.\n\n\nCode\ncolSums(is.na(df_new))\n\n\n                    COUNTYFIPS                          STATE \n                             0                              0 \n                        COUNTY                 ACS_TOT_POP_WT \n                             0                              0 \n                  ACS_PCT_MALE                 ACS_PCT_FEMALE \n                             0                              0 \n                  ACS_PCT_AIAN                  ACS_PCT_ASIAN \n                             0                              0 \n                 ACS_PCT_BLACK               ACS_PCT_HISPANIC \n                             0                              0 \n             ACS_PCT_MULT_RACE                   ACS_PCT_NHPI \n                             0                              0 \n            ACS_PCT_OTHER_RACE                  ACS_PCT_WHITE \n                             0                              0 \n         CEN_POPDENSITY_COUNTY             NEPHTN_HEATIND_105 \n                             0                              0 \n         NOAAC_AVG_TEMP_YEARLY NOAAC_PRECIPITATION_AVG_YEARLY \n                             0                              0 \n   NOAAS_TOT_NATURAL_DISASTERS         SAIPE_MEDIAN_HH_INCOME \n                             0                              0 \n                 SAIPE_PCT_POV        LTC_AVG_OBS_REHOSP_RATE \n                             0                             44 \n\n\nThis is not ideal, as that’s our dependent variable. However, 44 / 254 is not bad. That still leaves us with plenty of counties to review.\n\n\nCode\ndf_new %>%\n  drop_na() %>%\n  print(nrow(df_new))\n\n\n# A tibble: 210 × 22\n   COUNTYFIPS STATE COUNTY           ACS_TOT_POP_WT ACS_PCT_MALE ACS_PCT_FEMALE\n   <chr>      <chr> <chr>                     <dbl>        <dbl>          <dbl>\n 1 48001      Texas Anderson County           57917         61.2           38.8\n 2 48003      Texas Andrews County            18227         49.6           50.4\n 3 48005      Texas Angelina County           87119         48.9           51.1\n 4 48007      Texas Aransas County            24220         49.5           50.5\n 5 48011      Texas Armstrong County           1950         45.7           54.3\n 6 48013      Texas Atascosa County           50194         50.2           49.8\n 7 48015      Texas Austin County             29892         49.9           50.1\n 8 48017      Texas Bailey County              6916         50.0           50.0\n 9 48019      Texas Bandera County            22770         49.8           50.2\n10 48021      Texas Bastrop County            86839         50.8           49.2\n   ACS_PCT_AIAN ACS_PCT_ASIAN ACS_PCT_BLACK ACS_PCT_HISPANIC ACS_PCT_MULT_RACE\n          <dbl>         <dbl>         <dbl>            <dbl>             <dbl>\n 1         0.41          0.6          20.9             17.9               4.46\n 2         0             0.31          2.29            56.9               5.76\n 3         0.31          1.11         15.1             22.3               3.21\n 4         0.9           1.14          0.33            28.0               6.2 \n 5         0.77          0             0.72             8.46              5.33\n 6         0.08          0.5           1.08            64.7              11.4 \n 7         0.14          0.55          8.77            27.2               2.96\n 8         1             0.68          0.29            65.8               0.49\n 9         1.2           0.34          0.75            19.3               5.97\n10         0.53          0.84          7.83            38.8               6.98\n   ACS_PCT_NHPI ACS_PCT_OTHER_RACE ACS_PCT_WHITE CEN_POPDENSITY_COUNTY\n          <dbl>              <dbl>         <dbl>                 <dbl>\n 1         0.02               2.35          71.2                 54.5 \n 2         0.14              10.2           81.2                 12.2 \n 3         0.01               2.78          77.4                109.  \n 4         0                  3.57          87.9                 96.1 \n 5         0                  1.59          91.6                  2.14\n 6         0                  2.2           84.8                 41.2 \n 7         0                 12.1           75.5                 46.2 \n 8         0                  4.38          93.2                  8.36\n 9         0                  2.7           89.0                 28.8 \n10         0                 18.4           65.4                 97.8 \n   NEPHTN_HEATIND_105 NOAAC_AVG_TEMP_Y…¹ NOAAC…² NOAAS…³ SAIPE…⁴ SAIPE…⁵ LTC_A…⁶\n                <dbl>              <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1                 28               66.5   4.36       46   50879    20.9    0.21\n 2                  0               64.6   0.595      26   76600     9.2    0.2 \n 3                 26               67.6   4.05       15   49943    17      0.18\n 4                  7               73.2   2.24       36   51461    17.1    0.09\n 5                  0               60.6   1.09       90   62256     9.3    0.33\n 6                 47               71.8   2.09       38   60594    14.9    0.16\n 7                 33               70.4   3.41       19   60593    11.4    0.08\n 8                  0               59.6   0.692      38   48259    14.4    0   \n 9                  7               68.2   2.03       29   64389    11      0.08\n10                 44               70.0   2.89       30   74612    10.8    0.14\n# … with 200 more rows, and abbreviated variable names ¹​NOAAC_AVG_TEMP_YEARLY, ²​NOAAC_PRECIPITATION_AVG_YEARLY, ³​NOAAS_TOT_NATURAL_DISASTERS, ⁴​SAIPE_MEDIAN_HH_INCOME, ⁵​SAIPE_PCT_POV, ⁶​LTC_AVG_OBS_REHOSP_RATE\n\n\n210 x 22 is a good place to start. We’ll need to re-do this step for the descriptive statistics section, but we can carry over this object when we fit the linear models."
  },
  {
    "objectID": "posts/FinalPart1_CalebHill.html#descriptive-statistics",
    "href": "posts/FinalPart1_CalebHill.html#descriptive-statistics",
    "title": "Final Part 1",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\nFor our preliminary analysis, we’re going to provide summary statistics analyzing the 8 variables relevant to our research question, from Population Density to the end of the data-set, and a visualization for each. Re-hospitalization rates will be the dependent variable in future models, with the 11 demographic variables as potential controls for the regression(s).\n\n\nCode\ndata <- df_new %>%\n  select(CEN_POPDENSITY_COUNTY,\n         NEPHTN_HEATIND_105,\n         NOAAC_AVG_TEMP_YEARLY,\n         NOAAC_PRECIPITATION_AVG_YEARLY,\n         NOAAS_TOT_NATURAL_DISASTERS,\n         SAIPE_MEDIAN_HH_INCOME,\n         SAIPE_PCT_POV,\n         LTC_AVG_OBS_REHOSP_RATE) %>%\n  drop_na()\nsummary(data)\n\n\n CEN_POPDENSITY_COUNTY NEPHTN_HEATIND_105 NOAAC_AVG_TEMP_YEARLY\n Min.   :   0.78       Min.   : 0.00      Min.   :56.52        \n 1st Qu.:  12.53       1st Qu.: 7.00      1st Qu.:64.89        \n Median :  30.48       Median :24.00      Median :66.53        \n Mean   : 143.53       Mean   :22.14      Mean   :67.06        \n 3rd Qu.:  78.46       3rd Qu.:34.00      3rd Qu.:69.71        \n Max.   :3003.99       Max.   :59.00      Max.   :76.47        \n NOAAC_PRECIPITATION_AVG_YEARLY NOAAS_TOT_NATURAL_DISASTERS\n Min.   :0.4583                 Min.   :  0.00             \n 1st Qu.:1.6135                 1st Qu.: 14.25             \n Median :2.5933                 Median : 28.50             \n Mean   :2.7027                 Mean   : 32.75             \n 3rd Qu.:3.8808                 3rd Qu.: 40.00             \n Max.   :5.4558                 Max.   :186.00             \n SAIPE_MEDIAN_HH_INCOME SAIPE_PCT_POV   LTC_AVG_OBS_REHOSP_RATE\n Min.   : 33513         Min.   : 4.80   Min.   :0.0000         \n 1st Qu.: 48455         1st Qu.:11.45   1st Qu.:0.1100         \n Median : 54536         Median :14.50   Median :0.1500         \n Mean   : 57028         Mean   :14.75   Mean   :0.1528         \n 3rd Qu.: 61901         3rd Qu.:17.40   3rd Qu.:0.2000         \n Max.   :106225         Max.   :28.70   Max.   :1.0000         \n\n\n\nPopulation Density\n\n\nCode\nggplot(data, aes(CEN_POPDENSITY_COUNTY)) +\n  geom_histogram(binwidth = 50)\n\n\n\n\n\nWe see quite a number of counties have a low population density. This is no surprise, as over 80% of counties in Texas are labeled as “rural” by multiple federal agencies – dependent upon low population density.\nThis is further attested and we see a wide range between this variable’s median (21.8) and mean (119.4). Lots of out-liers. If we had a urban/rural classification code, we could filter on only rural counties to help mitigate this spread. I may need to merge a data-set due to this wide range.\n\n\nHeat Index Over 105F\n\n\nCode\nggplot(data, aes(NEPHTN_HEATIND_105)) +\n  geom_boxplot()\n\n\n\n\n\nTexas is a hot state, and this visualization is evidence of that. The median number of days Texas’ counties experience a heat index of over 105F each year is 20 days per year. One county even reached 59 days!\n\n\nCode\nggplot(data, aes(NEPHTN_HEATIND_105)) +\n  geom_histogram()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nThe data-set has a very normal distribution, centered around the 25/30 mark – if the number of counties at 0 were removed. Yet because that’s not so, this variable has a sharp bimodal distribution. We may have to separate the data into two bins: those with less than 10 days over 105F and those with more than 10 days over 105F. That’s yet to be determined.\n\n\nAverage Yearly Temperature\n\n\nCode\nggplot(data, aes(NOAAC_AVG_TEMP_YEARLY)) +\n  geom_histogram()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nThere’s a good distribution. Average temperature each month is between 65 to 67 for most of the counties. The range (20) is also fairly small for a state with such a large area and multiple climates within its borders.\n\n\nAverage Yearly Precipitation\n\n\nCode\nggplot(data, aes(NOAAC_PRECIPITATION_AVG_YEARLY)) +\n  geom_boxplot()\n\n\n\n\n\nAverage precipitation each month is fairly uniform, with the mean at 2.5 inches of rain, on average, each month. This variable will most likely provide less variation in the analysis compared to others, such as population density and heat index. This can be both a good and a bad thing, as variations in precipitation was one of the variables I was most interested in exploring for this project. Oh well.\n\n\nTotal Natural Disasters\n\n\nCode\nggplot(data, aes(NOAAS_TOT_NATURAL_DISASTERS)) +\n  geom_boxplot()\n\n\n\n\n\nMany high out-liers over 75. Let’s plot a histogram to get a better look at the data’s distribution.\n\n\nCode\nggplot(data, aes(NOAAS_TOT_NATURAL_DISASTERS)) +\n  geom_histogram()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nA right skewed variable, with observations dropping off dramatically once we reach 50 total recorded natural disasters.\n\n\nMedian Household Income\n\n\nCode\nggplot(data, aes(SAIPE_MEDIAN_HH_INCOME)) +\n  geom_histogram()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nA couple of high out-liers, hovering around $90,000+ in median household income, but the mean holds at $57,291.\n\n\nPercent in Poverty\n\n\nCode\nggplot(data, aes(SAIPE_PCT_POV)) +\n  geom_histogram()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nAnother close to normal distribution. Most counties have poverty rates ranging from 10% to 20%. There are of course out-liers, especially a good number below 10%, but those are rare.\n\n\nRe-hospitalization Rate\n\n\nCode\nggplot(data, aes(LTC_AVG_OBS_REHOSP_RATE)) +   geom_histogram()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nAnother right skewed variable. Lots of counties with 0.00 rates of re-hospitalization, and few, if any, above 0.25 per 100,000 people. From a health perspective, this is good news! From a research perspective, that’s going to make analysis a little trickier. However, the somewhat normal and/or bimodal distribution should be fairly easy to work with, needing little to no transformation for a linear regression.\n\n\nCorrelation\nFinally, let’s plot a brief correlation matrix to see if there’s any relationships we can explore as a simple linear regression in the next section.\n\n\nCode\ndata %>%\n  cor(data) %>%\n  corrplot(is.corr = FALSE, method=\"number\", tl.cex = .4)\n\n\nError in corrplot(., is.corr = FALSE, method = \"number\", tl.cex = 0.4): could not find function \"corrplot\"\n\n\nThe closer a box is to 1, the higher the correlation. Not particularly exciting news, as it shows there’s not a high correlation between re-hospitalization rates and any of the explanatory variables. This may throw a kink in our analysis – and explain why others haven’t delved deeply into this research!\nPerhaps this step should have been completed first, but nonetheless, we shall continue on with the report. I may pull two more environmental variables, to see if we can find a correlation somewhere. Even so, the sum total of all environmental variables might contribute to re-hospitalization rates as well. I’m just not sure if that – along with control variables – is outside the scope of this report.\nFor Part 2, I’d like to rename the variables to more digestible phrases, and I would like to overhaul the code outputs, to make the tables and visualizations a little easier on the eyes. That’s just polish work, though, and won’t affect the analysis.\nLooking over the Spatz et. al. (2020) article again, the two most significant Built Environment variables (with the highest R2 value) are 1) Long Commute, Driving Alone and 2) Severe Housing Problems. I’m going to scour the SDOH data-set to see what relevant variables match these two and add them into Part 2."
  },
  {
    "objectID": "posts/FinalPart1_CalebHill.html#references",
    "href": "posts/FinalPart1_CalebHill.html#references",
    "title": "Final Part 1",
    "section": "References",
    "text": "References\nBarnett, M., Hsu, J. & McWilliams, M. (2015). “Patient Characteristics and Differences in Hospital Readmission Rates.” JAMA Intern Med., 175(11): 1803-1812.\nLi, Y., Cai, X. & Glance, L. (2015). “Disparities in 30-day rehospitalization rates among Medicare skilled nursing facility residents by race and site of care.” Med Care, 53(12): 1058-1065.\nMurray, F., Allen, M., Clark, C., Daly, C. & Jacobs, D. (2021). “Socio-demographic and -economic factors associated with 30-day readmission for conditions targeted by the hospital readmissions reduction program: a population-based study.” BMC Public Health, 21.\nSpatz, E., Bernheim, S., Horwitz, L. & Herrin, J. (2020). Community factors and hospital wide readmission rates: Does context matter? PLoS One, 15(10)."
  },
  {
    "objectID": "posts/CalebHill_HW1.html",
    "href": "posts/CalebHill_HW1.html",
    "title": "Homework 1",
    "section": "",
    "text": "First, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(dplyr)\ndf <- read_excel(\"_data/LungCapData.xls\")\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(df$LungCap)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15).\n\n\n\nNext, let’s compare the probability distribution of the LungCap with respect to Males and Females, using a boxplot.\n\n\nCode\nboxplot(LungCap ~ Gender, df)\n\n\n\n\n\nThe minimum and mean are very similar to each other, with the minimum around 1 and the mean around 8. The maximum does differ though by gender, at 13 to 14/15 respectively.\n\n\n\nFor the third question, we’re going to compare the mean lung capacities for smokers and non-smokers. To compare the mean, we’ll again use the box-plot.\n\n\nCode\nboxplot(LungCap ~ Smoke, df)\n\n\n\n\n\nWhile the mean is very similar, hovering between 8 and 9, the range is what is substantial. A smoker’s lung capacity has a much smaller range, 4 - 13, compared to non-smokers, at 1 - 15. This makes sense, as a smoker’s lungs would start to have less capacity through consistent substance abuse.\n\n\n\nFor question four, we need to create a new variable, Age Group, followed by comparing the relationship between Smoking and Lung Capacity, broken down by Age Group. First, we’ll create the new column, referencing the Age column to determine groups.\n\n\nCode\ndf_new <- df %>%\n  mutate(\n    Age_Group = dplyr::case_when(\n      Age <= 13 ~ \"Less than or equal to 13\",\n      Age == 14 | Age == 15 ~ \"14 or 15\",\n      Age == 16 | Age == 17 ~ \"16 or 17\",\n      Age >= 18 ~ \"Greater than or equal to 18\"\n    ),\n    Age_Group = factor(\n      Age_Group,\n      level = c(\"Less than or equal to 13\", \"14 or 15\", \"16 or 17\", \"Greater than or equal to 18\")\n    )\n  )\nhead(df_new)\n\n\n# A tibble: 6 × 7\n  LungCap   Age Height Smoke Gender Caesarean Age_Group                  \n    <dbl> <dbl>  <dbl> <chr> <chr>  <chr>     <fct>                      \n1    6.48     6   62.1 no    male   no        Less than or equal to 13   \n2   10.1     18   74.7 yes   female no        Greater than or equal to 18\n3    9.55    16   69.7 no    female yes       16 or 17                   \n4   11.1     14   71   no    male   no        14 or 15                   \n5    4.8      5   56.9 no    male   no        Less than or equal to 13   \n6    6.22    11   58.7 no    female no        Less than or equal to 13   \n\n\nGood. Now we can place a histogram to better understand the relationship between LungCap and Smoking status. To view it by age group, we’ll add a facet wrap to the visualization.\n\n\nCode\nggplot(df_new, aes(LungCap, color=Smoke)) +\n  geom_histogram() +\n  facet_wrap(~Age_Group)\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nThose that are smokers have a smaller sample size than non-smokers. Looking purely at the distribution of each, we can see that three of the four age groups follow a normal distribution, save the 14 or 15 group that has a somewhat “two hump” distribution.\nEven so, smoking status does seem to mirror the non-smoker distribution, when it comes to the overall sample count and LungCap.\n\n\n\nFor the fifth question, we’ll compare the lung capacities for smokers and non-smokers within each age group. We’ll use a box-plot and facet wrap this visualization again by Age Group.\n\n\nCode\nggplot(df_new, aes(LungCap, Smoke)) +\n  geom_boxplot() +\n  facet_wrap(~Age_Group)\n\n\n\n\n\nWe can readily see that smokers, irrespective of age, have a substantially smaller lung capacity range compared to non-smokers. While the mean might be similar, sometimes even smaller for “13 years old or less”, the length of each capacity varies for non-smokers where it doesn’t for smokers.\n\n\n\nFor the sixth question, we shall calculate the covariance and correlation between LungCap and Age.\n\n\nCode\ncov(df$LungCap, df$Age)\n\n\n[1] 8.738289\n\n\nCode\ncor(df$LungCap, df$Age)\n\n\n[1] 0.8196749\n\n\nCovariance is the relationship between a pair of random variables where change in one variable causes change in another variable. With a covariance of 8.73, that means that there is a positive relationship between the two variables and that, by every 1 point change of Age, that can result in an average of 8.73 point change in LungCap.\nCorrelations show whether and how strongly pairs or variables are related to one another. Correlation can range from 0.0 to 1.0. With a result of 0.81, that means there is a high correlation between LungCap and Age."
  },
  {
    "objectID": "posts/CalebHill_HW1.html#a-1",
    "href": "posts/CalebHill_HW1.html#a-1",
    "title": "Homework 1",
    "section": "a",
    "text": "a\nLet’s calculate the probability that a randomly selected inmate has EXACTLY 2 prior convictions.\n\n\nCode\ndbinom(2, 810, 0.1975)\n\n\n[1] 7.90917e-74\n\n\nSo 7.9%."
  },
  {
    "objectID": "posts/CalebHill_HW1.html#b-1",
    "href": "posts/CalebHill_HW1.html#b-1",
    "title": "Homework 1",
    "section": "b",
    "text": "b\nLet’s calculate the probability that a randomly selected inmate has FEWER THAN 2 prior convictions.\n\n\nCode\npbinom(2, 810, 0.1975, lower.tail=FALSE)\n\n\n[1] 1\n\n\nNot sure why it’s pulling 1."
  },
  {
    "objectID": "posts/CalebHill_HW1.html#c-1",
    "href": "posts/CalebHill_HW1.html#c-1",
    "title": "Homework 1",
    "section": "c",
    "text": "c\nLet’s calculate the probability that a randomly selected inmate has 2 OR FEWER prior convictions.\n\n\nCode\npbinom(2, 810, 0.1975)\n\n\n[1] 7.989018e-74\n\n\nSo 7.98%."
  },
  {
    "objectID": "posts/CalebHill_HW1.html#d-1",
    "href": "posts/CalebHill_HW1.html#d-1",
    "title": "Homework 1",
    "section": "d",
    "text": "d\nLet’s calculate the probability that a randomly selected inmate has MORE THAN 2 prior convictions."
  },
  {
    "objectID": "posts/CalebHill_HW1.html#e-1",
    "href": "posts/CalebHill_HW1.html#e-1",
    "title": "Homework 1",
    "section": "e",
    "text": "e\nLet’s calculate the expected value for the number of prior convictions. As I am unable to calculate sections B and D, I’m unable to determine the expected value."
  },
  {
    "objectID": "posts/CalebHill_HW1.html#f-1",
    "href": "posts/CalebHill_HW1.html#f-1",
    "title": "Homework 1",
    "section": "f",
    "text": "f\nLet’s calculate the variance and the standard deviation for the Prior Convictions.As I am unable to determine the expected value, I cannot calculate the variance and standard deviation either."
  },
  {
    "objectID": "posts/DACSS 603 HW 1.html",
    "href": "posts/DACSS 603 HW 1.html",
    "title": "DACSS 603 HW 1 Kimble",
    "section": "",
    "text": "Code\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(readxl)\nlibrary(tidyverse)\n\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ ggplot2 3.3.6     ✔ purrr   0.3.5\n✔ tibble  3.1.8     ✔ stringr 1.4.1\n✔ tidyr   1.2.1     ✔ forcats 0.5.2\n✔ readr   2.1.3     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nknitr::opts_chunk$set(echo = TRUE)\n\n# Reading in File\nLungCapData <- read_excel(\"_data/LungCapData.xls\")\n\n\n\n\n\n\n\nCode\nhist(LungCapData$LungCap)\n\n\n\n\n\nThe histogram above shows that the Lung Cap data is roughly normally distributed because a majority of the observations are centered around the mean. There are fewer observations at the tail ends of the histogram.\n\n\n\n\n\nCode\nboxplot(LungCap ~ Gender, data = LungCapData, main = \"Lung Capacity by Gender\",\n        xlab = \"Gender\", ylab = \"Lung Capacity\")\n\n\n\n\n\nFrom the box-plots above, it appears that males in this study had slightly higher lung capacities than females, with the median for males at 9 and the median for females at 8. However, both genders had large ranges, but these ranges reflected the overall pattern of males having slightly higher lung capacities.\n\n\n\n\n\nCode\nsmokers <- filter(LungCapData, Smoke == \"yes\")\nmean(smokers$LungCap)\n\n\n[1] 8.645455\n\n\nCode\nnonsmokers <- filter(LungCapData, Smoke == \"no\")\nmean(nonsmokers$LungCap)\n\n\n[1] 7.770188\n\n\nThe mean lung capacity for smokers (8.65) is higher than the mean lung capacity for non-smokers (7.77). Based on what we now know about how smoking affects the lungs, these results don’t seem to make sense. However, there is the possibility that smokers may be more used to deep inhales/exhales and therefore could have better lung capacity until the substance has more of an effect on their lungs. There may also be external factors that led to these results that aren’t clear from the data right now.\n\n\n\n\n\nCode\nLungCapData <- within(LungCapData, {\n  Age.group <- NA\n  Age.group[Age <= 13] <- \"13 and Under\"\n  Age.group[Age >= 14 & Age <= 15] <- \"14-15\"\n  Age.group[Age >= 16 & Age <= 17] <- \"16-17\"\n  Age.group[Age >= 18] <- \"18 and Over\"\n} )\n\n\n\n\n\n\nCode\n# Boxplots\n\nsmoking_age <- filter(LungCapData, Smoke == \"yes\")\n\nboxplot(LungCap ~ Age.group, data = smoking_age,\n        main = \"Lung Capacity of Smokers by Age Group\",\n        xlab = \"Age Group\", ylab = \"Lung Capacity\")\n\n\n\n\n\nFrom the boxplot above, we can see that smokers’ lung capacities reach about a maximum of 12 as age increases, but there is not very much improvement in the maximums. The medians move a bit more as age increases, but still not very dramatically after ages 14 and 15. Smokers that are 18 and over have higher lung capacities overall, but this may just be because of natural aging processes and development.\n\n\nCode\n# Means\n\nsmoking_age %>%\n  group_by(Age.group) %>%\n  summarise_at(vars(LungCap), list(name = mean))\n\n\n# A tibble: 4 × 2\n  Age.group     name\n  <chr>        <dbl>\n1 13 and Under  7.20\n2 14-15         8.39\n3 16-17         9.38\n4 18 and Over  10.5 \n\n\nWe see the same trend in means as in the medians: mean lung capacity to increases as the age increases.\n\n\n\n\n\nCode\n# Boxplot\n\nnonsmoking_age <- filter(LungCapData, Smoke == \"no\")\n\nboxplot(LungCap ~ Age.group, data = nonsmoking_age,\n        main = \"Lung Capacity of Non-Smokers by Age Group\",\n        xlab = \"Age Group\", ylab = \"Lung Capacity\")\n\n\n\n\n\nIn non-smokers, we see the same trend of increasing lung capacities as age increases, but the median lung capacities in the two older age groups in the non-smoking group are higher than those in the smoking group. There are also more outliers for non-smokers, especially in the 14-15 category.\n\n\nCode\n# Means\n\nnonsmoking_age %>%\n  group_by(Age.group) %>%\n  summarise_at(vars(LungCap), list(name = mean))\n\n\n# A tibble: 4 × 2\n  Age.group     name\n  <chr>        <dbl>\n1 13 and Under  6.36\n2 14-15         9.14\n3 16-17        10.5 \n4 18 and Over  11.1 \n\n\nThe means of the non-smoking group by age follow the same trend as the medians, as well as in the smoking group. However, the mean lung capacity for the oldest two age groups in the non-smoking category are higher than the means for those groups in the smoking category.\n\n\n\n\n\n\n\n\nCode\nLungCapData %>%\n  filter(Age.group == \"13 and Under\") %>%\n  group_by(Smoke) %>%\n  summarise_at(vars(LungCap), list(name = mean))\n\n\n# A tibble: 2 × 2\n  Smoke  name\n  <chr> <dbl>\n1 no     6.36\n2 yes    7.20\n\n\nThe mean lung capacity for smokers is higher than the mean lung capacity for non-smokers in the age group 13 and under, which mirrors the general means we found earlier. However, from the boxplot of Smokers by Age Group, we can see that there is a very low outlier in this age group, which might be affecting the mean for this group as well as overall smokers.\n\n\n\n\n\nCode\nLungCapData %>%\n  filter(Age.group == \"14-15\") %>%\n  group_by(Smoke) %>%\n  summarise_at(vars(LungCap), list(name = mean))\n\n\n# A tibble: 2 × 2\n  Smoke  name\n  <chr> <dbl>\n1 no     9.14\n2 yes    8.39\n\n\nIn this age group, the mean lung capacity for non-smokers is higher than the mean lung capacity for smokers–unlike the younger group.\n\n\n\n\n\nCode\nLungCapData %>%\n  filter(Age.group == \"16-17\") %>%\n  group_by(Smoke) %>%\n  summarise_at(vars(LungCap), list(name = mean))\n\n\n# A tibble: 2 × 2\n  Smoke  name\n  <chr> <dbl>\n1 no    10.5 \n2 yes    9.38\n\n\nThe same trend continues in this age group, with the mean lung capacity in non-smokers ages 16 and 17 higher than the mean lung capacity of smokers in this group. Yet as the ages increase, the mean lung capacities for non-smokers and smokers increase about the same amount (by 1).\n\n\n\n\n\nCode\nLungCapData %>%\n  filter(Age.group == \"18 and Over\") %>%\n  group_by(Smoke) %>%\n  summarise_at(vars(LungCap), list(name = mean))\n\n\n# A tibble: 2 × 2\n  Smoke  name\n  <chr> <dbl>\n1 no     11.1\n2 yes    10.5\n\n\nIn this oldest age group, the same trend continues: the mean lung capacity for non-smokers is higher than that of smokers. This pattern in the groups 18+, 16-17, and 14-15 are not found in the overall means for smokers and nonsmokers, suggesting that the outlier in the 13 and Under group might have brought down the overall mean for smokers.\n\n\n\n\n\n\nCode\n# Correlation\n\ncor(LungCapData$Age, LungCapData$LungCap, use = \"everything\")\n\n\n[1] 0.8196749\n\n\nThe correlation between lung capacity and age is positive and strong. As age increases, lung capacity also increases. The value of 0.8 is close to 1, meaning there is a somewhat strong relationship between the two variables.\n\n\nCode\n# Covariance\n\ncov(LungCapData$Age, LungCapData$LungCap, use = \"everything\")\n\n\n[1] 8.738289\n\n\nThe covariance is positive, meaning that there is a positive relationship between the varaibles, which is also clear from the correlation (since the correlation coefficient is a function of the covariance). Age and lung capacity have an overall positive relationship: as age increases, so does lung capacity."
  },
  {
    "objectID": "posts/DACSS 603 HW 1.html#part-a",
    "href": "posts/DACSS 603 HW 1.html#part-a",
    "title": "DACSS 603 HW 1 Kimble",
    "section": "Part A",
    "text": "Part A\n\n\nCode\n160/810\n\n\n[1] 0.1975309"
  },
  {
    "objectID": "posts/DACSS 603 HW 1.html#part-b",
    "href": "posts/DACSS 603 HW 1.html#part-b",
    "title": "DACSS 603 HW 1 Kimble",
    "section": "Part B",
    "text": "Part B\n\n\nCode\n(434 + 128)/810\n\n\n[1] 0.6938272"
  },
  {
    "objectID": "posts/DACSS 603 HW 1.html#part-c",
    "href": "posts/DACSS 603 HW 1.html#part-c",
    "title": "DACSS 603 HW 1 Kimble",
    "section": "Part C",
    "text": "Part C\n\n\nCode\n(160 + 434 + 128)/810\n\n\n[1] 0.891358"
  },
  {
    "objectID": "posts/DACSS 603 HW 1.html#part-d",
    "href": "posts/DACSS 603 HW 1.html#part-d",
    "title": "DACSS 603 HW 1 Kimble",
    "section": "Part D",
    "text": "Part D\n\n\nCode\n(64 + 24)/810\n\n\n[1] 0.108642"
  },
  {
    "objectID": "posts/DACSS 603 HW 1.html#part-e",
    "href": "posts/DACSS 603 HW 1.html#part-e",
    "title": "DACSS 603 HW 1 Kimble",
    "section": "Part E",
    "text": "Part E\n\n\nCode\n# Creating vector\nconvict <- c(rep(0, 128), rep(1, 434), rep(2, 160), rep(3, 64), rep(4, 24))\n\nweighted.mean(convict)\n\n\n[1] 1.28642\n\n\nThe expected value for the number of prior convictions is 1.27–but since prior convictions have to be a whole number, that would be rounded to 1."
  },
  {
    "objectID": "posts/DACSS 603 HW 1.html#part-f",
    "href": "posts/DACSS 603 HW 1.html#part-f",
    "title": "DACSS 603 HW 1 Kimble",
    "section": "Part F",
    "text": "Part F\n\n\nCode\nvar(convict)\n\n\n[1] 0.8572937\n\n\nCode\nsd(convict)\n\n\n[1] 0.9259016"
  },
  {
    "objectID": "posts/ShoshanaBuck- HW1.html",
    "href": "posts/ShoshanaBuck- HW1.html",
    "title": "ShoshanaBuck-HW1",
    "section": "",
    "text": "Question 1\nUse the LungCapData to answer the following questions.\n\n\nCode\n# read in data\nlung_cap<- read_xls(\"_data/LungCapData.xls\")\nlung_cap\n\n\n# A tibble: 725 × 6\n   LungCap   Age Height Smoke Gender Caesarean\n     <dbl> <dbl>  <dbl> <chr> <chr>  <chr>    \n 1    6.48     6   62.1 no    male   no       \n 2   10.1     18   74.7 yes   female no       \n 3    9.55    16   69.7 no    female yes      \n 4   11.1     14   71   no    male   no       \n 5    4.8      5   56.9 no    male   no       \n 6    6.22    11   58.7 no    female no       \n 7    4.95     8   63.3 no    male   yes      \n 8    7.32    11   70.4 no    male   no       \n 9    8.88    15   70.5 no    male   no       \n10    6.8     11   59.2 no    male   no       \n# … with 715 more rows\n\n\n\na. What does the distribution of LungCap look like?\n\n\nCode\n#plot histogram\nhist(lung_cap$LungCap)\n\n\n\n\n\nThe histogram shows that the distribution is pretty close to a normal distribution, with an almost a bell shaped curve. Meaning that the data near the mean are more of a frequent occurrence which is true because there are fewer observations near the margins.\n\n\nb. compare the probability distribution of the LungCap with respect to Males and Females?\n\n\nCode\n#Box plot\nggplot(lung_cap, aes (Gender,LungCap)) + geom_boxplot()\n\n\n\n\n\nThe box plot shows that male’s have a slightly higher lung capacity than females. Female’s have more values in the first quartile range and a lower minimum value than male’s. On the other hand male’s have a higher max value and more values in the 3rd quartile range.\n\n\nc. Compare the mean lung capacities for smokers and non-smokers. Does it make sense?\n\n\nCode\nlung_cap %>% \n  group_by(Smoke) %>% \n  summarise(avg_lung_cap = mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke avg_lung_cap\n  <chr>        <dbl>\n1 no            7.77\n2 yes           8.65\n\n\nThis does not make sense. Smokers have a higher sample mean than non-smokers which intuitively does not make sense because we would assume non-smokers would have a higher lung capacity.\n\n\nd. Examine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\n\nCode\n#categorical variable of age_groups \ndf<- lung_cap %>% \ngroup_by(Smoke,LungCap) %>% \n  summarise(age_group = case_when(Age<=13 ~ \"13 & under\",Age ==14 | Age == 15 ~ \"14 to 15\",Age== 16 | Age == 17 ~ \"16 to 17\", Age>=18 ~ \"18 & older\")) \n\n\n`summarise()` has grouped output by 'Smoke', 'LungCap'. You can override using\nthe `.groups` argument.\n\n\nCode\n#mean of lung capacity with new variable\ndf %>% \n  group_by(Smoke, age_group) %>% \n  summarise(avg_lung_cap = mean(LungCap)) %>% \n  arrange(desc(avg_lung_cap))\n\n\n`summarise()` has grouped output by 'Smoke'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 3\n# Groups:   Smoke [2]\n  Smoke age_group  avg_lung_cap\n  <chr> <chr>             <dbl>\n1 no    18 & older        11.1 \n2 yes   18 & older        10.5 \n3 no    16 to 17          10.5 \n4 yes   16 to 17           9.38\n5 no    14 to 15           9.14\n6 yes   14 to 15           8.39\n7 yes   13 & under         7.20\n8 no    13 & under         6.36\n\n\nCode\n#histogram\nggplot(df, aes(x = LungCap)) + facet_grid(Smoke ~age_group) +geom_histogram()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nUsing the package ggplot I used the function facet_grids to show a good visualization of the lung capacity between non-smokers and smokers within each age group. Looking at the histograms all age_groups that are non-smokers have a higher sample mean proving that non-smokers have\n\n\ne. Compare the lung capacities for smokers and non-smokers within each age group. Is your answer different from the one in part d. What could possibly be going on here?\n\n\nCode\n# Mean of non-smokers 13 & younger\ndf %>% \n  filter(Smoke == 'no' & age_group == '13 & under') %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 6.358746\n\n\nCode\n# Mean of smokers 13 & younger\ndf %>% \n  filter(Smoke == 'yes' & age_group == '13 &under') %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] NaN\n\n\nCode\n#Mean of non-smokers 14 to 15\ndf %>% \n  filter(Smoke == 'no' & age_group == '14 to 15') %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 9.13881\n\n\nCode\n#Mean of smokers 14 to 15\ndf %>% \n  filter(Smoke == 'yes' & age_group == '14 to 15') %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 8.391667\n\n\nCode\n#Mean of non-smokers 16 to 17\ndf %>% \n  filter(Smoke == 'no' & age_group == '16 to 17') %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 10.46981\n\n\nCode\n#Mean of smokers 16 to 17\ndf %>% \n  filter(Smoke == 'yes' & age_group == '16 to 17') %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 9.38375\n\n\nCode\n#Mean of non-smokers 18 & older\ndf %>% \n  filter(Smoke == 'no' & age_group == '18 & older') %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 11.06885\n\n\nCode\n# Mean of smokers 18 & older\ndf %>% \n  filter(Smoke == 'yes' & age_group == '18 & older') %>% \n  pull(LungCap) %>% \n  mean()\n\n\n[1] 10.51333\n\n\nCode\nlung_cap\n\n\n# A tibble: 725 × 6\n   LungCap   Age Height Smoke Gender Caesarean\n     <dbl> <dbl>  <dbl> <chr> <chr>  <chr>    \n 1    6.48     6   62.1 no    male   no       \n 2   10.1     18   74.7 yes   female no       \n 3    9.55    16   69.7 no    female yes      \n 4   11.1     14   71   no    male   no       \n 5    4.8      5   56.9 no    male   no       \n 6    6.22    11   58.7 no    female no       \n 7    4.95     8   63.3 no    male   yes      \n 8    7.32    11   70.4 no    male   no       \n 9    8.88    15   70.5 no    male   no       \n10    6.8     11   59.2 no    male   no       \n# … with 715 more rows\n\n\n\n\nf. Calculate the correlation and covariance between Lung Capacity and Age. (use the cov() and cor() functions in R). Interpret your results.\n\n\nCode\n#Correlation\ncor(lung_cap$LungCap, lung_cap$Age)\n\n\n[1] 0.8196749\n\n\nCode\n#Covariance\ncov(lung_cap$LungCap, lung_cap$Age)\n\n\n[1] 8.738289\n\n\nThe correlation is 0.81 which is pretty close to +1, meaning that the there is a positive relationship between lung capacity and age. The covariance is also high which shows that the two variables of lung capacity and age have a positive relationship. #2 Let X = number of prior convictions for prisoners at a state prison at which there are 810 prisoners.\n\n\nCode\n# x= prior convictions \nx<-c(0, 1, 2, 3, 4)\nfrequency<-c(128, 434, 160, 64, 24)\nstate_prison<- data_frame(x,frequency)\n\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nℹ Please use `tibble()` instead.\n\n\nCode\nstate_prison\n\n\n# A tibble: 5 × 2\n      x frequency\n  <dbl>     <dbl>\n1     0       128\n2     1       434\n3     2       160\n4     3        64\n5     4        24\n\n\n\n\na. What is the probability that a randomly selected inmate has exactly 2 prior convictions?\n\n\nCode\n# 2 prior convictions.P(2)/total\n160/810\n\n\n[1] 0.1975309\n\n\nThere is a 1.9% probability that a randomly selected inmate has exactly 2 prior convictions.\n\n\nb. What is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\n\nCode\n#  less than 2 prior convictions. (P(0) + P(1))/total \n(128+434)/810\n\n\n[1] 0.6938272\n\n\nThere is a 6.9% probability that a randomly selected inmate has fewer than 2 prior convictions.\n\n\nc. What is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\n\nCode\n# 2 or fewer prior convictions. (P(0) + P(1) + P(2)) +total\n(128+434+160)/810\n\n\n[1] 0.891358\n\n\nThere is a 8.9% probability that a randomly selected inmate has 2 or fewer prior convictions.\n\n\nd. What is the probability that a randomly selected inmate has more than 2 prior convictions?\n\n\nCode\n# More than 2 prior convictions. (P(3) +P(4)) + total\n(64+24)/810\n\n\n[1] 0.108642\n\n\nThere is a 10.8% probability that a randomly selected inmate has more than 2 prior convictions.\n\n\ne. What is the expected value for the number of prior convictions?\n\n\nCode\n#Prior convictions. ((0*P(0)) +(1*(P(1)) + (2*P(2)) + (3*P(3)) + (4*P(4)))\ndf<-((128*0/810) +(434*1/810) +(160*2/810) +(64*3/810) +(24*4/810)) \nmean(df)\n\n\n[1] 1.28642\n\n\nThe expected value for number of prior convictions is 1.28\n\n\nf. Calculate the variance and the standard deviation for the Prior Convictions.\n\n\nCode\n# variance\nv<- ((0-1.28)^2) *(128/810) +((1-1.28)^2) * (434/810)+((2-1.28)^2) * (160/810)+((3-1.28)^2) *(64/810) +((4-1.28)^2) * (24/810)\nv\n\n\n[1] 0.8562765\n\n\nCode\n# standard deviation\nsd<- sqrt(v)\nsd\n\n\n[1] 0.9253521\n\n\nThe variance is 0.856 and the standard deviation is 0.925."
  },
  {
    "objectID": "posts/nboonstra_final_603_proposal.html",
    "href": "posts/nboonstra_final_603_proposal.html",
    "title": "Voter Turnout and Partisan Bias in U.S. Presidential Elections",
    "section": "",
    "text": "Code\nrm(list=ls())\n\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(readxl)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)"
  },
  {
    "objectID": "posts/nboonstra_final_603_proposal.html#theory",
    "href": "posts/nboonstra_final_603_proposal.html#theory",
    "title": "Voter Turnout and Partisan Bias in U.S. Presidential Elections",
    "section": "Theory",
    "text": "Theory\nA review of even such a small sample of the literature as the works mentioned above will clearly demonstrate that, beyond disagreement over the presence of partisan turnout bias, there is little consensus on the theoretical aspect of such a phenomenon. Before offering my hypothesis, therefore, I would like to briefly address this theoretical side of the argument.\nShaw and Petrocik (2020) take issue with a notion found in turnout bias literature, the notion being “that turnout is endogenous to candidate preference” (p. 53). They cite Downs’ (1957) famous equation, \\(V=(P*B)-C\\), as evidence that it is the intensity of one’s political beliefs, and not their direction, that determines the decision to vote or not, and that therefore turnout is not endogenous to candidate preference.\nI believe this argument misses a subtle nuance that is key to the turnout bias debate. Suppose that not all individuals in a given polity face the same costs to voting; assume, in other words, that a more accurate rendition of Downs’ equation would be \\(V_i=(P*B_i)-C_i\\), in which both cost of voting and the perceived benefit of a preferred candidate’s victory are unique to the individual. For the sake of this argument, the manner in which these costs are distributed is not important; only the fact that there are unequal costs matters. Suppose further that one of the parties in this polity has established itself as being the party that lobbies for a reduction in the cost of voting, particularly for those who face disproportionately high barriers. In a world of rational actors and perfect information, it would follow, ceteris paribus, that an individual who faced disproportionately high costs to voting would support this party, since this party would lobby to improve opportunities for this group. However, the very higher cost of voting that would motivate this individual to support this party could also prevent them from ultimately voting for that candidate in an election. Thus, it could be said that turnout is endogenous to candidate preference – or, more accurately, that the cost of voting is endogenous to both candidate preference and turnout.\nWe can apply this theoretical model to the American case. Certain individuals do face higher barriers to voting; unfortunately, unlike in the model, these barriers do tend to be distributed in a certain manner, often inequitably by race and socioeconomic status. Additionally, it would not be difficult to argue that, of the two major parties, the Democrats have placed themselves in the position of the party lobbying for expanded voting access and reduction of barriers to the ballot box, starting with their role in the Civil Rights movement and corresponding legislation, and continuing to the start of the present Congress and the introduction of H.R. 1, a bill explicitly aimed at expanding voting rights. Thus, while our world is not one of completely perfect information or completely rational actors, and while a number of factors contribute to partisan identity and vote choice, there is a reasonable case to be made that individuals who face barriers to voting, ceteris paribus, would be more likely to support the Democratic Party. Once again, these very barriers to voting that would push individuals toward the Democrats also can restrict them from expressing that preference at the ballot box. Thus, we have our situation of endogeneity between partisan preference and turnout."
  },
  {
    "objectID": "posts/nboonstra_final_603_proposal.html#hypotheses",
    "href": "posts/nboonstra_final_603_proposal.html#hypotheses",
    "title": "Voter Turnout and Partisan Bias in U.S. Presidential Elections",
    "section": "Hypotheses",
    "text": "Hypotheses\nWith the theoretical argument out of the way, I can proceed to out line some of the hypotheses I would like to test with this project.\n\\(H_1\\): Higher turnout will benefit Democrats in state-level Presidential elections.\n\\(H_2\\): Democrats will perform better in state-level Presidential elections as turnout increases relative to the previous election in that state.\nThe distinction of state-level elections is an important one; Shaw and Petrocik (2020) tend to aggregate their data, either by assessing elections on the national level or by aggregating county-level data. In the United States, Presidential elections are conducted at the state level, and I believe that this is the appropriate level of analysis for this analysis."
  },
  {
    "objectID": "posts/nboonstra_final_603_proposal.html#election-data-1976-2020",
    "href": "posts/nboonstra_final_603_proposal.html#election-data-1976-2020",
    "title": "Voter Turnout and Partisan Bias in U.S. Presidential Elections",
    "section": "Election Data, 1976-2020",
    "text": "Election Data, 1976-2020\nObtained from the MIT Election Project on 10/10/2022.\n\n\nCode\nelection_full <- read_csv(\"./_data/mit_election_1976_2020.csv\")\n\nelection_full <- election_full %>% \n  mutate(party_simplified2 = case_when(\n    party_detailed == \"DEMOCRAT\" ~ \"DEMOCRAT\",\n    party_detailed == \"REPUBLICAN\" ~ \"REPUBLICAN\",\n    party_detailed == \"LIBERTARIAN\" ~ \"LIBERTARIAN\",\n    party_detailed == \"GREEN\" ~ \"GREEN\",\n    party_detailed == \"INDEPENDENT\" ~ \"INDEPENDENT\",\n    TRUE ~ \"OTHER\"\n  )) %>% \n  mutate(party_dem = case_when(\n    party_detailed == \"DEMOCRAT\" ~ 1,\n    TRUE ~ 0\n  ))\n\nhead(election_full, n=20)\n\n\n# A tibble: 20 × 17\n    year state    state…¹ state…² state…³ state…⁴ office candi…⁵ party…⁶ writein\n   <dbl> <chr>    <chr>     <dbl>   <dbl>   <dbl> <chr>  <chr>   <chr>   <lgl>  \n 1  1976 ALABAMA  AL            1      63      41 US PR… \"CARTE… DEMOCR… FALSE  \n 2  1976 ALABAMA  AL            1      63      41 US PR… \"FORD,… REPUBL… FALSE  \n 3  1976 ALABAMA  AL            1      63      41 US PR… \"MADDO… AMERIC… FALSE  \n 4  1976 ALABAMA  AL            1      63      41 US PR… \"BUBAR… PROHIB… FALSE  \n 5  1976 ALABAMA  AL            1      63      41 US PR… \"HALL,… COMMUN… FALSE  \n 6  1976 ALABAMA  AL            1      63      41 US PR… \"MACBR… LIBERT… FALSE  \n 7  1976 ALABAMA  AL            1      63      41 US PR…  <NA>   <NA>    TRUE   \n 8  1976 ALASKA   AK            2      94      81 US PR… \"FORD,… REPUBL… FALSE  \n 9  1976 ALASKA   AK            2      94      81 US PR… \"CARTE… DEMOCR… FALSE  \n10  1976 ALASKA   AK            2      94      81 US PR… \"MACBR… LIBERT… FALSE  \n11  1976 ALASKA   AK            2      94      81 US PR…  <NA>   <NA>    TRUE   \n12  1976 ARIZONA  AZ            4      86      61 US PR… \"FORD,… REPUBL… FALSE  \n13  1976 ARIZONA  AZ            4      86      61 US PR… \"CARTE… DEMOCR… FALSE  \n14  1976 ARIZONA  AZ            4      86      61 US PR… \"MCCAR… INDEPE… FALSE  \n15  1976 ARIZONA  AZ            4      86      61 US PR… \"MACBR… LIBERT… FALSE  \n16  1976 ARIZONA  AZ            4      86      61 US PR… \"CAMEJ… SOCIAL… FALSE  \n17  1976 ARIZONA  AZ            4      86      61 US PR… \"ANDER… AMERIC… FALSE  \n18  1976 ARIZONA  AZ            4      86      61 US PR… \"MADDO… AMERIC… FALSE  \n19  1976 ARIZONA  AZ            4      86      61 US PR…  <NA>   <NA>    TRUE   \n20  1976 ARKANSAS AR            5      71      42 US PR… \"CARTE… DEMOCR… FALSE  \n# … with 7 more variables: candidatevotes <dbl>, totalvotes <dbl>,\n#   version <dbl>, notes <lgl>, party_simplified <chr>,\n#   party_simplified2 <chr>, party_dem <dbl>, and abbreviated variable names\n#   ¹​state_po, ²​state_fips, ³​state_cen, ⁴​state_ic, ⁵​candidate, ⁶​party_detailed\n\n\nCode\ncolnames(election_full)\n\n\n [1] \"year\"              \"state\"             \"state_po\"         \n [4] \"state_fips\"        \"state_cen\"         \"state_ic\"         \n [7] \"office\"            \"candidate\"         \"party_detailed\"   \n[10] \"writein\"           \"candidatevotes\"    \"totalvotes\"       \n[13] \"version\"           \"notes\"             \"party_simplified\" \n[16] \"party_simplified2\" \"party_dem\"        \n\n\nCode\nsummary(election_full)\n\n\n      year         state             state_po           state_fips   \n Min.   :1976   Length:4287        Length:4287        Min.   : 1.00  \n 1st Qu.:1988   Class :character   Class :character   1st Qu.:16.00  \n Median :2000   Mode  :character   Mode  :character   Median :28.00  \n Mean   :1999                                         Mean   :28.62  \n 3rd Qu.:2012                                         3rd Qu.:41.00  \n Max.   :2020                                         Max.   :56.00  \n   state_cen        state_ic        office           candidate        \n Min.   :11.00   Min.   : 1.00   Length:4287        Length:4287       \n 1st Qu.:33.00   1st Qu.:22.00   Class :character   Class :character  \n Median :53.00   Median :42.00   Mode  :character   Mode  :character  \n Mean   :53.67   Mean   :39.75                                        \n 3rd Qu.:81.00   3rd Qu.:61.00                                        \n Max.   :95.00   Max.   :82.00                                        \n party_detailed      writein        candidatevotes       totalvotes      \n Length:4287        Mode :logical   Min.   :       0   Min.   :  123574  \n Class :character   FALSE:3807      1st Qu.:    1177   1st Qu.:  652274  \n Mode  :character   TRUE :477       Median :    7499   Median : 1569180  \n                    NA's :3         Mean   :  311908   Mean   : 2366924  \n                                    3rd Qu.:  199242   3rd Qu.: 3033118  \n                                    Max.   :11110250   Max.   :17500881  \n    version          notes         party_simplified   party_simplified2 \n Min.   :20210113   Mode:logical   Length:4287        Length:4287       \n 1st Qu.:20210113   NA's:4287      Class :character   Class :character  \n Median :20210113                  Mode  :character   Mode  :character  \n Mean   :20210113                                                       \n 3rd Qu.:20210113                                                       \n Max.   :20210113                                                       \n   party_dem     \n Min.   :0.0000  \n 1st Qu.:0.0000  \n Median :0.0000  \n Mean   :0.1428  \n 3rd Qu.:0.0000  \n Max.   :1.0000  \n\n\nThis dataframe contains state-level election results for all 50 states and the District of Columbia for the six Presidential elections from 1976 to 2020. (I am currently not sure that I will use that entire date range, particularly because it does not exactly coincide with the turnout data available, but for now I am including the full data set.) Included in the dataframe are candidate vote totals and party affiliations, which I have used to add an extra column, party_dem, which is a dummy variable recording whether or not a given candidate is a Democrat. The data already come in tidy, which is a nice touch; a “case” or row is a given candidate’s performance in a given state’s Presidential election in a given year."
  },
  {
    "objectID": "posts/nboonstra_final_603_proposal.html#turnout-data-1980-2014",
    "href": "posts/nboonstra_final_603_proposal.html#turnout-data-1980-2014",
    "title": "Voter Turnout and Partisan Bias in U.S. Presidential Elections",
    "section": "Turnout data, 1980-2014",
    "text": "Turnout data, 1980-2014\nObtained from the US Elections Project on 10/11/2022.\n\n\nCode\nturnout <- read_excel(\"./_data/1980-2014 November General Election.xlsx\",\n                      skip=2,\n                      col_types=c(\n                        \"numeric\",\"skip\",\"skip\",\"text\",\n                        \"numeric\",\"numeric\",\"numeric\",\n                        \"numeric\",\"numeric\",\"numeric\",\"numeric\",\n                        \"numeric\",\"numeric\",\"numeric\",\"numeric\",\"numeric\",\"numeric\"\n                      ),\n                      col_names=c(\n                        \"year\",\"state\",\n                        \"totballots_vep_rate\",\"highestoff_vep_rate\",\"highestoff_vap_rate\",\n                        \"totalballots_count\",\"highestoff_count\",\"vep_count\",\"vap_count\",\n                        \"noncitizen_percent\",\"prison_count\",\"probation_count\",\n                        \"parole_count\",\"totineligible_count\",\"overseas_count\"\n                      ))\n\nhead(turnout,n=20)\n\n\n# A tibble: 20 × 15\n    year state   totba…¹ highe…² highe…³ total…⁴ highe…⁵ vep_c…⁶ vap_c…⁷ nonci…⁸\n   <dbl> <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1  2014 United…   0.367   0.36    0.332  8.33e7  8.17e7  2.27e8  2.46e8   0.084\n 2  2014 Alabama   0.332   0.329   0.315  1.19e6  1.18e6  3.59e6  3.75e6   0.025\n 3  2014 Alaska    0.548   0.542   0.51   2.85e5  2.82e5  5.21e5  5.53e5   0.039\n 4  2014 Arizona   0.341   0.334   0.295  1.54e6  1.51e6  4.51e6  5.11e6   0.101\n 5  2014 Arkans…   0.403   0.401   0.375  8.53e5  8.49e5  2.12e6  2.26e6   0.04 \n 6  2014 Califo…   0.307   0.299   0.247  7.51e6  7.32e6  2.44e7  2.96e7   0.168\n 7  2014 Colora…   0.547   0.537   0.494  2.08e6  2.04e6  3.80e6  4.13e6   0.072\n 8  2014 Connec…   0.425   0.423   0.385  1.10e6  1.09e6  2.58e6  2.83e6   0.082\n 9  2014 Delawa…   0.349   0.343   0.318  2.38e5  2.34e5  6.82e5  7.35e5   0.051\n10  2014 Distri…   0.357   0.353   0.32   1.77e5  1.75e5  4.96e5  5.47e5   0.094\n11  2014 Florida   0.433   0.428   0.376  6.03e6  5.95e6  1.39e7  1.58e7   0.106\n12  2014 Georgia   0.386   0.382   0.338  2.60e6  2.57e6  6.73e6  7.60e6   0.071\n13  2014 Hawaii    0.365   0.362   0.329  3.70e5  3.66e5  1.01e6  1.11e6   0.086\n14  2014 Idaho     0.398   0.393   0.365  4.45e5  4.40e5  1.12e6  1.21e6   0.046\n15  2014 Illino…   0.408   0.402   0.366  3.68e6  3.63e6  9.03e6  9.92e6   0.085\n16  2014 Indiana   0.287   0.278   0.267  1.39e6  1.34e6  4.83e6  5.03e6   0.035\n17  2014 Iowa      0.503   0.498   0.473  1.14e6  1.13e6  2.27e6  2.39e6   0.036\n18  2014 Kansas    0.433   0.425   0.398  8.87e5  8.70e5  2.05e6  2.18e6   0.052\n19  2014 Kentuc…   0.449   0.442   0.422  1.46e6  1.44e6  3.25e6  3.41e6   0.027\n20  2014 Louisi…   0.449   0.439   0.415  1.50e6  1.47e6  3.35e6  3.55e6   0.03 \n# … with 5 more variables: prison_count <dbl>, probation_count <dbl>,\n#   parole_count <dbl>, totineligible_count <dbl>, overseas_count <dbl>, and\n#   abbreviated variable names ¹​totballots_vep_rate, ²​highestoff_vep_rate,\n#   ³​highestoff_vap_rate, ⁴​totalballots_count, ⁵​highestoff_count, ⁶​vep_count,\n#   ⁷​vap_count, ⁸​noncitizen_percent\n\n\nCode\ncolnames(turnout)\n\n\n [1] \"year\"                \"state\"               \"totballots_vep_rate\"\n [4] \"highestoff_vep_rate\" \"highestoff_vap_rate\" \"totalballots_count\" \n [7] \"highestoff_count\"    \"vep_count\"           \"vap_count\"          \n[10] \"noncitizen_percent\"  \"prison_count\"        \"probation_count\"    \n[13] \"parole_count\"        \"totineligible_count\" \"overseas_count\"     \n\n\nCode\nsummary(turnout)\n\n\n      year         state           totballots_vep_rate highestoff_vep_rate\n Min.   :1980   Length:936         Min.   :0.0000      Min.   :0.2020     \n 1st Qu.:1988   Class :character   1st Qu.:0.4310      1st Qu.:0.4140     \n Median :1997   Mode  :character   Median :0.5200      Median :0.5010     \n Mean   :1997                      Mean   :0.5125      Mean   :0.4993     \n 3rd Qu.:2006                      3rd Qu.:0.6040      3rd Qu.:0.5840     \n Max.   :2014                      Max.   :0.7880      Max.   :0.7840     \n                                   NA's   :215         NA's   :1          \n highestoff_vap_rate totalballots_count  highestoff_count   \n Min.   :0.1990      Min.   :   122356   Min.   :   117623  \n 1st Qu.:0.3895      1st Qu.:   422851   1st Qu.:   488820  \n Median :0.4770      Median :  1170867   Median :  1236230  \n Mean   :0.4733      Mean   :  3074280   Mean   :  3509231  \n 3rd Qu.:0.5560      3rd Qu.:  2395791   3rd Qu.:  2336586  \n Max.   :0.7390      Max.   :132609063   Max.   :131304731  \n NA's   :1           NA's   :223         NA's   :1          \n   vep_count           vap_count         noncitizen_percent  prison_count    \n Min.   :   270122   Min.   :   277261   Min.   :0.00400    Min.   :      0  \n 1st Qu.:   999644   1st Qu.:  1044366   1st Qu.:0.01500    1st Qu.:   3464  \n Median :  2662524   Median :  2778086   Median :0.03100    Median :  10018  \n Mean   :  7277622   Mean   :  7840064   Mean   :0.04344    Mean   :  39257  \n 3rd Qu.:  4569632   3rd Qu.:  4898253   3rd Qu.:0.06600    3rd Qu.:  24819  \n Max.   :227157964   Max.   :245712915   Max.   :0.18900    Max.   :1605448  \n                                                                             \n probation_count    parole_count    totineligible_count overseas_count   \n Min.   :      0   Min.   :     0   Min.   :      0     Min.   :   6916  \n 1st Qu.:      0   1st Qu.:     0   1st Qu.:   6210     1st Qu.:  43108  \n Median :   7982   Median :  1870   Median :  21329     Median :  89605  \n Mean   :  67542   Mean   : 16227   Mean   :  90039     Mean   : 920963  \n 3rd Qu.:  38902   3rd Qu.:  6592   3rd Qu.:  52525     3rd Qu.:1803021  \n Max.   :2451708   Max.   :637410   Max.   :3363118     Max.   :5345814  \n                                                        NA's   :867      \n\n\nAdditional turnout data are available from the USEP by election from 2000-2020, albeit in their own individual spreadsheets; I may end up merging the 2016 and 2020 spreadsheets into this 1980-2014 set. It is important to note that this dataset includes observations for both Presidential and midterm election years, while I only intend to analyze Presidential elections.\nThis dataset makes distinctions between turnout based on voting-age population (VAP) and voting-eligible population (VEP). The literature generally agrees that VEP is the most reliable and consistent measure. However, given that one of the main differences between the two is the barrier of felony disenfranchisement, a barrier that is often inequitably distributed by race, I may end up using VAP turnout in my analysis; I have not yet decided as of the time of this submission."
  },
  {
    "objectID": "posts/nboonstra_final_603_proposal.html#voter-id-data-2000-2020",
    "href": "posts/nboonstra_final_603_proposal.html#voter-id-data-2000-2020",
    "title": "Voter Turnout and Partisan Bias in U.S. Presidential Elections",
    "section": "Voter ID data, 2000-2020",
    "text": "Voter ID data, 2000-2020\nObtained from the National Conference of State Legislatures, who kindly provided via email a spreadsheet version of the data on this webpage on 10/11/2022.\n\n\nCode\nvoter_id <- read_excel(\"./_data/voter_id_chronology.xlsx\",\n                      skip = 2,\n                      col_types = c(\"text\",\"skip\",\"text\",\"skip\",\"text\",\"skip\",\n                                    \"text\",\"skip\",\"text\",\"skip\",\"text\",\"skip\",\n                                    \"text\",\"skip\",\"skip\"))\n\nvoter_id <- voter_id %>% \n  pivot_longer(cols=c(2:7),\n               names_to=\"year\",\n               values_to=\"id_text\") %>% \n  mutate(id_req = case_when(\n    grepl(\"no id\", id_text, ignore.case = TRUE) ~ 0,\n    TRUE ~ 1\n  )) %>% \n  mutate(id_strict = case_when(\n    grepl(\"Strict\", id_text) ~ 1,\n    TRUE ~ 0\n  )) %>% \n  mutate(id_photo = case_when(\n    grepl(\" photo\", id_text, ignore.case = TRUE) ~ 1,\n    TRUE ~ 0\n  ))\n\nhead(voter_id,n=20)\n\n\n# A tibble: 20 × 6\n   State    year  id_text                 id_req id_strict id_photo\n   <chr>    <chr> <chr>                    <dbl>     <dbl>    <dbl>\n 1 Alabama  2000  No ID required at polls      0         0        0\n 2 Alabama  2004  Non-strict, non-photo        1         0        0\n 3 Alabama  2008  Non-strict, non-photo        1         0        0\n 4 Alabama  2012  Non-strict, non-photo        1         0        0\n 5 Alabama  2016  Non-strict, photo            1         0        1\n 6 Alabama  2020  Non-strict, photo            1         0        1\n 7 Alaska   2000  Non-strict, non-photo        1         0        0\n 8 Alaska   2004  Non-strict, non-photo        1         0        0\n 9 Alaska   2008  Non-strict, non-photo        1         0        0\n10 Alaska   2012  Non-strict, non-photo        1         0        0\n11 Alaska   2016  Non-strict, non-photo        1         0        0\n12 Alaska   2020  Non-strict, non-photo        1         0        0\n13 Arizona  2000  No ID required at polls      0         0        0\n14 Arizona  2004  No ID required at polls      0         0        0\n15 Arizona  2008  Strict non-photo             1         1        0\n16 Arizona  2012  Strict non-photo             1         1        0\n17 Arizona  2016  Strict non-photo             1         1        0\n18 Arizona  2020  Strict non-photo             1         1        0\n19 Arkansas 2000  Non-strict, non-photo        1         0        0\n20 Arkansas 2004  Non-strict, non-photo        1         0        0\n\n\nCode\ncolnames(voter_id)\n\n\n[1] \"State\"     \"year\"      \"id_text\"   \"id_req\"    \"id_strict\" \"id_photo\" \n\n\nCode\nsummary(voter_id)\n\n\n    State               year             id_text              id_req      \n Length:306         Length:306         Length:306         Min.   :0.0000  \n Class :character   Class :character   Class :character   1st Qu.:0.0000  \n Mode  :character   Mode  :character   Mode  :character   Median :1.0000  \n                                                          Mean   :0.5033  \n                                                          3rd Qu.:1.0000  \n                                                          Max.   :1.0000  \n   id_strict          id_photo     \n Min.   :0.00000   Min.   :0.0000  \n 1st Qu.:0.00000   1st Qu.:0.0000  \n Median :0.00000   Median :0.0000  \n Mean   :0.09804   Mean   :0.1928  \n 3rd Qu.:0.00000   3rd Qu.:0.0000  \n Max.   :1.00000   Max.   :1.0000  \n\n\nGiven that barriers to voting factor into the argument behind my research, I wanted to include data on voter ID laws in my analysis, as a controlling (or other type of) variable. The data here track voter ID laws across all 50 U.S. states and the District of Columbia from 2000 to 2020.\nThese data are surprisingly well balanced when it comes to the occurrence of voter ID laws; 50.33 percent of elections were held under voter-ID laws of some sort. Cases are also specified by whether or not a voter ID law was strict (i.e. required the voter to cast a provisional ballot and verify their identity after Election Day), and whether or not the state required a photo on the identification. Strict voter ID laws are the most rare, occurring in only 9.8 percent of elections in the data set; photo requirements are slightly more common, occurring in 19.28 percent of elections."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html",
    "href": "posts/HW1_ToryBartelloni.html",
    "title": "DACSS 603: Homework 1",
    "section": "",
    "text": "First, let’s load our packages and read in the data.\n\n\nCode\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(readxl)\n\nlcdata <- read_xls(\"_data/LungCapData.xls\")"
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q1a",
    "href": "posts/HW1_ToryBartelloni.html#q1a",
    "title": "DACSS 603: Homework 1",
    "section": "Q1a",
    "text": "Q1a\nWhat does the distribution of LungCap look like?\n\n\nCode\nlcdata %>% \n  ggplot(aes(x=LungCap)) +\n  geom_histogram(bins=45) +\n  theme_bw() +\n  labs(x=\"Lung Capacity\", y=\"Frequency\", \n       title = \"Lung Capacity Distribution\")\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15)."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q1b",
    "href": "posts/HW1_ToryBartelloni.html#q1b",
    "title": "DACSS 603: Homework 1",
    "section": "Q1b",
    "text": "Q1b\nCompare the probability density of the LungCap with respect to Males and Females.\n\n\nCode\nlcdata %>%\n  ggplot(aes(x=LungCap)) +\n  geom_boxplot(aes(group=Gender, fill=Gender)) +\n  theme_bw() +\n  theme (axis.text.y = element_blank ()) +\n  labs(x=\"Lung Capacity\", title = \"Lung Capacity Distribution\",\n       subtitle = \"Comparing lung capacity between genders\")\n\n\n\n\n\nThe boxplot comparison indicates that on average males have larger lung capacity, but it also shows that the range and IQR for each gender are similar and have a significant amount of overlap."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q1c",
    "href": "posts/HW1_ToryBartelloni.html#q1c",
    "title": "DACSS 603: Homework 1",
    "section": "Q1c",
    "text": "Q1c\nCompare the mean lung capacities for smokers and non-smokers. Does it make sense?\n\n\nCode\nlcdata %>% \n  ggplot(aes(x=LungCap)) +\n  geom_boxplot(aes(fill=Smoke)) +\n  scale_fill_discrete(labels=c(\"Non-Smoker\", \"Smoker\")) +\n  theme_bw() +\n  theme (axis.text.y = element_blank ()) +\n  labs(title=\"Lung Capacity Distribution\", \n       subtitle = \"Comparing smokers and non-smokers\")\n\n\n\n\n\nComparing the distributions shows that Smokers have a higher mean lung capacity and a significantly smaller range and IQR. This does not make sense intuitively so I would want to investigate the data a bit more to understand the possible reasons."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q1d",
    "href": "posts/HW1_ToryBartelloni.html#q1d",
    "title": "DACSS 603: Homework 1",
    "section": "Q1d",
    "text": "Q1d\nExamine the relationship between Smoking and Lung Capacity within age groups: “less than or equal to 13”, “14 to 15”, “16 to 17”, and “greater than or equal to 18”.\n\n\nCode\nlc_with_age_groups <- lcdata %>%\n  mutate(Age_Group = factor(case_when(\n    Age <= 13 ~ \"<=13\",\n    Age %in% c(14,15) ~ \"14-15\",\n    Age %in% c(16,17) ~ \"16-17\",\n    Age >= 18 ~ \">=18\"\n      ),\n    levels = c(\"<=13\",\"14-15\",\"16-17\",\">=18\")\n    )\n  )\n\nlc_with_age_groups %>% \n  ggplot(aes(x=Age_Group,y=LungCap)) +\n  geom_boxplot() +\n  theme_bw() +\n  labs(title=\"Lung Capacity Distribution\", \n       subtitle = \"Comparing age groups\",\n       x=\"Age Group\",\n       y=\"Lung Capacity\")\n\n\n\n\n\nComparing age groups shows a consistent and clear increase in lung capacity as ages increase up to and over 18 years old."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q1e",
    "href": "posts/HW1_ToryBartelloni.html#q1e",
    "title": "DACSS 603: Homework 1",
    "section": "Q1e",
    "text": "Q1e\nCompare the lung capacities for smokers and non-smokers within each age group. Is your answer different from the one in part c? What could possibly be going on here?\n\n\nCode\nlc_with_age_groups %>%\n  ggplot(aes(x=Smoke, y=LungCap)) +\n  geom_boxplot(aes(fill=Smoke)) +\n  scale_fill_discrete(labels=c(\"Non-Smoker\", \"Smoker\")) +\n  facet_wrap(~Age_Group) +\n  theme_bw() +\n  labs(title=\"Lung Capacity Distribution\", \n       subtitle = \"Comparing smokers and non-smokers within age groups\",\n       x=\"Age Group\",\n       y=\"Lung Capacity\")\n\n\n\n\n\nOutside of ages 13 and under all ages groups show higher average, range, and IRQ for non-smokers. It seems likely that the youngest age group, 13 and under, has the largest number of observations of non-smokers which is bringing down the overall average and lower end of the range. This effect is what is causing us to see the higher lung capacity in smokers overall, but we can infer that the causal factor is more likely age than smoking."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q1f",
    "href": "posts/HW1_ToryBartelloni.html#q1f",
    "title": "DACSS 603: Homework 1",
    "section": "Q1f",
    "text": "Q1f\nCalculate the correlation and covariance between Lung Capacity and Age (use the cov() and cor() functions in R). Interpret your results.\n\n\nCode\nknitr::kable(\n  lcdata %>% summarise(Covariance = cov(LungCap, Age),\n                     Correlation = cor(LungCap, Age)),\n  caption = \"Relationship between lung capacity and age.\"\n)\n\n\n\nRelationship between lung capacity and age.\n\n\nCovariance\nCorrelation\n\n\n\n\n8.738289\n0.8196749\n\n\n\n\n\nThe covariance shows us that the relationship is positive and the correlation coefficient shows us that the relationship is a strong, positive relationship. So the older the people in the data the larger the lung capacity was observed, on average."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q2a",
    "href": "posts/HW1_ToryBartelloni.html#q2a",
    "title": "DACSS 603: Homework 1",
    "section": "Q2a",
    "text": "Q2a\nWhat is the probability that a randomly selected inmate has exactly 2 prior convictions?\n\n\nCode\nprison_props <-  prison_data %>% group_by(X) %>%\n    summarise(Frequency = Frequency,\n      Proportion = Frequency / sum(prison_data$Frequency))\nknitr::kable(prison_props,\n  caption=\"Proportion of Inmates\"\n\n)\n\n\n\nProportion of Inmates\n\n\nX\nFrequency\nProportion\n\n\n\n\n0\n128\n0.1580247\n\n\n1\n434\n0.5358025\n\n\n2\n160\n0.1975309\n\n\n3\n64\n0.0790123\n\n\n4\n24\n0.0296296\n\n\n\n\n\nBy calculating the proportion of inmates with each number of prior convictions we can see that the probability of randomly selecting an inmate with 2 prior convictions is 0.1975 or about 19.8%."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q2b",
    "href": "posts/HW1_ToryBartelloni.html#q2b",
    "title": "DACSS 603: Homework 1",
    "section": "Q2b",
    "text": "Q2b\nWhat is the probability that a randomly selected inmate has fewer than 2 prior convictions?\n\n\nCode\nprint(paste(\"Probability of fewer than 2 prior convictions:\",\nsum(filter(prison_props, X < 2)$Proportion)))\n\n\n[1] \"Probability of fewer than 2 prior convictions: 0.693827160493827\"\n\n\nSumming prisoners with zero and one prior conviction provides us a probability that 0.6938 or about 69.4% chance that a randomly selected inmate would have less than 2 prior convictions."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q2c",
    "href": "posts/HW1_ToryBartelloni.html#q2c",
    "title": "DACSS 603: Homework 1",
    "section": "Q2c",
    "text": "Q2c\nWhat is the probability that a randomly selected inmate has 2 or fewer prior convictions?\n\n\nCode\nprint(paste(\"Probability of 2 or fewer prior convictions:\",\n            sum(filter(prison_props, X <=2)$Proportion)))\n\n\n[1] \"Probability of 2 or fewer prior convictions: 0.891358024691358\"\n\n\nSumming the prisoners with two or fewer prior convictions gives us the probability that 0.89 or about 89% probability that a randomly selected inmate would have two prior convictions or fewer."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q2d",
    "href": "posts/HW1_ToryBartelloni.html#q2d",
    "title": "DACSS 603: Homework 1",
    "section": "Q2d",
    "text": "Q2d\nWhat is the probability that a randomly selected inmate has more than two prior convictions?\n\n\nCode\nprint(paste(\"Probability of more than 2 prior convictions:\",\nsum(filter(prison_props, X > 2)$Proportion)))\n\n\n[1] \"Probability of more than 2 prior convictions: 0.108641975308642\"\n\n\nThe probability found for either 3 or 4 prior convictions (there is no inmate with more than 4 prior convictions) is 0.1084 or about 10.8% probability."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q2e",
    "href": "posts/HW1_ToryBartelloni.html#q2e",
    "title": "DACSS 603: Homework 1",
    "section": "Q2e",
    "text": "Q2e\nWhat is the expected value for the number of prior convictions?\n\n\nCode\nprint(paste(\"The expected value for prior convictions:\", mean(prison_indi_data$X)))\n\n\n[1] \"The expected value for prior convictions: 1.28641975308642\"\n\n\nBy taking a weighted average or an average of all possible observations to select from the expected value is 1.28642 or about 1.3 prior convictions."
  },
  {
    "objectID": "posts/HW1_ToryBartelloni.html#q2f",
    "href": "posts/HW1_ToryBartelloni.html#q2f",
    "title": "DACSS 603: Homework 1",
    "section": "Q2f",
    "text": "Q2f\nCalculate the variance and standard deviation for Prior Convictions.\n\n\nCode\nknitr::kable(\n  prison_indi_data %>% summarise(Variance = var(X),\n                     \"Standard Deviation\" = sd(X)),\n  caption = \"Spread of Inmate Prior Convictions\"\n)\n\n\n\nSpread of Inmate Prior Convictions\n\n\nVariance\nStandard Deviation\n\n\n\n\n0.8572937\n0.9259016"
  },
  {
    "objectID": "posts/Final pt 1.html",
    "href": "posts/Final pt 1.html",
    "title": "Final Project Proposal",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(dplyr)"
  },
  {
    "objectID": "posts/Final pt 1.html#research-question",
    "href": "posts/Final pt 1.html#research-question",
    "title": "Final Project Proposal",
    "section": "Research Question",
    "text": "Research Question\nIn the United States, wage stagnation has become a hot-button issue for many people in various fields of employment. Graduate students have been at the center of this issue in recent years- strikes for wage increases and cost-of-living adjustments have taken place at multiple universities throughout the country. Because PhD students often do not have the time to earn extra income (and their contracts often prohibit them from pursuing work elsewhere), how much they will earn from their stipend is a huge factor in considering where to pursue their research (Powell, 2004; Soar et al., 2022). Knowing how much My research question is: What is the strongest predictor of the value of a PhD stipend?"
  },
  {
    "objectID": "posts/Final pt 1.html#hypothesis",
    "href": "posts/Final pt 1.html#hypothesis",
    "title": "Final Project Proposal",
    "section": "Hypothesis",
    "text": "Hypothesis\nH₀: Cost of living is not the strongest predictor of the value of a PhD stipend.\nH₁: Cost of living is the strongest predictor of the value of a PhD stipend."
  },
  {
    "objectID": "posts/Final pt 1.html#dataset",
    "href": "posts/Final pt 1.html#dataset",
    "title": "Final Project Proposal",
    "section": "Dataset",
    "text": "Dataset\nThis dataset is comprised of self-reported survey data collected by PhDStipends.com. Respondents are asked their university, department, academic year, and year in the program. They are also asked whether they receive a 12-month or 9-month salary, gross pay, and required fees. PhDStipends automatically calculators the LW Ratio (living wage ratio), which is the stipend divided by the living wage of the country the university is located in. I will likely need to add additional information for my own analysis.\nThe variables of interest for me are the university, department, and program year.\n\n\nCode\nlibrary(readr)\ncsv <- read_csv(\"~/School/UMASS/DACSS 603/Final Project/csv.csv\")\n\n\nError: '~/School/UMASS/DACSS 603/Final Project/csv.csv' does not exist.\n\n\nCode\nsummary(csv)\n\n\nError in summary(csv): object 'csv' not found\n\n\n\n\nCode\nprint(summarytools::dfSummary(csv,\n                              varnumbers = FALSE,\n                              plain.ascii  = FALSE,\n                              style        = \"grid\",\n                              graph.magnif = 0.70,\n                              valid.col    = FALSE),\n      method = 'render',\n      table.classes = 'table-condensed')\n\n\nWarning: no DISPLAY variable so Tk is not available\n\n\nError in summarytools::dfSummary(csv, varnumbers = FALSE, plain.ascii = FALSE, : object 'csv' not found\n\n\nBased on this summary, there are some extreme outliers in need of removal, particularly in the Overall Pay column. Interesting, the mean Overall Pay of $27549.4 does not seem unreasonable,."
  },
  {
    "objectID": "posts/Final pt 1.html#references",
    "href": "posts/Final pt 1.html#references",
    "title": "Final Project Proposal",
    "section": "References",
    "text": "References\nLiving Wage Calculator. (n.d.). Retrieved October 10, 2022, from https://livingwage.mit.edu/\nPowell, K. Stipend survival. Nature 428, 102–103 (2004). https://doi.org/10.1038/nj6978-102a\nEmily Roberts & Kyle Roberts. (2022, October 10). PhD stipends Dataset. http://www.phdstipends.com/csv\nSoar, M., Stewart, L., Nissen, S. et al. Sweat Equity: Student Scholarships in Aotearoa New Zealand’s Universities. NZ J Educ Stud (2022). https://doi.org/10.1007/s40841-022-00244-5"
  },
  {
    "objectID": "posts/hw1_boonstra.html",
    "href": "posts/hw1_boonstra.html",
    "title": "Homework 1",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(readxl)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)"
  },
  {
    "objectID": "posts/hw1_boonstra.html#a",
    "href": "posts/hw1_boonstra.html#a",
    "title": "Homework 1",
    "section": "a",
    "text": "a\nFirst, let’s read in the data from the Excel file:\n\n\nCode\nlibrary(readxl)\nlungcap <- read_excel(\"_data/LungCapData.xls\")\n\n\nThe distribution of LungCap looks as follows:\n\n\nCode\nhist(lungcap$LungCap)\n\n\n\n\n\nThe histogram suggests that the distribution is close to a normal distribution. Most of the observations are close to the mean. Very few observations are close to the margins (0 and 15)."
  },
  {
    "objectID": "posts/hw1_boonstra.html#b",
    "href": "posts/hw1_boonstra.html#b",
    "title": "Homework 1",
    "section": "b",
    "text": "b\nThese are the boxplots of the distributions for the lung capacity of males and females in the sample:\n\n\nCode\nlungcap %>% \n  ggplot(aes(x=Gender,y=LungCap)) +\n  geom_boxplot()\n\n\n\n\n\nAccording to these boxplots, it appears that males and females have similar median lung capacities, but that males may be more likely to have a higher lung capacity than females."
  },
  {
    "objectID": "posts/hw1_boonstra.html#c",
    "href": "posts/hw1_boonstra.html#c",
    "title": "Homework 1",
    "section": "c",
    "text": "c\n\n\nCode\nlungcap %>% \n  group_by(Smoke) %>% \n  summarise(mean_lungcap=mean(LungCap))\n\n\n# A tibble: 2 × 2\n  Smoke mean_lungcap\n  <chr>        <dbl>\n1 no            7.77\n2 yes           8.65\n\n\nAccording to this sample, it would appear that smokers have a higher lung capacity than non-smokers. This would appear to be counter-intuitive, as one would likely expect smoking to reduce lung functionality and, by extension, capacity."
  },
  {
    "objectID": "posts/hw1_boonstra.html#d",
    "href": "posts/hw1_boonstra.html#d",
    "title": "Homework 1",
    "section": "d",
    "text": "d\nIn order to complete this examination by group, we must create a new nominal variable that groups observations by age; this can be accomplished fairly simply using the mutate() and case_when() functions:\n\n\nCode\nlungcap_age <- lungcap %>% \n  mutate(age_group = case_when(\n    Age <= 13 ~ \"13 and under\",\n    Age == 14 | Age == 15 ~ \"14 to 15\",\n    Age == 16 | Age == 17 ~ \"16 to 17\",\n    Age >= 18 ~ \"18 and older\"\n  ))\n\n\nWith this new dataframe, we can use the group_by() function to calculate mean lung capacity by age group and smoker status:\n\n\nCode\nlungcap_age %>% \n  group_by(age_group,Smoke) %>% \n  summarise(mean(LungCap))\n\n\n# A tibble: 8 × 3\n# Groups:   age_group [4]\n  age_group    Smoke `mean(LungCap)`\n  <chr>        <chr>           <dbl>\n1 13 and under no               6.36\n2 13 and under yes              7.20\n3 14 to 15     no               9.14\n4 14 to 15     yes              8.39\n5 16 to 17     no              10.5 \n6 16 to 17     yes              9.38\n7 18 and older no              11.1 \n8 18 and older yes             10.5 \n\n\nAccording to these data, it appears that lung capacity generally increases with age. Interestingly, lung capacity is worse for smokers than it is for non-smokers in every age group except for “13 and under”. This is surprising on the surface, given that, when the data are ungrouped, smokers have a higher lung capacity than non-smokers (see part c). However, this begins to make more sense when we see how much better the “13 and under” group is represented compared to the others in this dataset:\n\n\nCode\nlungcap_age %>% \n  group_by(age_group) %>% \n  count()\n\n\n# A tibble: 4 × 2\n# Groups:   age_group [4]\n  age_group        n\n  <chr>        <int>\n1 13 and under   428\n2 14 to 15       120\n3 16 to 17        97\n4 18 and older    80\n\n\nThis high number of observations compared to other age groups likely plays a significant role in skewing the mean of the entire dataset."
  },
  {
    "objectID": "posts/hw1_boonstra.html#e",
    "href": "posts/hw1_boonstra.html#e",
    "title": "Homework 1",
    "section": "e",
    "text": "e\nIt is not clear to me how this part is different from part d; from what I do understand, I believe the question being asked here is addressed in that part."
  },
  {
    "objectID": "posts/hw1_boonstra.html#f",
    "href": "posts/hw1_boonstra.html#f",
    "title": "Homework 1",
    "section": "f",
    "text": "f\n\n\nCode\ncov(lungcap$LungCap, lungcap$Age)\n\n\n[1] 8.738289\n\n\nCode\ncor(lungcap$LungCap, lungcap$Age)\n\n\n[1] 0.8196749\n\n\nIt would appear that lung capacity and age covary together positively, such that a higher age means a higher lung capacity. We can confirm this with a simple visualization:\n\n\nCode\nlungcap %>% \n  ggplot(aes(x=Age,y=LungCap)) +\n  geom_point() +\n  geom_smooth(method='lm')"
  },
  {
    "objectID": "posts/hw1_boonstra.html#a-1",
    "href": "posts/hw1_boonstra.html#a-1",
    "title": "Homework 1",
    "section": "a",
    "text": "a\nThe probability that a randomly selected inmate has exactly 2 prior convictions is 160 / 810 = 0.1975309."
  },
  {
    "objectID": "posts/hw1_boonstra.html#b-1",
    "href": "posts/hw1_boonstra.html#b-1",
    "title": "Homework 1",
    "section": "b",
    "text": "b\nThe probability that a randomly selected inmate has less than 2 prior convictions is (128+434) / 810 = 0.6938272."
  },
  {
    "objectID": "posts/hw1_boonstra.html#c-1",
    "href": "posts/hw1_boonstra.html#c-1",
    "title": "Homework 1",
    "section": "c",
    "text": "c\nThe probability that a randomly selected inmate has 2 or fewer prior convictions is (128+434+160) / 810 = 0.891358."
  },
  {
    "objectID": "posts/hw1_boonstra.html#d-1",
    "href": "posts/hw1_boonstra.html#d-1",
    "title": "Homework 1",
    "section": "d",
    "text": "d\nThe probability that a randomly selected inmate has more than 2 prior convictions is (64+24) / 810 = 0.108642."
  },
  {
    "objectID": "posts/hw1_boonstra.html#e-1",
    "href": "posts/hw1_boonstra.html#e-1",
    "title": "Homework 1",
    "section": "e",
    "text": "e\nBefore calculating expected value, we should put together a probability mass function for the prisoners data.\n\n\nCode\nprisoners <- prisoners %>% \n  mutate(prob=freq/810) %>% \n  mutate(expect=prob*priors)\n\nprisoners %>% \n  summarise(sum(expect))\n\n\n  sum(expect)\n1     1.28642\n\n\nThe expected value for the number of prior convictions is about 1.29 priors.\nEDIT: There is a much simpler way to compute this! Rather than using the dataframe I created, storing values and their frequencies, I can create one vector that stores each value a certain number of times, according to the given frequencies:\n\n\nCode\nprisoners_full <- rep(c(0,1,2,3,4),times=c(128,434,160,64,24))\nprisoners_full\n\n\n  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n [38] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n [75] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[112] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[556] 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[593] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[630] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[667] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n[704] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n[741] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n[778] 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n\n\nBecause each value now appears as frequently as its “probability” of appearing, taking the mean of this vector also provides the correct expected value.\n\n\nCode\nmean(prisoners_full)\n\n\n[1] 1.28642"
  },
  {
    "objectID": "posts/hw1_boonstra.html#f-1",
    "href": "posts/hw1_boonstra.html#f-1",
    "title": "Homework 1",
    "section": "f",
    "text": "f\nCreating this numerical vector also makes the standard deviation calculation extremely simple in R.\n\n\nCode\nsd(prisoners_full)\n\n\n[1] 0.9259016"
  },
  {
    "objectID": "about/AboutTemplate_mani.html",
    "href": "about/AboutTemplate_mani.html",
    "title": "Your Name",
    "section": "",
    "text": "##Instructions"
  },
  {
    "objectID": "about/AboutTemplate_mani.html#educationwork-background",
    "href": "about/AboutTemplate_mani.html#educationwork-background",
    "title": "Your Name",
    "section": "Education/Work Background",
    "text": "Education/Work Background"
  },
  {
    "objectID": "about/AboutTemplate_mani.html#r-experience",
    "href": "about/AboutTemplate_mani.html#r-experience",
    "title": "Your Name",
    "section": "R experience",
    "text": "R experience"
  },
  {
    "objectID": "about/AboutTemplate_mani.html#research-interests",
    "href": "about/AboutTemplate_mani.html#research-interests",
    "title": "Your Name",
    "section": "Research interests",
    "text": "Research interests"
  },
  {
    "objectID": "about/AboutTemplate_mani.html#hometown",
    "href": "about/AboutTemplate_mani.html#hometown",
    "title": "Your Name",
    "section": "Hometown",
    "text": "Hometown"
  },
  {
    "objectID": "about/AboutTemplate_mani.html#hobbies",
    "href": "about/AboutTemplate_mani.html#hobbies",
    "title": "Your Name",
    "section": "Hobbies",
    "text": "Hobbies"
  },
  {
    "objectID": "about/AboutTemplate_mani.html#fun-fact",
    "href": "about/AboutTemplate_mani.html#fun-fact",
    "title": "Your Name",
    "section": "Fun fact",
    "text": "Fun fact"
  }
]